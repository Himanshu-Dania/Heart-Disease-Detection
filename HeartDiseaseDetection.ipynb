{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"UCI_Heart_Disease_Dataset_Combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   40    1              1        140          289          0           0   \n",
       "1   49    0              2        160          180          0           0   \n",
       "2   37    1              1        130          283          0           1   \n",
       "3   48    0              3        138          214          0           0   \n",
       "4   54    1              2        150          195          0           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n",
       "0    172               0      0.0             0  \n",
       "1    156               0      1.0             1  \n",
       "2     98               0      0.0             0  \n",
       "3    108               1      1.5             1  \n",
       "4    122               0      0.0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2943, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2943 entries, 0 to 2942\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             2943 non-null   int64  \n",
      " 1   Sex             2943 non-null   int64  \n",
      " 2   ChestPainType   2943 non-null   int64  \n",
      " 3   RestingBP       2943 non-null   int64  \n",
      " 4   Cholesterol     2943 non-null   int64  \n",
      " 5   FastingBS       2943 non-null   int64  \n",
      " 6   RestingECG      2943 non-null   int64  \n",
      " 7   MaxHR           2943 non-null   int64  \n",
      " 8   ExerciseAngina  2943 non-null   int64  \n",
      " 9   Oldpeak         2943 non-null   float64\n",
      " 10  HeartDisease    2943 non-null   int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 253.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS',\n",
       "       'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'HeartDisease'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows except the first occurrence based on all columns are:\n",
      "      Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "1933   34    0              1        118          210          0           1   \n",
      "1949   50    0              1        120          244          0           1   \n",
      "1961   46    1              0        120          249          0           0   \n",
      "1973   55    1              0        140          217          0           1   \n",
      "1979   66    0              2        146          278          0           0   \n",
      "...   ...  ...            ...        ...          ...        ...         ...   \n",
      "2938   59    1              1        140          221          0           1   \n",
      "2939   60    1              0        125          258          0           0   \n",
      "2940   47    1              0        110          275          0           0   \n",
      "2941   50    0              0        110          254          0           0   \n",
      "2942   54    1              0        120          188          0           1   \n",
      "\n",
      "      MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n",
      "1933    192               0      0.7             1  \n",
      "1949    162               0      1.1             1  \n",
      "1961    144               0      0.8             0  \n",
      "1973    111               1      5.6             0  \n",
      "1979    152               0      0.0             1  \n",
      "...     ...             ...      ...           ...  \n",
      "2938    164               1      0.0             1  \n",
      "2939    141               1      2.8             0  \n",
      "2940    118               1      1.0             0  \n",
      "2941    159               0      0.0             1  \n",
      "2942    113               0      1.4             0  \n",
      "\n",
      "[723 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print(\"\\nDuplicate Rows except the first occurrence based on all columns are:\")\n",
    "print(duplicate_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after removing duplicates:\n",
      "      Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0      40    1              1        140          289          0           0   \n",
      "1      49    0              2        160          180          0           0   \n",
      "2      37    1              1        130          283          0           1   \n",
      "3      48    0              3        138          214          0           0   \n",
      "4      54    1              2        150          195          0           0   \n",
      "...   ...  ...            ...        ...          ...        ...         ...   \n",
      "2641   68    0              2        120          211          0           0   \n",
      "2651   44    0              2        108          141          0           1   \n",
      "2657   52    1              0        128          255          0           1   \n",
      "2761   59    1              3        160          273          0           0   \n",
      "2796   54    1              0        120          188          0           1   \n",
      "\n",
      "      MaxHR  ExerciseAngina  Oldpeak  HeartDisease  \n",
      "0       172               0      0.0             0  \n",
      "1       156               0      1.0             1  \n",
      "2        98               0      0.0             0  \n",
      "3       108               1      1.5             1  \n",
      "4       122               0      0.0             0  \n",
      "...     ...             ...      ...           ...  \n",
      "2641    115               0      1.5             1  \n",
      "2651    175               0      0.6             1  \n",
      "2657    161               1      0.0             0  \n",
      "2761    125               0      0.0             0  \n",
      "2796    113               0      1.4             0  \n",
      "\n",
      "[2220 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 968.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        1252.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.hist(df[\"HeartDisease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_0</th>\n",
       "      <th>ChestPainType_1</th>\n",
       "      <th>ChestPainType_2</th>\n",
       "      <th>ChestPainType_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  RestingBP  Cholesterol  FastingBS  RestingECG  MaxHR  \\\n",
       "0   40    1        140          289          0           0    172   \n",
       "1   49    0        160          180          0           0    156   \n",
       "2   37    1        130          283          0           1     98   \n",
       "3   48    0        138          214          0           0    108   \n",
       "4   54    1        150          195          0           0    122   \n",
       "\n",
       "   ExerciseAngina  Oldpeak  HeartDisease  ChestPainType_0  ChestPainType_1  \\\n",
       "0               0      0.0             0            False             True   \n",
       "1               0      1.0             1            False            False   \n",
       "2               0      0.0             0            False             True   \n",
       "3               1      1.5             1            False            False   \n",
       "4               0      0.0             0            False            False   \n",
       "\n",
       "   ChestPainType_2  ChestPainType_3  \n",
       "0            False            False  \n",
       "1             True            False  \n",
       "2            False            False  \n",
       "3            False             True  \n",
       "4             True            False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['ChestPainType'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression test Accuracy: 0.7432432432432432, Precision: 0.7605633802816901, Recall: 0.8244274809160306, F1 Score: 0.7912087912087912\n",
      "Logistic Regression validation Accuracy: 0.7882882882882883, Precision: 0.8059701492537313, Recall: 0.8372093023255814, F1 Score: 0.8212927756653993\n",
      "Random Forest test Accuracy: 0.8198198198198198, Precision: 0.837037037037037, Recall: 0.8625954198473282, F1 Score: 0.849624060150376\n",
      "Random Forest validation Accuracy: 0.7972972972972973, Precision: 0.8333333333333334, Recall: 0.813953488372093, F1 Score: 0.8235294117647058\n",
      "SVM test Accuracy: 0.6576576576576577, Precision: 0.7894736842105263, Recall: 0.5725190839694656, F1 Score: 0.6637168141592921\n",
      "SVM validation Accuracy: 0.7342342342342343, Precision: 0.8645833333333334, Recall: 0.6434108527131783, F1 Score: 0.7377777777777779\n",
      "XGBoost test Accuracy: 0.8063063063063063, Precision: 0.8333333333333334, Recall: 0.8396946564885496, F1 Score: 0.8365019011406843\n",
      "XGBoost validation Accuracy: 0.7702702702702703, Precision: 0.8095238095238095, Recall: 0.7906976744186046, F1 Score: 0.8\n",
      "[LightGBM] [Info] Number of positive: 992, number of negative: 784\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1776, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558559 -> initscore=0.235314\n",
      "[LightGBM] [Info] Start training from score 0.235314\n",
      "LightGBM test Accuracy: 0.8018018018018018, Precision: 0.8270676691729323, Recall: 0.8396946564885496, F1 Score: 0.8333333333333333\n",
      "LightGBM validation Accuracy: 0.7837837837837838, Precision: 0.824, Recall: 0.7984496124031008, F1 Score: 0.8110236220472441\n",
      "CatBoost test Accuracy: 0.8378378378378378, Precision: 0.8518518518518519, Recall: 0.8778625954198473, F1 Score: 0.8646616541353385\n",
      "CatBoost validation Accuracy: 0.8198198198198198, Precision: 0.856, Recall: 0.8294573643410853, F1 Score: 0.8425196850393701\n",
      "GradientBoost test Accuracy: 0.8153153153153153, Precision: 0.8409090909090909, Recall: 0.8473282442748091, F1 Score: 0.8441064638783269\n",
      "GradientBoost validation Accuracy: 0.8108108108108109, Precision: 0.8536585365853658, Recall: 0.813953488372093, F1 Score: 0.8333333333333333\n",
      "ExtraTrees test Accuracy: 0.8468468468468469, Precision: 0.8489208633093526, Recall: 0.9007633587786259, F1 Score: 0.8740740740740741\n",
      "ExtraTrees validation Accuracy: 0.8108108108108109, Precision: 0.8536585365853658, Recall: 0.813953488372093, F1 Score: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, random_state=42)\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(silent=True),\n",
    "    'GradientBoost':GradientBoostingClassifier(),\n",
    "    'ExtraTrees':ExtraTreesClassifier()\n",
    "}\n",
    "\n",
    "# Train and test each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    test_precision = precision_score(y_test, test_predictions)\n",
    "    test_recall = recall_score(y_test, test_predictions)\n",
    "    test_f1 = f1_score(y_test, test_predictions)\n",
    "    print(f'{name} test Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}')\n",
    "    \n",
    "    val_predictions = clf.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    val_precision = precision_score(y_val, val_predictions)\n",
    "    val_recall = recall_score(y_val, val_predictions)\n",
    "    val_f1 = f1_score(y_val, val_predictions)\n",
    "    print(f'{name} validation Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {val_f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 20:35:30.218760: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 20:35:30.303040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-12 20:35:30.303104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-12 20:35:30.304818: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-12 20:35:30.319448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 20:35:32.131811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-12 20:35:33.857471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:34.089013: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:34.089215: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:34.092053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:34.092127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:34.092144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:37.847513: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:37.848644: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:37.848677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-12 20:35:37.849239: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-12 20:35:37.849595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1577 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 20:40:02.389181: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-12 20:40:03.529546: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3fa8146050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-12 20:40:03.529609: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-01-12 20:40:03.589352: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-12 20:40:04.497449: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705072204.637841  157193 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 268s 15ms/step - loss: 1.0308 - accuracy: 0.5580 - val_loss: 0.6435 - val_accuracy: 0.6171\n",
      "Epoch 2/50\n",
      "18/56 [========>.....................] - ETA: 0s - loss: 0.6758 - accuracy: 0.5851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5850 - val_loss: 0.6304 - val_accuracy: 0.6396\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.6773 - accuracy: 0.5878 - val_loss: 0.6106 - val_accuracy: 0.6486\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6453 - accuracy: 0.5991 - val_loss: 0.8002 - val_accuracy: 0.5045\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.6578 - accuracy: 0.5968 - val_loss: 0.5987 - val_accuracy: 0.6802\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.6374 - val_loss: 0.6255 - val_accuracy: 0.6216\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.6408 - val_loss: 0.5790 - val_accuracy: 0.7027\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.6037 - accuracy: 0.6419 - val_loss: 0.5758 - val_accuracy: 0.7432\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.6802 - val_loss: 0.5971 - val_accuracy: 0.7072\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.6423 - accuracy: 0.6374 - val_loss: 0.5908 - val_accuracy: 0.7387\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5746 - accuracy: 0.6959 - val_loss: 0.5830 - val_accuracy: 0.6351\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5657 - accuracy: 0.7128 - val_loss: 0.5508 - val_accuracy: 0.7568\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.6898 - val_loss: 0.5380 - val_accuracy: 0.7613\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7179 - val_loss: 0.5242 - val_accuracy: 0.7703\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7309 - val_loss: 0.4910 - val_accuracy: 0.7703\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7303 - val_loss: 0.5048 - val_accuracy: 0.7703\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7207 - val_loss: 0.5176 - val_accuracy: 0.7928\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7506 - val_loss: 0.4977 - val_accuracy: 0.7793\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7354 - val_loss: 0.5178 - val_accuracy: 0.7703\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7511 - val_loss: 0.4831 - val_accuracy: 0.7658\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7579 - val_loss: 0.5473 - val_accuracy: 0.7568\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7297 - val_loss: 0.5043 - val_accuracy: 0.7703\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7421 - val_loss: 0.5285 - val_accuracy: 0.7342\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7461 - val_loss: 0.5026 - val_accuracy: 0.7658\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7427 - val_loss: 0.5293 - val_accuracy: 0.7793\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7652 - val_loss: 0.5113 - val_accuracy: 0.7387\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5469 - accuracy: 0.7061 - val_loss: 0.5636 - val_accuracy: 0.7297\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7404 - val_loss: 0.4859 - val_accuracy: 0.7658\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7573 - val_loss: 0.4859 - val_accuracy: 0.7703\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7534 - val_loss: 0.5289 - val_accuracy: 0.7252\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7258 - val_loss: 0.5346 - val_accuracy: 0.7342\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7342 - val_loss: 0.4807 - val_accuracy: 0.7748\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7590 - val_loss: 0.6120 - val_accuracy: 0.6982\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7539 - val_loss: 0.4885 - val_accuracy: 0.7748\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7494 - val_loss: 0.4895 - val_accuracy: 0.7838\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7646 - val_loss: 0.4709 - val_accuracy: 0.7793\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7748 - val_loss: 0.4815 - val_accuracy: 0.7613\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7325 - val_loss: 0.4821 - val_accuracy: 0.7838\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7669 - val_loss: 0.4634 - val_accuracy: 0.7928\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7663 - val_loss: 0.4816 - val_accuracy: 0.7658\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7663 - val_loss: 0.4762 - val_accuracy: 0.7793\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7703 - val_loss: 0.4647 - val_accuracy: 0.7838\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7573 - val_loss: 0.4487 - val_accuracy: 0.7973\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7517 - val_loss: 0.4908 - val_accuracy: 0.7838\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7618 - val_loss: 0.4893 - val_accuracy: 0.7703\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7770 - val_loss: 0.4580 - val_accuracy: 0.7928\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7669 - val_loss: 0.4563 - val_accuracy: 0.7838\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7658 - val_loss: 0.5672 - val_accuracy: 0.7252\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7748 - val_loss: 0.4659 - val_accuracy: 0.7793\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7776 - val_loss: 0.4540 - val_accuracy: 0.7838\n",
      "56/56 - 0s - loss: 0.4386 - accuracy: 0.7804 - 143ms/epoch - 3ms/step\n",
      "\n",
      "Train accuracy: 0.7804054021835327\n",
      "7/7 - 0s - loss: 0.4540 - accuracy: 0.7838 - 36ms/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.7837837934494019\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # adjust this according to your problem\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # adjust this according to your problem\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_model.h5\", save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[checkpoint_cb])\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "print('\\nTrain accuracy:', train_acc)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-01-12 20:40:23,509] A new study created in memory with name: no-name-459f3e6e-ce60-4d6c-a83f-604c738d9c82\n",
      "[I 2024-01-12 20:40:23,750] Trial 0 finished with value: 0.8226718495899223 and parameters: {'iterations': 63, 'depth': 8, 'learning_rate': 0.13657481267651655, 'random_strength': 64, 'bagging_temperature': 0.07631069982880788, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 0 with value: 0.8226718495899223.\n",
      "[I 2024-01-12 20:40:24,320] Trial 1 finished with value: 0.8412404970025789 and parameters: {'iterations': 262, 'depth': 8, 'learning_rate': 0.039096074814094245, 'random_strength': 11, 'bagging_temperature': 0.010254176081197913, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:24,508] Trial 2 finished with value: 0.8057795541931729 and parameters: {'iterations': 155, 'depth': 6, 'learning_rate': 0.03717431760595131, 'random_strength': 58, 'bagging_temperature': 0.2793511317862055, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:24,816] Trial 3 finished with value: 0.7894144144144144 and parameters: {'iterations': 144, 'depth': 9, 'learning_rate': 0.011362314493019571, 'random_strength': 54, 'bagging_temperature': 0.035237713075455104, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:24,954] Trial 4 finished with value: 0.8191500616101444 and parameters: {'iterations': 145, 'depth': 7, 'learning_rate': 0.17936580920890663, 'random_strength': 60, 'bagging_temperature': 0.05893534633644963, 'od_type': 'IncToDec', 'od_wait': 11}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:25,063] Trial 5 finished with value: 0.7930305672241157 and parameters: {'iterations': 77, 'depth': 9, 'learning_rate': 0.012331768018131718, 'random_strength': 100, 'bagging_temperature': 0.6952457997309472, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:25,148] Trial 6 finished with value: 0.7862968443775985 and parameters: {'iterations': 111, 'depth': 6, 'learning_rate': 0.02499965512403855, 'random_strength': 98, 'bagging_temperature': 19.495634874418947, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 1 with value: 0.8412404970025789.\n",
      "[I 2024-01-12 20:40:25,333] Trial 7 finished with value: 0.8415917345645018 and parameters: {'iterations': 166, 'depth': 8, 'learning_rate': 0.13216503670926097, 'random_strength': 33, 'bagging_temperature': 4.081953474670285, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:25,447] Trial 8 finished with value: 0.7877125359785843 and parameters: {'iterations': 172, 'depth': 5, 'learning_rate': 0.1966141576969563, 'random_strength': 69, 'bagging_temperature': 31.922370255838235, 'od_type': 'Iter', 'od_wait': 11}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:25,710] Trial 9 finished with value: 0.8368889581576149 and parameters: {'iterations': 291, 'depth': 6, 'learning_rate': 0.09646934447637834, 'random_strength': 62, 'bagging_temperature': 8.694048208623045, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:26,000] Trial 10 finished with value: 0.8010650677711588 and parameters: {'iterations': 215, 'depth': 4, 'learning_rate': 0.07692631225068151, 'random_strength': 19, 'bagging_temperature': 2.8423461104104795, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:26,772] Trial 11 finished with value: 0.8412404970025789 and parameters: {'iterations': 232, 'depth': 10, 'learning_rate': 0.04522277889617487, 'random_strength': 7, 'bagging_temperature': 0.012985421766977765, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:27,243] Trial 12 finished with value: 0.827429728579154 and parameters: {'iterations': 293, 'depth': 8, 'learning_rate': 0.023303748131039977, 'random_strength': 30, 'bagging_temperature': 2.678455848016428, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 7 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 20:40:27,539] Trial 13 finished with value: 0.8465761215761216 and parameters: {'iterations': 231, 'depth': 8, 'learning_rate': 0.2943455824146425, 'random_strength': 33, 'bagging_temperature': 0.29379600831899405, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:28,088] Trial 14 finished with value: 0.8148130633004671 and parameters: {'iterations': 209, 'depth': 10, 'learning_rate': 0.22509752676383446, 'random_strength': 35, 'bagging_temperature': 0.24532630006096737, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:28,302] Trial 15 finished with value: 0.8097037845172175 and parameters: {'iterations': 196, 'depth': 7, 'learning_rate': 0.2792009222030456, 'random_strength': 34, 'bagging_temperature': 2.161949324496676, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:28,660] Trial 16 finished with value: 0.8187655090640165 and parameters: {'iterations': 263, 'depth': 9, 'learning_rate': 0.09653121211622856, 'random_strength': 43, 'bagging_temperature': 96.33239418081861, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:28,870] Trial 17 finished with value: 0.8415917345645018 and parameters: {'iterations': 121, 'depth': 8, 'learning_rate': 0.29956595399273767, 'random_strength': 78, 'bagging_temperature': 0.5865355030544068, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:29,094] Trial 18 finished with value: 0.8195013195013195 and parameters: {'iterations': 240, 'depth': 7, 'learning_rate': 0.16376037061584503, 'random_strength': 21, 'bagging_temperature': 6.7831441205829455, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:29,412] Trial 19 finished with value: 0.8328800815150558 and parameters: {'iterations': 191, 'depth': 9, 'learning_rate': 0.12421315617399699, 'random_strength': 49, 'bagging_temperature': 0.17257136098795275, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:29,564] Trial 20 finished with value: 0.8285262535262534 and parameters: {'iterations': 100, 'depth': 7, 'learning_rate': 0.07172873949878919, 'random_strength': 2, 'bagging_temperature': 1.1852073152292126, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:29,764] Trial 21 finished with value: 0.8415917345645018 and parameters: {'iterations': 114, 'depth': 8, 'learning_rate': 0.2884841001058981, 'random_strength': 77, 'bagging_temperature': 0.7225662268800792, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:29,955] Trial 22 finished with value: 0.8285262535262534 and parameters: {'iterations': 123, 'depth': 8, 'learning_rate': 0.2884814353819999, 'random_strength': 84, 'bagging_temperature': 0.4007529776872729, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:30,244] Trial 23 finished with value: 0.8191500616101444 and parameters: {'iterations': 172, 'depth': 9, 'learning_rate': 0.2208670085519781, 'random_strength': 43, 'bagging_temperature': 5.672627396761105, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:30,386] Trial 24 finished with value: 0.8097037845172175 and parameters: {'iterations': 89, 'depth': 8, 'learning_rate': 0.1330759059224004, 'random_strength': 24, 'bagging_temperature': 0.1175452787648738, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:30,809] Trial 25 finished with value: 0.8459506827044141 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.1668519984709544, 'random_strength': 88, 'bagging_temperature': 1.0975967176823862, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:31,270] Trial 26 finished with value: 0.8049526106031681 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.09514555928014083, 'random_strength': 48, 'bagging_temperature': 1.373225779690148, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:31,876] Trial 27 finished with value: 0.8281925585296372 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.15669554536581887, 'random_strength': 90, 'bagging_temperature': 4.575378724888573, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:31,994] Trial 28 finished with value: 0.8368889581576149 and parameters: {'iterations': 132, 'depth': 5, 'learning_rate': 0.22744915007827582, 'random_strength': 39, 'bagging_temperature': 13.111182267159105, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:32,090] Trial 29 finished with value: 0.8092644368506438 and parameters: {'iterations': 53, 'depth': 9, 'learning_rate': 0.12284834354826671, 'random_strength': 27, 'bagging_temperature': 1.5813068751871724, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:32,391] Trial 30 finished with value: 0.8238465724077614 and parameters: {'iterations': 229, 'depth': 7, 'learning_rate': 0.06945746462556765, 'random_strength': 15, 'bagging_temperature': 0.07508699736163914, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:32,511] Trial 31 finished with value: 0.8328800815150558 and parameters: {'iterations': 79, 'depth': 8, 'learning_rate': 0.23681369172229375, 'random_strength': 79, 'bagging_temperature': 0.640561140907306, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:32,713] Trial 32 finished with value: 0.8285262535262534 and parameters: {'iterations': 165, 'depth': 8, 'learning_rate': 0.15559015417973857, 'random_strength': 90, 'bagging_temperature': 0.3615088608737625, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:32,927] Trial 33 finished with value: 0.8452100356170124 and parameters: {'iterations': 127, 'depth': 9, 'learning_rate': 0.29910669197529033, 'random_strength': 72, 'bagging_temperature': 0.657730432575482, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:33,384] Trial 34 finished with value: 0.8097037845172175 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.19206931619828688, 'random_strength': 68, 'bagging_temperature': 0.16437735161981998, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:33,684] Trial 35 finished with value: 0.8281925585296372 and parameters: {'iterations': 262, 'depth': 9, 'learning_rate': 0.24388786135436774, 'random_strength': 55, 'bagging_temperature': 1.1183931214903917, 'od_type': 'IncToDec', 'od_wait': 14}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:34,023] Trial 36 finished with value: 0.8044843469837604 and parameters: {'iterations': 156, 'depth': 9, 'learning_rate': 0.18587469065148418, 'random_strength': 89, 'bagging_temperature': 4.165231295848882, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:34,712] Trial 37 finished with value: 0.8234879328004447 and parameters: {'iterations': 204, 'depth': 10, 'learning_rate': 0.1083989687508314, 'random_strength': 70, 'bagging_temperature': 0.44691581706928085, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:34,926] Trial 38 finished with value: 0.8191500616101444 and parameters: {'iterations': 102, 'depth': 9, 'learning_rate': 0.1568168978491686, 'random_strength': 73, 'bagging_temperature': 0.24433444285722963, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:35,131] Trial 39 finished with value: 0.8097037845172175 and parameters: {'iterations': 134, 'depth': 9, 'learning_rate': 0.05655418266985324, 'random_strength': 96, 'bagging_temperature': 0.017540738940410357, 'od_type': 'IncToDec', 'od_wait': 13}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:35,387] Trial 40 finished with value: 0.8230965538028735 and parameters: {'iterations': 184, 'depth': 8, 'learning_rate': 0.03160410090244593, 'random_strength': 65, 'bagging_temperature': 0.04086221577159161, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:35,524] Trial 41 finished with value: 0.836512374443409 and parameters: {'iterations': 119, 'depth': 7, 'learning_rate': 0.2876529600902451, 'random_strength': 82, 'bagging_temperature': 0.6716027759947922, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:35,736] Trial 42 finished with value: 0.8092644368506438 and parameters: {'iterations': 135, 'depth': 8, 'learning_rate': 0.2526059531960489, 'random_strength': 74, 'bagging_temperature': 1.869131051838382, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:35,924] Trial 43 finished with value: 0.8321685254027262 and parameters: {'iterations': 150, 'depth': 8, 'learning_rate': 0.2059234607016438, 'random_strength': 86, 'bagging_temperature': 0.9346282988894731, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:36,148] Trial 44 finished with value: 0.7781043454802321 and parameters: {'iterations': 96, 'depth': 10, 'learning_rate': 0.013499828565536377, 'random_strength': 58, 'bagging_temperature': 0.11555522167039572, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:36,468] Trial 45 finished with value: 0.8130959183590762 and parameters: {'iterations': 164, 'depth': 9, 'learning_rate': 0.17856838753517537, 'random_strength': 95, 'bagging_temperature': 3.2825187518463643, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:36,609] Trial 46 finished with value: 0.8234879328004447 and parameters: {'iterations': 127, 'depth': 7, 'learning_rate': 0.2572828804096286, 'random_strength': 31, 'bagging_temperature': 0.5566097207733359, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:36,784] Trial 47 finished with value: 0.8325398336824732 and parameters: {'iterations': 141, 'depth': 8, 'learning_rate': 0.2076585219667482, 'random_strength': 38, 'bagging_temperature': 27.458913535357603, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:36,966] Trial 48 finished with value: 0.8057795541931729 and parameters: {'iterations': 109, 'depth': 6, 'learning_rate': 0.111090595622268, 'random_strength': 79, 'bagging_temperature': 0.3202373524281424, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,256] Trial 49 finished with value: 0.8234879328004447 and parameters: {'iterations': 252, 'depth': 9, 'learning_rate': 0.2978258064011983, 'random_strength': 54, 'bagging_temperature': 11.354319184692695, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,356] Trial 50 finished with value: 0.8226718495899223 and parameters: {'iterations': 69, 'depth': 8, 'learning_rate': 0.14017228164703208, 'random_strength': 64, 'bagging_temperature': 0.9723148856855746, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,507] Trial 51 finished with value: 0.8368889581576149 and parameters: {'iterations': 113, 'depth': 8, 'learning_rate': 0.2999136914645627, 'random_strength': 77, 'bagging_temperature': 0.8087611291808497, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,617] Trial 52 finished with value: 0.8278272336108157 and parameters: {'iterations': 87, 'depth': 7, 'learning_rate': 0.25974340851143074, 'random_strength': 82, 'bagging_temperature': 2.511475397441021, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,820] Trial 53 finished with value: 0.8321685254027262 and parameters: {'iterations': 117, 'depth': 8, 'learning_rate': 0.1820963749293263, 'random_strength': 100, 'bagging_temperature': 0.20408424217690574, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:37,951] Trial 54 finished with value: 0.8234879328004447 and parameters: {'iterations': 126, 'depth': 7, 'learning_rate': 0.22237331898776672, 'random_strength': 74, 'bagging_temperature': 0.45485170511175316, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:38,267] Trial 55 finished with value: 0.8238465724077614 and parameters: {'iterations': 284, 'depth': 9, 'learning_rate': 0.2602527947644015, 'random_strength': 45, 'bagging_temperature': 1.618862723177103, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:38,432] Trial 56 finished with value: 0.8049526106031681 and parameters: {'iterations': 105, 'depth': 9, 'learning_rate': 0.08741322844706101, 'random_strength': 86, 'bagging_temperature': 0.13662059802451998, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:39,070] Trial 57 finished with value: 0.8412404970025789 and parameters: {'iterations': 221, 'depth': 10, 'learning_rate': 0.14186205912279992, 'random_strength': 93, 'bagging_temperature': 0.2498510149122526, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:39,350] Trial 58 finished with value: 0.8278272336108157 and parameters: {'iterations': 158, 'depth': 8, 'learning_rate': 0.20912203200941476, 'random_strength': 17, 'bagging_temperature': 0.6755885334629342, 'od_type': 'IncToDec', 'od_wait': 17}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:39,466] Trial 59 finished with value: 0.8226718495899223 and parameters: {'iterations': 142, 'depth': 6, 'learning_rate': 0.16824574372404896, 'random_strength': 9, 'bagging_temperature': 1.224734191506616, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:39,676] Trial 60 finished with value: 0.8281925585296372 and parameters: {'iterations': 184, 'depth': 8, 'learning_rate': 0.2594897070959767, 'random_strength': 22, 'bagging_temperature': 2.271968099563969, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:40,083] Trial 61 finished with value: 0.8317656008930031 and parameters: {'iterations': 280, 'depth': 8, 'learning_rate': 0.03460257154672422, 'random_strength': 4, 'bagging_temperature': 0.010834483222698746, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:40,505] Trial 62 finished with value: 0.8144360319184163 and parameters: {'iterations': 247, 'depth': 8, 'learning_rate': 0.02172032001207262, 'random_strength': 11, 'bagging_temperature': 0.022116123908668177, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:40,945] Trial 63 finished with value: 0.8148130633004671 and parameters: {'iterations': 269, 'depth': 9, 'learning_rate': 0.049892468946288196, 'random_strength': 0, 'bagging_temperature': 94.81497822413549, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:41,268] Trial 64 finished with value: 0.8049526106031681 and parameters: {'iterations': 237, 'depth': 7, 'learning_rate': 0.026870794741378903, 'random_strength': 27, 'bagging_temperature': 0.5279730229979602, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:41,417] Trial 65 finished with value: 0.8001817909863886 and parameters: {'iterations': 91, 'depth': 9, 'learning_rate': 0.03983857995482302, 'random_strength': 70, 'bagging_temperature': 0.04518937371249224, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:42,120] Trial 66 finished with value: 0.8459506827044141 and parameters: {'iterations': 206, 'depth': 10, 'learning_rate': 0.06290905570399524, 'random_strength': 13, 'bagging_temperature': 0.07175716865094625, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:42,800] Trial 67 finished with value: 0.8325398336824732 and parameters: {'iterations': 203, 'depth': 10, 'learning_rate': 0.05886422854031805, 'random_strength': 14, 'bagging_temperature': 0.07632383470107537, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:43,478] Trial 68 finished with value: 0.8368889581576149 and parameters: {'iterations': 215, 'depth': 10, 'learning_rate': 0.07681147606723239, 'random_strength': 37, 'bagging_temperature': 0.08369262768141196, 'od_type': 'IncToDec', 'od_wait': 35}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:44,035] Trial 69 finished with value: 0.8281925585296372 and parameters: {'iterations': 224, 'depth': 10, 'learning_rate': 0.24033954555019446, 'random_strength': 61, 'bagging_temperature': 0.37268644784576604, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:44,564] Trial 70 finished with value: 0.8241730165768567 and parameters: {'iterations': 194, 'depth': 10, 'learning_rate': 0.06416023226514239, 'random_strength': 51, 'bagging_temperature': 7.637256199666122, 'od_type': 'IncToDec', 'od_wait': 12}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:44,766] Trial 71 finished with value: 0.8039786460839093 and parameters: {'iterations': 121, 'depth': 8, 'learning_rate': 0.04144435743614854, 'random_strength': 20, 'bagging_temperature': 0.02430916535505336, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:45,128] Trial 72 finished with value: 0.8135780982868414 and parameters: {'iterations': 248, 'depth': 9, 'learning_rate': 0.27393221220982283, 'random_strength': 77, 'bagging_temperature': 0.05228592983304184, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:45,299] Trial 73 finished with value: 0.8230965538028735 and parameters: {'iterations': 175, 'depth': 7, 'learning_rate': 0.028810900422508463, 'random_strength': 5, 'bagging_temperature': 0.199632977635467, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:45,448] Trial 74 finished with value: 0.799683575504369 and parameters: {'iterations': 149, 'depth': 4, 'learning_rate': 0.04833203791741243, 'random_strength': 11, 'bagging_temperature': 0.030730395591002085, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:45,607] Trial 75 finished with value: 0.7851496251496252 and parameters: {'iterations': 131, 'depth': 8, 'learning_rate': 0.01773539609042039, 'random_strength': 32, 'bagging_temperature': 3.5090731094814, 'od_type': 'IncToDec', 'od_wait': 34}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:46,098] Trial 76 finished with value: 0.8151562481961826 and parameters: {'iterations': 263, 'depth': 10, 'learning_rate': 0.23107554736157662, 'random_strength': 25, 'bagging_temperature': 1.4932553680389908, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:46,391] Trial 77 finished with value: 0.8415917345645018 and parameters: {'iterations': 168, 'depth': 9, 'learning_rate': 0.11821821858760075, 'random_strength': 87, 'bagging_temperature': 0.8306273214731175, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:46,732] Trial 78 finished with value: 0.836512374443409 and parameters: {'iterations': 166, 'depth': 9, 'learning_rate': 0.11276221170588659, 'random_strength': 88, 'bagging_temperature': 0.3137720112644967, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:47,081] Trial 79 finished with value: 0.8325398336824732 and parameters: {'iterations': 180, 'depth': 9, 'learning_rate': 0.0994758257465439, 'random_strength': 93, 'bagging_temperature': 0.8376516244694181, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 13 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 20:40:47,737] Trial 80 finished with value: 0.8506436354465302 and parameters: {'iterations': 210, 'depth': 10, 'learning_rate': 0.1485489827192142, 'random_strength': 83, 'bagging_temperature': 1.9225889649967491, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:48,495] Trial 81 finished with value: 0.8234879328004447 and parameters: {'iterations': 210, 'depth': 10, 'learning_rate': 0.08319944121940068, 'random_strength': 82, 'bagging_temperature': 5.117926567355211, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:49,126] Trial 82 finished with value: 0.8317656008930031 and parameters: {'iterations': 202, 'depth': 10, 'learning_rate': 0.13120327747947585, 'random_strength': 84, 'bagging_temperature': 1.8441718573519505, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:49,705] Trial 83 finished with value: 0.8375511875511874 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.1228726644562036, 'random_strength': 79, 'bagging_temperature': 1.265967359938641, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:50,142] Trial 84 finished with value: 0.8285262535262534 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.14716998098052195, 'random_strength': 91, 'bagging_temperature': 0.5001151482604419, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:50,493] Trial 85 finished with value: 0.7958806390033156 and parameters: {'iterations': 234, 'depth': 9, 'learning_rate': 0.16826771719947883, 'random_strength': 86, 'bagging_temperature': 1.0019680500950985, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:50,864] Trial 86 finished with value: 0.827429728579154 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.19854974324795052, 'random_strength': 72, 'bagging_temperature': 0.809104488075062, 'od_type': 'IncToDec', 'od_wait': 15}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:51,105] Trial 87 finished with value: 0.8140245822030209 and parameters: {'iterations': 226, 'depth': 5, 'learning_rate': 0.10266811292944479, 'random_strength': 67, 'bagging_temperature': 2.937677437055337, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:51,318] Trial 88 finished with value: 0.8049526106031681 and parameters: {'iterations': 217, 'depth': 8, 'learning_rate': 0.2755525772216633, 'random_strength': 76, 'bagging_temperature': 0.5859284296333876, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:51,664] Trial 89 finished with value: 0.8317656008930031 and parameters: {'iterations': 199, 'depth': 9, 'learning_rate': 0.17746076300141495, 'random_strength': 97, 'bagging_temperature': 3.959273817071237, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:51,924] Trial 90 finished with value: 0.8178941595494262 and parameters: {'iterations': 160, 'depth': 9, 'learning_rate': 0.15276877853160303, 'random_strength': 81, 'bagging_temperature': 1.93579916460334, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:52,287] Trial 91 finished with value: 0.8325398336824732 and parameters: {'iterations': 208, 'depth': 8, 'learning_rate': 0.11660441244108338, 'random_strength': 41, 'bagging_temperature': 0.01640377059404626, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:52,625] Trial 92 finished with value: 0.8178941595494262 and parameters: {'iterations': 254, 'depth': 8, 'learning_rate': 0.21243747547152952, 'random_strength': 88, 'bagging_temperature': 0.7383583564276845, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:53,004] Trial 93 finished with value: 0.84191359062235 and parameters: {'iterations': 300, 'depth': 8, 'learning_rate': 0.13035511506553613, 'random_strength': 17, 'bagging_temperature': 0.3994081552905476, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:53,159] Trial 94 finished with value: 0.8148130633004671 and parameters: {'iterations': 106, 'depth': 8, 'learning_rate': 0.28039685048396473, 'random_strength': 14, 'bagging_temperature': 0.3777623224223231, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:53,390] Trial 95 finished with value: 0.8144360319184163 and parameters: {'iterations': 300, 'depth': 7, 'learning_rate': 0.19435119405510284, 'random_strength': 17, 'bagging_temperature': 0.26818071748613875, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:53,533] Trial 96 finished with value: 0.8278272336108157 and parameters: {'iterations': 98, 'depth': 8, 'learning_rate': 0.13041959390664867, 'random_strength': 34, 'bagging_temperature': 1.119156198595714, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 80 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 20:40:53,978] Trial 97 finished with value: 0.8509470997296442 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.08950887879308136, 'random_strength': 27, 'bagging_temperature': 0.45256131361186913, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:54,511] Trial 98 finished with value: 0.8195013195013195 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.2999441369341082, 'random_strength': 28, 'bagging_temperature': 0.09751840454307664, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:54,888] Trial 99 finished with value: 0.8230965538028735 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.08725828659403027, 'random_strength': 22, 'bagging_temperature': 0.4420573845006753, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:55,311] Trial 100 finished with value: 0.8187655090640165 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.06840236402451044, 'random_strength': 18, 'bagging_temperature': 0.16036847502890103, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:55,832] Trial 101 finished with value: 0.833469421937483 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.09105689016719712, 'random_strength': 29, 'bagging_temperature': 0.6666931655921199, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:56,297] Trial 102 finished with value: 0.8325398336824732 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.10280426756439766, 'random_strength': 25, 'bagging_temperature': 0.9761885883414885, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:56,584] Trial 103 finished with value: 0.8452100356170124 and parameters: {'iterations': 155, 'depth': 9, 'learning_rate': 0.13673263614391493, 'random_strength': 92, 'bagging_temperature': 1.418527538482404, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:56,781] Trial 104 finished with value: 0.8278272336108157 and parameters: {'iterations': 152, 'depth': 8, 'learning_rate': 0.13741407940209843, 'random_strength': 84, 'bagging_temperature': 1.450521599296597, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:57,020] Trial 105 finished with value: 0.8325398336824732 and parameters: {'iterations': 161, 'depth': 8, 'learning_rate': 0.16226812645206945, 'random_strength': 94, 'bagging_temperature': 0.5499289614627703, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:57,240] Trial 106 finished with value: 0.8230965538028735 and parameters: {'iterations': 129, 'depth': 9, 'learning_rate': 0.22479325725520746, 'random_strength': 8, 'bagging_temperature': 0.32336153944749374, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:57,664] Trial 107 finished with value: 0.8108108108108109 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.24841202587612612, 'random_strength': 75, 'bagging_temperature': 0.2075464251871659, 'od_type': 'IncToDec', 'od_wait': 18}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:57,925] Trial 108 finished with value: 0.8226718495899223 and parameters: {'iterations': 123, 'depth': 9, 'learning_rate': 0.14507807757737576, 'random_strength': 35, 'bagging_temperature': 2.4985289190497846, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:58,275] Trial 109 finished with value: 0.8281925585296372 and parameters: {'iterations': 272, 'depth': 7, 'learning_rate': 0.07577432782035423, 'random_strength': 92, 'bagging_temperature': 0.42385107516515064, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:58,488] Trial 110 finished with value: 0.8238465724077614 and parameters: {'iterations': 179, 'depth': 8, 'learning_rate': 0.2697390092346607, 'random_strength': 79, 'bagging_temperature': 10.171409767162134, 'od_type': 'IncToDec', 'od_wait': 10}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:58,761] Trial 111 finished with value: 0.8222131906342433 and parameters: {'iterations': 166, 'depth': 9, 'learning_rate': 0.12357453309345928, 'random_strength': 87, 'bagging_temperature': 0.6135242173014506, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:59,090] Trial 112 finished with value: 0.8230965538028735 and parameters: {'iterations': 171, 'depth': 9, 'learning_rate': 0.10792555282593912, 'random_strength': 90, 'bagging_temperature': 0.9330765428684141, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:59,357] Trial 113 finished with value: 0.8144360319184163 and parameters: {'iterations': 154, 'depth': 9, 'learning_rate': 0.11942754490961409, 'random_strength': 80, 'bagging_temperature': 1.6831211699409323, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:40:59,753] Trial 114 finished with value: 0.8151562481961826 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.1297190718066866, 'random_strength': 98, 'bagging_temperature': 1.3428629582466134, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:00,024] Trial 115 finished with value: 0.8148130633004671 and parameters: {'iterations': 134, 'depth': 9, 'learning_rate': 0.17299113747959693, 'random_strength': 83, 'bagging_temperature': 0.7722678281197028, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:00,245] Trial 116 finished with value: 0.8317656008930031 and parameters: {'iterations': 146, 'depth': 8, 'learning_rate': 0.08081029981517814, 'random_strength': 72, 'bagging_temperature': 2.119776881123815, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:00,564] Trial 117 finished with value: 0.8226718495899223 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.09425061674950734, 'random_strength': 85, 'bagging_temperature': 6.248651883096264, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:01,185] Trial 118 finished with value: 0.8285262535262534 and parameters: {'iterations': 189, 'depth': 10, 'learning_rate': 0.15223389141371155, 'random_strength': 23, 'bagging_temperature': 1.1556093381985342, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:01,372] Trial 119 finished with value: 0.83723505544913 and parameters: {'iterations': 108, 'depth': 8, 'learning_rate': 0.13589004825239762, 'random_strength': 45, 'bagging_temperature': 0.47522545284089585, 'od_type': 'IncToDec', 'od_wait': 21}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:01,776] Trial 120 finished with value: 0.8285262535262534 and parameters: {'iterations': 243, 'depth': 9, 'learning_rate': 0.10996717330067733, 'random_strength': 77, 'bagging_temperature': 0.6854874220350806, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:02,241] Trial 121 finished with value: 0.836512374443409 and parameters: {'iterations': 289, 'depth': 8, 'learning_rate': 0.05470841162117673, 'random_strength': 12, 'bagging_temperature': 0.9031770511477487, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:02,648] Trial 122 finished with value: 0.8183470827148989 and parameters: {'iterations': 276, 'depth': 8, 'learning_rate': 0.06238403997438105, 'random_strength': 31, 'bagging_temperature': 0.5406014169347224, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:03,047] Trial 123 finished with value: 0.8191500616101444 and parameters: {'iterations': 229, 'depth': 8, 'learning_rate': 0.036426835651353955, 'random_strength': 15, 'bagging_temperature': 0.2790867291603394, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:03,243] Trial 124 finished with value: 0.8183470827148989 and parameters: {'iterations': 157, 'depth': 8, 'learning_rate': 0.044823121198191304, 'random_strength': 6, 'bagging_temperature': 0.03413370200409309, 'od_type': 'Iter', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:03,501] Trial 125 finished with value: 0.8234879328004447 and parameters: {'iterations': 177, 'depth': 8, 'learning_rate': 0.2833643502206033, 'random_strength': 89, 'bagging_temperature': 0.314734481337136, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:03,830] Trial 126 finished with value: 0.8140245822030209 and parameters: {'iterations': 260, 'depth': 9, 'learning_rate': 0.16064366711003833, 'random_strength': 9, 'bagging_temperature': 0.0652029538978921, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:04,053] Trial 127 finished with value: 0.8321685254027262 and parameters: {'iterations': 194, 'depth': 7, 'learning_rate': 0.05285699645224536, 'random_strength': 33, 'bagging_temperature': 3.1289730901700654, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:04,596] Trial 128 finished with value: 0.8509470997296442 and parameters: {'iterations': 256, 'depth': 10, 'learning_rate': 0.24477759829644333, 'random_strength': 37, 'bagging_temperature': 0.01214256293653298, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:05,030] Trial 129 finished with value: 0.8230965538028735 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.25190981442351407, 'random_strength': 36, 'bagging_temperature': 0.010315041320498939, 'od_type': 'IncToDec', 'od_wait': 32}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:05,548] Trial 130 finished with value: 0.8238465724077614 and parameters: {'iterations': 219, 'depth': 10, 'learning_rate': 0.23790715166986925, 'random_strength': 41, 'bagging_temperature': 0.3857135452538226, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:06,140] Trial 131 finished with value: 0.8187655090640165 and parameters: {'iterations': 210, 'depth': 10, 'learning_rate': 0.2960319553082323, 'random_strength': 38, 'bagging_temperature': 0.014106801782795306, 'od_type': 'IncToDec', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:06,669] Trial 132 finished with value: 0.8325398336824732 and parameters: {'iterations': 238, 'depth': 10, 'learning_rate': 0.26681004905196515, 'random_strength': 26, 'bagging_temperature': 0.013373823510126302, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:07,229] Trial 133 finished with value: 0.8087888675268976 and parameters: {'iterations': 252, 'depth': 10, 'learning_rate': 0.21148441684178415, 'random_strength': 3, 'bagging_temperature': 0.022281195315020364, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:07,547] Trial 134 finished with value: 0.8459506827044141 and parameters: {'iterations': 295, 'depth': 8, 'learning_rate': 0.1452292931800755, 'random_strength': 19, 'bagging_temperature': 0.012313553026265748, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:07,834] Trial 135 finished with value: 0.8281925585296372 and parameters: {'iterations': 289, 'depth': 8, 'learning_rate': 0.18741761753699132, 'random_strength': 32, 'bagging_temperature': 0.017818442580743513, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:08,465] Trial 136 finished with value: 0.8144360319184163 and parameters: {'iterations': 284, 'depth': 10, 'learning_rate': 0.14267775453008494, 'random_strength': 21, 'bagging_temperature': 0.029037811710213038, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:08,663] Trial 137 finished with value: 0.8053841310363877 and parameters: {'iterations': 142, 'depth': 6, 'learning_rate': 0.1261827755896928, 'random_strength': 27, 'bagging_temperature': 0.7621381891631509, 'od_type': 'IncToDec', 'od_wait': 22}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:08,881] Trial 138 finished with value: 0.8130959183590762 and parameters: {'iterations': 169, 'depth': 8, 'learning_rate': 0.11706109944176853, 'random_strength': 20, 'bagging_temperature': 1.0416489986985957, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:09,328] Trial 139 finished with value: 0.827429728579154 and parameters: {'iterations': 295, 'depth': 9, 'learning_rate': 0.1518450147010315, 'random_strength': 17, 'bagging_temperature': 1.3198758019050905, 'od_type': 'IncToDec', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:09,787] Trial 140 finished with value: 0.8375511875511874 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.23732483421577302, 'random_strength': 86, 'bagging_temperature': 0.6498665695104073, 'od_type': 'IncToDec', 'od_wait': 29}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:10,113] Trial 141 finished with value: 0.8148130633004671 and parameters: {'iterations': 298, 'depth': 8, 'learning_rate': 0.13715119663597214, 'random_strength': 11, 'bagging_temperature': 0.011704680509278568, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:10,341] Trial 142 finished with value: 0.836512374443409 and parameters: {'iterations': 264, 'depth': 8, 'learning_rate': 0.2990717139802827, 'random_strength': 51, 'bagging_temperature': 0.01462217756805011, 'od_type': 'IncToDec', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:10,637] Trial 143 finished with value: 0.8278272336108157 and parameters: {'iterations': 285, 'depth': 8, 'learning_rate': 0.2678562701211534, 'random_strength': 13, 'bagging_temperature': 0.011121522593205558, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:11,037] Trial 144 finished with value: 0.8187655090640165 and parameters: {'iterations': 256, 'depth': 8, 'learning_rate': 0.030935400687461496, 'random_strength': 16, 'bagging_temperature': 0.01954167237434675, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:11,279] Trial 145 finished with value: 0.827429728579154 and parameters: {'iterations': 162, 'depth': 7, 'learning_rate': 0.1614775925208224, 'random_strength': 29, 'bagging_temperature': 0.010023583112644575, 'od_type': 'IncToDec', 'od_wait': 13}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:11,725] Trial 146 finished with value: 0.8278272336108157 and parameters: {'iterations': 268, 'depth': 9, 'learning_rate': 0.01068602863872333, 'random_strength': 95, 'bagging_temperature': 0.49889039333439683, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:12,266] Trial 147 finished with value: 0.8325398336824732 and parameters: {'iterations': 293, 'depth': 10, 'learning_rate': 0.17317904293073205, 'random_strength': 19, 'bagging_temperature': 1.7028580319712403, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:12,590] Trial 148 finished with value: 0.8140245822030209 and parameters: {'iterations': 242, 'depth': 8, 'learning_rate': 0.27964814502701074, 'random_strength': 40, 'bagging_temperature': 0.12201848047758192, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:12,967] Trial 149 finished with value: 0.8148130633004671 and parameters: {'iterations': 277, 'depth': 8, 'learning_rate': 0.10315496149133052, 'random_strength': 81, 'bagging_temperature': 4.5567424954922435, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:13,473] Trial 150 finished with value: 0.8230965538028735 and parameters: {'iterations': 233, 'depth': 10, 'learning_rate': 0.2502875046524296, 'random_strength': 23, 'bagging_temperature': 0.2387876763067499, 'od_type': 'IncToDec', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:14,290] Trial 151 finished with value: 0.836512374443409 and parameters: {'iterations': 247, 'depth': 10, 'learning_rate': 0.0441560311761582, 'random_strength': 9, 'bagging_temperature': 0.012606531054243175, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:15,034] Trial 152 finished with value: 0.8144360319184163 and parameters: {'iterations': 232, 'depth': 10, 'learning_rate': 0.049652064983274, 'random_strength': 13, 'bagging_temperature': 0.016171674139229496, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:15,834] Trial 153 finished with value: 0.8412404970025789 and parameters: {'iterations': 226, 'depth': 10, 'learning_rate': 0.04008196520392944, 'random_strength': 7, 'bagging_temperature': 0.024305510384169792, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:16,299] Trial 154 finished with value: 0.8473064211998946 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.03658717234153814, 'random_strength': 0, 'bagging_temperature': 14.699880812509104, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:16,757] Trial 155 finished with value: 0.8368889581576149 and parameters: {'iterations': 111, 'depth': 10, 'learning_rate': 0.14530899703802388, 'random_strength': 1, 'bagging_temperature': 84.9925535977439, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:17,029] Trial 156 finished with value: 0.799683575504369 and parameters: {'iterations': 101, 'depth': 10, 'learning_rate': 0.033762481680194634, 'random_strength': 56, 'bagging_temperature': 0.806703441131842, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:17,185] Trial 157 finished with value: 0.8187655090640165 and parameters: {'iterations': 118, 'depth': 8, 'learning_rate': 0.12564384545416088, 'random_strength': 78, 'bagging_temperature': 13.243200336018521, 'od_type': 'IncToDec', 'od_wait': 26}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:17,400] Trial 158 finished with value: 0.8092644368506438 and parameters: {'iterations': 93, 'depth': 9, 'learning_rate': 0.03760045097039194, 'random_strength': 30, 'bagging_temperature': 35.66063502194803, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:17,968] Trial 159 finished with value: 0.8288288288288288 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.1152167773159405, 'random_strength': 84, 'bagging_temperature': 25.006237634894106, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:18,232] Trial 160 finished with value: 0.8140245822030209 and parameters: {'iterations': 122, 'depth': 9, 'learning_rate': 0.135040876048628, 'random_strength': 34, 'bagging_temperature': 41.66036185480457, 'od_type': 'IncToDec', 'od_wait': 28}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:18,813] Trial 161 finished with value: 0.8424710748057271 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.04321363205907748, 'random_strength': 0, 'bagging_temperature': 0.5860572339327849, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:19,398] Trial 162 finished with value: 0.84709015035102 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.037313786310543565, 'random_strength': 0, 'bagging_temperature': 0.418417755434806, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:19,851] Trial 163 finished with value: 0.836512374443409 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.04304958580432777, 'random_strength': 3, 'bagging_temperature': 0.386033379040789, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:20,452] Trial 164 finished with value: 0.8465761215761216 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.037008932284225145, 'random_strength': 1, 'bagging_temperature': 0.5239652085956833, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:20,987] Trial 165 finished with value: 0.8506436354465302 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.03466770004128539, 'random_strength': 2, 'bagging_temperature': 0.5683336751606168, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:21,572] Trial 166 finished with value: 0.8368889581576149 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.034148045843155735, 'random_strength': 1, 'bagging_temperature': 0.5703108387312461, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:21,989] Trial 167 finished with value: 0.8178941595494262 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.037250242859869685, 'random_strength': 5, 'bagging_temperature': 0.4475416849805732, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:22,552] Trial 168 finished with value: 0.8331897849575306 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.03281565161957882, 'random_strength': 0, 'bagging_temperature': 0.3220896465455748, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:23,172] Trial 169 finished with value: 0.8375511875511874 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.030098711584222736, 'random_strength': 1, 'bagging_temperature': 0.6003611273296674, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:23,679] Trial 170 finished with value: 0.8087888675268976 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.026296643330745776, 'random_strength': 4, 'bagging_temperature': 0.4762731830236906, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 97 with value: 0.8509470997296442.\n",
      "[I 2024-01-12 20:41:24,325] Trial 171 finished with value: 0.8556010556010556 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.04164252549751643, 'random_strength': 0, 'bagging_temperature': 0.35747777576955, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:24,914] Trial 172 finished with value: 0.8465761215761216 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.04708851276825657, 'random_strength': 0, 'bagging_temperature': 0.34465101894000216, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:25,559] Trial 173 finished with value: 0.8378378378378378 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.04712148499890099, 'random_strength': 0, 'bagging_temperature': 0.22841901208920112, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:26,096] Trial 174 finished with value: 0.836512374443409 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.04708436748994993, 'random_strength': 2, 'bagging_temperature': 0.17722353108954797, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:26,549] Trial 175 finished with value: 0.827429728579154 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.0417700684076739, 'random_strength': 4, 'bagging_temperature': 0.38146284574042066, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:27,143] Trial 176 finished with value: 0.8412404970025789 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.036456532672164865, 'random_strength': 2, 'bagging_temperature': 0.3360125331815057, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:27,823] Trial 177 finished with value: 0.8514727276739713 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.039378660179771825, 'random_strength': 0, 'bagging_temperature': 0.2838669703305917, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 171 with value: 0.8556010556010556.\n",
      "[I 2024-01-12 20:41:28,505] Trial 178 finished with value: 0.8604743805422155 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.041216919863773814, 'random_strength': 0, 'bagging_temperature': 0.26161851453373347, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:28,949] Trial 179 finished with value: 0.827429728579154 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.039447731532618324, 'random_strength': 6, 'bagging_temperature': 0.3020784820134405, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:29,550] Trial 180 finished with value: 0.8558558558558559 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.03550223570416499, 'random_strength': 0, 'bagging_temperature': 0.1481817812885767, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:30,105] Trial 181 finished with value: 0.836512374443409 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.0389981370077937, 'random_strength': 3, 'bagging_temperature': 0.14744977259166694, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:30,697] Trial 182 finished with value: 0.8558558558558559 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.03659141890841036, 'random_strength': 0, 'bagging_temperature': 0.25214578084800343, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:31,329] Trial 183 finished with value: 0.84709015035102 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03527879608603743, 'random_strength': 0, 'bagging_temperature': 0.19904721163717398, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:31,978] Trial 184 finished with value: 0.8468468468468469 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.03421103741743854, 'random_strength': 0, 'bagging_temperature': 0.19014374717373583, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:32,597] Trial 185 finished with value: 0.8473064211998946 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.02886013580511529, 'random_strength': 0, 'bagging_temperature': 0.1893609992939334, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:33,219] Trial 186 finished with value: 0.8516957111551706 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.02875283417431951, 'random_strength': 0, 'bagging_temperature': 0.1974777609837416, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:33,908] Trial 187 finished with value: 0.8516957111551706 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.023297485775239563, 'random_strength': 0, 'bagging_temperature': 0.17997939581279382, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:34,578] Trial 188 finished with value: 0.8427075724373022 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.019819474072428404, 'random_strength': 0, 'bagging_temperature': 0.1775870964323031, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:35,143] Trial 189 finished with value: 0.827429728579154 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.0233518010388288, 'random_strength': 3, 'bagging_temperature': 0.20108177885711775, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:35,619] Trial 190 finished with value: 0.8039786460839093 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.027724848324348357, 'random_strength': 5, 'bagging_temperature': 0.25589691073112447, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:36,228] Trial 191 finished with value: 0.8514727276739713 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03167087084636224, 'random_strength': 0, 'bagging_temperature': 0.13631550755071148, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:36,920] Trial 192 finished with value: 0.8378378378378378 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.031718357111473146, 'random_strength': 0, 'bagging_temperature': 0.0943723132065016, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:37,463] Trial 193 finished with value: 0.8325398336824732 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.035396771053290636, 'random_strength': 2, 'bagging_temperature': 0.1512239897308592, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:38,063] Trial 194 finished with value: 0.8321685254027262 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.02954794741781432, 'random_strength': 2, 'bagging_temperature': 0.12485497818656528, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:38,705] Trial 195 finished with value: 0.84709015035102 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.03250394371182255, 'random_strength': 0, 'bagging_temperature': 0.21595283543050062, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:39,155] Trial 196 finished with value: 0.8130959183590762 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03259695613513996, 'random_strength': 5, 'bagging_temperature': 0.20572994949354576, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:39,590] Trial 197 finished with value: 0.8183470827148989 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.035306983241856056, 'random_strength': 7, 'bagging_temperature': 0.2572201086361292, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:40,159] Trial 198 finished with value: 0.8226718495899223 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.02476655245146564, 'random_strength': 3, 'bagging_temperature': 0.17607453344320517, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:40,397] Trial 199 finished with value: 0.8111113621983187 and parameters: {'iterations': 53, 'depth': 10, 'learning_rate': 0.028799842492957393, 'random_strength': 0, 'bagging_temperature': 0.23119138212694867, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:40,950] Trial 200 finished with value: 0.84191359062235 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.030935652710233998, 'random_strength': 2, 'bagging_temperature': 0.2787084152651838, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:41,605] Trial 201 finished with value: 0.84709015035102 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.0387103878334682, 'random_strength': 0, 'bagging_temperature': 0.10864877425130733, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:42,140] Trial 202 finished with value: 0.8234879328004447 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03399027901222842, 'random_strength': 4, 'bagging_temperature': 0.13331791608085872, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:42,773] Trial 203 finished with value: 0.84709015035102 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.037496102153839576, 'random_strength': 0, 'bagging_temperature': 0.10644266621010384, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:43,134] Trial 204 finished with value: 0.842916430236183 and parameters: {'iterations': 83, 'depth': 10, 'learning_rate': 0.039314025238465014, 'random_strength': 0, 'bagging_temperature': 0.10405111407664186, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:43,657] Trial 205 finished with value: 0.8230965538028735 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.03301695583187142, 'random_strength': 3, 'bagging_temperature': 0.15922349371083797, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:44,096] Trial 206 finished with value: 0.827429728579154 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.026775375878378842, 'random_strength': 6, 'bagging_temperature': 0.19795802963204562, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:44,716] Trial 207 finished with value: 0.8412404970025789 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.041334278014185946, 'random_strength': 2, 'bagging_temperature': 0.1165892551739556, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:45,404] Trial 208 finished with value: 0.8558558558558559 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.035475955601138226, 'random_strength': 0, 'bagging_temperature': 0.14560505012387454, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:46,067] Trial 209 finished with value: 0.8468468468468469 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.035776900078110616, 'random_strength': 0, 'bagging_temperature': 0.0888843737327588, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:46,539] Trial 210 finished with value: 0.8135780982868414 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.029955994960422037, 'random_strength': 4, 'bagging_temperature': 0.15338667602244785, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:47,178] Trial 211 finished with value: 0.8512233217188787 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03551227132701841, 'random_strength': 0, 'bagging_temperature': 0.08340261382713487, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:47,765] Trial 212 finished with value: 0.8321685254027262 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.038265137000063856, 'random_strength': 2, 'bagging_temperature': 0.1206814510078494, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:48,426] Trial 213 finished with value: 0.8516957111551706 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.03233322004578177, 'random_strength': 0, 'bagging_temperature': 0.05457332029044116, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:48,886] Trial 214 finished with value: 0.8087888675268976 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.03131120153497529, 'random_strength': 4, 'bagging_temperature': 0.05449095158262984, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:49,428] Trial 215 finished with value: 0.8412404970025789 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.03699336453539679, 'random_strength': 2, 'bagging_temperature': 0.10111622229365452, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:49,738] Trial 216 finished with value: 0.8380954533128446 and parameters: {'iterations': 72, 'depth': 10, 'learning_rate': 0.04159264271150296, 'random_strength': 0, 'bagging_temperature': 0.06958994355862351, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:50,244] Trial 217 finished with value: 0.8230965538028735 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.0349508621844438, 'random_strength': 6, 'bagging_temperature': 0.13856082741937445, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:50,865] Trial 218 finished with value: 0.8285262535262534 and parameters: {'iterations': 189, 'depth': 10, 'learning_rate': 0.02817657805207297, 'random_strength': 2, 'bagging_temperature': 0.22192530018925574, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:51,448] Trial 219 finished with value: 0.8516957111551706 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.031562172781168296, 'random_strength': 0, 'bagging_temperature': 0.08244190400163061, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:51,874] Trial 220 finished with value: 0.8087888675268976 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.03182716533632161, 'random_strength': 4, 'bagging_temperature': 0.1741698891563055, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:52,413] Trial 221 finished with value: 0.8278272336108157 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.03969022412380726, 'random_strength': 2, 'bagging_temperature': 0.078403361956112, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:53,016] Trial 222 finished with value: 0.8424710748057271 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.03294934524389643, 'random_strength': 0, 'bagging_temperature': 0.09992590090459674, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:53,639] Trial 223 finished with value: 0.8558558558558559 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.03692069444955248, 'random_strength': 0, 'bagging_temperature': 0.1339202146212077, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:54,127] Trial 224 finished with value: 0.8144360319184163 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.0208703046512072, 'random_strength': 2, 'bagging_temperature': 0.1364492316603385, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:54,885] Trial 225 finished with value: 0.8383244459763589 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.024561886905873895, 'random_strength': 0, 'bagging_temperature': 0.2769330736205786, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:55,686] Trial 226 finished with value: 0.8234879328004447 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.03527389502161094, 'random_strength': 4, 'bagging_temperature': 0.0620920480631876, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:56,216] Trial 227 finished with value: 0.8135780982868414 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.029726172745901468, 'random_strength': 8, 'bagging_temperature': 0.2255163463722841, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:56,918] Trial 228 finished with value: 0.8278272336108157 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.03329450227474678, 'random_strength': 2, 'bagging_temperature': 0.08424421566349266, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:57,513] Trial 229 finished with value: 0.8269994515719551 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.03865553856731033, 'random_strength': 5, 'bagging_temperature': 0.1609972178297658, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:58,283] Trial 230 finished with value: 0.8558558558558559 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.04377726912375193, 'random_strength': 0, 'bagging_temperature': 0.13949025902522885, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:59,047] Trial 231 finished with value: 0.8514727276739713 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.041170240379701406, 'random_strength': 0, 'bagging_temperature': 0.13427375387706855, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:41:59,710] Trial 232 finished with value: 0.8415917345645018 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.043692097451187115, 'random_strength': 2, 'bagging_temperature': 0.14457528683430684, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:00,420] Trial 233 finished with value: 0.8380954533128446 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.041483227703415594, 'random_strength': 0, 'bagging_temperature': 0.1897495528774385, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:01,017] Trial 234 finished with value: 0.8321685254027262 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.035806535147851995, 'random_strength': 3, 'bagging_temperature': 0.2596007604363884, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:01,636] Trial 235 finished with value: 0.8368889581576149 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.0314184422091837, 'random_strength': 2, 'bagging_temperature': 0.12861319307986996, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:02,278] Trial 236 finished with value: 0.8514727276739713 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.03414446149038201, 'random_strength': 0, 'bagging_temperature': 0.21480450607222945, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:02,697] Trial 237 finished with value: 0.8226718495899223 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.04473462670417662, 'random_strength': 47, 'bagging_temperature': 0.17025746109300657, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:03,215] Trial 238 finished with value: 0.8183470827148989 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.03477480015982603, 'random_strength': 4, 'bagging_temperature': 0.048392177191360915, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:03,872] Trial 239 finished with value: 0.8468468468468469 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.03731039792405542, 'random_strength': 0, 'bagging_temperature': 0.3012562921906564, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:04,448] Trial 240 finished with value: 0.8178941595494262 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.026456643295980943, 'random_strength': 6, 'bagging_temperature': 0.038713067417303924, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:05,093] Trial 241 finished with value: 0.8604743805422155 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.03249993635500385, 'random_strength': 0, 'bagging_temperature': 0.2222295984490755, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:05,638] Trial 242 finished with value: 0.8317656008930031 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.04102538213269984, 'random_strength': 2, 'bagging_temperature': 0.22723907801204124, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:06,267] Trial 243 finished with value: 0.8516957111551706 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.028990753272509964, 'random_strength': 0, 'bagging_temperature': 0.18625491488343976, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:06,803] Trial 244 finished with value: 0.8321685254027262 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.029081103629113318, 'random_strength': 2, 'bagging_temperature': 0.14710267095984048, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:07,450] Trial 245 finished with value: 0.8427075724373022 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.01785500389558255, 'random_strength': 0, 'bagging_temperature': 0.2527633936347712, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:07,922] Trial 246 finished with value: 0.8087888675268976 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.030693838149228533, 'random_strength': 4, 'bagging_temperature': 0.12524850300640544, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:08,542] Trial 247 finished with value: 0.8278272336108157 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.027865846439228077, 'random_strength': 2, 'bagging_temperature': 0.1728894705611145, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:09,212] Trial 248 finished with value: 0.8378378378378378 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.0328810947717738, 'random_strength': 0, 'bagging_temperature': 0.3356076938876668, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:09,823] Trial 249 finished with value: 0.8278272336108157 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.03756445114637499, 'random_strength': 4, 'bagging_temperature': 0.17470034228796086, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:10,477] Trial 250 finished with value: 0.8278272336108157 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.04041937894915265, 'random_strength': 2, 'bagging_temperature': 0.21332374246856797, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:11,181] Trial 251 finished with value: 0.83723505544913 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.05219738236738414, 'random_strength': 0, 'bagging_temperature': 0.29984654276008504, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:11,314] Trial 252 finished with value: 0.8044843469837604 and parameters: {'iterations': 157, 'depth': 4, 'learning_rate': 0.033186932892075714, 'random_strength': 2, 'bagging_temperature': 0.14901758224681794, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:11,738] Trial 253 finished with value: 0.8087888675268976 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.025704254650471253, 'random_strength': 5, 'bagging_temperature': 17.185740972987954, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:12,459] Trial 254 finished with value: 0.8514727276739713 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.03007695081779648, 'random_strength': 0, 'bagging_temperature': 0.39910920610821216, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:13,031] Trial 255 finished with value: 0.827429728579154 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.028842959754313016, 'random_strength': 3, 'bagging_temperature': 0.2533055943339885, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:13,782] Trial 256 finished with value: 0.8560848473891952 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.030197604277202666, 'random_strength': 0, 'bagging_temperature': 0.11272678185369274, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:14,372] Trial 257 finished with value: 0.8459506827044141 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.03084833550755309, 'random_strength': 2, 'bagging_temperature': 0.09103079931860812, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:14,927] Trial 258 finished with value: 0.8183470827148989 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.023385243727097837, 'random_strength': 6, 'bagging_temperature': 0.0671528592316997, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:15,575] Trial 259 finished with value: 0.84709015035102 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.03382620361291923, 'random_strength': 0, 'bagging_temperature': 0.1058761762600628, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:16,086] Trial 260 finished with value: 0.8183470827148989 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.0346981014730674, 'random_strength': 4, 'bagging_temperature': 0.12474118020623945, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:16,714] Trial 261 finished with value: 0.8328800815150558 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.03118168217104434, 'random_strength': 2, 'bagging_temperature': 0.07561737541680633, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:17,571] Trial 262 finished with value: 0.8465761215761216 and parameters: {'iterations': 198, 'depth': 10, 'learning_rate': 0.045220537676226545, 'random_strength': 0, 'bagging_temperature': 0.36389685705088626, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:18,039] Trial 263 finished with value: 0.8135780982868414 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.02761864026007809, 'random_strength': 8, 'bagging_temperature': 0.11771663808573503, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:18,648] Trial 264 finished with value: 0.8187655090640165 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03612686129101, 'random_strength': 3, 'bagging_temperature': 0.1476168325865899, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:19,347] Trial 265 finished with value: 0.8516957111551706 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.030813382575636865, 'random_strength': 0, 'bagging_temperature': 57.958913316121986, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:19,975] Trial 266 finished with value: 0.827429728579154 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.03048423825474134, 'random_strength': 2, 'bagging_temperature': 0.08412027511715017, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:20,539] Trial 267 finished with value: 0.8222131906342433 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.032563192801375755, 'random_strength': 5, 'bagging_temperature': 54.71751556698473, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:20,749] Trial 268 finished with value: 0.8281925585296372 and parameters: {'iterations': 151, 'depth': 5, 'learning_rate': 0.02758447955493645, 'random_strength': 0, 'bagging_temperature': 0.19727584256453898, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:21,292] Trial 269 finished with value: 0.827429728579154 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.030106529077518252, 'random_strength': 3, 'bagging_temperature': 0.28035944680606134, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:21,924] Trial 270 finished with value: 0.8325398336824732 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.02512630308013646, 'random_strength': 2, 'bagging_temperature': 0.11400981615279937, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:22,316] Trial 271 finished with value: 0.827429728579154 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.04000249017302958, 'random_strength': 58, 'bagging_temperature': 0.1414100333648336, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:23,043] Trial 272 finished with value: 0.84709015035102 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03219964457079925, 'random_strength': 0, 'bagging_temperature': 0.1594204615509668, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:23,640] Trial 273 finished with value: 0.827429728579154 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.03408283399680427, 'random_strength': 4, 'bagging_temperature': 0.4308338157638092, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:24,090] Trial 274 finished with value: 0.8039786460839093 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.029042401850333095, 'random_strength': 62, 'bagging_temperature': 0.23451955738306526, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:24,561] Trial 275 finished with value: 0.8321685254027262 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.042896340926443385, 'random_strength': 7, 'bagging_temperature': 0.09428386505991734, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:25,199] Trial 276 finished with value: 0.8412404970025789 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.03789504715462449, 'random_strength': 2, 'bagging_temperature': 0.3289467140460001, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:25,939] Trial 277 finished with value: 0.84709015035102 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.035110291545116835, 'random_strength': 0, 'bagging_temperature': 0.19837098785366467, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:26,483] Trial 278 finished with value: 0.8183470827148989 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03189411719097409, 'random_strength': 4, 'bagging_temperature': 0.12990580050366252, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:27,039] Trial 279 finished with value: 0.8135780982868414 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.03869778663265891, 'random_strength': 43, 'bagging_temperature': 7.746531128965569, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:27,707] Trial 280 finished with value: 0.8562883964234301 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.029660448932740186, 'random_strength': 0, 'bagging_temperature': 0.16901914140749968, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:28,255] Trial 281 finished with value: 0.8368889581576149 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.029273010267442168, 'random_strength': 2, 'bagging_temperature': 0.17037748209180872, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:28,869] Trial 282 finished with value: 0.8473064211998946 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.026769245189860902, 'random_strength': 0, 'bagging_temperature': 0.10749591464185833, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:29,377] Trial 283 finished with value: 0.8368889581576149 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.0495317859735972, 'random_strength': 6, 'bagging_temperature': 0.21588696719217318, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:30,150] Trial 284 finished with value: 0.8516957111551706 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.03076274657974193, 'random_strength': 0, 'bagging_temperature': 0.16371504249961377, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:30,935] Trial 285 finished with value: 0.8514727276739713 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.030510634589399042, 'random_strength': 0, 'bagging_temperature': 0.16165352282682735, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:31,727] Trial 286 finished with value: 0.84709015035102 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.030591593993630987, 'random_strength': 0, 'bagging_temperature': 0.055093776285046706, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:32,328] Trial 287 finished with value: 0.8230965538028735 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.02731150769505445, 'random_strength': 4, 'bagging_temperature': 0.16412376207524867, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:32,987] Trial 288 finished with value: 0.8325398336824732 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03183635630979273, 'random_strength': 2, 'bagging_temperature': 0.1366044633420412, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:33,672] Trial 289 finished with value: 0.8516957111551706 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.0219219889142878, 'random_strength': 0, 'bagging_temperature': 0.17992263867804972, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:34,395] Trial 290 finished with value: 0.8337194337194337 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.02213356803977605, 'random_strength': 0, 'bagging_temperature': 0.18231093213650756, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:35,074] Trial 291 finished with value: 0.8321685254027262 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.02183684992208685, 'random_strength': 2, 'bagging_temperature': 0.1564779781093359, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:35,735] Trial 292 finished with value: 0.8230965538028735 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.020064223511982646, 'random_strength': 4, 'bagging_temperature': 0.23940055540025268, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:36,533] Trial 293 finished with value: 0.8474960166283303 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.01777778057740253, 'random_strength': 0, 'bagging_temperature': 0.12658429642015293, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:37,267] Trial 294 finished with value: 0.8230965538028735 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.025222719781212277, 'random_strength': 2, 'bagging_temperature': 0.1877769210771072, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:37,811] Trial 295 finished with value: 0.8135780982868414 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.023454109370707712, 'random_strength': 5, 'bagging_temperature': 0.1452681493179703, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:38,639] Trial 296 finished with value: 0.8516957111551706 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.028668661959777974, 'random_strength': 0, 'bagging_temperature': 0.21111599804096096, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:39,339] Trial 297 finished with value: 0.83723505544913 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.028464703529646977, 'random_strength': 2, 'bagging_temperature': 0.21360890760825632, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:40,070] Trial 298 finished with value: 0.8560848473891952 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.027019890906858794, 'random_strength': 0, 'bagging_temperature': 0.18713302859812994, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:40,613] Trial 299 finished with value: 0.8178941595494262 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.025357523863390026, 'random_strength': 4, 'bagging_temperature': 0.27473658094082704, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:41,188] Trial 300 finished with value: 0.8230965538028735 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.02781618343541079, 'random_strength': 2, 'bagging_temperature': 0.2360181625568381, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:41,746] Trial 301 finished with value: 0.8183470827148989 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.026250139503670347, 'random_strength': 6, 'bagging_temperature': 0.18723623264578215, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:42,413] Trial 302 finished with value: 0.8516957111551706 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.023831788555837383, 'random_strength': 0, 'bagging_temperature': 0.19556272656263704, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:42,977] Trial 303 finished with value: 0.8368889581576149 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.02421328407656039, 'random_strength': 3, 'bagging_temperature': 0.19367994076225387, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:43,675] Trial 304 finished with value: 0.8562883964234301 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.02343583332632252, 'random_strength': 0, 'bagging_temperature': 0.16553670085069644, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:44,236] Trial 305 finished with value: 0.8321685254027262 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.021985708950917907, 'random_strength': 2, 'bagging_temperature': 0.12439904125433304, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:44,726] Trial 306 finished with value: 0.8183470827148989 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.022912554789014286, 'random_strength': 4, 'bagging_temperature': 0.16292351263208715, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:45,391] Trial 307 finished with value: 0.8378378378378378 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.019393710515943904, 'random_strength': 0, 'bagging_temperature': 0.14273883632686338, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:45,957] Trial 308 finished with value: 0.845595020307664 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.023749348933657738, 'random_strength': 2, 'bagging_temperature': 0.17086649616060004, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:46,415] Trial 309 finished with value: 0.827429728579154 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.02517533555468442, 'random_strength': 7, 'bagging_temperature': 0.10620798598603064, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:47,050] Trial 310 finished with value: 0.8383244459763589 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.02131016272659469, 'random_strength': 0, 'bagging_temperature': 0.2592393996183121, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:47,549] Trial 311 finished with value: 0.8183470827148989 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.02793834690968804, 'random_strength': 4, 'bagging_temperature': 0.2011131445471619, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:48,109] Trial 312 finished with value: 0.8321685254027262 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.026542973804009596, 'random_strength': 2, 'bagging_temperature': 0.13190147635306387, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:48,574] Trial 313 finished with value: 0.8183470827148989 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.024279389311677387, 'random_strength': 10, 'bagging_temperature': 0.16042717849287713, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:48,738] Trial 314 finished with value: 0.8234879328004447 and parameters: {'iterations': 155, 'depth': 5, 'learning_rate': 0.026800472130131203, 'random_strength': 0, 'bagging_temperature': 0.1120962259994332, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:49,353] Trial 315 finished with value: 0.8325398336824732 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.04304500003458124, 'random_strength': 2, 'bagging_temperature': 0.2215726606492035, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:49,819] Trial 316 finished with value: 0.8135780982868414 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.022796372590909122, 'random_strength': 5, 'bagging_temperature': 0.14678087921115354, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:50,525] Trial 317 finished with value: 0.8604743805422155 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.046701499366292684, 'random_strength': 0, 'bagging_temperature': 0.0445131305812073, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:51,022] Trial 318 finished with value: 0.8321685254027262 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.045475225559820115, 'random_strength': 3, 'bagging_temperature': 0.03839526160257852, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:51,207] Trial 319 finished with value: 0.8183470827148989 and parameters: {'iterations': 148, 'depth': 6, 'learning_rate': 0.028894694146766396, 'random_strength': 2, 'bagging_temperature': 0.047517463175090646, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:51,873] Trial 320 finished with value: 0.8383244459763589 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.01998993959508295, 'random_strength': 0, 'bagging_temperature': 0.027646847185279228, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:52,317] Trial 321 finished with value: 0.836512374443409 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.047163490023930096, 'random_strength': 6, 'bagging_temperature': 0.05763690724866674, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:52,897] Trial 322 finished with value: 0.8144360319184163 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.013150725315293012, 'random_strength': 2, 'bagging_temperature': 0.04191400027547333, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:53,416] Trial 323 finished with value: 0.8135780982868414 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.029287278824403903, 'random_strength': 4, 'bagging_temperature': 0.2761334587166766, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:54,090] Trial 324 finished with value: 0.8514727276739713 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.032096263878571826, 'random_strength': 0, 'bagging_temperature': 0.20383586481331886, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:54,709] Trial 325 finished with value: 0.8325398336824732 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.02569821060875961, 'random_strength': 2, 'bagging_temperature': 0.24841249998122197, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:55,281] Trial 326 finished with value: 0.8562883964234301 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.03167403831874712, 'random_strength': 0, 'bagging_temperature': 0.18321976164567763, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:55,724] Trial 327 finished with value: 0.827429728579154 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.05194124222828539, 'random_strength': 4, 'bagging_temperature': 0.18276838738943413, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:56,165] Trial 328 finished with value: 0.8183470827148989 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.027200050139151687, 'random_strength': 8, 'bagging_temperature': 0.23276532605144346, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:56,736] Trial 329 finished with value: 0.8288288288288288 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.021067848274101637, 'random_strength': 0, 'bagging_temperature': 0.29459891769663143, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:56,946] Trial 330 finished with value: 0.8226718495899223 and parameters: {'iterations': 166, 'depth': 6, 'learning_rate': 0.03342435386614037, 'random_strength': 2, 'bagging_temperature': 0.17658482250156265, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:57,478] Trial 331 finished with value: 0.8226718495899223 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.02969678676964772, 'random_strength': 5, 'bagging_temperature': 0.21429633435521886, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:58,113] Trial 332 finished with value: 0.8516957111551706 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.03854396065665696, 'random_strength': 0, 'bagging_temperature': 0.17110868369691676, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:58,541] Trial 333 finished with value: 0.8234879328004447 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.03676804821061586, 'random_strength': 3, 'bagging_temperature': 0.1688211204147618, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:59,149] Trial 334 finished with value: 0.84709015035102 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.023827454804592314, 'random_strength': 0, 'bagging_temperature': 0.09649054283324159, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:42:59,705] Trial 335 finished with value: 0.8459506827044141 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.031553094491520974, 'random_strength': 2, 'bagging_temperature': 0.03286189726288824, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:00,224] Trial 336 finished with value: 0.827429728579154 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.042486142390958326, 'random_strength': 4, 'bagging_temperature': 0.07132904025915195, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:00,874] Trial 337 finished with value: 0.8468468468468469 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.0591206680399414, 'random_strength': 0, 'bagging_temperature': 0.15224508517935914, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:01,316] Trial 338 finished with value: 0.8092644368506438 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.02580903567638179, 'random_strength': 6, 'bagging_temperature': 0.11445389787893244, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:01,825] Trial 339 finished with value: 0.8321685254027262 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.02900783835532303, 'random_strength': 2, 'bagging_temperature': 0.19404209702095582, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:02,326] Trial 340 finished with value: 0.8321685254027262 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.03411335211563942, 'random_strength': 2, 'bagging_temperature': 0.17405228298788095, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:02,954] Trial 341 finished with value: 0.8560848473891952 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.039979159364563074, 'random_strength': 0, 'bagging_temperature': 0.13781478304769998, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:03,512] Trial 342 finished with value: 0.8183470827148989 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.04541688468349956, 'random_strength': 4, 'bagging_temperature': 0.12604295355544728, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:04,177] Trial 343 finished with value: 0.8473064211998946 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.022257177331016027, 'random_strength': 0, 'bagging_temperature': 0.14442324188500213, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:04,851] Trial 344 finished with value: 0.836512374443409 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.0311371783747962, 'random_strength': 2, 'bagging_temperature': 0.11162971496618215, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:05,325] Trial 345 finished with value: 0.8183470827148989 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.027886030044909683, 'random_strength': 6, 'bagging_temperature': 0.08303007340145331, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:05,831] Trial 346 finished with value: 0.8281925585296372 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.04863584837458861, 'random_strength': 3, 'bagging_temperature': 0.22734340181848564, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:06,515] Trial 347 finished with value: 0.84709015035102 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.03285626764314757, 'random_strength': 0, 'bagging_temperature': 0.1449823371866337, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:07,209] Trial 348 finished with value: 0.8230965538028735 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.04037501615200154, 'random_strength': 2, 'bagging_temperature': 0.046445056492271555, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:07,696] Trial 349 finished with value: 0.8082763742703633 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.01909332498252638, 'random_strength': 4, 'bagging_temperature': 0.05935362930154476, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:08,319] Trial 350 finished with value: 0.8514727276739713 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.030157671832240832, 'random_strength': 0, 'bagging_temperature': 0.09624414957479539, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:08,928] Trial 351 finished with value: 0.8238465724077614 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03564516213013051, 'random_strength': 2, 'bagging_temperature': 0.21168433605873152, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:09,613] Trial 352 finished with value: 0.8514727276739713 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.024786781226824137, 'random_strength': 0, 'bagging_temperature': 0.183167044698782, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:10,146] Trial 353 finished with value: 0.8135780982868414 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.02661826954475705, 'random_strength': 4, 'bagging_temperature': 0.24346179482615793, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:10,671] Trial 354 finished with value: 0.8183470827148989 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.03756158941038135, 'random_strength': 7, 'bagging_temperature': 0.12724165454697225, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:11,266] Trial 355 finished with value: 0.8415917345645018 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.0327784550157031, 'random_strength': 2, 'bagging_temperature': 0.15115226628712491, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:11,914] Trial 356 finished with value: 0.8560848473891952 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.04217197913554659, 'random_strength': 0, 'bagging_temperature': 0.19103624459296753, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:12,404] Trial 357 finished with value: 0.836512374443409 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.04411516087818855, 'random_strength': 4, 'bagging_temperature': 0.11984951367325691, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:12,930] Trial 358 finished with value: 0.8412404970025789 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.042135098941409724, 'random_strength': 2, 'bagging_temperature': 0.28626445182713983, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:13,529] Trial 359 finished with value: 0.8427075724373022 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.03924012909019003, 'random_strength': 0, 'bagging_temperature': 0.16015856595754505, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:14,084] Trial 360 finished with value: 0.8222131906342433 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.03607830425782679, 'random_strength': 5, 'bagging_temperature': 0.2384610112176998, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:14,640] Trial 361 finished with value: 0.8459506827044141 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.0412142818052142, 'random_strength': 2, 'bagging_temperature': 0.0993850031173222, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:15,420] Trial 362 finished with value: 0.8422065533382046 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.048271038566145855, 'random_strength': 0, 'bagging_temperature': 0.18104946265039903, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:16,068] Trial 363 finished with value: 0.8368889581576149 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.030325950913208027, 'random_strength': 2, 'bagging_temperature': 0.13367323671937267, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:16,592] Trial 364 finished with value: 0.8135780982868414 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03380012279768487, 'random_strength': 4, 'bagging_temperature': 0.06671938737124646, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:17,034] Trial 365 finished with value: 0.8278272336108157 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.04446771434733538, 'random_strength': 8, 'bagging_temperature': 0.210396294044243, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:17,734] Trial 366 finished with value: 0.8473064211998946 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.028680585586369878, 'random_strength': 0, 'bagging_temperature': 0.15673707124731154, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:18,383] Trial 367 finished with value: 0.83723505544913 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.03548618581280552, 'random_strength': 2, 'bagging_temperature': 0.11563418261020537, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:18,928] Trial 368 finished with value: 0.8230965538028735 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.038144096107721986, 'random_strength': 6, 'bagging_temperature': 0.31845577227494076, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:19,567] Trial 369 finished with value: 0.8424710748057271 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.054272388860395725, 'random_strength': 0, 'bagging_temperature': 0.1880204946180463, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:20,107] Trial 370 finished with value: 0.8187655090640165 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.03189055237613618, 'random_strength': 3, 'bagging_temperature': 0.2444838890482476, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:20,706] Trial 371 finished with value: 0.8368889581576149 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.015585843545901163, 'random_strength': 2, 'bagging_temperature': 0.08799493891482882, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:21,298] Trial 372 finished with value: 0.8514727276739713 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.02997015793490042, 'random_strength': 0, 'bagging_temperature': 0.15747303757347522, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:21,804] Trial 373 finished with value: 0.8321685254027262 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.04051413436690577, 'random_strength': 4, 'bagging_temperature': 0.1351700047969797, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:22,375] Trial 374 finished with value: 0.8321685254027262 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.03332786300687214, 'random_strength': 2, 'bagging_temperature': 0.20373404379300378, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:23,026] Trial 375 finished with value: 0.8516957111551706 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.02771896032943999, 'random_strength': 0, 'bagging_temperature': 0.18025634697763662, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:23,506] Trial 376 finished with value: 0.8269994515719551 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.04421363137793921, 'random_strength': 5, 'bagging_temperature': 0.11128047292411125, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:24,092] Trial 377 finished with value: 0.827429728579154 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.03710927348427817, 'random_strength': 2, 'bagging_temperature': 76.43575919796227, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:24,784] Trial 378 finished with value: 0.8514727276739713 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.03096429237884184, 'random_strength': 0, 'bagging_temperature': 0.26408480763581815, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:25,252] Trial 379 finished with value: 0.8230965538028735 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.05067496853448346, 'random_strength': 4, 'bagging_temperature': 0.15861598479219235, 'od_type': 'Iter', 'od_wait': 49}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:25,930] Trial 380 finished with value: 0.8321685254027262 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.035320771777516316, 'random_strength': 2, 'bagging_temperature': 0.21152338458512182, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:26,506] Trial 381 finished with value: 0.8562883964234301 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.04120285318673642, 'random_strength': 0, 'bagging_temperature': 0.055105623990547865, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:26,918] Trial 382 finished with value: 0.8230965538028735 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.04589657996529855, 'random_strength': 7, 'bagging_temperature': 0.05218136949949336, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:27,346] Trial 383 finished with value: 0.8325398336824732 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.04126947662689179, 'random_strength': 3, 'bagging_temperature': 0.0453517182502756, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:27,887] Trial 384 finished with value: 0.8518926342226868 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.03991071249470786, 'random_strength': 0, 'bagging_temperature': 0.03482366552049512, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:28,030] Trial 385 finished with value: 0.8044843469837604 and parameters: {'iterations': 124, 'depth': 4, 'learning_rate': 0.04246682652884838, 'random_strength': 2, 'bagging_temperature': 0.0351424851393643, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:28,414] Trial 386 finished with value: 0.8178941595494262 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.03929419076095399, 'random_strength': 5, 'bagging_temperature': 0.036810282102543064, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:28,961] Trial 387 finished with value: 0.8468468468468469 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.04729454568811135, 'random_strength': 0, 'bagging_temperature': 0.04178037643560517, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:29,464] Trial 388 finished with value: 0.840859352196084 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.03813523772207611, 'random_strength': 2, 'bagging_temperature': 0.02675198581899518, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:29,951] Trial 389 finished with value: 0.8468468468468469 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.042275000974607686, 'random_strength': 0, 'bagging_temperature': 0.05612646713393578, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:30,384] Trial 390 finished with value: 0.8135780982868414 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.03973432163302118, 'random_strength': 4, 'bagging_temperature': 0.07224333922331493, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:30,876] Trial 391 finished with value: 0.840859352196084 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.0360486355607605, 'random_strength': 2, 'bagging_temperature': 0.0472457409213887, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:31,429] Trial 392 finished with value: 0.8516957111551706 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.033927493012489096, 'random_strength': 0, 'bagging_temperature': 0.031043038523832826, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:31,856] Trial 393 finished with value: 0.836512374443409 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.04452319390629288, 'random_strength': 4, 'bagging_temperature': 0.08026723517825725, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:32,296] Trial 394 finished with value: 0.8226718495899223 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.036880566755611674, 'random_strength': 9, 'bagging_temperature': 0.0387649856284433, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:32,760] Trial 395 finished with value: 0.8321685254027262 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.039822976327382596, 'random_strength': 6, 'bagging_temperature': 0.06040001953979613, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:33,294] Trial 396 finished with value: 0.8368889581576149 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.0328023390740807, 'random_strength': 2, 'bagging_temperature': 0.08951305351430718, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:33,854] Trial 397 finished with value: 0.84709015035102 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.03731259209679679, 'random_strength': 0, 'bagging_temperature': 0.051335458120845556, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:34,353] Trial 398 finished with value: 0.8234879328004447 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.042824411333893246, 'random_strength': 3, 'bagging_temperature': 0.10060199432986251, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:34,880] Trial 399 finished with value: 0.8415917345645018 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.034431480004605525, 'random_strength': 2, 'bagging_temperature': 0.033124877820519316, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:35,540] Trial 400 finished with value: 0.8512233217188787 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.04621092090611318, 'random_strength': 0, 'bagging_temperature': 0.06945877439896501, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:35,916] Trial 401 finished with value: 0.8044843469837604 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.031212543151307472, 'random_strength': 6, 'bagging_temperature': 0.12334008051388347, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:36,472] Trial 402 finished with value: 0.827429728579154 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.0404063425803577, 'random_strength': 4, 'bagging_temperature': 0.13848663271426506, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:37,124] Trial 403 finished with value: 0.8427075724373022 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.035409904810266665, 'random_strength': 0, 'bagging_temperature': 0.31713832991496405, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:37,698] Trial 404 finished with value: 0.8459506827044141 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.03244407683273756, 'random_strength': 2, 'bagging_temperature': 26.278053314862067, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:38,346] Trial 405 finished with value: 0.8509470997296442 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.04891797313489691, 'random_strength': 2, 'bagging_temperature': 0.10904765360914202, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:39,054] Trial 406 finished with value: 0.8514727276739713 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.03863615341236636, 'random_strength': 0, 'bagging_temperature': 0.14529883139248315, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:39,562] Trial 407 finished with value: 0.8135780982868414 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.0293770283670011, 'random_strength': 4, 'bagging_temperature': 0.062090522165082825, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:40,230] Trial 408 finished with value: 0.8238465724077614 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.04290796678799845, 'random_strength': 2, 'bagging_temperature': 0.042347227596844804, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:40,850] Trial 409 finished with value: 0.8516957111551706 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.02670874032529561, 'random_strength': 0, 'bagging_temperature': 0.24845752332344925, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:41,364] Trial 410 finished with value: 0.8178941595494262 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.033905623529794815, 'random_strength': 6, 'bagging_temperature': 0.12863614165892626, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:41,736] Trial 411 finished with value: 0.8183470827148989 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.036842059952307604, 'random_strength': 4, 'bagging_temperature': 0.020265849196256056, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:42,359] Trial 412 finished with value: 0.8465761215761216 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.030916324504866206, 'random_strength': 2, 'bagging_temperature': 0.1685075117929026, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:42,949] Trial 413 finished with value: 0.8328800815150558 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.056815469151595924, 'random_strength': 0, 'bagging_temperature': 0.07853348114211005, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:43,469] Trial 414 finished with value: 0.8415917345645018 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.028006535063540193, 'random_strength': 2, 'bagging_temperature': 0.19011008617679176, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:43,996] Trial 415 finished with value: 0.8281925585296372 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.040664142799900764, 'random_strength': 4, 'bagging_temperature': 0.09771132614109275, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:44,545] Trial 416 finished with value: 0.84709015035102 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.032569025672048765, 'random_strength': 0, 'bagging_temperature': 0.2625596791937284, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:45,122] Trial 417 finished with value: 0.8368889581576149 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.046454628799252606, 'random_strength': 2, 'bagging_temperature': 0.14461888470763684, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:45,852] Trial 418 finished with value: 0.8514727276739713 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.038028028980020695, 'random_strength': 0, 'bagging_temperature': 0.167487446779563, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:46,174] Trial 419 finished with value: 0.8187655090640165 and parameters: {'iterations': 158, 'depth': 9, 'learning_rate': 0.035267484694877595, 'random_strength': 6, 'bagging_temperature': 0.3428495004534319, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:46,675] Trial 420 finished with value: 0.8087888675268976 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.029962483179451764, 'random_strength': 4, 'bagging_temperature': 0.11512501498210503, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:47,300] Trial 421 finished with value: 0.8281925585296372 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.04306208681307078, 'random_strength': 2, 'bagging_temperature': 0.21848005528307532, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:48,034] Trial 422 finished with value: 0.8465761215761216 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.05093302048578513, 'random_strength': 0, 'bagging_temperature': 0.14308161525919597, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:48,526] Trial 423 finished with value: 0.8230965538028735 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.026671732630623318, 'random_strength': 8, 'bagging_temperature': 0.04791772024464403, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:48,996] Trial 424 finished with value: 0.8178941595494262 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.031450173453029154, 'random_strength': 3, 'bagging_temperature': 0.2003405296382399, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:49,703] Trial 425 finished with value: 0.8424710748057271 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.03474715126167601, 'random_strength': 0, 'bagging_temperature': 0.2939483084969026, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:50,263] Trial 426 finished with value: 0.8325398336824732 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.03938845355634894, 'random_strength': 2, 'bagging_temperature': 0.16715821077568108, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:50,726] Trial 427 finished with value: 0.8130959183590762 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.028498831922260284, 'random_strength': 5, 'bagging_temperature': 0.027197493565990695, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:51,374] Trial 428 finished with value: 0.8518926342226868 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.02513399944624051, 'random_strength': 0, 'bagging_temperature': 19.96903900008733, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:51,932] Trial 429 finished with value: 0.8278272336108157 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.02471136544077571, 'random_strength': 2, 'bagging_temperature': 56.81091679231206, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:52,440] Trial 430 finished with value: 0.8140245822030209 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.025138027095186116, 'random_strength': 4, 'bagging_temperature': 32.17384567200984, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:53,090] Trial 431 finished with value: 0.8468468468468469 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.0446158437897093, 'random_strength': 0, 'bagging_temperature': 18.924730754054664, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:53,610] Trial 432 finished with value: 0.8325398336824732 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.02601244604399137, 'random_strength': 2, 'bagging_temperature': 56.3655279997294, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:54,244] Trial 433 finished with value: 0.8473064211998946 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.0231142775466333, 'random_strength': 0, 'bagging_temperature': 0.06572964983837064, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:54,654] Trial 434 finished with value: 0.8183470827148989 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.04180417184873959, 'random_strength': 4, 'bagging_temperature': 10.52347581000478, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:54,848] Trial 435 finished with value: 0.8230965538028735 and parameters: {'iterations': 164, 'depth': 5, 'learning_rate': 0.037007758898558736, 'random_strength': 2, 'bagging_temperature': 0.05440325743937468, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:55,270] Trial 436 finished with value: 0.8178941595494262 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.026614540782814475, 'random_strength': 7, 'bagging_temperature': 96.13722533575228, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:55,678] Trial 437 finished with value: 0.7991466778070471 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.028044115407858807, 'random_strength': 67, 'bagging_temperature': 0.03969880474355347, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:56,269] Trial 438 finished with value: 0.8516957111551706 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.03905968387527602, 'random_strength': 0, 'bagging_temperature': 47.40469360751796, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:56,811] Trial 439 finished with value: 0.8230965538028735 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.02406437285930956, 'random_strength': 3, 'bagging_temperature': 0.08207831765462541, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:57,239] Trial 440 finished with value: 0.8230965538028735 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.03293069366327623, 'random_strength': 52, 'bagging_temperature': 23.873781722293465, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:57,854] Trial 441 finished with value: 0.8321685254027262 and parameters: {'iterations': 155, 'depth': 10, 'learning_rate': 0.04724069463279216, 'random_strength': 2, 'bagging_temperature': 37.24901328322552, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:58,229] Trial 442 finished with value: 0.8135780982868414 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.03561706652341465, 'random_strength': 5, 'bagging_temperature': 5.319599496258479, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:58,899] Trial 443 finished with value: 0.8604743805422155 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.041246146403409734, 'random_strength': 0, 'bagging_temperature': 16.02210099993745, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:43:59,506] Trial 444 finished with value: 0.8468468468468469 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.04186832087052463, 'random_strength': 0, 'bagging_temperature': 0.23540762809369056, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:00,050] Trial 445 finished with value: 0.836512374443409 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.044739149033253864, 'random_strength': 2, 'bagging_temperature': 20.881988610389584, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:00,538] Trial 446 finished with value: 0.8187655090640165 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.04006950697388693, 'random_strength': 4, 'bagging_temperature': 0.12414119068829385, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:01,138] Trial 447 finished with value: 0.8424710748057271 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.04844709006688317, 'random_strength': 0, 'bagging_temperature': 0.09728846036719001, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:01,432] Trial 448 finished with value: 0.8187655090640165 and parameters: {'iterations': 158, 'depth': 9, 'learning_rate': 0.04320371593402256, 'random_strength': 6, 'bagging_temperature': 14.592860941550004, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:01,969] Trial 449 finished with value: 0.8321685254027262 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.038793096554407595, 'random_strength': 2, 'bagging_temperature': 18.586843084419716, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:02,482] Trial 450 finished with value: 0.8234879328004447 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.037230415754515765, 'random_strength': 3, 'bagging_temperature': 0.27772177612671956, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:03,100] Trial 451 finished with value: 0.8514727276739713 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.05386128270703538, 'random_strength': 0, 'bagging_temperature': 16.274015513179858, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:03,576] Trial 452 finished with value: 0.8135780982868414 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.0414247775722791, 'random_strength': 10, 'bagging_temperature': 0.185826021199324, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:04,020] Trial 453 finished with value: 0.8321685254027262 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.044858960944535974, 'random_strength': 2, 'bagging_temperature': 0.13519500336957022, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:04,500] Trial 454 finished with value: 0.827429728579154 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.03735761900264806, 'random_strength': 4, 'bagging_temperature': 22.504069322716713, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:05,057] Trial 455 finished with value: 0.8516957111551706 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.03531739920690893, 'random_strength': 0, 'bagging_temperature': 0.03160502795953021, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:05,667] Trial 456 finished with value: 0.8234879328004447 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.022938304630062474, 'random_strength': 2, 'bagging_temperature': 12.833366285318304, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:06,093] Trial 457 finished with value: 0.8226718495899223 and parameters: {'iterations': 148, 'depth': 10, 'learning_rate': 0.04162845789889185, 'random_strength': 6, 'bagging_temperature': 0.23009151512305206, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:06,873] Trial 458 finished with value: 0.8422065533382046 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.05019883653169723, 'random_strength': 0, 'bagging_temperature': 0.18866976690420628, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:07,384] Trial 459 finished with value: 0.8135780982868414 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.02562677701632652, 'random_strength': 4, 'bagging_temperature': 0.11744256461396334, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:07,965] Trial 460 finished with value: 0.8278272336108157 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.03957226856061289, 'random_strength': 2, 'bagging_temperature': 0.1495573365438611, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:08,790] Trial 461 finished with value: 0.8512233217188787 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.0336289989844245, 'random_strength': 0, 'bagging_temperature': 30.06837184981476, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:08,964] Trial 462 finished with value: 0.8187655090640165 and parameters: {'iterations': 128, 'depth': 7, 'learning_rate': 0.029300481337805977, 'random_strength': 2, 'bagging_temperature': 0.3562649183940055, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:09,437] Trial 463 finished with value: 0.8226718495899223 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.04607038022144637, 'random_strength': 4, 'bagging_temperature': 0.07748643738436514, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:10,086] Trial 464 finished with value: 0.8427075724373022 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.037661090377510434, 'random_strength': 0, 'bagging_temperature': 0.10173736297783767, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:10,645] Trial 465 finished with value: 0.8368889581576149 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03356425611519903, 'random_strength': 2, 'bagging_temperature': 0.26140258774914266, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:11,163] Trial 466 finished with value: 0.8187655090640165 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.040994007687366676, 'random_strength': 6, 'bagging_temperature': 0.20573323899805773, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:11,524] Trial 467 finished with value: 0.8203604955292878 and parameters: {'iterations': 143, 'depth': 9, 'learning_rate': 0.020568713284024983, 'random_strength': 0, 'bagging_temperature': 0.160934020988835, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:12,069] Trial 468 finished with value: 0.8226718495899223 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.02731308081494954, 'random_strength': 3, 'bagging_temperature': 0.060091633484908265, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:12,534] Trial 469 finished with value: 0.8187655090640165 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.03583804564526757, 'random_strength': 8, 'bagging_temperature': 0.1314181034568348, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:13,001] Trial 470 finished with value: 0.8325398336824732 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.04391897865953804, 'random_strength': 2, 'bagging_temperature': 3.578442675736347, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:13,710] Trial 471 finished with value: 0.84709015035102 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.02981544761741909, 'random_strength': 0, 'bagging_temperature': 0.036636034809159695, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:14,214] Trial 472 finished with value: 0.8183470827148989 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03189546509871429, 'random_strength': 4, 'bagging_temperature': 0.04568338312893896, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:14,736] Trial 473 finished with value: 0.840859352196084 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.0240922277717781, 'random_strength': 2, 'bagging_temperature': 0.21887651318150234, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:15,315] Trial 474 finished with value: 0.8514727276739713 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.038755310665067357, 'random_strength': 0, 'bagging_temperature': 0.16534081256649977, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:15,842] Trial 475 finished with value: 0.8278272336108157 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.03426020094067896, 'random_strength': 4, 'bagging_temperature': 0.11345245503479062, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:16,355] Trial 476 finished with value: 0.8459506827044141 and parameters: {'iterations': 153, 'depth': 10, 'learning_rate': 0.04108042044666711, 'random_strength': 2, 'bagging_temperature': 0.08979251887144961, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:17,027] Trial 477 finished with value: 0.8516957111551706 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.025277646455323516, 'random_strength': 0, 'bagging_temperature': 0.19585726437751325, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:17,569] Trial 478 finished with value: 0.8226718495899223 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.02779191970634917, 'random_strength': 6, 'bagging_temperature': 0.28089133456763904, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:18,074] Trial 479 finished with value: 0.8281925585296372 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.03177958668457438, 'random_strength': 2, 'bagging_temperature': 0.14462539282695275, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:18,597] Trial 480 finished with value: 0.827429728579154 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.04667174008119703, 'random_strength': 4, 'bagging_temperature': 0.2391446963589285, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:19,433] Trial 481 finished with value: 0.8378378378378378 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.03675575618584022, 'random_strength': 0, 'bagging_temperature': 0.178502259950843, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:19,953] Trial 482 finished with value: 0.8415917345645018 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.02932809371477782, 'random_strength': 2, 'bagging_temperature': 0.137830960254854, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:20,620] Trial 483 finished with value: 0.8512233217188787 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.04243480347614783, 'random_strength': 0, 'bagging_temperature': 0.053695380547289055, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:21,087] Trial 484 finished with value: 0.8269994515719551 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.03903812758221932, 'random_strength': 5, 'bagging_temperature': 0.11431798233688337, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:21,281] Trial 485 finished with value: 0.7953905956806795 and parameters: {'iterations': 165, 'depth': 6, 'learning_rate': 0.021283433160276134, 'random_strength': 100, 'bagging_temperature': 0.32531174713926353, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:21,804] Trial 486 finished with value: 0.8325398336824732 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.035522267623498645, 'random_strength': 2, 'bagging_temperature': 0.07211766571326193, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:22,201] Trial 487 finished with value: 0.8424710748057271 and parameters: {'iterations': 173, 'depth': 9, 'learning_rate': 0.03319232756489644, 'random_strength': 0, 'bagging_temperature': 0.21365794450957354, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:22,660] Trial 488 finished with value: 0.8230965538028735 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.05102367975978476, 'random_strength': 4, 'bagging_temperature': 0.16227740936918175, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:23,124] Trial 489 finished with value: 0.827429728579154 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.045155418929083646, 'random_strength': 8, 'bagging_temperature': 0.10029469949979751, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:23,685] Trial 490 finished with value: 0.8325398336824732 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.026125231981700067, 'random_strength': 2, 'bagging_temperature': 0.02312314488736808, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:24,251] Trial 491 finished with value: 0.84709015035102 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.029819199818920852, 'random_strength': 0, 'bagging_temperature': 0.18762684055676046, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:24,804] Trial 492 finished with value: 0.827429728579154 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.022851538673386098, 'random_strength': 4, 'bagging_temperature': 0.13402292043262645, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:25,296] Trial 493 finished with value: 0.836512374443409 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.03857535949953838, 'random_strength': 2, 'bagging_temperature': 0.2375461977553689, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:25,967] Trial 494 finished with value: 0.8422065533382046 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.032064425127109414, 'random_strength': 0, 'bagging_temperature': 0.39067317563581877, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:26,468] Trial 495 finished with value: 0.8278272336108157 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.03595424400638713, 'random_strength': 6, 'bagging_temperature': 0.04141292958818569, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:26,996] Trial 496 finished with value: 0.8187655090640165 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.027809735145476334, 'random_strength': 2, 'bagging_temperature': 0.1530804496111377, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:27,582] Trial 497 finished with value: 0.8422065533382046 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.042447246003858775, 'random_strength': 0, 'bagging_temperature': 2.404978376376096, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:28,037] Trial 498 finished with value: 0.8044843469837604 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.01000039647987729, 'random_strength': 4, 'bagging_temperature': 0.3008138829029526, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:28,503] Trial 499 finished with value: 0.8230965538028735 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.03448138562014761, 'random_strength': 2, 'bagging_temperature': 0.08812884883465093, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:29,199] Trial 500 finished with value: 0.8468468468468469 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.040149315726817666, 'random_strength': 0, 'bagging_temperature': 0.19048660956938007, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:29,732] Trial 501 finished with value: 0.8226718495899223 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.03060745565515826, 'random_strength': 3, 'bagging_temperature': 0.12202258375771026, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:30,287] Trial 502 finished with value: 0.8412404970025789 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.048019534287441344, 'random_strength': 5, 'bagging_temperature': 0.06674894554249286, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:30,863] Trial 503 finished with value: 0.8278272336108157 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.025168449023363, 'random_strength': 2, 'bagging_temperature': 0.1601916503286476, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:31,357] Trial 504 finished with value: 0.8562883964234301 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.037384328107788405, 'random_strength': 0, 'bagging_temperature': 0.029996983090551394, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:31,824] Trial 505 finished with value: 0.8516957111551706 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.03758035588357922, 'random_strength': 0, 'bagging_temperature': 0.05154125144608661, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:32,206] Trial 506 finished with value: 0.8321685254027262 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.04051983409263105, 'random_strength': 3, 'bagging_temperature': 0.028558407803632706, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:32,586] Trial 507 finished with value: 0.8135780982868414 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.03688785590412247, 'random_strength': 6, 'bagging_temperature': 0.03700622449577109, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:32,887] Trial 508 finished with value: 0.8278272336108157 and parameters: {'iterations': 123, 'depth': 9, 'learning_rate': 0.04169366009886167, 'random_strength': 2, 'bagging_temperature': 0.02993138469157069, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:33,363] Trial 509 finished with value: 0.8424710748057271 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.04348067608100331, 'random_strength': 0, 'bagging_temperature': 0.034768891165457776, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:33,801] Trial 510 finished with value: 0.8230965538028735 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.03421829760020764, 'random_strength': 4, 'bagging_temperature': 0.024546204928952844, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:34,239] Trial 511 finished with value: 0.8368889581576149 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.03600113917525816, 'random_strength': 2, 'bagging_temperature': 0.04420173919353831, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:34,775] Trial 512 finished with value: 0.8427075724373022 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.039880058020149114, 'random_strength': 0, 'bagging_temperature': 0.02391710491755488, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:35,171] Trial 513 finished with value: 0.8230965538028735 and parameters: {'iterations': 114, 'depth': 10, 'learning_rate': 0.046017532749423794, 'random_strength': 4, 'bagging_temperature': 0.03498931191280804, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:35,666] Trial 514 finished with value: 0.8230965538028735 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.04420647129692818, 'random_strength': 7, 'bagging_temperature': 0.10887810972691149, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:36,147] Trial 515 finished with value: 0.836512374443409 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.03748057629544668, 'random_strength': 2, 'bagging_temperature': 0.05587857882095609, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:36,695] Trial 516 finished with value: 0.8514727276739713 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.03352518808133531, 'random_strength': 0, 'bagging_temperature': 8.973150929965307, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:37,122] Trial 517 finished with value: 0.8368889581576149 and parameters: {'iterations': 110, 'depth': 10, 'learning_rate': 0.0669728500659059, 'random_strength': 2, 'bagging_temperature': 0.08404198748282993, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:37,827] Trial 518 finished with value: 0.8560848473891952 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.038849053578094275, 'random_strength': 0, 'bagging_temperature': 20.521314113482397, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:38,395] Trial 519 finished with value: 0.8368889581576149 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.0387264336278034, 'random_strength': 4, 'bagging_temperature': 0.017288882914178575, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:38,571] Trial 520 finished with value: 0.8097037845172175 and parameters: {'iterations': 179, 'depth': 5, 'learning_rate': 0.04243545540127122, 'random_strength': 64, 'bagging_temperature': 16.54575195976918, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:39,308] Trial 521 finished with value: 0.8468468468468469 and parameters: {'iterations': 189, 'depth': 10, 'learning_rate': 0.039749679713691, 'random_strength': 0, 'bagging_temperature': 27.84111768894196, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:39,680] Trial 522 finished with value: 0.8368889581576149 and parameters: {'iterations': 105, 'depth': 10, 'learning_rate': 0.037280218588417756, 'random_strength': 2, 'bagging_temperature': 23.394612699916124, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:40,267] Trial 523 finished with value: 0.8321685254027262 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.04902610172943027, 'random_strength': 6, 'bagging_temperature': 27.99324481792386, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:40,824] Trial 524 finished with value: 0.8321685254027262 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.04387203149497134, 'random_strength': 10, 'bagging_temperature': 16.83212286606854, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:41,517] Trial 525 finished with value: 0.8281925585296372 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.059030142018248785, 'random_strength': 0, 'bagging_temperature': 20.895154005928482, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:42,049] Trial 526 finished with value: 0.8321685254027262 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.040294231952874134, 'random_strength': 4, 'bagging_temperature': 0.0203189240560868, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:42,699] Trial 527 finished with value: 0.8412404970025789 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.03631432173937569, 'random_strength': 2, 'bagging_temperature': 20.69211207290352, 'od_type': 'Iter', 'od_wait': 11}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:43,409] Trial 528 finished with value: 0.8514727276739713 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.04173995274973704, 'random_strength': 0, 'bagging_temperature': 13.5746639178938, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:43,669] Trial 529 finished with value: 0.827429728579154 and parameters: {'iterations': 67, 'depth': 10, 'learning_rate': 0.04636635574887098, 'random_strength': 2, 'bagging_temperature': 0.26084757385575763, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:44,203] Trial 530 finished with value: 0.8321685254027262 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.03814313021585542, 'random_strength': 4, 'bagging_temperature': 0.2216143408346316, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:44,907] Trial 531 finished with value: 0.8512233217188787 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.03500081383270768, 'random_strength': 0, 'bagging_temperature': 0.029332743548750637, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:45,483] Trial 532 finished with value: 0.8465761215761216 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.05426093629372173, 'random_strength': 2, 'bagging_temperature': 19.631696564318965, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:45,910] Trial 533 finished with value: 0.8230965538028735 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.022264924205028715, 'random_strength': 5, 'bagging_temperature': 0.2823932601031624, 'od_type': 'Iter', 'od_wait': 30}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:46,666] Trial 534 finished with value: 0.8468468468468469 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.03913365988039986, 'random_strength': 0, 'bagging_temperature': 0.36688594602947266, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:47,170] Trial 535 finished with value: 0.8278272336108157 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.043546249500380746, 'random_strength': 3, 'bagging_temperature': 0.224206023764807, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:47,614] Trial 536 finished with value: 0.8140245822030209 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.034186233677089485, 'random_strength': 8, 'bagging_temperature': 0.17813823182190203, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:48,014] Trial 537 finished with value: 0.8325398336824732 and parameters: {'iterations': 194, 'depth': 9, 'learning_rate': 0.03673435256634932, 'random_strength': 2, 'bagging_temperature': 0.13811424410393763, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:48,239] Trial 538 finished with value: 0.8148130633004671 and parameters: {'iterations': 185, 'depth': 4, 'learning_rate': 0.04104826548338993, 'random_strength': 0, 'bagging_temperature': 0.03207535513892097, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:48,703] Trial 539 finished with value: 0.8368889581576149 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.047284156160118274, 'random_strength': 5, 'bagging_temperature': 0.1798404942953372, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:49,332] Trial 540 finished with value: 0.8281925585296372 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.033669919285617494, 'random_strength': 2, 'bagging_temperature': 15.04640057571956, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:50,058] Trial 541 finished with value: 0.842916430236183 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.018950192859718183, 'random_strength': 0, 'bagging_temperature': 0.2111111383708497, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:50,578] Trial 542 finished with value: 0.8230965538028735 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.03219538096648915, 'random_strength': 3, 'bagging_temperature': 0.2493264967312212, 'od_type': 'Iter', 'od_wait': 28}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:51,070] Trial 543 finished with value: 0.7942921942921943 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.023721412823157716, 'random_strength': 48, 'bagging_temperature': 0.024714527329370475, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:51,775] Trial 544 finished with value: 0.8604743805422155 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.0386197409808999, 'random_strength': 0, 'bagging_temperature': 11.751419026559855, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:52,295] Trial 545 finished with value: 0.827429728579154 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.0396321257395128, 'random_strength': 6, 'bagging_temperature': 14.798060526897846, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:52,787] Trial 546 finished with value: 0.827429728579154 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.04410871339919183, 'random_strength': 58, 'bagging_temperature': 21.181438379160717, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:53,378] Trial 547 finished with value: 0.8368889581576149 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.038549677928539146, 'random_strength': 2, 'bagging_temperature': 13.271018376729504, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:54,085] Trial 548 finished with value: 0.8465761215761216 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.04214054294499798, 'random_strength': 0, 'bagging_temperature': 10.700484495368185, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:54,641] Trial 549 finished with value: 0.8321685254027262 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.03712719024777451, 'random_strength': 4, 'bagging_temperature': 19.18964238302516, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:55,262] Trial 550 finished with value: 0.8278272336108157 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.0419162485813449, 'random_strength': 2, 'bagging_temperature': 11.652646119470184, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:56,000] Trial 551 finished with value: 0.8558558558558559 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.05188499315388346, 'random_strength': 0, 'bagging_temperature': 0.1614010608177393, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:56,746] Trial 552 finished with value: 0.8512233217188787 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.05376262649878957, 'random_strength': 0, 'bagging_temperature': 24.918048586450034, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:57,333] Trial 553 finished with value: 0.8230965538028735 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.05279967610201042, 'random_strength': 4, 'bagging_temperature': 34.52771726647434, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:57,998] Trial 554 finished with value: 0.8415917345645018 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.04955302480923687, 'random_strength': 2, 'bagging_temperature': 15.63606690982869, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:58,688] Trial 555 finished with value: 0.8424710748057271 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.058119118657665954, 'random_strength': 0, 'bagging_temperature': 18.960748587692617, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:59,071] Trial 556 finished with value: 0.8183470827148989 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.051333058012230495, 'random_strength': 7, 'bagging_temperature': 25.569629403146745, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:59,640] Trial 557 finished with value: 0.8415917345645018 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.047841565373799466, 'random_strength': 2, 'bagging_temperature': 6.124554453562062, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:44:59,844] Trial 558 finished with value: 0.827429728579154 and parameters: {'iterations': 171, 'depth': 7, 'learning_rate': 0.04711904906984015, 'random_strength': 4, 'bagging_temperature': 0.15312538340703533, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:00,625] Trial 559 finished with value: 0.8422065533382046 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.0445162175477461, 'random_strength': 0, 'bagging_temperature': 12.373330696638522, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:01,060] Trial 560 finished with value: 0.8317656008930031 and parameters: {'iterations': 119, 'depth': 10, 'learning_rate': 0.0456437175340495, 'random_strength': 2, 'bagging_temperature': 0.13382697278224592, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:01,406] Trial 561 finished with value: 0.8368889581576149 and parameters: {'iterations': 165, 'depth': 9, 'learning_rate': 0.04101703062225688, 'random_strength': 5, 'bagging_temperature': 0.3270163000150434, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:02,022] Trial 562 finished with value: 0.8331897849575306 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.04934923276392539, 'random_strength': 0, 'bagging_temperature': 16.84093962882999, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:02,500] Trial 563 finished with value: 0.8368889581576149 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.03870495006294945, 'random_strength': 3, 'bagging_temperature': 7.765025854586126, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:03,054] Trial 564 finished with value: 0.8459506827044141 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.06276243439670356, 'random_strength': 2, 'bagging_temperature': 0.15040644878530324, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:03,770] Trial 565 finished with value: 0.8604743805422155 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.0356903036427194, 'random_strength': 0, 'bagging_temperature': 0.18271809972640798, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:04,280] Trial 566 finished with value: 0.8278272336108157 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.03530121425134638, 'random_strength': 6, 'bagging_temperature': 0.16246969653727333, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:05,071] Trial 567 finished with value: 0.8558558558558559 and parameters: {'iterations': 194, 'depth': 10, 'learning_rate': 0.036281634549145854, 'random_strength': 0, 'bagging_temperature': 0.12558113581029368, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:05,540] Trial 568 finished with value: 0.827429728579154 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.03622367903705009, 'random_strength': 70, 'bagging_temperature': 0.1073470512884224, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:06,131] Trial 569 finished with value: 0.8321685254027262 and parameters: {'iterations': 198, 'depth': 10, 'learning_rate': 0.03788406198670105, 'random_strength': 4, 'bagging_temperature': 0.12081935870554965, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:08,208] Trial 570 finished with value: 0.8281925585296372 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.03559947666965845, 'random_strength': 2, 'bagging_temperature': 0.1383525487008427, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:09,052] Trial 571 finished with value: 0.8512233217188787 and parameters: {'iterations': 191, 'depth': 10, 'learning_rate': 0.04025360222632793, 'random_strength': 0, 'bagging_temperature': 0.12176827273118786, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:09,869] Trial 572 finished with value: 0.8459506827044141 and parameters: {'iterations': 201, 'depth': 10, 'learning_rate': 0.03653477406944068, 'random_strength': 2, 'bagging_temperature': 0.17811537049710885, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:10,537] Trial 573 finished with value: 0.827429728579154 and parameters: {'iterations': 199, 'depth': 10, 'learning_rate': 0.04314040487415165, 'random_strength': 4, 'bagging_temperature': 0.14265825493370046, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:11,329] Trial 574 finished with value: 0.8558558558558559 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.038981791256308254, 'random_strength': 0, 'bagging_temperature': 0.20726192845218644, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:12,055] Trial 575 finished with value: 0.8278272336108157 and parameters: {'iterations': 193, 'depth': 10, 'learning_rate': 0.033731392077615205, 'random_strength': 2, 'bagging_temperature': 0.20693399517773647, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:13,020] Trial 576 finished with value: 0.8550124072512131 and parameters: {'iterations': 203, 'depth': 10, 'learning_rate': 0.038378490918447625, 'random_strength': 0, 'bagging_temperature': 0.26196662890549954, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:13,778] Trial 577 finished with value: 0.8238465724077614 and parameters: {'iterations': 208, 'depth': 10, 'learning_rate': 0.03516229174150432, 'random_strength': 8, 'bagging_temperature': 0.1997312962503772, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:14,335] Trial 578 finished with value: 0.8135780982868414 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.03922621875291409, 'random_strength': 45, 'bagging_temperature': 0.17024304189618256, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:14,918] Trial 579 finished with value: 0.8234879328004447 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.04385931845902693, 'random_strength': 3, 'bagging_temperature': 0.29125506901590587, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:15,496] Trial 580 finished with value: 0.8234879328004447 and parameters: {'iterations': 195, 'depth': 10, 'learning_rate': 0.037259010392849574, 'random_strength': 6, 'bagging_temperature': 0.2391529372232196, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:16,243] Trial 581 finished with value: 0.8468468468468469 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.03497819255890392, 'random_strength': 0, 'bagging_temperature': 0.1168236064701445, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:16,932] Trial 582 finished with value: 0.8281925585296372 and parameters: {'iterations': 194, 'depth': 10, 'learning_rate': 0.04204466530464446, 'random_strength': 2, 'bagging_temperature': 0.1804316643850741, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:17,520] Trial 583 finished with value: 0.836512374443409 and parameters: {'iterations': 198, 'depth': 10, 'learning_rate': 0.03312112253249001, 'random_strength': 4, 'bagging_temperature': 0.1452023800197867, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:18,293] Trial 584 finished with value: 0.8604743805422155 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.05643124374274996, 'random_strength': 0, 'bagging_temperature': 0.21743453400876467, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:18,947] Trial 585 finished with value: 0.84191359062235 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.05661667182822652, 'random_strength': 2, 'bagging_temperature': 0.21042402665218443, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:19,693] Trial 586 finished with value: 0.8512233217188787 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.05603412868231471, 'random_strength': 0, 'bagging_temperature': 0.10212788970410418, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:20,324] Trial 587 finished with value: 0.8278272336108157 and parameters: {'iterations': 189, 'depth': 10, 'learning_rate': 0.05826224269043021, 'random_strength': 4, 'bagging_temperature': 0.15251442176684066, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:20,982] Trial 588 finished with value: 0.8465761215761216 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.054110026284475476, 'random_strength': 2, 'bagging_temperature': 0.1240044872717578, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:21,428] Trial 589 finished with value: 0.8424710748057271 and parameters: {'iterations': 199, 'depth': 9, 'learning_rate': 0.05094394010121304, 'random_strength': 0, 'bagging_temperature': 0.16345004749046899, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:22,024] Trial 590 finished with value: 0.8281925585296372 and parameters: {'iterations': 194, 'depth': 10, 'learning_rate': 0.061871751485512515, 'random_strength': 6, 'bagging_temperature': 0.20624820378427827, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:22,792] Trial 591 finished with value: 0.8465761215761216 and parameters: {'iterations': 195, 'depth': 10, 'learning_rate': 0.0710647410329052, 'random_strength': 2, 'bagging_temperature': 0.24375988529835177, 'od_type': 'Iter', 'od_wait': 14}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:23,563] Trial 592 finished with value: 0.8422065533382046 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.04967178396520594, 'random_strength': 0, 'bagging_temperature': 0.1761717424350941, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:24,192] Trial 593 finished with value: 0.8412404970025789 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.06105111390850686, 'random_strength': 4, 'bagging_temperature': 0.13215791212012795, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:24,869] Trial 594 finished with value: 0.8550124072512131 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.05330567863059229, 'random_strength': 2, 'bagging_temperature': 0.10249588299024405, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:25,591] Trial 595 finished with value: 0.8512233217188787 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.0329911060841383, 'random_strength': 0, 'bagging_temperature': 0.2010343233638787, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:26,130] Trial 596 finished with value: 0.8135780982868414 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.035859172677347416, 'random_strength': 4, 'bagging_temperature': 0.160394240420965, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:26,771] Trial 597 finished with value: 0.8553200492881156 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.0651756404109359, 'random_strength': 2, 'bagging_temperature': 0.12780250518378533, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:27,509] Trial 598 finished with value: 0.8556010556010556 and parameters: {'iterations': 189, 'depth': 10, 'learning_rate': 0.04641507929116122, 'random_strength': 0, 'bagging_temperature': 0.2468463742754191, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:28,026] Trial 599 finished with value: 0.8135780982868414 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03867083808579717, 'random_strength': 24, 'bagging_temperature': 0.18853425765998275, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:28,583] Trial 600 finished with value: 0.8178941595494262 and parameters: {'iterations': 196, 'depth': 10, 'learning_rate': 0.03158646627883727, 'random_strength': 6, 'bagging_temperature': 0.14614990555406332, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:29,419] Trial 601 finished with value: 0.8593844402022841 and parameters: {'iterations': 214, 'depth': 10, 'learning_rate': 0.034817616277792354, 'random_strength': 2, 'bagging_temperature': 0.09507256941864581, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:30,294] Trial 602 finished with value: 0.8415917345645018 and parameters: {'iterations': 225, 'depth': 10, 'learning_rate': 0.03336261598576419, 'random_strength': 3, 'bagging_temperature': 0.09387667596787867, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:30,939] Trial 603 finished with value: 0.8321685254027262 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.03449902979915179, 'random_strength': 2, 'bagging_temperature': 0.08612761588159921, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:31,739] Trial 604 finished with value: 0.845595020307664 and parameters: {'iterations': 214, 'depth': 10, 'learning_rate': 0.03625663235782283, 'random_strength': 5, 'bagging_temperature': 0.10628931237177258, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:32,792] Trial 605 finished with value: 0.8285262535262534 and parameters: {'iterations': 231, 'depth': 10, 'learning_rate': 0.03211518819233899, 'random_strength': 0, 'bagging_temperature': 0.11259052387493632, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:33,293] Trial 606 finished with value: 0.8226718495899223 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.03498937829203398, 'random_strength': 9, 'bagging_temperature': 0.09417659505446588, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:33,976] Trial 607 finished with value: 0.8230965538028735 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.03172904180058062, 'random_strength': 2, 'bagging_temperature': 0.12213590041498103, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:34,202] Trial 608 finished with value: 0.7905782834818402 and parameters: {'iterations': 52, 'depth': 10, 'learning_rate': 0.037086711278626866, 'random_strength': 4, 'bagging_temperature': 0.1505530594878385, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:34,897] Trial 609 finished with value: 0.8512233217188787 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.04000653495293054, 'random_strength': 0, 'bagging_temperature': 0.12275596038264766, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:35,220] Trial 610 finished with value: 0.83723505544913 and parameters: {'iterations': 216, 'depth': 6, 'learning_rate': 0.044593895564710134, 'random_strength': 2, 'bagging_temperature': 0.07365550484305786, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:36,076] Trial 611 finished with value: 0.8599806088369385 and parameters: {'iterations': 212, 'depth': 10, 'learning_rate': 0.05070323718441, 'random_strength': 2, 'bagging_temperature': 0.0997884286539955, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:36,878] Trial 612 finished with value: 0.8140245822030209 and parameters: {'iterations': 215, 'depth': 10, 'learning_rate': 0.0515862893676851, 'random_strength': 6, 'bagging_temperature': 0.07971355236209561, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:37,603] Trial 613 finished with value: 0.8317656008930031 and parameters: {'iterations': 211, 'depth': 10, 'learning_rate': 0.0507475268013902, 'random_strength': 8, 'bagging_temperature': 0.1059053602434321, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:38,362] Trial 614 finished with value: 0.8278272336108157 and parameters: {'iterations': 214, 'depth': 10, 'learning_rate': 0.01606434666515649, 'random_strength': 4, 'bagging_temperature': 0.09723857225648241, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:38,922] Trial 615 finished with value: 0.83723505544913 and parameters: {'iterations': 224, 'depth': 9, 'learning_rate': 0.05463005385456669, 'random_strength': 3, 'bagging_temperature': 0.14492063229147512, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:39,548] Trial 616 finished with value: 0.8412404970025789 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.049075573575432054, 'random_strength': 2, 'bagging_temperature': 72.0004732511538, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:40,282] Trial 617 finished with value: 0.836512374443409 and parameters: {'iterations': 206, 'depth': 10, 'learning_rate': 0.04632439914644222, 'random_strength': 11, 'bagging_temperature': 0.07062581537451494, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:40,812] Trial 618 finished with value: 0.8187655090640165 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.048585830427664144, 'random_strength': 5, 'bagging_temperature': 0.09348762508175733, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:41,638] Trial 619 finished with value: 0.8368889581576149 and parameters: {'iterations': 207, 'depth': 10, 'learning_rate': 0.057672366213026474, 'random_strength': 2, 'bagging_temperature': 0.17695541484459107, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:42,481] Trial 620 finished with value: 0.8368889581576149 and parameters: {'iterations': 213, 'depth': 10, 'learning_rate': 0.054861165117526256, 'random_strength': 4, 'bagging_temperature': 0.1605736424846568, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:43,053] Trial 621 finished with value: 0.84191359062235 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.052681688292626434, 'random_strength': 0, 'bagging_temperature': 0.13030196118773782, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:43,975] Trial 622 finished with value: 0.8415917345645018 and parameters: {'iterations': 220, 'depth': 10, 'learning_rate': 0.04491716333832747, 'random_strength': 2, 'bagging_temperature': 0.169103064585146, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:44,933] Trial 623 finished with value: 0.8550124072512131 and parameters: {'iterations': 245, 'depth': 10, 'learning_rate': 0.04294516634796827, 'random_strength': 6, 'bagging_temperature': 9.477681577357504, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:45,619] Trial 624 finished with value: 0.8187655090640165 and parameters: {'iterations': 210, 'depth': 10, 'learning_rate': 0.047261581166082374, 'random_strength': 40, 'bagging_temperature': 0.10911140340529232, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:46,340] Trial 625 finished with value: 0.8604743805422155 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03077360327607808, 'random_strength': 0, 'bagging_temperature': 4.312676012386775, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:47,273] Trial 626 finished with value: 0.8550124072512131 and parameters: {'iterations': 231, 'depth': 10, 'learning_rate': 0.03063626811476371, 'random_strength': 2, 'bagging_temperature': 43.40275772598057, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:48,066] Trial 627 finished with value: 0.8412404970025789 and parameters: {'iterations': 217, 'depth': 10, 'learning_rate': 0.030031063229001342, 'random_strength': 4, 'bagging_temperature': 2.708458093547607, 'od_type': 'Iter', 'od_wait': 18}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:48,755] Trial 628 finished with value: 0.8427075724373022 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.03085617100311212, 'random_strength': 0, 'bagging_temperature': 3.6989580202837105, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:49,595] Trial 629 finished with value: 0.8459506827044141 and parameters: {'iterations': 208, 'depth': 10, 'learning_rate': 0.03302303128791163, 'random_strength': 2, 'bagging_temperature': 4.6626640523843585, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:50,427] Trial 630 finished with value: 0.8278272336108157 and parameters: {'iterations': 221, 'depth': 10, 'learning_rate': 0.03390352480234147, 'random_strength': 7, 'bagging_temperature': 1.7535105455080042, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:51,409] Trial 631 finished with value: 0.8378378378378378 and parameters: {'iterations': 220, 'depth': 10, 'learning_rate': 0.029405114653362575, 'random_strength': 0, 'bagging_temperature': 8.216670502758044, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:51,726] Trial 632 finished with value: 0.8135780982868414 and parameters: {'iterations': 148, 'depth': 9, 'learning_rate': 0.03249456344887917, 'random_strength': 4, 'bagging_temperature': 4.300305206481586, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:52,325] Trial 633 finished with value: 0.827429728579154 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.04104296742949306, 'random_strength': 2, 'bagging_temperature': 0.08412640575600584, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:53,071] Trial 634 finished with value: 0.8468468468468469 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.034646064403317814, 'random_strength': 0, 'bagging_temperature': 0.2924415715448099, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:53,598] Trial 635 finished with value: 0.8278272336108157 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.0380926988550031, 'random_strength': 4, 'bagging_temperature': 5.764054841446064, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:54,008] Trial 636 finished with value: 0.8230965538028735 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.032251870291786985, 'random_strength': 53, 'bagging_temperature': 0.2262731134230682, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:54,232] Trial 637 finished with value: 0.8230965538028735 and parameters: {'iterations': 153, 'depth': 7, 'learning_rate': 0.0367015700896424, 'random_strength': 2, 'bagging_temperature': 0.11345609651500045, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:54,681] Trial 638 finished with value: 0.8135780982868414 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.030499838728225794, 'random_strength': 56, 'bagging_temperature': 14.137655926703394, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:55,438] Trial 639 finished with value: 0.8558558558558559 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.040721470850107536, 'random_strength': 0, 'bagging_temperature': 1.4844014422295573, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:55,992] Trial 640 finished with value: 0.8328800815150558 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.028328600351529783, 'random_strength': 2, 'bagging_temperature': 11.585585357866455, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:56,761] Trial 641 finished with value: 0.8550124072512131 and parameters: {'iterations': 203, 'depth': 10, 'learning_rate': 0.034819468023552694, 'random_strength': 5, 'bagging_temperature': 0.13593809780266822, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:57,342] Trial 642 finished with value: 0.84709015035102 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.038500114539219546, 'random_strength': 0, 'bagging_temperature': 0.25404850750480495, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:57,562] Trial 643 finished with value: 0.8097037845172175 and parameters: {'iterations': 173, 'depth': 6, 'learning_rate': 0.031377340101590004, 'random_strength': 3, 'bagging_temperature': 0.19622378500377569, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:58,522] Trial 644 finished with value: 0.8226718495899223 and parameters: {'iterations': 240, 'depth': 10, 'learning_rate': 0.043268407227927956, 'random_strength': 2, 'bagging_temperature': 0.09101693281221516, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:59,181] Trial 645 finished with value: 0.8558558558558559 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.04112196422853914, 'random_strength': 0, 'bagging_temperature': 0.06430966291266929, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:45:59,633] Trial 646 finished with value: 0.8183470827148989 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.03446402310267061, 'random_strength': 7, 'bagging_temperature': 2.97908976172504, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:00,462] Trial 647 finished with value: 0.8550124072512131 and parameters: {'iterations': 227, 'depth': 10, 'learning_rate': 0.03710417447697985, 'random_strength': 4, 'bagging_temperature': 1.1397159593813357, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:00,651] Trial 648 finished with value: 0.8140245822030209 and parameters: {'iterations': 181, 'depth': 4, 'learning_rate': 0.028946150843308115, 'random_strength': 2, 'bagging_temperature': 0.12627374865466973, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:01,238] Trial 649 finished with value: 0.8424710748057271 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.03894511267131573, 'random_strength': 0, 'bagging_temperature': 0.18533176003815197, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:01,615] Trial 650 finished with value: 0.8183470827148989 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.03275986643118288, 'random_strength': 4, 'bagging_temperature': 0.47085324844981574, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:02,162] Trial 651 finished with value: 0.8412404970025789 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.04195545272954242, 'random_strength': 2, 'bagging_temperature': 9.606613647032644, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:02,873] Trial 652 finished with value: 0.8422065533382046 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.035029255610814936, 'random_strength': 0, 'bagging_temperature': 2.0294919279322823, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:03,317] Trial 653 finished with value: 0.827429728579154 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.03719664714140575, 'random_strength': 61, 'bagging_temperature': 7.168758426506302, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:03,796] Trial 654 finished with value: 0.8230965538028735 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.030648635604126173, 'random_strength': 6, 'bagging_temperature': 0.3268378657224061, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:04,372] Trial 655 finished with value: 0.8234879328004447 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.045366918297495194, 'random_strength': 2, 'bagging_temperature': 0.22768371173240684, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:05,077] Trial 656 finished with value: 0.8380954533128446 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.03978472160280981, 'random_strength': 0, 'bagging_temperature': 17.523204682723726, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:05,912] Trial 657 finished with value: 0.8459506827044141 and parameters: {'iterations': 204, 'depth': 10, 'learning_rate': 0.0327010633382305, 'random_strength': 4, 'bagging_temperature': 0.07601320020075343, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:06,443] Trial 658 finished with value: 0.8234879328004447 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.02728261734097498, 'random_strength': 2, 'bagging_temperature': 0.14751746549353978, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:06,996] Trial 659 finished with value: 0.8562883964234301 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.03649471311760922, 'random_strength': 0, 'bagging_temperature': 0.10212736975596831, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:07,552] Trial 660 finished with value: 0.8424710748057271 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.03512025230797795, 'random_strength': 0, 'bagging_temperature': 0.0805984806145283, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:07,935] Trial 661 finished with value: 0.8135780982868414 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.0378495473894048, 'random_strength': 9, 'bagging_temperature': 0.06666405959177985, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:08,305] Trial 662 finished with value: 0.8230965538028735 and parameters: {'iterations': 122, 'depth': 10, 'learning_rate': 0.03514420540927948, 'random_strength': 4, 'bagging_temperature': 0.09912086543836965, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:08,596] Trial 663 finished with value: 0.8230965538028735 and parameters: {'iterations': 131, 'depth': 9, 'learning_rate': 0.031668399715547677, 'random_strength': 2, 'bagging_temperature': 0.09221671693998389, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:09,041] Trial 664 finished with value: 0.8278272336108157 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.036463324466222705, 'random_strength': 6, 'bagging_temperature': 0.10864853508565356, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:09,441] Trial 665 finished with value: 0.8092644368506438 and parameters: {'iterations': 136, 'depth': 10, 'learning_rate': 0.03356044871956606, 'random_strength': 15, 'bagging_temperature': 0.06179224212800754, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:10,006] Trial 666 finished with value: 0.8380954533128446 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.02943120982813818, 'random_strength': 0, 'bagging_temperature': 0.2811223018250191, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:10,442] Trial 667 finished with value: 0.8044843469837604 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.03346813338538165, 'random_strength': 36, 'bagging_temperature': 30.884780545012756, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:10,925] Trial 668 finished with value: 0.827429728579154 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.03711305025607641, 'random_strength': 3, 'bagging_temperature': 0.019271602659464006, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:11,398] Trial 669 finished with value: 0.8230965538028735 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.03991057800993011, 'random_strength': 2, 'bagging_temperature': 0.11297911715628171, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:12,380] Trial 670 finished with value: 0.8288288288288288 and parameters: {'iterations': 220, 'depth': 10, 'learning_rate': 0.03095542233793861, 'random_strength': 0, 'bagging_temperature': 0.07982513099551163, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:12,804] Trial 671 finished with value: 0.8135780982868414 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.03551024772271496, 'random_strength': 4, 'bagging_temperature': 0.22111287950323763, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:13,268] Trial 672 finished with value: 0.836512374443409 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.03863541709358419, 'random_strength': 2, 'bagging_temperature': 0.1701810180433849, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:14,350] Trial 673 finished with value: 0.8427075724373022 and parameters: {'iterations': 237, 'depth': 10, 'learning_rate': 0.02780337217036685, 'random_strength': 0, 'bagging_temperature': 0.045278113898986616, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:14,774] Trial 674 finished with value: 0.8178941595494262 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.0333871363826571, 'random_strength': 6, 'bagging_temperature': 0.13849361148732522, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:15,296] Trial 675 finished with value: 0.840859352196084 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.04143276221305432, 'random_strength': 2, 'bagging_temperature': 24.787625659545352, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:15,840] Trial 676 finished with value: 0.8427075724373022 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.03653918780839635, 'random_strength': 0, 'bagging_temperature': 0.09367651548836216, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:16,375] Trial 677 finished with value: 0.8087888675268976 and parameters: {'iterations': 154, 'depth': 10, 'learning_rate': 0.029927845173386897, 'random_strength': 4, 'bagging_temperature': 0.1896078159108861, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:16,722] Trial 678 finished with value: 0.8187655090640165 and parameters: {'iterations': 117, 'depth': 10, 'learning_rate': 0.07937678200048413, 'random_strength': 21, 'bagging_temperature': 0.3924775124688444, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:17,238] Trial 679 finished with value: 0.8412404970025789 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.03222549114251555, 'random_strength': 2, 'bagging_temperature': 0.12625306457407856, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:17,825] Trial 680 finished with value: 0.8516957111551706 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.039346623384474554, 'random_strength': 0, 'bagging_temperature': 0.25423659147031796, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:18,398] Trial 681 finished with value: 0.8317656008930031 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.034476582195165126, 'random_strength': 5, 'bagging_temperature': 0.9424610904220173, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:18,951] Trial 682 finished with value: 0.8321685254027262 and parameters: {'iterations': 158, 'depth': 10, 'learning_rate': 0.04167981656756011, 'random_strength': 2, 'bagging_temperature': 13.199032370108199, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:19,736] Trial 683 finished with value: 0.8512233217188787 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.03697883259710133, 'random_strength': 0, 'bagging_temperature': 0.15695596157269542, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:20,270] Trial 684 finished with value: 0.8130959183590762 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.03133909933723505, 'random_strength': 4, 'bagging_temperature': 0.2036061665038081, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:20,686] Trial 685 finished with value: 0.790016981343731 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.011401218171898882, 'random_strength': 8, 'bagging_temperature': 0.10588203708602559, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:21,201] Trial 686 finished with value: 0.836512374443409 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.03448864569369289, 'random_strength': 2, 'bagging_temperature': 0.1337647501331589, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:21,828] Trial 687 finished with value: 0.8514727276739713 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.043693322689898326, 'random_strength': 0, 'bagging_temperature': 0.16520565141251514, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:22,393] Trial 688 finished with value: 0.8278272336108157 and parameters: {'iterations': 213, 'depth': 9, 'learning_rate': 0.038214761192914976, 'random_strength': 3, 'bagging_temperature': 0.23547306202794568, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:22,881] Trial 689 finished with value: 0.8230965538028735 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.03005925594990957, 'random_strength': 6, 'bagging_temperature': 0.07354530398171281, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:23,474] Trial 690 finished with value: 0.8234879328004447 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.027393380450656712, 'random_strength': 2, 'bagging_temperature': 16.62022573089495, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 178 with value: 0.8604743805422155.\n",
      "[I 2024-01-12 20:46:24,176] Trial 691 finished with value: 0.8648648648648649 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.04120708926898952, 'random_strength': 0, 'bagging_temperature': 0.015807752863827622, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:24,870] Trial 692 finished with value: 0.84191359062235 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.04592730054649589, 'random_strength': 0, 'bagging_temperature': 0.049380970903324974, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:25,437] Trial 693 finished with value: 0.8230965538028735 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.04202016609735735, 'random_strength': 4, 'bagging_temperature': 0.06006460282283946, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:26,079] Trial 694 finished with value: 0.836512374443409 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.04691876264271967, 'random_strength': 2, 'bagging_temperature': 0.015750598411866937, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:26,243] Trial 695 finished with value: 0.8010650677711588 and parameters: {'iterations': 108, 'depth': 5, 'learning_rate': 0.040325923241249936, 'random_strength': 75, 'bagging_temperature': 0.021769828469794167, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:26,806] Trial 696 finished with value: 0.8140245822030209 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.04395195933946286, 'random_strength': 31, 'bagging_temperature': 0.3013080957979644, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:27,339] Trial 697 finished with value: 0.8516957111551706 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.03991566771557919, 'random_strength': 0, 'bagging_temperature': 0.014486345737737863, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:27,819] Trial 698 finished with value: 0.8278272336108157 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.060590382531879934, 'random_strength': 50, 'bagging_temperature': 0.01966647098851233, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:28,284] Trial 699 finished with value: 0.8226718495899223 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03658328996103858, 'random_strength': 4, 'bagging_temperature': 0.024476371677882185, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:28,762] Trial 700 finished with value: 0.8325398336824732 and parameters: {'iterations': 133, 'depth': 10, 'learning_rate': 0.04306284492517921, 'random_strength': 2, 'bagging_temperature': 0.013847926861277298, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:29,408] Trial 701 finished with value: 0.8468468468468469 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.03281898484283535, 'random_strength': 0, 'bagging_temperature': 22.415093598453147, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:29,910] Trial 702 finished with value: 0.8321685254027262 and parameters: {'iterations': 147, 'depth': 10, 'learning_rate': 0.049899188411901045, 'random_strength': 5, 'bagging_temperature': 0.014535208658669677, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:30,524] Trial 703 finished with value: 0.83723505544913 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.028377931023653935, 'random_strength': 2, 'bagging_temperature': 0.016880166341497235, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:31,227] Trial 704 finished with value: 0.8604743805422155 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.038834627711362285, 'random_strength': 0, 'bagging_temperature': 0.010209589814986979, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:31,724] Trial 705 finished with value: 0.8462775523686227 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.044620814220686145, 'random_strength': 3, 'bagging_temperature': 0.011017505100797275, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:32,035] Trial 706 finished with value: 0.8183470827148989 and parameters: {'iterations': 97, 'depth': 10, 'learning_rate': 0.04014234519775551, 'random_strength': 7, 'bagging_temperature': 0.011204418730614963, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:32,921] Trial 707 finished with value: 0.8288288288288288 and parameters: {'iterations': 250, 'depth': 10, 'learning_rate': 0.047287381086583195, 'random_strength': 0, 'bagging_temperature': 0.015877028006260816, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:33,532] Trial 708 finished with value: 0.8361047435944837 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.03830431753276533, 'random_strength': 2, 'bagging_temperature': 0.012019451634333779, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:33,871] Trial 709 finished with value: 0.8412404970025789 and parameters: {'iterations': 155, 'depth': 9, 'learning_rate': 0.04106831522198294, 'random_strength': 4, 'bagging_temperature': 0.012385520913422805, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:34,461] Trial 710 finished with value: 0.8514727276739713 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.0435922824008233, 'random_strength': 0, 'bagging_temperature': 0.011117115488134361, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:34,767] Trial 711 finished with value: 0.8044843469837604 and parameters: {'iterations': 87, 'depth': 10, 'learning_rate': 0.04154725393378532, 'random_strength': 97, 'bagging_temperature': 0.0281496136974125, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:35,343] Trial 712 finished with value: 0.8317656008930031 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03842130147033272, 'random_strength': 2, 'bagging_temperature': 0.05386348664215321, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:35,782] Trial 713 finished with value: 0.8269994515719551 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.04818653118305701, 'random_strength': 5, 'bagging_temperature': 0.010538617883365398, 'od_type': 'Iter', 'od_wait': 50}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:36,392] Trial 714 finished with value: 0.8560848473891952 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.026321267401382145, 'random_strength': 0, 'bagging_temperature': 0.017798964509279393, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:36,775] Trial 715 finished with value: 0.8154661162009946 and parameters: {'iterations': 76, 'depth': 10, 'learning_rate': 0.026807338693797533, 'random_strength': 0, 'bagging_temperature': 0.016821506245592484, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:37,352] Trial 716 finished with value: 0.83723505544913 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.025522013842601093, 'random_strength': 2, 'bagging_temperature': 0.01433042369120252, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:38,187] Trial 717 finished with value: 0.8415917345645018 and parameters: {'iterations': 222, 'depth': 10, 'learning_rate': 0.025645704056790546, 'random_strength': 3, 'bagging_temperature': 0.020045990346478706, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:38,566] Trial 718 finished with value: 0.8288288288288288 and parameters: {'iterations': 206, 'depth': 7, 'learning_rate': 0.02708060737964828, 'random_strength': 0, 'bagging_temperature': 0.017116443856110077, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:39,104] Trial 719 finished with value: 0.8039786460839093 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.028252861713770297, 'random_strength': 5, 'bagging_temperature': 0.022132310260287412, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:39,655] Trial 720 finished with value: 0.8325398336824732 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.024984172211278275, 'random_strength': 2, 'bagging_temperature': 0.013473481607219813, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:40,343] Trial 721 finished with value: 0.8427075724373022 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.0293963224810561, 'random_strength': 0, 'bagging_temperature': 0.018422634705258296, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:40,830] Trial 722 finished with value: 0.8234879328004447 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.026557028204093787, 'random_strength': 4, 'bagging_temperature': 0.018360051418193555, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:41,346] Trial 723 finished with value: 0.8234879328004447 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.0229218800717171, 'random_strength': 2, 'bagging_temperature': 0.01062818670098416, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:41,882] Trial 724 finished with value: 0.8278272336108157 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.045800762843613556, 'random_strength': 8, 'bagging_temperature': 0.015728613789788595, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:42,624] Trial 725 finished with value: 0.8562883964234301 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.024138621117157345, 'random_strength': 0, 'bagging_temperature': 0.027185649786834458, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:43,177] Trial 726 finished with value: 0.8135780982868414 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.024296520264564372, 'random_strength': 6, 'bagging_temperature': 0.012457260141397931, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:43,701] Trial 727 finished with value: 0.7991466778070471 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.021681943206789962, 'random_strength': 42, 'bagging_temperature': 0.02632719482760617, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:44,192] Trial 728 finished with value: 0.8135780982868414 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.02431529890531441, 'random_strength': 28, 'bagging_temperature': 0.02127647455589345, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:44,936] Trial 729 finished with value: 0.8516957111551706 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.026036334741238946, 'random_strength': 0, 'bagging_temperature': 0.010104718029091105, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:45,603] Trial 730 finished with value: 0.8234879328004447 and parameters: {'iterations': 200, 'depth': 10, 'learning_rate': 0.02423453594497809, 'random_strength': 13, 'bagging_temperature': 0.031208365310274995, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:46,204] Trial 731 finished with value: 0.827429728579154 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.021369153091426184, 'random_strength': 3, 'bagging_temperature': 0.022479795616337155, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:46,811] Trial 732 finished with value: 0.8412404970025789 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.024045531903396856, 'random_strength': 2, 'bagging_temperature': 0.02273348726735635, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:47,562] Trial 733 finished with value: 0.8516957111551706 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.02655078641082593, 'random_strength': 0, 'bagging_temperature': 0.03990783243729986, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:48,236] Trial 734 finished with value: 0.8135780982868414 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.02093305462284649, 'random_strength': 4, 'bagging_temperature': 0.026479855524594312, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:48,832] Trial 735 finished with value: 0.8321685254027262 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.022861334267408173, 'random_strength': 2, 'bagging_temperature': 0.01384280959299746, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:49,231] Trial 736 finished with value: 0.8378378378378378 and parameters: {'iterations': 176, 'depth': 9, 'learning_rate': 0.02788948649737014, 'random_strength': 0, 'bagging_temperature': 0.03009897750982821, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:50,009] Trial 737 finished with value: 0.8178941595494262 and parameters: {'iterations': 211, 'depth': 10, 'learning_rate': 0.05721231198799706, 'random_strength': 6, 'bagging_temperature': 0.017942070203454827, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:50,508] Trial 738 finished with value: 0.8183470827148989 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.029183335176349336, 'random_strength': 67, 'bagging_temperature': 0.02403948930854714, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:51,100] Trial 739 finished with value: 0.8321685254027262 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.022858805524846475, 'random_strength': 2, 'bagging_temperature': 0.03489754587552622, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:51,834] Trial 740 finished with value: 0.8424710748057271 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.0258442135103604, 'random_strength': 0, 'bagging_temperature': 0.015260551465830838, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:52,282] Trial 741 finished with value: 0.7991466778070471 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.019882413700778503, 'random_strength': 4, 'bagging_temperature': 0.03070870469954337, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:52,795] Trial 742 finished with value: 0.8226718495899223 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.027707383244471463, 'random_strength': 10, 'bagging_temperature': 0.04096887444938955, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:53,362] Trial 743 finished with value: 0.8325398336824732 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.05232129278553109, 'random_strength': 2, 'bagging_temperature': 0.013418651854859897, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:53,923] Trial 744 finished with value: 0.8331897849575306 and parameters: {'iterations': 129, 'depth': 10, 'learning_rate': 0.044927275024973685, 'random_strength': 0, 'bagging_temperature': 0.025527505004239927, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:54,484] Trial 745 finished with value: 0.836512374443409 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.06452872903893109, 'random_strength': 4, 'bagging_temperature': 0.018784563872376654, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:55,282] Trial 746 finished with value: 0.8317656008930031 and parameters: {'iterations': 203, 'depth': 10, 'learning_rate': 0.02986223994773696, 'random_strength': 2, 'bagging_temperature': 0.013257643872131233, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:55,724] Trial 747 finished with value: 0.84709015035102 and parameters: {'iterations': 116, 'depth': 10, 'learning_rate': 0.05033054082096678, 'random_strength': 0, 'bagging_temperature': 0.03558784811356791, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:56,538] Trial 748 finished with value: 0.8368889581576149 and parameters: {'iterations': 227, 'depth': 10, 'learning_rate': 0.04329508133737148, 'random_strength': 6, 'bagging_temperature': 11.750372611257186, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:57,324] Trial 749 finished with value: 0.836512374443409 and parameters: {'iterations': 217, 'depth': 10, 'learning_rate': 0.027186720467705337, 'random_strength': 2, 'bagging_temperature': 0.021865978463050988, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:57,874] Trial 750 finished with value: 0.8321685254027262 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.02513142182731736, 'random_strength': 4, 'bagging_temperature': 0.04298143690963835, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:58,671] Trial 751 finished with value: 0.8424710748057271 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.030633706707270638, 'random_strength': 0, 'bagging_temperature': 0.027200681403992684, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:59,225] Trial 752 finished with value: 0.836512374443409 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.04086341734597717, 'random_strength': 2, 'bagging_temperature': 37.89863855151019, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:46:59,892] Trial 753 finished with value: 0.8558558558558559 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.046184303042208996, 'random_strength': 0, 'bagging_temperature': 6.969482983490632, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:00,302] Trial 754 finished with value: 0.8087888675268976 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.02203969506551499, 'random_strength': 4, 'bagging_temperature': 0.017781519009057, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:00,819] Trial 755 finished with value: 0.8226718495899223 and parameters: {'iterations': 195, 'depth': 10, 'learning_rate': 0.0287047905186844, 'random_strength': 7, 'bagging_temperature': 0.02025960834150296, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:01,287] Trial 756 finished with value: 0.8368889581576149 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.04298404400189727, 'random_strength': 2, 'bagging_temperature': 0.010065982116742795, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:01,967] Trial 757 finished with value: 0.8514727276739713 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.038943642728263714, 'random_strength': 0, 'bagging_temperature': 0.030592406611757016, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:02,480] Trial 758 finished with value: 0.8281925585296372 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.04846179113961351, 'random_strength': 3, 'bagging_temperature': 0.01299780149938094, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:02,892] Trial 759 finished with value: 0.8230965538028735 and parameters: {'iterations': 188, 'depth': 9, 'learning_rate': 0.02403973792725159, 'random_strength': 2, 'bagging_temperature': 0.05125541910069136, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:03,392] Trial 760 finished with value: 0.8269994515719551 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03208350200034899, 'random_strength': 5, 'bagging_temperature': 16.295876154555856, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:04,012] Trial 761 finished with value: 0.8422065533382046 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.055545950911557354, 'random_strength': 0, 'bagging_temperature': 28.948898484603877, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:04,460] Trial 762 finished with value: 0.8361047435944837 and parameters: {'iterations': 130, 'depth': 10, 'learning_rate': 0.04155803714889391, 'random_strength': 2, 'bagging_temperature': 0.07296149832793442, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:05,123] Trial 763 finished with value: 0.8606838498730391 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.02570196921099641, 'random_strength': 0, 'bagging_temperature': 0.015284235544047184, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:05,617] Trial 764 finished with value: 0.8226718495899223 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.036711234458818735, 'random_strength': 4, 'bagging_temperature': 0.011899087155646318, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:06,244] Trial 765 finished with value: 0.827429728579154 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03972622903488674, 'random_strength': 2, 'bagging_temperature': 18.115273546726694, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:06,913] Trial 766 finished with value: 0.8562883964234301 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.023500068855626728, 'random_strength': 0, 'bagging_temperature': 0.01541847327393759, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:07,354] Trial 767 finished with value: 0.827429728579154 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.022538979590448944, 'random_strength': 8, 'bagging_temperature': 0.015066965774931601, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:07,875] Trial 768 finished with value: 0.8183470827148989 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.023288276431970123, 'random_strength': 4, 'bagging_temperature': 0.011965015273260125, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:08,421] Trial 769 finished with value: 0.8230965538028735 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.020180402936301408, 'random_strength': 2, 'bagging_temperature': 0.01242646533487155, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:09,101] Trial 770 finished with value: 0.8427075724373022 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.02137995358478118, 'random_strength': 0, 'bagging_temperature': 0.015508721904948463, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:09,629] Trial 771 finished with value: 0.8044843469837604 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.024583233419351157, 'random_strength': 6, 'bagging_temperature': 0.010480955771461496, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:09,922] Trial 772 finished with value: 0.8187655090640165 and parameters: {'iterations': 160, 'depth': 7, 'learning_rate': 0.023406348385014587, 'random_strength': 2, 'bagging_temperature': 0.016577763752225663, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:10,567] Trial 773 finished with value: 0.8473064211998946 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.026036553485460804, 'random_strength': 0, 'bagging_temperature': 0.019428449012689204, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:11,091] Trial 774 finished with value: 0.8130959183590762 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.018183719918073882, 'random_strength': 4, 'bagging_temperature': 0.022043287804199334, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:11,614] Trial 775 finished with value: 0.8234879328004447 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.02118380186648803, 'random_strength': 2, 'bagging_temperature': 0.013250161974142494, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:12,263] Trial 776 finished with value: 0.8473064211998946 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.02463651065007262, 'random_strength': 0, 'bagging_temperature': 0.014302568973829966, 'od_type': 'Iter', 'od_wait': 47}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:12,763] Trial 777 finished with value: 0.8135780982868414 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.022975228264885263, 'random_strength': 4, 'bagging_temperature': 0.03785406047750987, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:13,328] Trial 778 finished with value: 0.8234879328004447 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.028035522882921354, 'random_strength': 2, 'bagging_temperature': 0.01607074937783234, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:14,433] Trial 779 finished with value: 0.8462775523686227 and parameters: {'iterations': 261, 'depth': 10, 'learning_rate': 0.02594729310529276, 'random_strength': 0, 'bagging_temperature': 2.4407636989133423, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:14,965] Trial 780 finished with value: 0.8140245822030209 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.024667235820310874, 'random_strength': 6, 'bagging_temperature': 0.6788094282121141, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:15,499] Trial 781 finished with value: 0.827429728579154 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.02225053129652786, 'random_strength': 3, 'bagging_temperature': 0.05857003116702449, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:15,685] Trial 782 finished with value: 0.8234879328004447 and parameters: {'iterations': 120, 'depth': 5, 'learning_rate': 0.030485654226440704, 'random_strength': 0, 'bagging_temperature': 0.04376399284347859, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:16,244] Trial 783 finished with value: 0.83723505544913 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.02847298990836184, 'random_strength': 2, 'bagging_temperature': 0.026722600325514805, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:16,841] Trial 784 finished with value: 0.8321685254027262 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.06938531978321692, 'random_strength': 5, 'bagging_temperature': 0.01143840961333096, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:17,458] Trial 785 finished with value: 0.8427075724373022 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.026124147832219745, 'random_strength': 0, 'bagging_temperature': 0.058191474448133364, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:17,926] Trial 786 finished with value: 0.8230965538028735 and parameters: {'iterations': 210, 'depth': 9, 'learning_rate': 0.019959135761923083, 'random_strength': 3, 'bagging_temperature': 0.08748691872231763, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:18,634] Trial 787 finished with value: 0.8281925585296372 and parameters: {'iterations': 199, 'depth': 10, 'learning_rate': 0.03119111752274445, 'random_strength': 2, 'bagging_temperature': 0.018707768699131582, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:19,099] Trial 788 finished with value: 0.8378378378378378 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.049878396940465815, 'random_strength': 0, 'bagging_temperature': 0.024127179882695714, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:19,480] Trial 789 finished with value: 0.8183470827148989 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.0599954403600196, 'random_strength': 4, 'bagging_temperature': 0.014054928406710122, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:20,019] Trial 790 finished with value: 0.8183470827148989 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.02849701642023007, 'random_strength': 8, 'bagging_temperature': 0.010272449636418757, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:20,555] Trial 791 finished with value: 0.8368889581576149 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.0335765266364117, 'random_strength': 2, 'bagging_temperature': 3.127690861969438, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:21,439] Trial 792 finished with value: 0.8328800815150558 and parameters: {'iterations': 271, 'depth': 10, 'learning_rate': 0.04591118280879926, 'random_strength': 0, 'bagging_temperature': 4.1718611716771665, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:21,961] Trial 793 finished with value: 0.8226718495899223 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.02436643153744339, 'random_strength': 5, 'bagging_temperature': 0.07720632247532899, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:22,582] Trial 794 finished with value: 0.8278272336108157 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.027175210334956634, 'random_strength': 2, 'bagging_temperature': 9.692067363128773, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:23,223] Trial 795 finished with value: 0.8422065533382046 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.05244177957753642, 'random_strength': 0, 'bagging_temperature': 0.03415844450651583, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:23,678] Trial 796 finished with value: 0.799683575504369 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.029921208988523063, 'random_strength': 38, 'bagging_temperature': 0.09092773219522084, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:24,282] Trial 797 finished with value: 0.836512374443409 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.03498319931288345, 'random_strength': 3, 'bagging_temperature': 1.2813770187260645, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:24,741] Trial 798 finished with value: 0.799683575504369 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.022093470406462683, 'random_strength': 33, 'bagging_temperature': 0.19072078964123204, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:25,266] Trial 799 finished with value: 0.84709015035102 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.03264056642234606, 'random_strength': 0, 'bagging_temperature': 0.016183965367688707, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:25,642] Trial 800 finished with value: 0.8234879328004447 and parameters: {'iterations': 176, 'depth': 9, 'learning_rate': 0.042712231243016416, 'random_strength': 6, 'bagging_temperature': 0.012760930783079268, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:26,186] Trial 801 finished with value: 0.8368889581576149 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.026446288910811123, 'random_strength': 2, 'bagging_temperature': 0.10805730428314864, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:26,798] Trial 802 finished with value: 0.8140245822030209 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.035951339319888934, 'random_strength': 4, 'bagging_temperature': 0.04446557943270411, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:27,402] Trial 803 finished with value: 0.8474960166283303 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.02344467931014364, 'random_strength': 0, 'bagging_temperature': 0.2235793116739729, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:27,993] Trial 804 finished with value: 0.8321685254027262 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.03163682716975286, 'random_strength': 2, 'bagging_temperature': 0.020405437129958317, 'od_type': 'Iter', 'od_wait': 21}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:28,741] Trial 805 finished with value: 0.8556010556010556 and parameters: {'iterations': 216, 'depth': 10, 'learning_rate': 0.04825834791408693, 'random_strength': 4, 'bagging_temperature': 0.18145315364950604, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:29,437] Trial 806 finished with value: 0.8465761215761216 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.04397163894376889, 'random_strength': 0, 'bagging_temperature': 0.029567693629771085, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:29,896] Trial 807 finished with value: 0.799683575504369 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.038343126387176775, 'random_strength': 19, 'bagging_temperature': 0.06484056395874728, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:30,564] Trial 808 finished with value: 0.8412404970025789 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.029262053046031935, 'random_strength': 2, 'bagging_temperature': 0.05101316420883938, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:31,501] Trial 809 finished with value: 0.8269994515719551 and parameters: {'iterations': 236, 'depth': 10, 'learning_rate': 0.04093213349852026, 'random_strength': 2, 'bagging_temperature': 0.01007879265313601, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:31,965] Trial 810 finished with value: 0.8178941595494262 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.0342278710227929, 'random_strength': 6, 'bagging_temperature': 4.981161371335558, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:32,656] Trial 811 finished with value: 0.8512233217188787 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.0541280660218495, 'random_strength': 0, 'bagging_temperature': 6.361502001367165, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:33,192] Trial 812 finished with value: 0.827429728579154 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.024892868596401666, 'random_strength': 4, 'bagging_temperature': 0.2586912502604793, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:33,686] Trial 813 finished with value: 0.836512374443409 and parameters: {'iterations': 125, 'depth': 10, 'learning_rate': 0.04709247559769517, 'random_strength': 2, 'bagging_temperature': 0.1160268361339776, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:34,278] Trial 814 finished with value: 0.8424710748057271 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.03165727034581048, 'random_strength': 0, 'bagging_temperature': 0.015628340297987247, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:34,791] Trial 815 finished with value: 0.8226718495899223 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.03681251434282443, 'random_strength': 4, 'bagging_temperature': 0.15450863496335818, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:35,486] Trial 816 finished with value: 0.8459506827044141 and parameters: {'iterations': 205, 'depth': 10, 'learning_rate': 0.041817276556703885, 'random_strength': 7, 'bagging_temperature': 0.20158840856985805, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:36,038] Trial 817 finished with value: 0.8230965538028735 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03455315943003082, 'random_strength': 2, 'bagging_temperature': 0.08208529861644684, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:36,725] Trial 818 finished with value: 0.8606838498730391 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.027523572903007807, 'random_strength': 0, 'bagging_temperature': 0.03721908656925616, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:37,429] Trial 819 finished with value: 0.8560848473891952 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.02666633234836525, 'random_strength': 0, 'bagging_temperature': 0.037252260744974876, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:38,012] Trial 820 finished with value: 0.8234879328004447 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.027403201980408114, 'random_strength': 2, 'bagging_temperature': 0.04721752334610039, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:38,568] Trial 821 finished with value: 0.8135780982868414 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.025686644633511762, 'random_strength': 4, 'bagging_temperature': 0.033198486551166785, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:39,264] Trial 822 finished with value: 0.8560848473891952 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.028975446024552095, 'random_strength': 0, 'bagging_temperature': 0.03093035791648608, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:39,845] Trial 823 finished with value: 0.8187655090640165 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.027391808585293793, 'random_strength': 2, 'bagging_temperature': 0.036650036150943886, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:40,362] Trial 824 finished with value: 0.8183470827148989 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.02414124240397446, 'random_strength': 4, 'bagging_temperature': 0.04505304757968264, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:41,173] Trial 825 finished with value: 0.8380954533128446 and parameters: {'iterations': 190, 'depth': 10, 'learning_rate': 0.029433991764783663, 'random_strength': 0, 'bagging_temperature': 0.03827249619520636, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:41,684] Trial 826 finished with value: 0.8183470827148989 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.02299717746233001, 'random_strength': 6, 'bagging_temperature': 0.028282235327189608, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:42,293] Trial 827 finished with value: 0.8281925585296372 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.03045245895862575, 'random_strength': 2, 'bagging_temperature': 0.024552518142953176, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:42,947] Trial 828 finished with value: 0.842916430236183 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.0207651234272481, 'random_strength': 0, 'bagging_temperature': 0.050888599250331304, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:43,495] Trial 829 finished with value: 0.827429728579154 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.02551839198734236, 'random_strength': 3, 'bagging_temperature': 0.04006381036353197, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:43,828] Trial 830 finished with value: 0.8187655090640165 and parameters: {'iterations': 222, 'depth': 6, 'learning_rate': 0.026890456045940515, 'random_strength': 9, 'bagging_temperature': 0.06318103977223173, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:44,464] Trial 831 finished with value: 0.8368889581576149 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.028961006022524466, 'random_strength': 2, 'bagging_temperature': 0.03267183740160611, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:44,735] Trial 832 finished with value: 0.8087888675268976 and parameters: {'iterations': 102, 'depth': 9, 'learning_rate': 0.0315861805285215, 'random_strength': 12, 'bagging_temperature': 0.019739206677369694, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:45,292] Trial 833 finished with value: 0.8183470827148989 and parameters: {'iterations': 195, 'depth': 10, 'learning_rate': 0.02495537725540389, 'random_strength': 5, 'bagging_temperature': 0.04188195715854112, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:45,953] Trial 834 finished with value: 0.8244677690692389 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.014589199789036843, 'random_strength': 0, 'bagging_temperature': 0.07325124264926244, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:46,600] Trial 835 finished with value: 0.8415917345645018 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.03287445010296436, 'random_strength': 2, 'bagging_temperature': 0.02419147047870713, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:47,095] Trial 836 finished with value: 0.8039786460839093 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.018814723468276853, 'random_strength': 4, 'bagging_temperature': 0.02965821894593567, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:47,810] Trial 837 finished with value: 0.8516957111551706 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.021882116962448815, 'random_strength': 0, 'bagging_temperature': 0.013406666889719965, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:48,267] Trial 838 finished with value: 0.8230965538028735 and parameters: {'iterations': 132, 'depth': 10, 'learning_rate': 0.027842189945139446, 'random_strength': 2, 'bagging_temperature': 0.03444375073084366, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:48,378] Trial 839 finished with value: 0.799683575504369 and parameters: {'iterations': 116, 'depth': 4, 'learning_rate': 0.030335691957078116, 'random_strength': 6, 'bagging_temperature': 0.04859547092869808, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:49,048] Trial 840 finished with value: 0.84709015035102 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.023425595925981136, 'random_strength': 0, 'bagging_temperature': 0.09067007046874202, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:49,617] Trial 841 finished with value: 0.83723505544913 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.07443451934205587, 'random_strength': 3, 'bagging_temperature': 0.02477223158037861, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:50,203] Trial 842 finished with value: 0.83723505544913 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.028462571551280274, 'random_strength': 2, 'bagging_temperature': 0.05943467355353563, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:50,873] Trial 843 finished with value: 0.8514727276739713 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.032190776604040086, 'random_strength': 0, 'bagging_temperature': 0.10328528575814298, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:51,432] Trial 844 finished with value: 0.8135780982868414 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.033916337955572584, 'random_strength': 4, 'bagging_temperature': 0.017336473395817547, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:52,025] Trial 845 finished with value: 0.8325398336824732 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.026076027323262026, 'random_strength': 2, 'bagging_temperature': 0.06806061732518645, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:52,692] Trial 846 finished with value: 0.8602400900995527 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.030365513149640866, 'random_strength': 0, 'bagging_temperature': 0.8259865118977765, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:53,186] Trial 847 finished with value: 0.8178941595494262 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.029543354730992427, 'random_strength': 7, 'bagging_temperature': 1.6081061241658157, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:53,914] Trial 848 finished with value: 0.8560848473891952 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.03082406887910632, 'random_strength': 0, 'bagging_temperature': 3.5575038825972207, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:54,466] Trial 849 finished with value: 0.8222131906342433 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.028316833114155938, 'random_strength': 4, 'bagging_temperature': 0.7744117548061373, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:55,040] Trial 850 finished with value: 0.8459506827044141 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.030851419712983434, 'random_strength': 2, 'bagging_temperature': 0.3521688965455431, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:55,774] Trial 851 finished with value: 0.8514727276739713 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.027577187546432673, 'random_strength': 0, 'bagging_temperature': 0.5784373187270533, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:56,324] Trial 852 finished with value: 0.8135780982868414 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.02586645290427463, 'random_strength': 4, 'bagging_temperature': 1.167965087466431, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:56,583] Trial 853 finished with value: 0.827429728579154 and parameters: {'iterations': 59, 'depth': 10, 'learning_rate': 0.03132175880751782, 'random_strength': 2, 'bagging_temperature': 2.2305721031423476, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:57,161] Trial 854 finished with value: 0.8130959183590762 and parameters: {'iterations': 191, 'depth': 10, 'learning_rate': 0.025017214646966105, 'random_strength': 6, 'bagging_temperature': 0.6873257987562942, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:57,842] Trial 855 finished with value: 0.8468468468468469 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.029296218803320277, 'random_strength': 0, 'bagging_temperature': 10.753322226180883, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:58,162] Trial 856 finished with value: 0.8226718495899223 and parameters: {'iterations': 183, 'depth': 8, 'learning_rate': 0.033233432039952646, 'random_strength': 91, 'bagging_temperature': 0.042160805985248545, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:58,749] Trial 857 finished with value: 0.8325398336824732 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.02752637288123923, 'random_strength': 2, 'bagging_temperature': 0.4703818436489942, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:59,028] Trial 858 finished with value: 0.8144360319184163 and parameters: {'iterations': 177, 'depth': 7, 'learning_rate': 0.056541526243812194, 'random_strength': 4, 'bagging_temperature': 1.0317763523643715, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:47:59,387] Trial 859 finished with value: 0.8087888675268976 and parameters: {'iterations': 126, 'depth': 10, 'learning_rate': 0.030008478789867014, 'random_strength': 46, 'bagging_temperature': 0.7978163441202039, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:00,289] Trial 860 finished with value: 0.8558558558558559 and parameters: {'iterations': 211, 'depth': 10, 'learning_rate': 0.023938721106844172, 'random_strength': 0, 'bagging_temperature': 0.014865290507985966, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:00,941] Trial 861 finished with value: 0.83723505544913 and parameters: {'iterations': 199, 'depth': 10, 'learning_rate': 0.03309380884505524, 'random_strength': 2, 'bagging_temperature': 0.31034177250142203, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:01,401] Trial 862 finished with value: 0.7948613738087422 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.026815488185873763, 'random_strength': 25, 'bagging_temperature': 0.028422274328807638, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:02,146] Trial 863 finished with value: 0.8512233217188787 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.06335523589890808, 'random_strength': 0, 'bagging_temperature': 0.39882193181869724, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:02,701] Trial 864 finished with value: 0.8317656008930031 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.0349278023289243, 'random_strength': 5, 'bagging_temperature': 1.8176862434721175, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:03,153] Trial 865 finished with value: 0.8230965538028735 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.02887489777277967, 'random_strength': 8, 'bagging_temperature': 1.4521861478524327, 'od_type': 'Iter', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:03,599] Trial 866 finished with value: 0.8234879328004447 and parameters: {'iterations': 120, 'depth': 10, 'learning_rate': 0.0317352658476122, 'random_strength': 2, 'bagging_temperature': 0.021017539887999825, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:04,220] Trial 867 finished with value: 0.827429728579154 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.021689066508597157, 'random_strength': 3, 'bagging_temperature': 0.010067950646913008, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:04,903] Trial 868 finished with value: 0.8606838498730391 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.0252048854246385, 'random_strength': 0, 'bagging_temperature': 0.05349898984316548, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:05,328] Trial 869 finished with value: 0.8293424707528233 and parameters: {'iterations': 184, 'depth': 9, 'learning_rate': 0.021230451118478193, 'random_strength': 0, 'bagging_temperature': 0.051775155229737975, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:05,991] Trial 870 finished with value: 0.840859352196084 and parameters: {'iterations': 192, 'depth': 10, 'learning_rate': 0.023776921774624208, 'random_strength': 2, 'bagging_temperature': 0.05485457395911815, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:06,217] Trial 871 finished with value: 0.799683575504369 and parameters: {'iterations': 180, 'depth': 5, 'learning_rate': 0.036088111531361676, 'random_strength': 5, 'bagging_temperature': 0.04503602453311616, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:07,195] Trial 872 finished with value: 0.8424710748057271 and parameters: {'iterations': 229, 'depth': 10, 'learning_rate': 0.022914346546016946, 'random_strength': 0, 'bagging_temperature': 0.05731453930485099, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:07,766] Trial 873 finished with value: 0.8230965538028735 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.025020164862357135, 'random_strength': 3, 'bagging_temperature': 0.06885587958026851, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:08,399] Trial 874 finished with value: 0.8238465724077614 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.022639745556295613, 'random_strength': 2, 'bagging_temperature': 0.03878471162450346, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:09,074] Trial 875 finished with value: 0.8604743805422155 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.03318884781665819, 'random_strength': 0, 'bagging_temperature': 0.03252325036882782, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:09,593] Trial 876 finished with value: 0.8187655090640165 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.03498126537307009, 'random_strength': 6, 'bagging_temperature': 0.0472970016928517, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:09,800] Trial 877 finished with value: 0.8057795541931729 and parameters: {'iterations': 132, 'depth': 6, 'learning_rate': 0.03728640834665114, 'random_strength': 73, 'bagging_temperature': 0.03465590576959109, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:10,462] Trial 878 finished with value: 0.8514727276739713 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.03380248152723536, 'random_strength': 0, 'bagging_temperature': 0.028123861210508992, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:10,968] Trial 879 finished with value: 0.8226718495899223 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.036484907101628904, 'random_strength': 4, 'bagging_temperature': 0.033007254881735934, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:11,439] Trial 880 finished with value: 0.8226718495899223 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.034527452874663724, 'random_strength': 10, 'bagging_temperature': 0.04178378468509402, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:11,975] Trial 881 finished with value: 0.8230965538028735 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.01972695903024019, 'random_strength': 2, 'bagging_temperature': 0.05073356569803604, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:12,705] Trial 882 finished with value: 0.8468468468468469 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.03213239221293691, 'random_strength': 0, 'bagging_temperature': 0.039229679441114274, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:13,262] Trial 883 finished with value: 0.8278272336108157 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.038022800959196204, 'random_strength': 4, 'bagging_temperature': 0.03887557192320731, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:14,069] Trial 884 finished with value: 0.8459506827044141 and parameters: {'iterations': 218, 'depth': 10, 'learning_rate': 0.032285821944926255, 'random_strength': 2, 'bagging_temperature': 0.02591797036891361, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:14,593] Trial 885 finished with value: 0.8422065533382046 and parameters: {'iterations': 137, 'depth': 10, 'learning_rate': 0.05774421725056891, 'random_strength': 0, 'bagging_temperature': 0.029416703475344544, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:15,327] Trial 886 finished with value: 0.8368889581576149 and parameters: {'iterations': 203, 'depth': 10, 'learning_rate': 0.03584724786753526, 'random_strength': 2, 'bagging_temperature': 0.05644444794010938, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:15,721] Trial 887 finished with value: 0.8140245822030209 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.024767786788293923, 'random_strength': 6, 'bagging_temperature': 0.03381804909340113, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:16,070] Trial 888 finished with value: 0.8230965538028735 and parameters: {'iterations': 162, 'depth': 9, 'learning_rate': 0.03883812472652071, 'random_strength': 4, 'bagging_temperature': 0.01973722120948175, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:16,749] Trial 889 finished with value: 0.8514727276739713 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03457541251746648, 'random_strength': 0, 'bagging_temperature': 0.04535195390140616, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:17,325] Trial 890 finished with value: 0.8462775523686227 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.05197060065811872, 'random_strength': 2, 'bagging_temperature': 0.023307146534296264, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:18,069] Trial 891 finished with value: 0.8473064211998946 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.02055871837591951, 'random_strength': 0, 'bagging_temperature': 0.032786011832450675, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:18,661] Trial 892 finished with value: 0.8278272336108157 and parameters: {'iterations': 197, 'depth': 10, 'learning_rate': 0.03227467373096997, 'random_strength': 3, 'bagging_temperature': 0.062469384492899536, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:19,250] Trial 893 finished with value: 0.8317656008930031 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.025778576231115704, 'random_strength': 2, 'bagging_temperature': 0.02695056607499901, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:19,623] Trial 894 finished with value: 0.8135780982868414 and parameters: {'iterations': 121, 'depth': 10, 'learning_rate': 0.022855364513104905, 'random_strength': 4, 'bagging_temperature': 0.037596010957285424, 'od_type': 'Iter', 'od_wait': 12}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:20,096] Trial 895 finished with value: 0.8226718495899223 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.03751507912637556, 'random_strength': 65, 'bagging_temperature': 0.5080407537056718, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:20,573] Trial 896 finished with value: 0.8183470827148989 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.03054840021330008, 'random_strength': 8, 'bagging_temperature': 0.011977009861587389, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:21,064] Trial 897 finished with value: 0.8321685254027262 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.04940021966947434, 'random_strength': 59, 'bagging_temperature': 0.05071372618821655, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:21,642] Trial 898 finished with value: 0.84709015035102 and parameters: {'iterations': 134, 'depth': 10, 'learning_rate': 0.03967204215523969, 'random_strength': 0, 'bagging_temperature': 2.7877187485966344, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:22,453] Trial 899 finished with value: 0.836512374443409 and parameters: {'iterations': 209, 'depth': 10, 'learning_rate': 0.03484299989510343, 'random_strength': 2, 'bagging_temperature': 0.018197271029011284, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:22,909] Trial 900 finished with value: 0.8187655090640165 and parameters: {'iterations': 168, 'depth': 10, 'learning_rate': 0.04524834774067506, 'random_strength': 94, 'bagging_temperature': 0.039080287196534266, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:23,458] Trial 901 finished with value: 0.8178941595494262 and parameters: {'iterations': 184, 'depth': 10, 'learning_rate': 0.028515694714428073, 'random_strength': 6, 'bagging_temperature': 0.021311242679578374, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:24,101] Trial 902 finished with value: 0.8516957111551706 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.02660649654819003, 'random_strength': 0, 'bagging_temperature': 0.031986485499433795, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:24,616] Trial 903 finished with value: 0.8230965538028735 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.033118799698934366, 'random_strength': 4, 'bagging_temperature': 0.04495583343191184, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:24,998] Trial 904 finished with value: 0.827429728579154 and parameters: {'iterations': 112, 'depth': 10, 'learning_rate': 0.03818297243316119, 'random_strength': 2, 'bagging_temperature': 0.06256699213282288, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:25,656] Trial 905 finished with value: 0.8606838498730391 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.02378002551803667, 'random_strength': 0, 'bagging_temperature': 0.016657568742127246, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:26,301] Trial 906 finished with value: 0.827429728579154 and parameters: {'iterations': 187, 'depth': 10, 'learning_rate': 0.03127936408719991, 'random_strength': 2, 'bagging_temperature': 8.450488592090943, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:26,820] Trial 907 finished with value: 0.8226718495899223 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03590811677196813, 'random_strength': 5, 'bagging_temperature': 0.028451216280434004, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:27,329] Trial 908 finished with value: 0.8044843469837604 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.041430166706185274, 'random_strength': 17, 'bagging_temperature': 0.02265502131639306, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:28,057] Trial 909 finished with value: 0.8380954533128446 and parameters: {'iterations': 193, 'depth': 10, 'learning_rate': 0.028419058482117517, 'random_strength': 0, 'bagging_temperature': 0.01756071163148327, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:28,635] Trial 910 finished with value: 0.8183470827148989 and parameters: {'iterations': 191, 'depth': 10, 'learning_rate': 0.025286542432140034, 'random_strength': 4, 'bagging_temperature': 0.025165918361271303, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:28,999] Trial 911 finished with value: 0.84191359062235 and parameters: {'iterations': 177, 'depth': 9, 'learning_rate': 0.054121804439817324, 'random_strength': 2, 'bagging_temperature': 0.03590061551449361, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:29,726] Trial 912 finished with value: 0.8514727276739713 and parameters: {'iterations': 186, 'depth': 10, 'learning_rate': 0.03354536783500194, 'random_strength': 0, 'bagging_temperature': 0.055064732691894235, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:30,317] Trial 913 finished with value: 0.8321685254027262 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.044227549375031705, 'random_strength': 2, 'bagging_temperature': 0.04640070505640023, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:30,876] Trial 914 finished with value: 0.8473064211998946 and parameters: {'iterations': 128, 'depth': 10, 'learning_rate': 0.02959003868514584, 'random_strength': 0, 'bagging_temperature': 5.584542408594823, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:31,446] Trial 915 finished with value: 0.8368889581576149 and parameters: {'iterations': 182, 'depth': 10, 'learning_rate': 0.036967259247885347, 'random_strength': 4, 'bagging_temperature': 0.012744108351838946, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:31,776] Trial 916 finished with value: 0.8321685254027262 and parameters: {'iterations': 190, 'depth': 8, 'learning_rate': 0.04796029010834907, 'random_strength': 2, 'bagging_temperature': 0.07127585747455006, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:32,639] Trial 917 finished with value: 0.8183470827148989 and parameters: {'iterations': 255, 'depth': 10, 'learning_rate': 0.03972187537305938, 'random_strength': 7, 'bagging_temperature': 0.030113849372093847, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:33,340] Trial 918 finished with value: 0.8606838498730391 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.02454444062551588, 'random_strength': 0, 'bagging_temperature': 0.4242157343786548, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:33,905] Trial 919 finished with value: 0.8135780982868414 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.03080149738598418, 'random_strength': 4, 'bagging_temperature': 0.8615532523269613, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:34,081] Trial 920 finished with value: 0.790016981343731 and parameters: {'iterations': 172, 'depth': 4, 'learning_rate': 0.017155051133818107, 'random_strength': 2, 'bagging_temperature': 0.4784375255086456, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:34,535] Trial 921 finished with value: 0.8317656008930031 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.03293022369974396, 'random_strength': 55, 'bagging_temperature': 0.41116178534593195, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:35,480] Trial 922 finished with value: 0.8378378378378378 and parameters: {'iterations': 225, 'depth': 10, 'learning_rate': 0.027367475505777582, 'random_strength': 0, 'bagging_temperature': 0.35158765705712164, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:35,901] Trial 923 finished with value: 0.8321685254027262 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.05966162295128491, 'random_strength': 6, 'bagging_temperature': 0.24562640950388745, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:36,699] Trial 924 finished with value: 0.8317656008930031 and parameters: {'iterations': 215, 'depth': 10, 'learning_rate': 0.036928971645131925, 'random_strength': 2, 'bagging_temperature': 0.6140080444359618, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:37,373] Trial 925 finished with value: 0.8468468468468469 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.04079637066214382, 'random_strength': 0, 'bagging_temperature': 0.4311206478985219, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:37,908] Trial 926 finished with value: 0.8178941595494262 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.02634948486443658, 'random_strength': 4, 'bagging_temperature': 1.0792775976770175, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:38,468] Trial 927 finished with value: 0.827429728579154 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.034347953750920084, 'random_strength': 2, 'bagging_temperature': 0.6211356560486682, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:39,140] Trial 928 finished with value: 0.8465761215761216 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.09435368011738375, 'random_strength': 0, 'bagging_temperature': 0.33634360043286404, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:39,730] Trial 929 finished with value: 0.8278272336108157 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.030227398321590732, 'random_strength': 3, 'bagging_temperature': 0.29228496169431156, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:40,268] Trial 930 finished with value: 0.8317656008930031 and parameters: {'iterations': 173, 'depth': 10, 'learning_rate': 0.043780367476831596, 'random_strength': 5, 'bagging_temperature': 68.4329191934692, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:40,785] Trial 931 finished with value: 0.8288288288288288 and parameters: {'iterations': 131, 'depth': 10, 'learning_rate': 0.022123594471890884, 'random_strength': 0, 'bagging_temperature': 0.373887912218872, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:41,356] Trial 932 finished with value: 0.8278272336108157 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.038777718843146104, 'random_strength': 2, 'bagging_temperature': 0.2673617923491962, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:41,770] Trial 933 finished with value: 0.8039786460839093 and parameters: {'iterations': 160, 'depth': 10, 'learning_rate': 0.02860449318729093, 'random_strength': 44, 'bagging_temperature': 0.7434815543770252, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:42,221] Trial 934 finished with value: 0.836512374443409 and parameters: {'iterations': 123, 'depth': 10, 'learning_rate': 0.051107723452562336, 'random_strength': 2, 'bagging_temperature': 0.4377095468246615, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:42,687] Trial 935 finished with value: 0.827429728579154 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.024398793203708417, 'random_strength': 8, 'bagging_temperature': 0.5927242836367589, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:43,354] Trial 936 finished with value: 0.8424710748057271 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.03286556124448473, 'random_strength': 0, 'bagging_temperature': 1.3099352900299501, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:43,905] Trial 937 finished with value: 0.8183470827148989 and parameters: {'iterations': 181, 'depth': 10, 'learning_rate': 0.03536484826146847, 'random_strength': 4, 'bagging_temperature': 0.9325355318304163, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:44,370] Trial 938 finished with value: 0.8278272336108157 and parameters: {'iterations': 135, 'depth': 10, 'learning_rate': 0.026431381411510375, 'random_strength': 2, 'bagging_temperature': 12.8893613608311, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:44,825] Trial 939 finished with value: 0.84709015035102 and parameters: {'iterations': 171, 'depth': 9, 'learning_rate': 0.04646447949444633, 'random_strength': 0, 'bagging_temperature': 0.2707797666119042, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:45,264] Trial 940 finished with value: 0.8278272336108157 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.04138222952324545, 'random_strength': 6, 'bagging_temperature': 0.2879802480357123, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:45,802] Trial 941 finished with value: 0.827429728579154 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.0383691941982129, 'random_strength': 3, 'bagging_temperature': 0.012477486612878046, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:46,511] Trial 942 finished with value: 0.8473064211998946 and parameters: {'iterations': 175, 'depth': 10, 'learning_rate': 0.030851899192188358, 'random_strength': 0, 'bagging_temperature': 0.4907495368921353, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:46,872] Trial 943 finished with value: 0.8230965538028735 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.034463127294642536, 'random_strength': 4, 'bagging_temperature': 0.31362562629357293, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:47,462] Trial 944 finished with value: 0.8412404970025789 and parameters: {'iterations': 163, 'depth': 10, 'learning_rate': 0.03645897777819452, 'random_strength': 2, 'bagging_temperature': 0.0706795992903189, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:48,146] Trial 945 finished with value: 0.8558558558558559 and parameters: {'iterations': 178, 'depth': 10, 'learning_rate': 0.06704118411262795, 'random_strength': 0, 'bagging_temperature': 0.3699619073092925, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:48,600] Trial 946 finished with value: 0.8183470827148989 and parameters: {'iterations': 171, 'depth': 10, 'learning_rate': 0.043240657623527856, 'random_strength': 70, 'bagging_temperature': 0.8657209421521027, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:49,447] Trial 947 finished with value: 0.8325398336824732 and parameters: {'iterations': 221, 'depth': 10, 'learning_rate': 0.028966291858399395, 'random_strength': 2, 'bagging_temperature': 0.014551831773763506, 'od_type': 'Iter', 'od_wait': 20}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:49,989] Trial 948 finished with value: 0.8183470827148989 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.02410245815263298, 'random_strength': 5, 'bagging_temperature': 14.540698225747864, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:50,539] Trial 949 finished with value: 0.8514727276739713 and parameters: {'iterations': 142, 'depth': 10, 'learning_rate': 0.031940149729505034, 'random_strength': 0, 'bagging_temperature': 0.23367474560004878, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:51,264] Trial 950 finished with value: 0.827429728579154 and parameters: {'iterations': 208, 'depth': 10, 'learning_rate': 0.026786845863594335, 'random_strength': 3, 'bagging_temperature': 0.5539510224839806, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:51,688] Trial 951 finished with value: 0.8183470827148989 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.049216857198996086, 'random_strength': 78, 'bagging_temperature': 0.22502960592268834, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:52,661] Trial 952 finished with value: 0.8459506827044141 and parameters: {'iterations': 284, 'depth': 10, 'learning_rate': 0.03978071496999656, 'random_strength': 2, 'bagging_temperature': 0.051963937314042564, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:53,121] Trial 953 finished with value: 0.8278272336108157 and parameters: {'iterations': 138, 'depth': 10, 'learning_rate': 0.036338088096384745, 'random_strength': 6, 'bagging_temperature': 0.0630634290513538, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:53,581] Trial 954 finished with value: 0.8244677690692389 and parameters: {'iterations': 108, 'depth': 10, 'learning_rate': 0.022143048860912, 'random_strength': 0, 'bagging_temperature': 0.011827767858510817, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:54,076] Trial 955 finished with value: 0.8044843469837604 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.029735251084661535, 'random_strength': 81, 'bagging_temperature': 0.2763551558475018, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:54,467] Trial 956 finished with value: 0.8321685254027262 and parameters: {'iterations': 127, 'depth': 10, 'learning_rate': 0.05488922709336011, 'random_strength': 4, 'bagging_temperature': 2.032948265587395, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:55,010] Trial 957 finished with value: 0.8187655090640165 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.04535952057379285, 'random_strength': 2, 'bagging_temperature': 0.01022323948947446, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:55,696] Trial 958 finished with value: 0.8238465724077614 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.19943452863299513, 'random_strength': 0, 'bagging_temperature': 0.05505254544854993, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:56,206] Trial 959 finished with value: 0.8230965538028735 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.033543824337646626, 'random_strength': 4, 'bagging_temperature': 0.07454719242374079, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:56,466] Trial 960 finished with value: 0.8234879328004447 and parameters: {'iterations': 165, 'depth': 8, 'learning_rate': 0.04262754072974717, 'random_strength': 2, 'bagging_temperature': 0.3174445623674286, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:56,876] Trial 961 finished with value: 0.833469421937483 and parameters: {'iterations': 177, 'depth': 9, 'learning_rate': 0.025849418841977178, 'random_strength': 0, 'bagging_temperature': 0.22271009023368252, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:57,375] Trial 962 finished with value: 0.8178941595494262 and parameters: {'iterations': 185, 'depth': 10, 'learning_rate': 0.02770249765945614, 'random_strength': 7, 'bagging_temperature': 0.046309192326659684, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:57,937] Trial 963 finished with value: 0.8321685254027262 and parameters: {'iterations': 161, 'depth': 10, 'learning_rate': 0.03883695213777118, 'random_strength': 2, 'bagging_temperature': 0.01424743010291874, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:58,863] Trial 964 finished with value: 0.8560848473891952 and parameters: {'iterations': 214, 'depth': 10, 'learning_rate': 0.03199740583069576, 'random_strength': 0, 'bagging_temperature': 0.01706987940328542, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:59,075] Trial 965 finished with value: 0.8097037845172175 and parameters: {'iterations': 173, 'depth': 6, 'learning_rate': 0.024562902682783737, 'random_strength': 4, 'bagging_temperature': 0.08032567393313465, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:48:59,710] Trial 966 finished with value: 0.8415917345645018 and parameters: {'iterations': 179, 'depth': 10, 'learning_rate': 0.03464710864512253, 'random_strength': 2, 'bagging_temperature': 0.21624750218701727, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:00,389] Trial 967 finished with value: 0.8468468468468469 and parameters: {'iterations': 170, 'depth': 10, 'learning_rate': 0.03701931820078958, 'random_strength': 0, 'bagging_temperature': 11.430896141907985, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:01,240] Trial 968 finished with value: 0.8187655090640165 and parameters: {'iterations': 242, 'depth': 10, 'learning_rate': 0.041047832611781555, 'random_strength': 9, 'bagging_temperature': 45.37587310352066, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:02,018] Trial 969 finished with value: 0.8317656008930031 and parameters: {'iterations': 234, 'depth': 10, 'learning_rate': 0.030332477054589878, 'random_strength': 5, 'bagging_temperature': 0.04029126050798513, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:02,487] Trial 970 finished with value: 0.8459506827044141 and parameters: {'iterations': 124, 'depth': 10, 'learning_rate': 0.04615955136673643, 'random_strength': 2, 'bagging_temperature': 0.01001647461004612, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:02,711] Trial 971 finished with value: 0.8241730165768567 and parameters: {'iterations': 132, 'depth': 7, 'learning_rate': 0.051921099681358954, 'random_strength': 0, 'bagging_temperature': 0.1883904494388053, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:03,231] Trial 972 finished with value: 0.8230965538028735 and parameters: {'iterations': 166, 'depth': 10, 'learning_rate': 0.0326893448406959, 'random_strength': 4, 'bagging_temperature': 0.37781349951323234, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:03,827] Trial 973 finished with value: 0.8325398336824732 and parameters: {'iterations': 183, 'depth': 10, 'learning_rate': 0.027845576710054807, 'random_strength': 2, 'bagging_temperature': 0.05786517418358391, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:04,521] Trial 974 finished with value: 0.8337194337194337 and parameters: {'iterations': 176, 'depth': 10, 'learning_rate': 0.02118852120570219, 'random_strength': 0, 'bagging_temperature': 0.23648502087449644, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:05,051] Trial 975 finished with value: 0.8325398336824732 and parameters: {'iterations': 159, 'depth': 10, 'learning_rate': 0.03650889263867113, 'random_strength': 3, 'bagging_temperature': 0.7096868096858617, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:05,392] Trial 976 finished with value: 0.790016981343731 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.025369034155007877, 'random_strength': 35, 'bagging_temperature': 0.016465743014188232, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:05,915] Trial 977 finished with value: 0.8183470827148989 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.023150750139252285, 'random_strength': 5, 'bagging_temperature': 9.182679364939723, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:06,499] Trial 978 finished with value: 0.8412404970025789 and parameters: {'iterations': 174, 'depth': 10, 'learning_rate': 0.03987292350874218, 'random_strength': 2, 'bagging_temperature': 0.26868183979105975, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:07,138] Trial 979 finished with value: 0.8422065533382046 and parameters: {'iterations': 162, 'depth': 10, 'learning_rate': 0.060623964651947755, 'random_strength': 0, 'bagging_temperature': 0.5307137681247976, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:07,886] Trial 980 finished with value: 0.840859352196084 and parameters: {'iterations': 201, 'depth': 10, 'learning_rate': 0.04348890088063633, 'random_strength': 2, 'bagging_temperature': 0.02057181628663571, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:08,425] Trial 981 finished with value: 0.827429728579154 and parameters: {'iterations': 180, 'depth': 10, 'learning_rate': 0.03466093856293785, 'random_strength': 6, 'bagging_temperature': 0.08200121035763092, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:09,157] Trial 982 finished with value: 0.8380954533128446 and parameters: {'iterations': 188, 'depth': 10, 'learning_rate': 0.029421133894065178, 'random_strength': 0, 'bagging_temperature': 1.0054789857176012, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:09,733] Trial 983 finished with value: 0.827429728579154 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.031803655859438985, 'random_strength': 3, 'bagging_temperature': 0.04456772070835602, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:10,224] Trial 984 finished with value: 0.827429728579154 and parameters: {'iterations': 156, 'depth': 10, 'learning_rate': 0.048132042008303906, 'random_strength': 4, 'bagging_temperature': 0.19365404786979137, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:10,891] Trial 985 finished with value: 0.84709015035102 and parameters: {'iterations': 165, 'depth': 10, 'learning_rate': 0.03711178467602559, 'random_strength': 0, 'bagging_temperature': 0.012321410231187073, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:11,558] Trial 986 finished with value: 0.8506436354465302 and parameters: {'iterations': 177, 'depth': 10, 'learning_rate': 0.08737042867023781, 'random_strength': 2, 'bagging_temperature': 0.06064471629091768, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:12,142] Trial 987 finished with value: 0.8606838498730391 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.027301954294746963, 'random_strength': 0, 'bagging_temperature': 7.226285709800327, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:12,553] Trial 988 finished with value: 0.799683575504369 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.026868302047768168, 'random_strength': 88, 'bagging_temperature': 7.382570321962863, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:12,970] Trial 989 finished with value: 0.7942921942921943 and parameters: {'iterations': 144, 'depth': 10, 'learning_rate': 0.025287499965745454, 'random_strength': 62, 'bagging_temperature': 5.653951263185409, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:13,362] Trial 990 finished with value: 0.7942921942921943 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.027579915083548092, 'random_strength': 49, 'bagging_temperature': 7.821399526010151, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:13,749] Trial 991 finished with value: 0.8226718495899223 and parameters: {'iterations': 139, 'depth': 10, 'learning_rate': 0.02562250037958051, 'random_strength': 7, 'bagging_temperature': 9.787133829718966, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:14,080] Trial 992 finished with value: 0.827429728579154 and parameters: {'iterations': 155, 'depth': 9, 'learning_rate': 0.028506249350446378, 'random_strength': 2, 'bagging_temperature': 12.078434860013642, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:14,549] Trial 993 finished with value: 0.8092644368506438 and parameters: {'iterations': 141, 'depth': 10, 'learning_rate': 0.023726692528676496, 'random_strength': 4, 'bagging_temperature': 6.125978138117113, 'od_type': 'Iter', 'od_wait': 43}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:15,154] Trial 994 finished with value: 0.8473064211998946 and parameters: {'iterations': 150, 'depth': 10, 'learning_rate': 0.026760244140838014, 'random_strength': 0, 'bagging_temperature': 6.168093362019973, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:15,700] Trial 995 finished with value: 0.840859352196084 and parameters: {'iterations': 157, 'depth': 10, 'learning_rate': 0.02385567894585306, 'random_strength': 2, 'bagging_temperature': 9.25022721658518, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:16,134] Trial 996 finished with value: 0.8230965538028735 and parameters: {'iterations': 149, 'depth': 10, 'learning_rate': 0.028411622435913178, 'random_strength': 4, 'bagging_temperature': 8.358185761106396, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:16,803] Trial 997 finished with value: 0.8516957111551706 and parameters: {'iterations': 143, 'depth': 10, 'learning_rate': 0.025655149553018727, 'random_strength': 0, 'bagging_temperature': 13.614699997418219, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:17,304] Trial 998 finished with value: 0.8321685254027262 and parameters: {'iterations': 145, 'depth': 10, 'learning_rate': 0.02237742918880382, 'random_strength': 2, 'bagging_temperature': 10.579237197093782, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 691 with value: 0.8648648648648649.\n",
      "[I 2024-01-12 20:49:17,715] Trial 999 finished with value: 0.8044843469837604 and parameters: {'iterations': 152, 'depth': 10, 'learning_rate': 0.03040852812737663, 'random_strength': 29, 'bagging_temperature': 15.182661875255036, 'od_type': 'Iter', 'od_wait': 40}. Best is trial 691 with value: 0.8648648648648649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.864865\n",
      "Model F1 Score: 0.864865\n",
      "Validation Accuracy: 0.819820\n",
      "Validation F1 Score: 0.820784\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "X_train=X_train.astype('int')\n",
    "X_test=X_test.astype('int')\n",
    "X_val=X_val.astype('int')\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations' : trial.suggest_int('iterations', 50, 300),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'random_strength' : trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature' : trial.suggest_float('bagging_temperature', 0.01, 100.00, log=True),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "        'od_wait' : trial.suggest_int('od_wait', 10, 50)\n",
    "    }\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = f1_score(y_test, preds,average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = CatBoostClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n",
    "\n",
    "# Now let's use the model with the best parameters on the validation set\n",
    "val_preds = best_model.predict(X_val)\n",
    "\n",
    "# Check the accuracy and F1 score of the best model on the validation set\n",
    "print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n",
    "print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"CB\",format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 21:05:55,256] A new study created in memory with name: no-name-cd25f6f6-45ff-47a1-8bdd-d0dd2759e9e2\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:55,302] Trial 0 finished with value: 0.75203399637828 and parameters: {'C': 0.07877016300171717, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 66, 'tol': 0.002948962347864648, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.9216467796311224}. Best is trial 0 with value: 0.75203399637828.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:55,310] Trial 1 finished with value: 0.5724680195067033 and parameters: {'C': 40.981534458032066, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 79, 'tol': 0.08600262402718124, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.19234165832477945}. Best is trial 0 with value: 0.75203399637828.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:55,326] Trial 2 finished with value: 0.6111282988119751 and parameters: {'C': 0.0002148560169681239, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 93, 'tol': 0.04454978043868755, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6527243972161834}. Best is trial 0 with value: 0.75203399637828.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:55,888] Trial 3 finished with value: 0.5436936827079013 and parameters: {'C': 6.196625322474216e-05, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 174, 'tol': 0.05820665797436692, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.929647200826816}. Best is trial 0 with value: 0.75203399637828.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,028] Trial 4 finished with value: 0.7661731858752979 and parameters: {'C': 0.07579709982472083, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 152, 'tol': 0.03101165423969641, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.8443209048182165}. Best is trial 4 with value: 0.7661731858752979.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,045] Trial 5 finished with value: 0.6244551002615518 and parameters: {'C': 0.0040852112068302075, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 132, 'tol': 0.046943898973771596, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.4101213995498091}. Best is trial 4 with value: 0.7661731858752979.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:05:56,152] Trial 6 finished with value: 0.7528261852586178 and parameters: {'C': 0.1087903728595809, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 132, 'tol': 0.06952952363000156, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6979567973183439}. Best is trial 4 with value: 0.7661731858752979.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,214] Trial 7 finished with value: 0.784432594635145 and parameters: {'C': 6.990427185178998, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 151, 'tol': 0.047433768713404545, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.1903129703053993}. Best is trial 7 with value: 0.784432594635145.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,225] Trial 8 finished with value: 0.7224523630773629 and parameters: {'C': 0.0018437532756074067, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 62, 'tol': 0.013695810786997284, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.911128060530958}. Best is trial 7 with value: 0.784432594635145.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:05:56,264] Trial 9 finished with value: 0.7470373599405857 and parameters: {'C': 0.12821285101086444, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 50, 'tol': 1.4199089121681556e-05, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.14912404490659903}. Best is trial 7 with value: 0.784432594635145.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,322] Trial 10 finished with value: 0.7934145698586808 and parameters: {'C': 15.033235147575006, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 191, 'tol': 0.09915332523402079, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.009567942907231064}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,388] Trial 11 finished with value: 0.7934145698586808 and parameters: {'C': 41.29760190644971, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 200, 'tol': 0.09815120879198021, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.004143696738482316}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,417] Trial 12 finished with value: 0.6112509597075283 and parameters: {'C': 2.9185585658598416, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 200, 'tol': 0.09430519517291078, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.012844774416476579}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,587] Trial 13 finished with value: 0.7934145698586808 and parameters: {'C': 85.46647081282505, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 199, 'tol': 0.09961840471267738, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.38369922175918453}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,668] Trial 14 finished with value: 0.7934145698586808 and parameters: {'C': 1.8279806300104273, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 174, 'tol': 0.07803657974179032, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.05843906491797783}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,732] Trial 15 finished with value: 0.7934145698586808 and parameters: {'C': 11.240977109455784, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 178, 'tol': 0.07293392398463279, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3238972044343251}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,762] Trial 16 finished with value: 0.6449685206441964 and parameters: {'C': 0.48838143166861536, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 104, 'tol': 0.09010298136118793, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.27331768084881214}. Best is trial 10 with value: 0.7934145698586808.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,839] Trial 17 finished with value: 0.798035410303664 and parameters: {'C': 0.9578142885538253, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 156, 'tol': 0.06484874268700436, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.49394618879038693}. Best is trial 17 with value: 0.798035410303664.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:56,945] Trial 18 finished with value: 0.7632115255111387 and parameters: {'C': 0.00950395880061095, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 154, 'tol': 0.06209184241315429, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5462763292685869}. Best is trial 17 with value: 0.798035410303664.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,028] Trial 19 finished with value: 0.802641903871957 and parameters: {'C': 0.7222340332825188, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.029854852596737307, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.48586616491425866}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,071] Trial 20 finished with value: 0.6423381907252875 and parameters: {'C': 0.8102574261851806, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 107, 'tol': 0.03150637283244951, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5238973107461491}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,126] Trial 21 finished with value: 0.802641903871957 and parameters: {'C': 0.5180453911864805, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.02831621163830919, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6524500675282626}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,198] Trial 22 finished with value: 0.798035410303664 and parameters: {'C': 0.8809713704749451, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.028784119724123036, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6575350565306932}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,279] Trial 23 finished with value: 0.802641903871957 and parameters: {'C': 0.35395887722274016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.015948871649917908, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7594475115205102}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,336] Trial 24 finished with value: 0.7764613692033047 and parameters: {'C': 0.014323393199907795, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.01943825644520935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7486125695798782}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,389] Trial 25 finished with value: 0.6335426335426335 and parameters: {'C': 0.2630698820051645, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 89, 'tol': 0.017510100957294036, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8025109542508019}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,468] Trial 26 finished with value: 0.7643951617832215 and parameters: {'C': 0.03423907515021116, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.038718494118948024, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5914919936481655}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,556] Trial 27 finished with value: 0.7934145698586808 and parameters: {'C': 2.5041406428847863, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 137, 'tol': 0.022526526613308527, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9926450441201278}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,719] Trial 28 finished with value: 0.6866079645032152 and parameters: {'C': 0.0010429703756908713, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 96, 'tol': 0.008378630487632911, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4408858307062589}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,752] Trial 29 finished with value: 0.5724680195067033 and parameters: {'C': 0.22873607119483927, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 80, 'tol': 0.03896777118434076, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6139471573456342}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,820] Trial 30 finished with value: 0.6955929143429144 and parameters: {'C': 0.056971118382448664, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 143, 'tol': 0.00761630647484818, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.759966929418507}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,869] Trial 31 finished with value: 0.802641903871957 and parameters: {'C': 0.6082654394594168, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05594035877111686, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4632271910378682}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,948] Trial 32 finished with value: 0.802641903871957 and parameters: {'C': 0.2766445884832573, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0574733447797254, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7059339178142988}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:57,985] Trial 33 finished with value: 0.7614561989915297 and parameters: {'C': 4.924784106575513, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 125, 'tol': 0.025186398980387634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4838527873051419}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,067] Trial 34 finished with value: 0.7681093417714366 and parameters: {'C': 0.021705367091980232, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.038235833044779226, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5835034833461628}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,132] Trial 35 finished with value: 0.6285520514310458 and parameters: {'C': 2.129705471964097e-05, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 111, 'tol': 0.053269109044749574, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.33208555850139243}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,225] Trial 36 finished with value: 0.7708024626943547 and parameters: {'C': 1.2789472182737187, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.012700386645828107, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6567645998225985}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,347] Trial 37 finished with value: 0.7691765275082738 and parameters: {'C': 0.39564488046561735, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 86, 'tol': 0.03394490219157997, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8419785257691845}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,388] Trial 38 finished with value: 0.6335426335426335 and parameters: {'C': 0.11693797463716492, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 138, 'tol': 0.04378701079104106, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.45705326281751285}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,436] Trial 39 finished with value: 0.6067286798994115 and parameters: {'C': 0.051726728549362215, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 101, 'tol': 0.05265238709509541, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5443360612024274}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:05:58,668] Trial 40 finished with value: 0.7527908343125734 and parameters: {'C': 17.574737415900326, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 74, 'tol': 0.02572565424933783, 'class_weight': None, 'warm_start': False, 'l1_ratio': 0.3670405334501368}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,855] Trial 41 finished with value: 0.802641903871957 and parameters: {'C': 0.18292532099768188, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.057866421356504584, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7337281191773145}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:58,964] Trial 42 finished with value: 0.802641903871957 and parameters: {'C': 0.4656114102113912, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05586399871293726, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6981872877554017}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,058] Trial 43 finished with value: 0.7934145698586808 and parameters: {'C': 4.379566836861222, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04354755331248705, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8120145284152896}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,134] Trial 44 finished with value: 0.7982688570923864 and parameters: {'C': 0.08729087656884074, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 143, 'tol': 0.04927671982757627, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9045176126505708}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,177] Trial 45 finished with value: 0.7661378770074423 and parameters: {'C': 0.43730257427246183, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 121, 'tol': 0.016696663490757782, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6213512125515896}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,254] Trial 46 finished with value: 0.7934145698586808 and parameters: {'C': 1.6456056977899605, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.06603790600893629, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6937359101892663}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,313] Trial 47 finished with value: 0.7577877911155836 and parameters: {'C': 0.005523126550527625, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 163, 'tol': 0.0801680635730117, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.42040519044866603}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:05:59,397] Trial 48 finished with value: 0.7563267813267813 and parameters: {'C': 0.19614446148693024, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 102, 'tol': 0.061050503143347284, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.26362455585726663}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,468] Trial 49 finished with value: 0.7934145698586808 and parameters: {'C': 7.999822324413777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.006105315454557815, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5631582526917699}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,549] Trial 50 finished with value: 0.7934145698586808 and parameters: {'C': 26.54587801120015, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 144, 'tol': 0.07108495309890722, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.785491886574691}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,635] Trial 51 finished with value: 0.7982688570923864 and parameters: {'C': 0.13823053519668269, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.058573023022894126, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7332630686295384}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,739] Trial 52 finished with value: 0.802641903871957 and parameters: {'C': 0.6943752669072943, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.05500439677947335, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8762176523086498}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,826] Trial 53 finished with value: 0.802641903871957 and parameters: {'C': 0.3123656760505343, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.03472767632090541, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6878455832665923}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:05:59,995] Trial 54 finished with value: 0.7934145698586808 and parameters: {'C': 2.564470000575634, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04545987745142618, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7298525267325993}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,075] Trial 55 finished with value: 0.7936710813206824 and parameters: {'C': 0.03846810042663952, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.06689121225508621, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6165381604781189}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,111] Trial 56 finished with value: 0.6196384233871589 and parameters: {'C': 0.13934505813787526, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 90, 'tol': 0.05841335218297023, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5117495959293547}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,155] Trial 57 finished with value: 0.6067286798994115 and parameters: {'C': 1.0877920626555913, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 120, 'tol': 0.0762062078705351, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8580020487282214}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,433] Trial 58 finished with value: 0.7708024626943547 and parameters: {'C': 0.6364379831955831, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.02867026041672272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9711604869540089}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,549] Trial 59 finished with value: 0.7691765275082738 and parameters: {'C': 0.07305212276533533, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.011046054159449122, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.47059096186912347}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,592] Trial 60 finished with value: 0.7696455177639956 and parameters: {'C': 0.022748016178132862, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 133, 'tol': 0.020537864513740095, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6604598346448506}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,680] Trial 61 finished with value: 0.802641903871957 and parameters: {'C': 0.3143778097025637, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.055065039196592724, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.719682987338941}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:00,870] Trial 62 finished with value: 0.7934145698586808 and parameters: {'C': 1.631159394702301, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.0626307488982612, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7726116125792288}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,136] Trial 63 finished with value: 0.802641903871957 and parameters: {'C': 0.6679623890266205, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.049704401540000775, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.698460343278601}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,205] Trial 64 finished with value: 0.7982688570923864 and parameters: {'C': 0.15531422925858496, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.04081103034620563, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8151884139093815}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,322] Trial 65 finished with value: 0.802641903871957 and parameters: {'C': 0.23033366564874974, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.056827556637477225, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6279464523174825}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,501] Trial 66 finished with value: 0.7934145698586808 and parameters: {'C': 3.3292337930893185, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05228851890659135, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6722198706316008}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,725] Trial 67 finished with value: 0.802641903871957 and parameters: {'C': 0.5508808994544504, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.046589732939726736, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5709562764460105}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,875] Trial 68 finished with value: 0.632883615560909 and parameters: {'C': 0.00019628732863102475, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 114, 'tol': 0.06095328582000014, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5252555553035068}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:01,977] Trial 69 finished with value: 0.622748289414956 and parameters: {'C': 0.37625502576221426, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 140, 'tol': 0.001173061706006888, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7623509445558025}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,001] Trial 70 finished with value: 0.6111282988119751 and parameters: {'C': 1.0819087864854846, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 94, 'tol': 0.06815570609601349, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.40928777611772305}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,154] Trial 71 finished with value: 0.802641903871957 and parameters: {'C': 0.6961059197595705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.055769234975270546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8887736437684955}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,358] Trial 72 finished with value: 0.7934145698586808 and parameters: {'C': 1.989966158500319, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.0497281759017971, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8521665999620285}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,480] Trial 73 finished with value: 0.802641903871957 and parameters: {'C': 0.21973022361908406, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.05319095825931456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9350321078690463}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,665] Trial 74 finished with value: 0.802641903871957 and parameters: {'C': 0.4505709486352807, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06415597510170643, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7065094088118972}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,774] Trial 75 finished with value: 0.7982688570923864 and parameters: {'C': 0.09759272623205571, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.01593116118339656, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7939207660782829}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,857] Trial 76 finished with value: 0.7934145698586808 and parameters: {'C': 0.9448472707470544, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05918528405199018, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8333609480888926}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,950] Trial 77 finished with value: 0.7934145698586808 and parameters: {'C': 6.500008888645727, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 148, 'tol': 0.03393622265595178, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6422346517224097}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:02,998] Trial 78 finished with value: 0.7614561989915297 and parameters: {'C': 3.8777431076843447, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 117, 'tol': 0.042329246885905954, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8837556568497149}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,083] Trial 79 finished with value: 0.7691765275082738 and parameters: {'C': 0.06849019262367774, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.02347246560191898, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5976589335363953}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,155] Trial 80 finished with value: 0.7934145698586808 and parameters: {'C': 1.420621367642576, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.04805092795303287, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7469749729093793}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,239] Trial 81 finished with value: 0.802641903871957 and parameters: {'C': 0.3292292620229591, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.03530310183236726, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.674874456248005}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,416] Trial 82 finished with value: 0.802641903871957 and parameters: {'C': 0.2868568519927278, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.029778409496806053, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6884899941957857}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,502] Trial 83 finished with value: 0.802641903871957 and parameters: {'C': 0.18010621317343678, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.026964890334492682, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3763737421985198}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,580] Trial 84 finished with value: 0.802641903871957 and parameters: {'C': 0.6155168800672373, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.031290000023633156, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4373242789450795}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,664] Trial 85 finished with value: 0.7982688570923864 and parameters: {'C': 0.1014116524791215, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.03633567751687933, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5463836334102236}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:03,749] Trial 86 finished with value: 0.7520388695314645 and parameters: {'C': 0.42168759392695465, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 118, 'tol': 0.050999078346543325, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.4915503554273511}. Best is trial 19 with value: 0.802641903871957.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,892] Trial 87 finished with value: 0.8028531639803915 and parameters: {'C': 0.04355878323719006, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05510694120831343, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7509362431841831}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:03,935] Trial 88 finished with value: 0.6246083039561301 and parameters: {'C': 0.04738194885849038, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 105, 'tol': 0.054974762659521566, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9436597302583368}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,038] Trial 89 finished with value: 0.7632115255111387 and parameters: {'C': 0.010242962625324733, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.06308018385770357, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7383665268258756}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,077] Trial 90 finished with value: 0.6198849451861501 and parameters: {'C': 0.03137554411040924, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 137, 'tol': 0.06032918030649896, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7814722858351902}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,164] Trial 91 finished with value: 0.798035410303664 and parameters: {'C': 0.9510184585749683, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.057457742072441136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.639995140444109}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,230] Trial 92 finished with value: 0.7934145698586808 and parameters: {'C': 2.199638665790433, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0211289560958891, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7190521017890568}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,308] Trial 93 finished with value: 0.802641903871957 and parameters: {'C': 0.26650601048425404, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.05399029159658837, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8282054495260731}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,531] Trial 94 finished with value: 0.802641903871957 and parameters: {'C': 0.17047890119644424, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.0472102265819287, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7666715102787227}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,628] Trial 95 finished with value: 0.802641903871957 and parameters: {'C': 0.751980447062997, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.040780535935643056, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7074086410031765}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,707] Trial 96 finished with value: 0.802641903871957 and parameters: {'C': 0.47134634740055176, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 60, 'tol': 0.056476641041723986, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.1243906114408947}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,742] Trial 97 finished with value: 0.5724680195067033 and parameters: {'C': 0.12130877177050824, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 103, 'tol': 0.07104573691886919, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8725972023454281}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,805] Trial 98 finished with value: 0.7934145698586808 and parameters: {'C': 1.22959016501193, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05186739082173768, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6804353238040206}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:04,887] Trial 99 finished with value: 0.7563267813267813 and parameters: {'C': 0.06946142065524646, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 91, 'tol': 0.018986231233407758, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7474613328549817}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,021] Trial 100 finished with value: 0.802641903871957 and parameters: {'C': 0.3202964790616864, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.014584857162116577, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5995877362619646}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,123] Trial 101 finished with value: 0.802641903871957 and parameters: {'C': 0.3102219869351594, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05451864421629961, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7204291354731268}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,212] Trial 102 finished with value: 0.802641903871957 and parameters: {'C': 0.19477587396795928, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06549965752697814, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7976646440771441}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,301] Trial 103 finished with value: 0.802641903871957 and parameters: {'C': 0.5307021220976332, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.058708651674126415, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6501607036524459}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,386] Trial 104 finished with value: 0.802641903871957 and parameters: {'C': 0.7786839944679221, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.045460775897171055, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7166408752337017}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,455] Trial 105 finished with value: 0.713849442663002 and parameters: {'C': 0.002301617864145027, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.06155617895653995, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8116258019814561}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,620] Trial 106 finished with value: 0.802641903871957 and parameters: {'C': 0.2343895268200432, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05633094703755037, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4517407604254636}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:05,727] Trial 107 finished with value: 0.7434528932550413 and parameters: {'C': 1.3331599706965342, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 86, 'tol': 0.005242485306136649, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7561468129914803}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,792] Trial 108 finished with value: 0.7807327381878917 and parameters: {'C': 0.01892448000692471, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.048769549071423814, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5111941305167472}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,844] Trial 109 finished with value: 0.6244551002615518 and parameters: {'C': 0.1519260879678992, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 123, 'tol': 0.025647734061657167, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3442279930643614}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:05,899] Trial 110 finished with value: 0.6397720169148741 and parameters: {'C': 0.3866126004143666, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 112, 'tol': 0.011071330298888203, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.40144803283819286}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:06,313] Trial 111 finished with value: 0.802641903871957 and parameters: {'C': 0.5949886823210775, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.03343983626182451, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6896042474737992}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:06,857] Trial 112 finished with value: 0.798035410303664 and parameters: {'C': 0.793843320661649, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.04983777156968272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7079922988435897}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:06,951] Trial 113 finished with value: 0.7934145698586808 and parameters: {'C': 1.8333888570621515, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05143590575966999, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4711201273759269}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,038] Trial 114 finished with value: 0.802641903871957 and parameters: {'C': 0.5465510204042591, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.023527218872451232, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6638394646892113}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,127] Trial 115 finished with value: 0.802641903871957 and parameters: {'C': 0.23490612601814484, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.06387772842948157, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7301166129430444}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,201] Trial 116 finished with value: 0.7982688570923864 and parameters: {'C': 0.08797839711569815, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.059686691391540855, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7754365625128626}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,294] Trial 117 finished with value: 0.7520388695314645 and parameters: {'C': 0.3191999274737508, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0540838369201406, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6354213541785025}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,406] Trial 118 finished with value: 0.798035410303664 and parameters: {'C': 0.9093825989638636, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.028325114946225655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6884242212706928}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,468] Trial 119 finished with value: 0.623929557403858 and parameters: {'C': 1.0993894947890295e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.08418492677123407, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5662990175623968}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,572] Trial 120 finished with value: 0.802641903871957 and parameters: {'C': 0.4403264827145164, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.03877747829356165, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7379354418329718}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,671] Trial 121 finished with value: 0.7934145698586808 and parameters: {'C': 2.664196210293584, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.057150252151357384, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6206890169509276}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,758] Trial 122 finished with value: 0.7982688570923864 and parameters: {'C': 0.12326365610712103, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.05497471418422321, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6635873462671634}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,938] Trial 123 finished with value: 0.802641903871957 and parameters: {'C': 0.19025544918002002, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.05705635025044324, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6923935454435166}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:07,979] Trial 124 finished with value: 0.7571431799692669 and parameters: {'C': 0.2421613061817837, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 128, 'tol': 0.05194190434535555, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6267845573079016}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:08,059] Trial 125 finished with value: 0.802641903871957 and parameters: {'C': 0.6830312480354725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.060761305977255736, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.532555316615164}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:08,128] Trial 126 finished with value: 0.8028531639803915 and parameters: {'C': 0.0463626079340886, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.050028381378797455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7494251638567654}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:08,918] Trial 127 finished with value: 0.8028531639803915 and parameters: {'C': 0.0522609460728277, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.042855473928424925, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.788821863280205}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,219] Trial 128 finished with value: 0.7936710813206824 and parameters: {'C': 0.03966631882952669, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.042541450310234964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7786212668742548}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,436] Trial 129 finished with value: 0.7893030285187149 and parameters: {'C': 0.025483417157864383, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.03200643067020522, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8280207836915212}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:09,520] Trial 130 finished with value: 0.7754506194116096 and parameters: {'C': 0.05373766730503894, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 133, 'tol': 0.03593955055511412, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9163816553020678}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,584] Trial 131 finished with value: 0.7982688570923864 and parameters: {'C': 0.07165791686592245, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.045098425673533435, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7566125326237709}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,646] Trial 132 finished with value: 0.7982688570923864 and parameters: {'C': 0.029793988398101292, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.05048004185819367, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8035408739260924}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,704] Trial 133 finished with value: 0.7632115255111387 and parameters: {'C': 0.009196139624656596, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04043587335752183, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.725190379125541}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,763] Trial 134 finished with value: 0.7764613692033047 and parameters: {'C': 0.01762587611654837, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.047722313901220004, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7427320341520035}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,832] Trial 135 finished with value: 0.7691765275082738 and parameters: {'C': 0.10944030296359508, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.052897176885464615, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7080097750863641}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:09,930] Trial 136 finished with value: 0.7934145698586808 and parameters: {'C': 1.106298808302348, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.04928955966434161, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7606882841901607}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,002] Trial 137 finished with value: 0.802641903871957 and parameters: {'C': 0.34969318623369844, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.04434422713128719, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7894104715648249}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,039] Trial 138 finished with value: 0.5979118796400523 and parameters: {'C': 0.04969857434313784, 'fit_intercept': False, 'solver': 'saga', 'max_iter': 125, 'tol': 0.05881829036133351, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8561232741380991}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,084] Trial 139 finished with value: 0.6335426335426335 and parameters: {'C': 0.013090020355256856, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 103, 'tol': 0.04648565648799258, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.675158443546917}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,246] Trial 140 finished with value: 0.802641903871957 and parameters: {'C': 0.528981973853227, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03687908297629479, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6990809137240197}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,319] Trial 141 finished with value: 0.7982688570923864 and parameters: {'C': 0.14924969098202065, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.05642107323098623, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6505521834038612}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,381] Trial 142 finished with value: 0.802641903871957 and parameters: {'C': 0.2775282822365956, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 189, 'tol': 0.054604877384273366, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7199675391278122}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,454] Trial 143 finished with value: 0.802641903871957 and parameters: {'C': 0.40922305685069627, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05308311347797211, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4297139968829739}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,541] Trial 144 finished with value: 0.802641903871957 and parameters: {'C': 0.1997177079714663, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06285810022508964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6046117535191858}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,606] Trial 145 finished with value: 0.802641903871957 and parameters: {'C': 0.6627049680018032, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.05824221390588766, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.48693470284865825}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,668] Trial 146 finished with value: 0.7934145698586808 and parameters: {'C': 1.426171001222667, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05075361276793891, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6746363387868574}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,762] Trial 147 finished with value: 0.7982688570923864 and parameters: {'C': 0.09806258677231514, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05579827854543787, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7432300784665047}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:10,821] Trial 148 finished with value: 0.7711067983441525 and parameters: {'C': 0.3530436625243845, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 122, 'tol': 0.06022220271581657, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7681917404992717}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:11,045] Trial 149 finished with value: 0.798035410303664 and parameters: {'C': 0.9151529238427764, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.0675510766874167, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7278123255496396}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:11,463] Trial 150 finished with value: 0.802641903871957 and parameters: {'C': 0.5000772717958434, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04847851593230067, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6975956301728716}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:11,952] Trial 151 finished with value: 0.802641903871957 and parameters: {'C': 0.2665487521991617, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.053035930151746916, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.551182926928214}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:12,320] Trial 152 finished with value: 0.802641903871957 and parameters: {'C': 0.6884444074321606, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.046928241548029354, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5922261363409836}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:12,596] Trial 153 finished with value: 0.802641903871957 and parameters: {'C': 0.4880201151549309, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 94, 'tol': 0.05105112891815122, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5676847172335259}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:13,224] Trial 154 finished with value: 0.7982688570923864 and parameters: {'C': 0.15875763275662172, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.042475507206076735, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6430604151410005}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:13,661] Trial 155 finished with value: 0.7934145698586808 and parameters: {'C': 1.0511453895084089, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.054799279969641915, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6652347237197105}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:13,756] Trial 156 finished with value: 0.7691765275082738 and parameters: {'C': 0.3877921875270324, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.029047058034110215, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5147361326239703}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:13,833] Trial 157 finished with value: 0.7934145698586808 and parameters: {'C': 1.7567179117361083, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.03307660503822927, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6196268631446814}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:13,942] Trial 158 finished with value: 0.802641903871957 and parameters: {'C': 0.23563786298416725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.05843036243351809, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5751742888407175}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:14,064] Trial 159 finished with value: 0.7477477477477478 and parameters: {'C': 0.5822775030989811, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 114, 'tol': 0.05669960518058185, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.45610319121301074}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,135] Trial 160 finished with value: 0.7982688570923864 and parameters: {'C': 0.06524761707777035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06182960229489876, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7075453301424194}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,252] Trial 161 finished with value: 0.802641903871957 and parameters: {'C': 0.7906664331456046, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.053963451848214376, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9564459407370376}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,363] Trial 162 finished with value: 0.802641903871957 and parameters: {'C': 0.33757352136528895, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.05659044915714717, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8853866409527948}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,452] Trial 163 finished with value: 0.802641903871957 and parameters: {'C': 0.6226124526529196, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.05009986181908167, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8896262595486503}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,527] Trial 164 finished with value: 0.7936710813206824 and parameters: {'C': 0.03899953602143175, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.052149811386474704, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9813361855969116}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,630] Trial 165 finished with value: 0.7934145698586808 and parameters: {'C': 1.149891069568872, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.09636126920159213, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6793194720165798}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,697] Trial 166 finished with value: 0.6244551002615518 and parameters: {'C': 0.20385822108509954, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 124, 'tol': 0.02691469605041447, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8394569291245546}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,765] Trial 167 finished with value: 0.802641903871957 and parameters: {'C': 0.49205703943638973, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.04479003888397893, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7508527918095004}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,810] Trial 168 finished with value: 0.6198849451861501 and parameters: {'C': 0.8330711045730577, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 113, 'tol': 0.05559271393303946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8107901620548318}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,878] Trial 169 finished with value: 0.802641903871957 and parameters: {'C': 0.3247251410380618, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.05921751836748042, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7807027614324022}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:14,973] Trial 170 finished with value: 0.7982688570923864 and parameters: {'C': 0.13632251224866995, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.048883805416056116, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9022159975596526}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,061] Trial 171 finished with value: 0.802641903871957 and parameters: {'C': 0.2690952333885784, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.05375064891511004, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9374511972128253}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,161] Trial 172 finished with value: 0.802641903871957 and parameters: {'C': 0.18706036261359363, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.030770294740196557, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9276529287949827}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,266] Trial 173 finished with value: 0.8028531639803915 and parameters: {'C': 0.09192014246334998, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.052126325200339725, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7203167426276362}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,339] Trial 174 finished with value: 0.7982688570923864 and parameters: {'C': 0.09617951465463227, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05143731422185919, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7241546750368879}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,410] Trial 175 finished with value: 0.632883615560909 and parameters: {'C': 0.00024316173073842025, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.04651173778077686, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7108563515975659}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,482] Trial 176 finished with value: 0.7982688570923864 and parameters: {'C': 0.07832724083157493, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05536927384950215, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.685041061077115}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,569] Trial 177 finished with value: 0.7982688570923864 and parameters: {'C': 0.1256168286935535, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05731545314053777, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7454753171246712}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,679] Trial 178 finished with value: 0.8028531639803915 and parameters: {'C': 0.05702261729077976, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.06035456322929641, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6462446670067082}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,759] Trial 179 finished with value: 0.8028531639803915 and parameters: {'C': 0.04844679613453018, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.06260305207302305, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6574901811290123}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,926] Trial 180 finished with value: 0.7643951617832215 and parameters: {'C': 0.052491610097870636, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06241177537541863, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6498522259746488}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:15,996] Trial 181 finished with value: 0.7982688570923864 and parameters: {'C': 0.028016078490748848, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06572254835174568, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.693267036479452}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,054] Trial 182 finished with value: 0.7982688570923864 and parameters: {'C': 0.034141495475483466, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06052863269585974, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6329266123689187}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,120] Trial 183 finished with value: 0.7982688570923864 and parameters: {'C': 0.07219154251833108, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05835135257916213, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6599500116163673}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,189] Trial 184 finished with value: 0.8028531639803915 and parameters: {'C': 0.04164947214865099, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.05970204543415777, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6145434460443802}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,271] Trial 185 finished with value: 0.7982688570923864 and parameters: {'C': 0.04139860488504105, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.06319866021320149, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.731621208888029}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,343] Trial 186 finished with value: 0.8028531639803915 and parameters: {'C': 0.048492159165165784, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.06017377491104074, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6738873429133072}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,386] Trial 187 finished with value: 0.7515784995494071 and parameters: {'C': 0.05461176853115105, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 104, 'tol': 0.06950042461900642, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6724132253406421}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,470] Trial 188 finished with value: 0.7893030285187149 and parameters: {'C': 0.02159535504514585, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.06465297011179744, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7063533085563903}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,553] Trial 189 finished with value: 0.7982688570923864 and parameters: {'C': 0.03315458029101791, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.059493898837369545, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6569730112610075}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,601] Trial 190 finished with value: 0.7473018473018472 and parameters: {'C': 0.016335099909302413, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.06151720065928298, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7704209134331407}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,666] Trial 191 finished with value: 0.8028531639803915 and parameters: {'C': 0.050516040838329605, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05785265820366369, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6318489892415011}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,742] Trial 192 finished with value: 0.8028531639803915 and parameters: {'C': 0.04690722972066788, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.060730456076274475, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6165409927250061}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:16,815] Trial 193 finished with value: 0.8028531639803915 and parameters: {'C': 0.04934491703794632, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06021979749395502, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6224053205845781}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,023] Trial 194 finished with value: 0.8028531639803915 and parameters: {'C': 0.04231621029647701, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06487843616132258, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6088757449534699}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,117] Trial 195 finished with value: 0.8028531639803915 and parameters: {'C': 0.04307987938354035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06440856715355492, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.609753264251811}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,193] Trial 196 finished with value: 0.8028531639803915 and parameters: {'C': 0.04512536441992513, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06612585693458685, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5964599632434405}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,273] Trial 197 finished with value: 0.8028531639803915 and parameters: {'C': 0.047064925510350165, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06677078729985601, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6058257660386912}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,375] Trial 198 finished with value: 0.7893030285187149 and parameters: {'C': 0.023989531263477352, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.07323773510129347, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6033705171140735}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,496] Trial 199 finished with value: 0.8028531639803915 and parameters: {'C': 0.047415023360016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06750168244762894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5852326561941056}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,567] Trial 200 finished with value: 0.7982688570923864 and parameters: {'C': 0.04219252420396686, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06818173923048698, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5900895031846293}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,651] Trial 201 finished with value: 0.8028531639803915 and parameters: {'C': 0.05469965649971683, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06729559271954472, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6215634513995806}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,759] Trial 202 finished with value: 0.8028531639803915 and parameters: {'C': 0.0558532124119656, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07201917669587568, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6102375049041969}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,835] Trial 203 finished with value: 0.8028531639803915 and parameters: {'C': 0.05224028676741502, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0755074498107096, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6075202484831609}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:17,929] Trial 204 finished with value: 0.8028531639803915 and parameters: {'C': 0.04863379037760413, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07510913417626514, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6094961151476888}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,177] Trial 205 finished with value: 0.8028531639803915 and parameters: {'C': 0.05558403438388455, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07668857070759982, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6118463248170873}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,293] Trial 206 finished with value: 0.8028531639803915 and parameters: {'C': 0.05314700441520152, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07764192258803429, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6147887862793493}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,640] Trial 207 finished with value: 0.7982688570923864 and parameters: {'C': 0.06510085339463419, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07585587380010551, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5870254750189415}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,781] Trial 208 finished with value: 0.7982688570923864 and parameters: {'C': 0.03134964671136105, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07208603597552994, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6099255548109698}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,848] Trial 209 finished with value: 0.8028531639803915 and parameters: {'C': 0.043223791812733225, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.08065504676186688, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5726528830805113}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:18,934] Trial 210 finished with value: 0.8028531639803915 and parameters: {'C': 0.058862534210472016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0700380730670022, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6331992438243874}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,014] Trial 211 finished with value: 0.8028531639803915 and parameters: {'C': 0.049816715622272925, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07639483898612584, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6099382089170999}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,113] Trial 212 finished with value: 0.7982688570923864 and parameters: {'C': 0.08006988828802389, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07413495492123104, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6187539389166516}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,294] Trial 213 finished with value: 0.7936710813206824 and parameters: {'C': 0.026086876031170905, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0796798617008589, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5926350546688863}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,367] Trial 214 finished with value: 0.7982688570923864 and parameters: {'C': 0.04198578306174437, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06639513662953894, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6316180056405295}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,467] Trial 215 finished with value: 0.8028531639803915 and parameters: {'C': 0.057347933980675544, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07860817275492413, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5492896618376165}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,601] Trial 216 finished with value: 0.7936710813206824 and parameters: {'C': 0.03684875507765714, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06916896901226925, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6119852984546789}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:19,686] Trial 217 finished with value: 0.7618143239764861 and parameters: {'C': 0.08318747639765081, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 163, 'tol': 0.07481195759783843, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.587880080587877}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,757] Trial 218 finished with value: 0.8028531639803915 and parameters: {'C': 0.05403371315155973, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.0814664589663438, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6155519198016232}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,829] Trial 219 finished with value: 0.7893030285187149 and parameters: {'C': 0.02183822830247045, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.07213843225004174, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6373735490730981}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,889] Trial 220 finished with value: 0.7982688570923864 and parameters: {'C': 0.033099182040749346, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06495268646091666, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5744063573578588}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:19,960] Trial 221 finished with value: 0.8028531639803915 and parameters: {'C': 0.043284698226409776, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.08333414894134517, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5652826209532041}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,023] Trial 222 finished with value: 0.8028531639803915 and parameters: {'C': 0.04824975454737885, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.07808178079631911, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5996174562799255}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,093] Trial 223 finished with value: 0.7938919441613183 and parameters: {'C': 0.06502798660605945, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.08759464536624255, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6255252283141844}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,161] Trial 224 finished with value: 0.7982688570923864 and parameters: {'C': 0.029482192955297977, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06676431580148721, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.577088297696258}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,249] Trial 225 finished with value: 0.8028531639803915 and parameters: {'C': 0.0914997956722476, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07728496595321145, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6410204241814451}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,295] Trial 226 finished with value: 0.5934331813570617 and parameters: {'C': 0.040573460341843406, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 122, 'tol': 0.06373753229970897, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6034300059215515}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,414] Trial 227 finished with value: 0.8028531639803915 and parameters: {'C': 0.05678172076748697, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.08179410680271236, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5816663639985815}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,477] Trial 228 finished with value: 0.6067286798994115 and parameters: {'C': 0.01405343404458194, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 117, 'tol': 0.07039137487613159, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6254315088182036}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,576] Trial 229 finished with value: 0.7938919441613183 and parameters: {'C': 0.06672780433139704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06790096411269181, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5613179214235745}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,856] Trial 230 finished with value: 0.7982688570923864 and parameters: {'C': 0.03255116125541305, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.0729090230653903, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6058703621634259}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:20,937] Trial 231 finished with value: 0.8028531639803915 and parameters: {'C': 0.057054723454936195, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07042348888196118, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6323708088834243}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,009] Trial 232 finished with value: 0.7982688570923864 and parameters: {'C': 0.08492915763512535, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0653004893890053, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6387963059258333}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,085] Trial 233 finished with value: 0.7982688570923864 and parameters: {'C': 0.04343091471348346, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07545805748434987, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6471954882577464}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,561] Trial 234 finished with value: 0.7893030285187149 and parameters: {'C': 0.023660079425348417, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0671526921227502, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6172819836004324}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,731] Trial 235 finished with value: 0.7982688570923864 and parameters: {'C': 0.06395196428559737, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06961988491530134, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.59827531344516}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,819] Trial 236 finished with value: 0.8028531639803915 and parameters: {'C': 0.045081224422433626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06337920609812428, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5854216694891994}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:21,921] Trial 237 finished with value: 0.8028531639803915 and parameters: {'C': 0.09358268990976826, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07397576352829213, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5380026508585782}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,006] Trial 238 finished with value: 0.7982688570923864 and parameters: {'C': 0.031990088402678044, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.07973042328222384, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6507847762156193}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,112] Trial 239 finished with value: 0.8028531639803915 and parameters: {'C': 0.05108146147406661, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06534981173385425, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6209290863006866}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,229] Trial 240 finished with value: 0.7691765275082738 and parameters: {'C': 0.07453180551552223, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.06169401749194055, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5974007074623076}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,315] Trial 241 finished with value: 0.8028531639803915 and parameters: {'C': 0.04773456611708121, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07260391558270286, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6150963486913725}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,429] Trial 242 finished with value: 0.7936710813206824 and parameters: {'C': 0.03796415202059065, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0766737559064006, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6292843101661743}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,525] Trial 243 finished with value: 0.8028531639803915 and parameters: {'C': 0.06011941519219747, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.0768359557826018, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6075844258167934}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,676] Trial 244 finished with value: 0.7893030285187149 and parameters: {'C': 0.02434569587841604, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06889194895206244, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5799291877552636}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,748] Trial 245 finished with value: 0.7982688570923864 and parameters: {'C': 0.10367611932859705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07122534846128291, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6557185334990843}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,821] Trial 246 finished with value: 0.8028531639803915 and parameters: {'C': 0.04870742910874324, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.07884271932703805, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6040866629534448}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,920] Trial 247 finished with value: 0.7938919441613183 and parameters: {'C': 0.06756028440540589, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.0748853807318514, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6353986428828357}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:22,978] Trial 248 finished with value: 0.7473018473018472 and parameters: {'C': 0.03408847632983603, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 123, 'tol': 0.06379305572155664, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5696966193738673}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:23,203] Trial 249 finished with value: 0.8028531639803915 and parameters: {'C': 0.045336416462410004, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.06168651011193005, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6187501654447783}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:23,529] Trial 250 finished with value: 0.7936710813206824 and parameters: {'C': 0.027021587318054, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06768105563293349, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6515375181955082}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:24,891] Trial 251 finished with value: 0.7982688570923864 and parameters: {'C': 0.07845780278356178, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.08101273352212966, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5869763890277988}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,059] Trial 252 finished with value: 0.7807327381878917 and parameters: {'C': 0.01881425814457229, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06531602504346741, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6103743892609688}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,133] Trial 253 finished with value: 0.8028531639803915 and parameters: {'C': 0.054330345293011326, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06009802183341561, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5567844075306566}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,205] Trial 254 finished with value: 0.7936710813206824 and parameters: {'C': 0.03698326822003514, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.0768142879118661, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6339389589101111}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,276] Trial 255 finished with value: 0.7982688570923864 and parameters: {'C': 0.06590168396182071, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06323104656273432, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5953286913763084}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,349] Trial 256 finished with value: 0.7982688570923864 and parameters: {'C': 0.0986700287725586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.06663055061476687, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6666104947045133}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,446] Trial 257 finished with value: 0.7936710813206824 and parameters: {'C': 0.038278628192170976, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.0717815266078012, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6240066704502815}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:25,531] Trial 258 finished with value: 0.7571431799692669 and parameters: {'C': 0.057073244164460205, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 110, 'tol': 0.07425850361683131, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6420416076167064}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,602] Trial 259 finished with value: 0.7936710813206824 and parameters: {'C': 0.027239329882148316, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06078631594910404, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5787650206005079}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,698] Trial 260 finished with value: 0.8028531639803915 and parameters: {'C': 0.04525660004809238, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 54, 'tol': 0.06969012903755589, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6070373113197578}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,801] Trial 261 finished with value: 0.7982688570923864 and parameters: {'C': 0.11496062900198563, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07769835300296188, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6526072263254029}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,891] Trial 262 finished with value: 0.7691765275082738 and parameters: {'C': 0.07627245924731907, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06358276827460106, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5517389452649889}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:25,942] Trial 263 finished with value: 0.6364637385465951 and parameters: {'C': 0.03216835612949347, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 124, 'tol': 0.06826943634750837, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6178305723372949}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,082] Trial 264 finished with value: 0.8028531639803915 and parameters: {'C': 0.04925069041681288, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07541823672754377, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5901918496413889}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,169] Trial 265 finished with value: 0.7982688570923864 and parameters: {'C': 0.07090952590696964, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05991565266068426, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6648715901350442}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,220] Trial 266 finished with value: 0.6155135550296841 and parameters: {'C': 0.017925404140546202, 'fit_intercept': False, 'solver': 'sag', 'max_iter': 122, 'tol': 0.06569786809134967, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6332780599760642}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,300] Trial 267 finished with value: 0.7936710813206824 and parameters: {'C': 0.03779125814235035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.08517732066807962, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6035031989727182}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,371] Trial 268 finished with value: 0.7936710813206824 and parameters: {'C': 0.025730731060431992, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.062292637228599616, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5708738703873489}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,502] Trial 269 finished with value: 0.7982688570923864 and parameters: {'C': 0.1068228742604405, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.07079343388018469, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6271252916490622}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,570] Trial 270 finished with value: 0.8028531639803915 and parameters: {'C': 0.051038201885527844, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.08179255942879475, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6438716591952001}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,668] Trial 271 finished with value: 0.7982688570923864 and parameters: {'C': 0.08060117043064674, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.0731536348623417, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.275470382908991}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,734] Trial 272 finished with value: 0.7936710813206824 and parameters: {'C': 0.03788566970633697, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07858778344766101, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6711727415074724}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,787] Trial 273 finished with value: 0.7515784995494071 and parameters: {'C': 0.06315195857024375, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 124, 'tol': 0.06452156422582019, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5895850632689303}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:26,855] Trial 274 finished with value: 0.8028531639803915 and parameters: {'C': 0.05332734321333848, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.06734416474240563, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6074312993437245}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:27,008] Trial 275 finished with value: 0.7849307243422452 and parameters: {'C': 0.0212184256232543, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.060024970562435435, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6269255418001569}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:27,320] Trial 276 finished with value: 0.7982688570923864 and parameters: {'C': 0.030824625424943356, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.057510956256991555, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5772996799231862}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:27,384] Trial 277 finished with value: 0.8028531639803915 and parameters: {'C': 0.08983656432411481, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06255205849904551, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5347157022600301}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:27,472] Trial 278 finished with value: 0.7982688570923864 and parameters: {'C': 0.042379233893648005, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07458998458723105, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6561056668283161}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:27,967] Trial 279 finished with value: 0.8028531639803915 and parameters: {'C': 0.0604705267602731, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07070960581583205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6160053455062863}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,071] Trial 280 finished with value: 0.7982688570923864 and parameters: {'C': 0.1295944898017554, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.058533735881235546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6012791592209296}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,162] Trial 281 finished with value: 0.7638512075293685 and parameters: {'C': 0.03149463380991347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.06579516237185934, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6374009884190857}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:28,354] Trial 282 finished with value: 0.7515784995494071 and parameters: {'C': 0.04585036054527187, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 107, 'tol': 0.07620448025921514, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5601624492971811}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,459] Trial 283 finished with value: 0.7982688570923864 and parameters: {'C': 0.07965974084860046, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06901133474593937, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5949555934735956}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,561] Trial 284 finished with value: 0.7934145698586808 and parameters: {'C': 68.71331762877676, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06142186659462446, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.66942053152838}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,624] Trial 285 finished with value: 0.7563267813267813 and parameters: {'C': 0.05877822911535563, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07916644357961858, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6174932247511348}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,690] Trial 286 finished with value: 0.7936710813206824 and parameters: {'C': 0.02564907233019875, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06415624935104498, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6441754635913843}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,752] Trial 287 finished with value: 0.7936710813206824 and parameters: {'C': 0.039726452395007855, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06756912976066635, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5823935191227171}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,801] Trial 288 finished with value: 0.6232254528464635 and parameters: {'C': 0.10448145081405691, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 133, 'tol': 0.05864871889981395, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6220819801030295}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,852] Trial 289 finished with value: 0.6155135550296841 and parameters: {'C': 0.071034918789693, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 128, 'tol': 0.07164126782176378, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.651574714021514}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,918] Trial 290 finished with value: 0.7764613692033047 and parameters: {'C': 0.01630625506991349, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.061259019109092774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.09834970494048145}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:28,981] Trial 291 finished with value: 0.8028531639803915 and parameters: {'C': 0.04975132741373273, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.07318882397504302, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6060139356639561}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,054] Trial 292 finished with value: 0.7982688570923864 and parameters: {'C': 0.0326038276152158, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.08331952143403588, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6849609004696894}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,119] Trial 293 finished with value: 0.8028531639803915 and parameters: {'C': 0.060391449496203835, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.08064680558939222, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5627398345186589}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,181] Trial 294 finished with value: 0.7893030285187149 and parameters: {'C': 0.021763811583570228, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 96, 'tol': 0.06595914049007297, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5893466016880634}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,246] Trial 295 finished with value: 0.7936710813206824 and parameters: {'C': 0.03933703486861373, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07659240986244299, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6293831728248062}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,318] Trial 296 finished with value: 0.7982688570923864 and parameters: {'C': 0.08742449931570698, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 75, 'tol': 0.06277994530784113, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6137035945450415}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,471] Trial 297 finished with value: 0.8028531639803915 and parameters: {'C': 0.049257959243097144, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.059379430283879577, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.645365144915876}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,559] Trial 298 finished with value: 0.7982688570923864 and parameters: {'C': 0.027813000124094003, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0698117402748899, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7843433231931521}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,632] Trial 299 finished with value: 0.7765503863064839 and parameters: {'C': 0.012152017490206926, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06493403215224991, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5794356586807964}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,684] Trial 300 finished with value: 0.7606120086567014 and parameters: {'C': 0.1235380649982931, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 113, 'tol': 0.07488184531761095, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6669836304085196}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,755] Trial 301 finished with value: 0.7691765275082738 and parameters: {'C': 0.07352573570757108, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06741000684621061, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6003027536915797}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,820] Trial 302 finished with value: 0.7982688570923864 and parameters: {'C': 0.041830071238593676, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.057131770630760005, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5465289123355944}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,883] Trial 303 finished with value: 0.8028531639803915 and parameters: {'C': 0.059619307697941805, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06091595823804021, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6337363732388895}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:29,945] Trial 304 finished with value: 0.7696455177639956 and parameters: {'C': 0.03187412621235454, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07796197953960324, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6133830885099429}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,008] Trial 305 finished with value: 0.7982688570923864 and parameters: {'C': 0.0935202033601338, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06390020990480678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5712531366371231}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,128] Trial 306 finished with value: 0.8028531639803915 and parameters: {'C': 0.04688305206486828, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07211553646137557, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6768442018653585}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,208] Trial 307 finished with value: 0.7893030285187149 and parameters: {'C': 0.021722691974707133, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06853174737481223, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.63704685743107}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,283] Trial 308 finished with value: 0.8028531639803915 and parameters: {'C': 0.05993520802030903, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05998969140916136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5932551763785906}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:30,365] Trial 309 finished with value: 0.7664686441880739 and parameters: {'C': 0.03473048874599951, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 124, 'tol': 0.06318061272881172, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6518852611357658}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,445] Trial 310 finished with value: 0.7982688570923864 and parameters: {'C': 0.07559351564495136, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.08788062284918696, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6196289234086807}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,511] Trial 311 finished with value: 0.8028531639803915 and parameters: {'C': 0.04383475266033316, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06636354817495008, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5204412354351667}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,634] Trial 312 finished with value: 0.7982688570923864 and parameters: {'C': 0.12352298046360574, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0800325465587319, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7965630926876375}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,686] Trial 313 finished with value: 0.5934331813570617 and parameters: {'C': 0.027741499821213433, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 116, 'tol': 0.05577599152484907, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6097320778863627}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,746] Trial 314 finished with value: 0.8028531639803915 and parameters: {'C': 0.06024630629584416, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07373417246813678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7536881328876023}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,811] Trial 315 finished with value: 0.7982688570923864 and parameters: {'C': 0.08695302635761046, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07611195864028593, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5935632164295296}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,885] Trial 316 finished with value: 0.7936710813206824 and parameters: {'C': 0.03796694752236047, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.057735989486775545, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6580043656894196}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:30,941] Trial 317 finished with value: 0.6244551002615518 and parameters: {'C': 0.05198613319107577, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 104, 'tol': 0.05349420613274736, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6277798309564563}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,013] Trial 318 finished with value: 0.7893030285187149 and parameters: {'C': 0.02304685638050571, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.07006436556669031, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5628599454167905}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,156] Trial 319 finished with value: 0.7982688570923864 and parameters: {'C': 0.07291283293197628, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.06288265129733947, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6364426878085563}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,235] Trial 320 finished with value: 0.7643951617832215 and parameters: {'C': 0.03590256493864861, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.061430510814817194, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.19232571990481928}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,305] Trial 321 finished with value: 0.8028531639803915 and parameters: {'C': 0.048657230033143005, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06603179354288655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6931839682946304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,470] Trial 322 finished with value: 0.7982688570923864 and parameters: {'C': 0.11807983766036087, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.059103234994845655, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5856000102634066}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,593] Trial 323 finished with value: 0.7938919441613183 and parameters: {'C': 0.06690218474709901, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.07748773072117479, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6064082413435199}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,832] Trial 324 finished with value: 0.7473018473018472 and parameters: {'C': 0.0169510853853983, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06911635049182041, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6740452165942106}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:31,959] Trial 325 finished with value: 0.7936710813206824 and parameters: {'C': 0.0379762746824459, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 190, 'tol': 0.07224174092799678, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6232057735033358}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,022] Trial 326 finished with value: 0.7606120086567014 and parameters: {'C': 0.08806242328009325, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 124, 'tol': 0.061730720206146804, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5716050604669304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,121] Trial 327 finished with value: 0.7982688570923864 and parameters: {'C': 0.027698211239893692, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.06455514034345403, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.026749647822675304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,208] Trial 328 finished with value: 0.8028531639803915 and parameters: {'C': 0.05268475563948519, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.07471080157231563, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6518387477792361}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,315] Trial 329 finished with value: 0.7587471277840314 and parameters: {'C': 0.0072186138378821174, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.0521657732403993, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6032582336162469}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,419] Trial 330 finished with value: 0.8028531639803915 and parameters: {'C': 0.06203616189664665, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.054847164098466517, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6372805139265771}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,503] Trial 331 finished with value: 0.7982688570923864 and parameters: {'C': 0.030574504958114448, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06764169442357403, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5890006727623525}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,600] Trial 332 finished with value: 0.8028531639803915 and parameters: {'C': 0.044885289572242776, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.057872378818835016, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7671943934894152}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,724] Trial 333 finished with value: 0.7982688570923864 and parameters: {'C': 0.10670578058887502, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07858859596763143, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5524937555746668}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:32,881] Trial 334 finished with value: 0.7895106372229068 and parameters: {'C': 0.020240823053505712, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0642732151941832, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6138549772332113}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:32,983] Trial 335 finished with value: 0.7528261852586178 and parameters: {'C': 0.07213526746448162, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 115, 'tol': 0.060931154212739536, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6598813130509951}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,075] Trial 336 finished with value: 0.6418376737179601 and parameters: {'C': 0.0004574782101172103, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.08305392665219997, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7268916863751611}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,153] Trial 337 finished with value: 0.7982688570923864 and parameters: {'C': 0.04164787155184279, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.07078807611995064, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6260444528355119}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,277] Trial 338 finished with value: 0.8028531639803915 and parameters: {'C': 0.05265020289871313, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 176, 'tol': 0.06649898045945989, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6843889893024842}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,407] Trial 339 finished with value: 0.7595927526039051 and parameters: {'C': 0.03319910060960575, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.07658724334829521, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5858803583529861}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,498] Trial 340 finished with value: 0.6287980131205215 and parameters: {'C': 4.5061511084860306e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.08044445116569328, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.819689201684726}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,553] Trial 341 finished with value: 0.6037188955357665 and parameters: {'C': 0.15331615547702174, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 113, 'tol': 0.07379206086754438, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.607666807083409}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,603] Trial 342 finished with value: 0.6244551002615518 and parameters: {'C': 0.07331548375524309, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 121, 'tol': 0.050037846975202596, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6428329287352678}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,646] Trial 343 finished with value: 0.7563267813267813 and parameters: {'C': 0.09298305903694527, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06020361016642713, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6228047905307061}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,729] Trial 344 finished with value: 0.7936710813206824 and parameters: {'C': 0.02577657817840821, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.06849789010047434, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5392848801076742}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:33,824] Trial 345 finished with value: 0.8028531639803915 and parameters: {'C': 0.04745179765424448, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.056773104133279656, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5720246194952846}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:34,015] Trial 346 finished with value: 0.8028531639803915 and parameters: {'C': 0.06010847524140057, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06229708987158206, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6623578304753869}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:34,127] Trial 347 finished with value: 0.7982688570923864 and parameters: {'C': 0.0349394474718052, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0646741842640976, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5974220348607964}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:34,223] Trial 348 finished with value: 0.8028531639803915 and parameters: {'C': 0.04309684185074493, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.05896002600160756, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7444516901652793}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:34,356] Trial 349 finished with value: 0.7982688570923864 and parameters: {'C': 0.10088654957513195, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07189322351733725, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6386253012603313}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:34,649] Trial 350 finished with value: 0.8028531639803915 and parameters: {'C': 0.06203827088628037, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.055413199689738936, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6158568482310922}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,139] Trial 351 finished with value: 0.7764613692033047 and parameters: {'C': 0.0167610252512241, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 167, 'tol': 0.07510878312729627, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7016030141593563}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,199] Trial 352 finished with value: 0.7743766493766494 and parameters: {'C': 0.028822870724578925, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 115, 'tol': 0.06686298670186863, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.593240842565961}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,272] Trial 353 finished with value: 0.7982688570923864 and parameters: {'C': 0.07659050460795483, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 185, 'tol': 0.04795588038151786, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6445621866639938}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,465] Trial 354 finished with value: 0.8028531639803915 and parameters: {'C': 0.047080213573377, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.07859430554025772, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.569808687596785}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,576] Trial 355 finished with value: 0.7893030285187149 and parameters: {'C': 0.02426418906955325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06278774636557949, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6749349176727647}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,652] Trial 356 finished with value: 0.7936710813206824 and parameters: {'C': 0.03812325002431852, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06998068821643759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7756261584414383}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,737] Trial 357 finished with value: 0.7982688570923864 and parameters: {'C': 0.14706276033950624, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.06498599735409819, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6220367034576616}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,819] Trial 358 finished with value: 0.7595927526039051 and parameters: {'C': 0.056642919216374814, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.053341603320539645, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6027296162114795}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:35,988] Trial 359 finished with value: 0.7982688570923864 and parameters: {'C': 0.08625854964908625, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.07316285603694712, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6577739624984225}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,262] Trial 360 finished with value: 0.7982688570923864 and parameters: {'C': 0.034491149945874905, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05938441348513178, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.801097851901431}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:36,511] Trial 361 finished with value: 0.7528261852586178 and parameters: {'C': 0.054542091730522796, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 118, 'tol': 0.0819145196594625, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6329781665284789}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,588] Trial 362 finished with value: 0.7982688570923864 and parameters: {'C': 0.07291011436619803, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07686439461018835, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5815178349228879}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,655] Trial 363 finished with value: 0.7515784995494071 and parameters: {'C': 0.041788989642906636, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.062071358389760196, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6087090893880408}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,755] Trial 364 finished with value: 0.7849307243422452 and parameters: {'C': 0.021312975709345577, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.0570515412127802, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7123196677625051}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,860] Trial 365 finished with value: 0.7982688570923864 and parameters: {'C': 0.10648782908930353, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06849126201674349, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5592341758720059}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,920] Trial 366 finished with value: 0.6111282988119751 and parameters: {'C': 0.029684765146055517, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 116, 'tol': 0.06574256414074968, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5035163569471104}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:36,985] Trial 367 finished with value: 0.8028531639803915 and parameters: {'C': 0.0540638839885315, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 96, 'tol': 0.05186618510083523, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6496286646830735}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,041] Trial 368 finished with value: 0.6198849451861501 and parameters: {'C': 0.07052849885142197, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 108, 'tol': 0.07144250729645836, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6265970456879114}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,108] Trial 369 finished with value: 0.7936710813206824 and parameters: {'C': 0.03902545873633384, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07545120337310586, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6859684076066792}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,190] Trial 370 finished with value: 0.7854029144351726 and parameters: {'C': 0.012512345860881296, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06067373457458366, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5916270839810096}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,388] Trial 371 finished with value: 0.8028531639803915 and parameters: {'C': 0.05496042559039586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.06437207194351457, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7612103897710315}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,496] Trial 372 finished with value: 0.7982688570923864 and parameters: {'C': 0.13499033007826586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.03974566560090511, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6094934615027132}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,574] Trial 373 finished with value: 0.7936710813206824 and parameters: {'C': 0.027063831874185432, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.058053553096157895, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7311414851852039}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,650] Trial 374 finished with value: 0.7982688570923864 and parameters: {'C': 0.08077310564417652, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06725823162622997, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5808077288987222}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,717] Trial 375 finished with value: 0.8028531639803915 and parameters: {'C': 0.041567592642269266, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.07902330051987647, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.641377409314465}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,847] Trial 376 finished with value: 0.8028531639803915 and parameters: {'C': 0.05788000810414231, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.05561034758005187, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5418623263745663}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:37,955] Trial 377 finished with value: 0.7895106372229068 and parameters: {'C': 0.019850042219598286, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06277487894980759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6667693279815848}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,016] Trial 378 finished with value: 0.7606120086567014 and parameters: {'C': 0.09568795904851136, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 122, 'tol': 0.0695286122736388, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6231105026476784}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,264] Trial 379 finished with value: 0.7643951617832215 and parameters: {'C': 0.036131932139346346, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.0728168131698729, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.61842420530497}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,343] Trial 380 finished with value: 0.8028531639803915 and parameters: {'C': 0.04557037504725462, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06039616985620053, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5980150942962856}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,520] Trial 381 finished with value: 0.7743766493766494 and parameters: {'C': 0.02648690532615667, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06356807423033421, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6457722454371416}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,795] Trial 382 finished with value: 0.7982688570923864 and parameters: {'C': 0.06949552816595507, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.07755224056064054, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5632904583691315}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:38,960] Trial 383 finished with value: 0.7982688570923864 and parameters: {'C': 0.11355558589664005, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.08034073056889454, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5959787524104083}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,077] Trial 384 finished with value: 0.7982688570923864 and parameters: {'C': 0.033868373109028134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06593046144132589, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6286380555666643}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,169] Trial 385 finished with value: 0.8028531639803915 and parameters: {'C': 0.0538437032428287, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05867301683463257, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6804911602696625}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,251] Trial 386 finished with value: 0.7982688570923864 and parameters: {'C': 0.07311001170046243, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0928058917052148, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.659999205511461}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:39,335] Trial 387 finished with value: 0.7571431799692669 and parameters: {'C': 0.045956038400105155, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 123, 'tol': 0.05430544822002826, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7479083696205373}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,453] Trial 388 finished with value: 0.7982688570923864 and parameters: {'C': 0.029943178239561764, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.049264127976956965, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5753061899149193}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,652] Trial 389 finished with value: 0.7982688570923864 and parameters: {'C': 0.08717222617726812, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06821432157490007, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6092379732722647}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,755] Trial 390 finished with value: 0.7764613692033047 and parameters: {'C': 0.015648134709282294, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07077514143807702, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7015459989683762}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,836] Trial 391 finished with value: 0.8028531639803915 and parameters: {'C': 0.0606837643247457, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.07417889717318207, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.63783386047548}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:39,959] Trial 392 finished with value: 0.7936710813206824 and parameters: {'C': 0.03712124192661099, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06104742034439947, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.24162457786043567}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,018] Trial 393 finished with value: 0.6198849451861501 and parameters: {'C': 0.048226626748314246, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 130, 'tol': 0.07615261431282636, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7872751447458931}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,066] Trial 394 finished with value: 0.6067286798994115 and parameters: {'C': 0.022422722108713274, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 117, 'tol': 0.08542621200116453, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6011923785681925}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,145] Trial 395 finished with value: 0.7982688570923864 and parameters: {'C': 0.12798317557332184, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.057175129438655124, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.581845723329726}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,224] Trial 396 finished with value: 0.7982688570923864 and parameters: {'C': 0.06280859785955308, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06383845268394935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6169027075652969}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,316] Trial 397 finished with value: 0.7595927526039051 and parameters: {'C': 0.03372197793728655, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05111891973619022, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6566567796055516}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,404] Trial 398 finished with value: 0.713849442663002 and parameters: {'C': 0.0023712628713021483, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 151, 'tol': 0.06671840112130671, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6335216941683285}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,474] Trial 399 finished with value: 0.7982688570923864 and parameters: {'C': 0.09907141294950776, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.059079429241376255, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7158034502366101}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,554] Trial 400 finished with value: 0.7515784995494071 and parameters: {'C': 0.04609282917337864, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.07357269572866133, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5926769309070329}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,637] Trial 401 finished with value: 0.7982688570923864 and parameters: {'C': 0.07082900038330826, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04502602436314456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6145762612567812}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,778] Trial 402 finished with value: 0.7936710813206824 and parameters: {'C': 0.02644801376988628, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07041834857945045, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5575497173861124}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:40,873] Trial 403 finished with value: 0.8028531639803915 and parameters: {'C': 0.044299133777733694, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.062274827098565626, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6764610135160439}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,023] Trial 404 finished with value: 0.7982688570923864 and parameters: {'C': 0.07732171139448843, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06574427018229714, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5260906864427125}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,085] Trial 405 finished with value: 0.7610556379121386 and parameters: {'C': 0.05552189967650849, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 133, 'tol': 0.037155433764439035, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6414026599284992}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,148] Trial 406 finished with value: 0.7936710813206824 and parameters: {'C': 0.0389960669654319, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05401165313549955, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5812215190753304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,217] Trial 407 finished with value: 0.7982688570923864 and parameters: {'C': 0.03046060559852499, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.042157018215366604, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6246791774831741}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,287] Trial 408 finished with value: 0.802641903871957 and parameters: {'C': 0.16822791006289006, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 200, 'tol': 0.08129183608255969, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6034879921278112}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,355] Trial 409 finished with value: 0.8028531639803915 and parameters: {'C': 0.09055076732752351, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.06880504243010822, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6483118277883663}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,528] Trial 410 finished with value: 0.7807327381878917 and parameters: {'C': 0.01841017865601841, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07749958564792847, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7573655623624669}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,614] Trial 411 finished with value: 0.8028531639803915 and parameters: {'C': 0.05682027951750585, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05624509329559338, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7333366366581814}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:41,727] Trial 412 finished with value: 0.7936710813206824 and parameters: {'C': 0.03701173075494421, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 93, 'tol': 0.04712559756073844, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6917155027243671}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:41,964] Trial 413 finished with value: 0.7528261852586178 and parameters: {'C': 0.06637409447403637, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 120, 'tol': 0.0643093907529506, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6245897350629365}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,190] Trial 414 finished with value: 0.7982688570923864 and parameters: {'C': 0.1140319009288295, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06041406961491485, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6625074851767281}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,318] Trial 415 finished with value: 0.7729338533936235 and parameters: {'C': 0.024331236890215255, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.07503132106779838, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5575090743315632}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,516] Trial 416 finished with value: 0.8028531639803915 and parameters: {'C': 0.04847567269205848, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06201196529266084, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5994309851059498}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,668] Trial 417 finished with value: 0.7982688570923864 and parameters: {'C': 0.08416608969131732, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.07228578428804465, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5811784042427922}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,733] Trial 418 finished with value: 0.5927498395207852 and parameters: {'C': 0.034627205144664074, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 126, 'tol': 0.07903753418095834, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6331446475793383}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,800] Trial 419 finished with value: 0.7515784995494071 and parameters: {'C': 0.047471366122045215, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.052517107004409105, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6118872711192929}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:42,962] Trial 420 finished with value: 0.8028531639803915 and parameters: {'C': 0.06224157622388511, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.058157678137564735, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7775138862419533}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,047] Trial 421 finished with value: 0.7936710813206824 and parameters: {'C': 0.0270766862224686, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06719527298283078, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6564295628255736}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,102] Trial 422 finished with value: 0.6155135550296841 and parameters: {'C': 0.04410595250995654, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 120, 'tol': 0.0647321469321853, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5721636712386371}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,174] Trial 423 finished with value: 0.7982688570923864 and parameters: {'C': 0.08693948682836582, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.060268979720002336, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5996012765049289}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,259] Trial 424 finished with value: 0.7934145698586808 and parameters: {'C': 10.379300936031601, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.0685982797546999, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6372806688562066}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,333] Trial 425 finished with value: 0.7982688570923864 and parameters: {'C': 0.13550670257432876, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07127549186312625, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.670357271826345}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,404] Trial 426 finished with value: 0.7982688570923864 and parameters: {'C': 0.06356965349754716, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.07643518360315651, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5388461346432983}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,498] Trial 427 finished with value: 0.7895106372229068 and parameters: {'C': 0.01975388133957822, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 136, 'tol': 0.055926534429779316, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8084706047472674}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,577] Trial 428 finished with value: 0.7982688570923864 and parameters: {'C': 0.03424554116269065, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.062792860022417, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6168966588710951}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,659] Trial 429 finished with value: 0.8028531639803915 and parameters: {'C': 0.05189052552842648, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.04955730655412226, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5883326339849066}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,719] Trial 430 finished with value: 0.7515784995494071 and parameters: {'C': 0.07350159452703162, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 114, 'tol': 0.08257041395299632, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6440930595821347}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,817] Trial 431 finished with value: 0.7982688570923864 and parameters: {'C': 0.030329165301488676, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06602272879154641, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6088262918524838}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,886] Trial 432 finished with value: 0.8028531639803915 and parameters: {'C': 0.04265912136544115, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07448485841537442, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6957760221283793}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:43,966] Trial 433 finished with value: 0.7982688570923864 and parameters: {'C': 0.09522296394777911, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.07935740765572902, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6244132360137967}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,138] Trial 434 finished with value: 0.8028531639803915 and parameters: {'C': 0.0592740081916378, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 70, 'tol': 0.05954349113172294, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7160155956976035}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,209] Trial 435 finished with value: 0.7893030285187149 and parameters: {'C': 0.023035888759822626, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06396900306153783, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5691573395140841}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,311] Trial 436 finished with value: 0.7820164992578785 and parameters: {'C': 0.013008233005838586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.057514914932856, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6528647706660788}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,427] Trial 437 finished with value: 0.7936710813206824 and parameters: {'C': 0.038983522806736656, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.0622001291118737, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7410775884356229}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,488] Trial 438 finished with value: 0.7515784995494071 and parameters: {'C': 0.05315690454416132, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06775820634198197, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5929452178032061}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:44,599] Trial 439 finished with value: 0.784432594635145 and parameters: {'C': 0.07839540445101727, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 120, 'tol': 0.07036907186872904, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6306650126690545}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,766] Trial 440 finished with value: 0.7982688570923864 and parameters: {'C': 0.1189748777226862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.054033390774965356, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6825106509829224}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,870] Trial 441 finished with value: 0.7936710813206824 and parameters: {'C': 0.03701886394668882, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07321212553768827, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6119274780603919}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:44,951] Trial 442 finished with value: 0.7982688570923864 and parameters: {'C': 0.028382188907263725, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07655029009269738, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5498029596108296}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,027] Trial 443 finished with value: 0.7982688570923864 and parameters: {'C': 0.06397256856383583, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 195, 'tol': 0.06060862357563582, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7626424573602737}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,113] Trial 444 finished with value: 0.8028531639803915 and parameters: {'C': 0.047036311501390454, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06451035255690156, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5858679451609304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,718] Trial 445 finished with value: 0.7982688570923864 and parameters: {'C': 0.11011811244068832, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.06940094191224594, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6685355925612256}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,806] Trial 446 finished with value: 0.6112509597075283 and parameters: {'C': 0.15989879777355095, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 119, 'tol': 0.05216549755492241, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6406916691123503}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,850] Trial 447 finished with value: 0.6244551002615518 and parameters: {'C': 0.01873424504054356, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 156, 'tol': 0.0559854757817538, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6062455330987523}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:45,907] Trial 448 finished with value: 0.7982688570923864 and parameters: {'C': 0.03348555487986003, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.0659365289242305, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6225226714730893}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,019] Trial 449 finished with value: 0.7982688570923864 and parameters: {'C': 0.07732289892544425, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.05825572920117313, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5644497513913909}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,112] Trial 450 finished with value: 0.8028531639803915 and parameters: {'C': 0.05280990829568593, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06191531701487025, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8321533048328175}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,203] Trial 451 finished with value: 0.7982688570923864 and parameters: {'C': 0.041793708454336775, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.07263451933548631, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6512373230616626}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,342] Trial 452 finished with value: 0.7936710813206824 and parameters: {'C': 0.025941596762969765, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 87, 'tol': 0.08062438357963518, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5959682890773528}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,461] Trial 453 finished with value: 0.7643951617832215 and parameters: {'C': 0.06678306653100048, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06819401475482667, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.791148732056707}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,555] Trial 454 finished with value: 0.7982688570923864 and parameters: {'C': 0.09544642533005741, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07791363268072343, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6238807590298622}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,647] Trial 455 finished with value: 0.8028531639803915 and parameters: {'C': 0.04871479543891322, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.07563222397940578, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5786692377735946}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,718] Trial 456 finished with value: 0.7982688570923864 and parameters: {'C': 0.03199901673934293, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0589429518170617, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6667664151854579}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,775] Trial 457 finished with value: 0.7468100862542021 and parameters: {'C': 20.270099000130585, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 123, 'tol': 0.06359441494063939, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6120534704540646}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:46,928] Trial 458 finished with value: 0.8028531639803915 and parameters: {'C': 0.058709822448996016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.0509935823291586, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6358573067780513}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,011] Trial 459 finished with value: 0.8028531639803915 and parameters: {'C': 0.04316867803391665, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06655886234314168, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7229272386014501}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,087] Trial 460 finished with value: 0.7982688570923864 and parameters: {'C': 0.07820285121552248, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.07100721200383125, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5972513471823934}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,164] Trial 461 finished with value: 0.7936710813206824 and parameters: {'C': 0.026910359806644805, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.04761046450942325, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6519605888911838}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,243] Trial 462 finished with value: 0.7632115255111387 and parameters: {'C': 0.009851232822229251, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06097225946925808, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.573859729826662}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,316] Trial 463 finished with value: 0.7936710813206824 and parameters: {'C': 0.039147082840142074, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.05393119170491986, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6918141437452895}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,387] Trial 464 finished with value: 0.7895106372229068 and parameters: {'C': 0.020635461338484557, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06271522254145327, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6306667380904281}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:47,547] Trial 465 finished with value: 0.7704578518597737 and parameters: {'C': 0.06630844150005592, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 107, 'tol': 0.07416322172135392, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6040786858414448}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,615] Trial 466 finished with value: 0.8028531639803915 and parameters: {'C': 0.09317129212098701, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06943023012795486, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6185176245162499}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,695] Trial 467 finished with value: 0.8028531639803915 and parameters: {'C': 0.05560379445464152, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.04306660960603282, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.746601069261686}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,768] Trial 468 finished with value: 0.7982688570923864 and parameters: {'C': 0.03229275521462924, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.05655911105941868, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5827756921265008}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,867] Trial 469 finished with value: 0.7764613692033047 and parameters: {'C': 0.015250615565117694, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06500595954881473, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.549915589988209}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:47,952] Trial 470 finished with value: 0.7982688570923864 and parameters: {'C': 0.13936681629543696, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05954425404396606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6429405634790057}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,008] Trial 471 finished with value: 0.6239677177177176 and parameters: {'C': 0.03787639096981552, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 117, 'tol': 0.07800060793060783, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6697831233374156}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,082] Trial 472 finished with value: 0.7643951617832215 and parameters: {'C': 0.04721081286391821, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.06713102267041501, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7777248457472298}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,136] Trial 473 finished with value: 0.6067286798994115 and parameters: {'C': 0.07446545176465894, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 110, 'tol': 0.07274326942497633, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5963864443009849}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,203] Trial 474 finished with value: 0.7982688570923864 and parameters: {'C': 0.10271290728106468, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0758776712564305, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6200851983041055}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,281] Trial 475 finished with value: 0.7893030285187149 and parameters: {'C': 0.023713326689807357, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.08278055882268802, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7028648072993066}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,345] Trial 476 finished with value: 0.7515784995494071 and parameters: {'C': 0.055277743541183685, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.06279053070356064, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5288240728771137}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,417] Trial 477 finished with value: 0.7936710813206824 and parameters: {'C': 0.03514120580983137, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.08469287774522166, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6319920700053345}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,505] Trial 478 finished with value: 0.7938919441613183 and parameters: {'C': 0.06645993994074981, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 81, 'tol': 0.061501077933505906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6559595221612763}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,654] Trial 479 finished with value: 0.8028531639803915 and parameters: {'C': 0.04687830992198366, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.08035178727282734, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6050980318822003}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,818] Trial 480 finished with value: 0.7982688570923864 and parameters: {'C': 0.0287192518202364, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.057448273952231954, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5801310965360049}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:48,942] Trial 481 finished with value: 0.7982688570923864 and parameters: {'C': 0.09229128526047473, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06525494192737959, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6841182246391354}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,025] Trial 482 finished with value: 0.8028531639803915 and parameters: {'C': 0.046031794208526544, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07150148560961464, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5613467051338724}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,098] Trial 483 finished with value: 0.7982688570923864 and parameters: {'C': 0.06301909671545444, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05477444458596651, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6450434226515604}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,154] Trial 484 finished with value: 0.7563267813267813 and parameters: {'C': 0.0361843276046819, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 126, 'tol': 0.06787286839219114, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6142422653006034}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,216] Trial 485 finished with value: 0.7982688570923864 and parameters: {'C': 0.12505695566612227, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 138, 'tol': 0.059825534027337604, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5912134462910585}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,350] Trial 486 finished with value: 0.7982688570923864 and parameters: {'C': 0.07814363693967213, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07542967329842465, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7343280831750485}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,428] Trial 487 finished with value: 0.7893030285187149 and parameters: {'C': 0.021577448446518512, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04986515971149586, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7639174308627599}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,495] Trial 488 finished with value: 0.802641903871957 and parameters: {'C': 0.18754406539291635, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.07825343949258638, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6284649674947566}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,567] Trial 489 finished with value: 0.8028531639803915 and parameters: {'C': 0.04987324359693949, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06994289317435909, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6634801872744486}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,810] Trial 490 finished with value: 0.7982688570923864 and parameters: {'C': 0.030999510012688143, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06418901571067367, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6066986928678448}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:49,957] Trial 491 finished with value: 0.8028531639803915 and parameters: {'C': 0.06223117769344189, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.058222447486941456, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6348165797862724}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:50,227] Trial 492 finished with value: 0.7394367794367793 and parameters: {'C': 0.043896951429812266, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 120, 'tol': 0.07406698210202708, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.474979112254474}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:50,596] Trial 493 finished with value: 0.7982688570923864 and parameters: {'C': 0.08901628345598323, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.061377495088477715, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.570493888652581}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:50,682] Trial 494 finished with value: 0.7982688570923864 and parameters: {'C': 0.02803245580789149, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.0870910847063394, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7106737976754121}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:50,776] Trial 495 finished with value: 0.7563267813267813 and parameters: {'C': 0.057560121251631007, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.052850538563055265, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5960825948333173}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:50,877] Trial 496 finished with value: 0.6733365283207366 and parameters: {'C': 0.038668755066916104, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 123, 'tol': 0.0015066680032787966, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5111257755306589}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:50,995] Trial 497 finished with value: 0.7982688570923864 and parameters: {'C': 0.11834232218950858, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.06623024285433138, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7960817815277785}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,074] Trial 498 finished with value: 0.7764613692033047 and parameters: {'C': 0.016114673144346645, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 62, 'tol': 0.06840562878635066, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6496952625728288}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,154] Trial 499 finished with value: 0.6112509597075283 and parameters: {'C': 0.07563184583174562, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.06304871846077975, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6180829712890816}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,227] Trial 500 finished with value: 0.8028531639803915 and parameters: {'C': 0.0488508089066419, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.05558587836012086, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6732354220740048}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,299] Trial 501 finished with value: 0.7936710813206824 and parameters: {'C': 0.0262800967140321, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05958382062606268, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5788780541123725}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,383] Trial 502 finished with value: 0.7936710813206824 and parameters: {'C': 0.03792127010864885, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.04645600548613024, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5522512011367585}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,473] Trial 503 finished with value: 0.7938919441613183 and parameters: {'C': 0.06633152375240281, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.07138459714409232, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6310449511975796}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:51,898] Trial 504 finished with value: 0.7982688570923864 and parameters: {'C': 0.09653534786644631, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07918667268682278, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6096378465751069}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,283] Trial 505 finished with value: 0.8028531639803915 and parameters: {'C': 0.05334662440977812, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06501318191358609, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5918701202380855}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,405] Trial 506 finished with value: 0.7895106372229068 and parameters: {'C': 0.02027899090954056, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07698922544459662, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6500298721435754}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,496] Trial 507 finished with value: 0.7936710813206824 and parameters: {'C': 0.039161090682610006, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07317698563250478, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.61885423058695}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,576] Trial 508 finished with value: 0.7982688570923864 and parameters: {'C': 0.07602784138155552, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.06131500554039953, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6388374714801324}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,644] Trial 509 finished with value: 0.7743766493766494 and parameters: {'C': 0.030407181875642668, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 109, 'tol': 0.06731337097232716, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7502771899199623}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:52,924] Trial 510 finished with value: 0.7643951617832215 and parameters: {'C': 0.05489417235694058, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.05712639114060345, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.14637096210369283}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,008] Trial 511 finished with value: 0.7982688570923864 and parameters: {'C': 0.15055533699220103, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.0638573827038361, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6753724356094438}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,191] Trial 512 finished with value: 0.633156233156233 and parameters: {'C': 2.5929436164009934e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.09887730306072082, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6046619788035308}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,275] Trial 513 finished with value: 0.7982688570923864 and parameters: {'C': 0.04214693902637938, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05194690807394356, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.583220652135125}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,437] Trial 514 finished with value: 0.7982688570923864 and parameters: {'C': 0.09729151191027187, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0759559943311495, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8109816936395905}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,602] Trial 515 finished with value: 0.7938919441613183 and parameters: {'C': 0.06476182423838123, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06909438245762768, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6915789878116776}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:53,709] Trial 516 finished with value: 0.7982688570923864 and parameters: {'C': 0.027677525031454483, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 94, 'tol': 0.05890519702045951, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7251721862919098}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,103] Trial 517 finished with value: 0.7515784995494071 and parameters: {'C': 0.04758542764390422, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06591846242519493, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6226542234505501}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:54,372] Trial 518 finished with value: 0.7438380465407493 and parameters: {'C': 0.033031664356042344, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 127, 'tol': 0.08023427529201027, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6619872489958416}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,471] Trial 519 finished with value: 0.7982688570923864 and parameters: {'C': 0.07377133162407083, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 182, 'tol': 0.06241505850024607, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5650173761059619}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,619] Trial 520 finished with value: 0.7807327381878917 and parameters: {'C': 0.018852243063597004, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.04854993664923597, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5957416521893459}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,759] Trial 521 finished with value: 0.6461619841901532 and parameters: {'C': 0.0004787656849029697, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05486798373204409, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6414166915858256}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,894] Trial 522 finished with value: 0.8028531639803915 and parameters: {'C': 0.05276487300048145, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07034186811046501, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5399153808315801}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:54,958] Trial 523 finished with value: 0.6232254528464635 and parameters: {'C': 0.03770542196244673, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 113, 'tol': 0.07506903417340759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8479498407223649}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,045] Trial 524 finished with value: 0.633156233156233 and parameters: {'C': 8.775913958497277e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06079354791718307, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6087367952976184}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,137] Trial 525 finished with value: 0.7982688570923864 and parameters: {'C': 0.11308444036011016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.04469580767659463, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6240926269938265}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,204] Trial 526 finished with value: 0.6198849451861501 and parameters: {'C': 0.02363523069495737, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 131, 'tol': 0.057192230305280506, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3896001630340331}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,286] Trial 527 finished with value: 0.7982688570923864 and parameters: {'C': 0.07785873987699106, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06379328515087815, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7666769095869382}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,465] Trial 528 finished with value: 0.8028531639803915 and parameters: {'C': 0.05359969519070741, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07325059657155589, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.581756749577717}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,586] Trial 529 finished with value: 0.7643951617832215 and parameters: {'C': 0.03910364964441341, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.05039617684416356, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.3084705561192202}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,678] Trial 530 finished with value: 0.7938919441613183 and parameters: {'C': 0.06638163575047694, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.0670949225614564, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6571259669589726}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:55,765] Trial 531 finished with value: 0.7982688570923864 and parameters: {'C': 0.030812330440439017, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.07730882697630784, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6303120558525491}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:56,528] Trial 532 finished with value: 0.8028531639803915 and parameters: {'C': 0.08935437054831374, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.07101557352798402, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6032744335144646}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:56,616] Trial 533 finished with value: 0.7515784995494071 and parameters: {'C': 0.04438119245007092, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.040557759435213336, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7058251016812792}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:56,717] Trial 534 finished with value: 0.8028531639803915 and parameters: {'C': 0.05710264614764407, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.08298678426747873, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.645578860448629}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:56,818] Trial 535 finished with value: 0.7854029144351726 and parameters: {'C': 0.013565005805453704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.03839836262653897, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5638011935678734}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:56,964] Trial 536 finished with value: 0.7893030285187149 and parameters: {'C': 0.02537762376122459, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.059243754829852495, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5902672016617474}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,049] Trial 537 finished with value: 0.802641903871957 and parameters: {'C': 0.18175840275780414, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06553302782093007, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6187856117327771}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,109] Trial 538 finished with value: 0.7606120086567014 and parameters: {'C': 0.12284689327408757, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 122, 'tol': 0.061059399432945964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6792440170610876}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,177] Trial 539 finished with value: 0.8028531639803915 and parameters: {'C': 0.042352469824621056, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.007065467328153677, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6374273767219412}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,252] Trial 540 finished with value: 0.7982688570923864 and parameters: {'C': 0.07795185111018879, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.07891877940209716, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7374547190419279}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,482] Trial 541 finished with value: 0.7982688570923864 and parameters: {'C': 0.0338131112936877, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.05283773414735063, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6016212646949887}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,580] Trial 542 finished with value: 0.8028531639803915 and parameters: {'C': 0.055680583036483884, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06874271772731944, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.659770192807505}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,720] Trial 543 finished with value: 0.7982688570923864 and parameters: {'C': 0.06439518135558608, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.0722036312563836, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7872305891403699}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:57,830] Trial 544 finished with value: 0.7982688570923864 and parameters: {'C': 0.10065166577170552, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06419030884249544, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5727412027545161}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:06:57,968] Trial 545 finished with value: 0.7531543903711447 and parameters: {'C': 0.01974690314234839, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 123, 'tol': 0.05602291208131459, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6059193975304801}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,180] Trial 546 finished with value: 0.7936710813206824 and parameters: {'C': 0.0413984820684327, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.07490557285923431, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6322224490001881}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,298] Trial 547 finished with value: 0.7982688570923864 and parameters: {'C': 0.030069560034816832, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0623857016053441, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5846209531226843}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,405] Trial 548 finished with value: 0.8028531639803915 and parameters: {'C': 0.052349320007945455, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.059073346501340836, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6171939506355589}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,524] Trial 549 finished with value: 0.7691765275082738 and parameters: {'C': 0.08073033323938018, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.06718068980488064, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5490350433845131}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,593] Trial 550 finished with value: 0.6068202628858366 and parameters: {'C': 0.04050610608113331, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 120, 'tol': 0.05426804058546431, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6458486217517201}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,640] Trial 551 finished with value: 0.660553716923932 and parameters: {'C': 0.02554925831757216, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.07741234684402504, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6758790925325321}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,697] Trial 552 finished with value: 0.7563267813267813 and parameters: {'C': 0.06185378777226074, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06989959939429129, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5936087555815319}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,834] Trial 553 finished with value: 0.7982688570923864 and parameters: {'C': 0.1313745688900057, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.08056244886776825, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6185713982576726}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:58,932] Trial 554 finished with value: 0.8028531639803915 and parameters: {'C': 0.0468171633479245, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06323891052000977, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.718895719359309}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,079] Trial 555 finished with value: 0.7982688570923864 and parameters: {'C': 0.032201102966033526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05784222171859227, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5681750800291419}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,197] Trial 556 finished with value: 0.8028531639803915 and parameters: {'C': 0.09005055819696636, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.06591907567978261, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6917937577897084}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,332] Trial 557 finished with value: 0.7982688570923864 and parameters: {'C': 0.06453724503787657, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06070537641565834, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6564755517096873}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,436] Trial 558 finished with value: 0.8028531639803915 and parameters: {'C': 0.046849914615915415, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 143, 'tol': 0.0735546985911832, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7603937976666441}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,513] Trial 559 finished with value: 0.7893030285187149 and parameters: {'C': 0.021791435407861152, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06845496235931403, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6246540222839594}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,619] Trial 560 finished with value: 0.7982688570923864 and parameters: {'C': 0.03372247139021724, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 51, 'tol': 0.05135398932661206, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5961336275389545}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,729] Trial 561 finished with value: 0.7606120086567014 and parameters: {'C': 0.07945693944522986, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 114, 'tol': 0.08173621823618286, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6311991500083297}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:06:59,859] Trial 562 finished with value: 0.8028531639803915 and parameters: {'C': 0.05321964240099119, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.07203020948166562, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5298874508016701}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,104] Trial 563 finished with value: 0.7982688570923864 and parameters: {'C': 0.1119346718961969, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06255257176129396, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6477484526692783}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,310] Trial 564 finished with value: 0.7936710813206824 and parameters: {'C': 0.04078838558013723, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07597914634859335, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.07304835462897763}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,412] Trial 565 finished with value: 0.8028531639803915 and parameters: {'C': 0.05807656381842851, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.048712489532701526, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6099610839953207}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,521] Trial 566 finished with value: 0.7936710813206824 and parameters: {'C': 0.02584406671375859, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.05619734774850121, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5815904121174343}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,658] Trial 567 finished with value: 0.7691765275082738 and parameters: {'C': 0.07582641759538547, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06466045912878643, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6703001808560753}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,797] Trial 568 finished with value: 0.7982688570923864 and parameters: {'C': 0.03548141404623569, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.0599524180181778, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.49718840420369675}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,896] Trial 569 finished with value: 0.7764613692033047 and parameters: {'C': 0.015492797017590609, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.03487240709904161, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6089282297930729}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:00,979] Trial 570 finished with value: 0.623929557403858 and parameters: {'C': 1.0600926079336846e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.0666634304419919, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8147688098423012}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:01,120] Trial 571 finished with value: 0.7515784995494071 and parameters: {'C': 0.15936459106533113, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 114, 'tol': 0.05793741774531076, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6376538148570051}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,196] Trial 572 finished with value: 0.8028531639803915 and parameters: {'C': 0.0491712923164117, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.07001173134243897, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5559281344868884}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,278] Trial 573 finished with value: 0.7934145698586808 and parameters: {'C': 5.1278977753602195, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07759033245251933, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7763416880810163}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,371] Trial 574 finished with value: 0.7982688570923864 and parameters: {'C': 0.10360945030744115, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06137356606576369, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5859431555456438}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,439] Trial 575 finished with value: 0.6239677177177176 and parameters: {'C': 0.06353339003779394, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 120, 'tol': 0.07487946576779937, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7377426510023166}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,514] Trial 576 finished with value: 0.7936710813206824 and parameters: {'C': 0.03896155004585495, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05342831233785775, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6174341656727851}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,602] Trial 577 finished with value: 0.6111282988119751 and parameters: {'C': 0.02215986348343098, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 171, 'tol': 0.06399393792947984, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6527039262844103}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,826] Trial 578 finished with value: 0.7982688570923864 and parameters: {'C': 0.03098463267045313, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.0677597189796574, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7065917281042897}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:01,946] Trial 579 finished with value: 0.7982688570923864 and parameters: {'C': 0.07696617473629791, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.0729668640210914, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5987047276648934}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,037] Trial 580 finished with value: 0.8028531639803915 and parameters: {'C': 0.04948667594270688, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07894237326048063, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6259778104414815}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,243] Trial 581 finished with value: 0.7982688570923864 and parameters: {'C': 0.06407054440180132, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.06523747192626231, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5698751767694687}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,331] Trial 582 finished with value: 0.7982688570923864 and parameters: {'C': 0.03322756133160251, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05947729988226126, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6831539041470843}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,420] Trial 583 finished with value: 0.7934145698586808 and parameters: {'C': 97.12919501972205, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.0624755863634335, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6398244091689029}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,501] Trial 584 finished with value: 0.8028531639803915 and parameters: {'C': 0.09134066906849134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0460253100728313, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6114623623928088}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,585] Trial 585 finished with value: 0.7227916475797833 and parameters: {'C': 0.0035490496269370802, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.05557184332535994, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6636979408516678}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,661] Trial 586 finished with value: 0.8028531639803915 and parameters: {'C': 0.05185775860237426, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05747903229407106, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5864381271883342}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:02,949] Trial 587 finished with value: 0.7643951617832215 and parameters: {'C': 0.04130339639850256, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.07121702166011012, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6286069283797086}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,045] Trial 588 finished with value: 0.7606120086567014 and parameters: {'C': 0.026788626785716734, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 119, 'tol': 0.06868271048064485, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7553539759832298}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,425] Trial 589 finished with value: 0.7934145698586808 and parameters: {'C': 51.34055124833512, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.07490158707913369, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6047928684916809}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,544] Trial 590 finished with value: 0.7563267813267813 and parameters: {'C': 0.13816780729697448, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.09026303551375281, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6491724817345126}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,666] Trial 591 finished with value: 0.7982688570923864 and parameters: {'C': 0.06843427630314546, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.0504327490763483, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5649117411720731}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,766] Trial 592 finished with value: 0.8028531639803915 and parameters: {'C': 0.04321801297325665, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.060760182328644906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5900367106098235}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,862] Trial 593 finished with value: 0.8028531639803915 and parameters: {'C': 0.09070699946793384, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06546236985011362, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6217801502364394}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:03,966] Trial 594 finished with value: 0.78512441012441 and parameters: {'C': 0.019514984400050065, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07725246327916313, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6684878285746185}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,083] Trial 595 finished with value: 0.8028531639803915 and parameters: {'C': 0.06082583325112333, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06208154506580692, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6377534507224047}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,193] Trial 596 finished with value: 0.7587471277840314 and parameters: {'C': 0.008927473392488868, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.08005016931859409, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6907765370585606}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,275] Trial 597 finished with value: 0.7982688570923864 and parameters: {'C': 0.03183134194561777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05892926319106415, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7250533248439166}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:04,359] Trial 598 finished with value: 0.7515784995494071 and parameters: {'C': 0.04755792290914346, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 97, 'tol': 0.06667800322199312, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7918982345369754}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,522] Trial 599 finished with value: 0.7982688570923864 and parameters: {'C': 0.07973699761055239, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 146, 'tol': 0.08381790197592656, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.542981588909875}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,608] Trial 600 finished with value: 0.7893030285187149 and parameters: {'C': 0.02519676090187061, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06392747360939974, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6051886639370162}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,676] Trial 601 finished with value: 0.6065720097978163 and parameters: {'C': 0.11854596711262201, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 138, 'tol': 0.07227688921034696, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5815883057560005}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,749] Trial 602 finished with value: 0.7936710813206824 and parameters: {'C': 0.03781575067423869, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05439998799139795, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.23089566301191022}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,828] Trial 603 finished with value: 0.6155135550296841 and parameters: {'C': 0.0593068697319123, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.06928571585198934, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.61867103416674}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:04,912] Trial 604 finished with value: 0.7764613692033047 and parameters: {'C': 0.015225891987354478, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.05698337227410093, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6544005952274389}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,025] Trial 605 finished with value: 0.7643951617832215 and parameters: {'C': 0.044437069963200425, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07423605713068705, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5991766632518639}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,122] Trial 606 finished with value: 0.7982688570923864 and parameters: {'C': 0.0711843334480872, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.06068580625105707, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6366292632448356}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,217] Trial 607 finished with value: 0.7982688570923864 and parameters: {'C': 0.03260374714259425, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.0761013943050108, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5741087378846722}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,328] Trial 608 finished with value: 0.7982688570923864 and parameters: {'C': 0.10599194120558436, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.052377849768500774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6184874243859868}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,418] Trial 609 finished with value: 0.7515784995494071 and parameters: {'C': 0.055426795716858386, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.047905771954216525, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7471344864225599}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,522] Trial 610 finished with value: 0.7893030285187149 and parameters: {'C': 0.02460026595117214, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06342472951517239, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7028525383988286}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,687] Trial 611 finished with value: 0.7936710813206824 and parameters: {'C': 0.03985947251830536, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.06710999931313731, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6705673157971632}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,785] Trial 612 finished with value: 0.7982688570923864 and parameters: {'C': 0.07221519234907924, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.07033755896432149, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.595105256711097}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,853] Trial 613 finished with value: 0.7610556379121386 and parameters: {'C': 0.04801903521532219, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 102, 'tol': 0.043277717881828506, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5530045389840159}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:05,932] Trial 614 finished with value: 0.7982688570923864 and parameters: {'C': 0.17455478826516438, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0791741174487174, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6395468674545073}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:06,025] Trial 615 finished with value: 0.7982688570923864 and parameters: {'C': 0.09358145118416637, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.05888153000727201, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.626733757725535}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:06,124] Trial 616 finished with value: 0.7982688570923864 and parameters: {'C': 0.03188637509241962, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06541772181839547, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6090485614216544}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:06,229] Trial 617 finished with value: 0.7982688570923864 and parameters: {'C': 0.06292058945163388, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06191036898913329, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7749763892455372}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:06,315] Trial 618 finished with value: 0.7807327381878917 and parameters: {'C': 0.01901512519676881, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.05603382241510345, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6532174814578587}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:06,432] Trial 619 finished with value: 0.8028531639803915 and parameters: {'C': 0.047558842405660974, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07212559740037017, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5737090494015425}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,159] Trial 620 finished with value: 0.7982688570923864 and parameters: {'C': 0.03407760608422555, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.08158484697530165, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.591244458344923}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,254] Trial 621 finished with value: 0.7982688570923864 and parameters: {'C': 0.08570138191675471, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.06824456697519056, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8283519011971006}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:07,363] Trial 622 finished with value: 0.7621305943576487 and parameters: {'C': 0.056727897216055555, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 117, 'tol': 0.07716171194162089, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.61208111180133}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,472] Trial 623 finished with value: 0.7893030285187149 and parameters: {'C': 0.025053181089277198, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06325943685129136, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6343902711414582}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,598] Trial 624 finished with value: 0.7643951617832215 and parameters: {'C': 0.04258874255466209, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06009756226608646, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6754090396930693}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,709] Trial 625 finished with value: 0.7982688570923864 and parameters: {'C': 0.12378673312090312, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.07400989576698463, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5265635955433231}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:07,944] Trial 626 finished with value: 0.7982688570923864 and parameters: {'C': 0.0693226063065312, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06546620345254966, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7207306583759182}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,013] Trial 627 finished with value: 0.5927498395207852 and parameters: {'C': 0.03394366259976605, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 125, 'tol': 0.05446908111807511, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.65587322654076}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,076] Trial 628 finished with value: 0.7515784995494071 and parameters: {'C': 0.05409605004425777, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0698845600455912, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5921464954298603}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,186] Trial 629 finished with value: 0.8028531639803915 and parameters: {'C': 0.09076479688881749, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.05842303498028555, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6213304423685713}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,277] Trial 630 finished with value: 0.8028531639803915 and parameters: {'C': 0.04208336005075086, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0669019956780649, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5676072561237545}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,348] Trial 631 finished with value: 0.6157458929517753 and parameters: {'C': 0.027087477105157208, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 100, 'tol': 0.06137638708779644, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6057773227047161}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,417] Trial 632 finished with value: 0.7982688570923864 and parameters: {'C': 0.07316108768035046, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05046852806378094, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6363222652892983}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,508] Trial 633 finished with value: 0.8028531639803915 and parameters: {'C': 0.05324273834178443, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07593024349051876, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6936151563480213}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,620] Trial 634 finished with value: 0.7849307243422452 and parameters: {'C': 0.021284457639303058, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06394011250803976, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6498831733823183}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,720] Trial 635 finished with value: 0.7982688570923864 and parameters: {'C': 0.03264444357230988, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.07167208893241128, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5906527801584114}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,813] Trial 636 finished with value: 0.7982688570923864 and parameters: {'C': 0.11069189095395651, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.057705598980964744, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6146871305496746}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:08,909] Trial 637 finished with value: 0.8028531639803915 and parameters: {'C': 0.04333768790362439, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 162, 'tol': 0.05337635329270243, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5526425284367765}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,289] Trial 638 finished with value: 0.7982688570923864 and parameters: {'C': 0.062234577123904754, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.07778783572789133, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7498736848718188}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,371] Trial 639 finished with value: 0.7606120086567014 and parameters: {'C': 0.08182433693544774, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 125, 'tol': 0.06832149272421924, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8058465170720722}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,474] Trial 640 finished with value: 0.7982688570923864 and parameters: {'C': 0.035024911197930796, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.07411860411177609, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6658548142471523}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,583] Trial 641 finished with value: 0.7982688570923864 and parameters: {'C': 0.15831440325951526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.060724495405518455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.44693082391803224}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,687] Trial 642 finished with value: 0.7764613692033047 and parameters: {'C': 0.015094015683827035, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06461483606859544, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6313242956009788}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,782] Trial 643 finished with value: 0.8028531639803915 and parameters: {'C': 0.05190798928639704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06282496183899455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5775234326476465}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,886] Trial 644 finished with value: 0.7729338533936235 and parameters: {'C': 0.024722992770816517, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.08062974732415495, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6035922484397495}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:09,975] Trial 645 finished with value: 0.7938919441613183 and parameters: {'C': 0.0660928797139652, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.056602938761219135, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6243064961128107}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:10,469] Trial 646 finished with value: 0.8028531639803915 and parameters: {'C': 0.04166208932755459, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.03287492758333808, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.3560350088294144}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:10,613] Trial 647 finished with value: 0.7982688570923864 and parameters: {'C': 0.09600590511824926, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06660608712130928, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7696873693900464}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:10,699] Trial 648 finished with value: 0.7524545461232856 and parameters: {'C': 0.011259636832364457, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.07069421752953961, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.681880180724427}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:10,827] Trial 649 finished with value: 0.8028531639803915 and parameters: {'C': 0.051949485137805215, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07854968604073466, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6498794484297488}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,048] Trial 650 finished with value: 0.7982688570923864 and parameters: {'C': 0.03171674680461659, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 93, 'tol': 0.013224646876483559, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5954798147506376}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:11,147] Trial 651 finished with value: 0.7571431799692669 and parameters: {'C': 0.06809829130502333, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 121, 'tol': 0.05848922862281347, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7358018860924466}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,329] Trial 652 finished with value: 0.7936710813206824 and parameters: {'C': 0.041022475072189764, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.05225471434589301, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6138635925928455}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,477] Trial 653 finished with value: 0.7895106372229068 and parameters: {'C': 0.020794699431668465, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.021787265723412438, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6386509707858512}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,581] Trial 654 finished with value: 0.6111282988119751 and parameters: {'C': 0.22105423382494022, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 117, 'tol': 0.07307942153990196, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5850015433313954}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,639] Trial 655 finished with value: 0.7982688570923864 and parameters: {'C': 0.10331584066416395, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.08498927649650856, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5568895659589597}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,735] Trial 656 finished with value: 0.8028531639803915 and parameters: {'C': 0.05092763309623741, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06046975092135163, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6632168114519}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,816] Trial 657 finished with value: 0.6276115195655426 and parameters: {'C': 0.029314747546886656, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 119, 'tol': 0.07581661044477603, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6257330032344471}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:11,982] Trial 658 finished with value: 0.7982688570923864 and parameters: {'C': 0.07516952530166203, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06868871694525716, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.710253551403503}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:12,257] Trial 659 finished with value: 0.7936710813206824 and parameters: {'C': 0.03879208689317101, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.04832890785322871, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5733555989997926}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:12,581] Trial 660 finished with value: 0.8028531639803915 and parameters: {'C': 0.054798555614517734, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06520701031548964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6112890078671185}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:12,884] Trial 661 finished with value: 0.7982688570923864 and parameters: {'C': 0.1252356583620632, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.009767923882454017, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6452018527565108}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:13,371] Trial 662 finished with value: 0.7691765275082738 and parameters: {'C': 0.08022338647138927, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.062143066970931, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6060924361909854}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:13,649] Trial 663 finished with value: 0.7982688570923864 and parameters: {'C': 0.029271833549005425, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.08251860926039534, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6897526669068704}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:14,167] Trial 664 finished with value: 0.8028531639803915 and parameters: {'C': 0.05848758879528302, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.05535716584191379, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5903606722454602}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:14,242] Trial 665 finished with value: 0.7606120086567014 and parameters: {'C': 0.037806785123371996, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 129, 'tol': 0.06370908411802097, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6308346164896005}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:14,321] Trial 666 finished with value: 0.7764613692033047 and parameters: {'C': 0.017302940976850006, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06686541893429429, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5763816371979339}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:14,437] Trial 667 finished with value: 0.7515784995494071 and parameters: {'C': 0.046100488106416156, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05917115623151436, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7889883550685156}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,012] Trial 668 finished with value: 0.7982688570923864 and parameters: {'C': 0.0693823307882461, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07063399676592579, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5373968157011363}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,118] Trial 669 finished with value: 0.7936710813206824 and parameters: {'C': 0.026996709212308394, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 97, 'tol': 0.07521595119342668, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6702841045418086}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,223] Trial 670 finished with value: 0.8028531639803915 and parameters: {'C': 0.0914404514300875, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.07838038855388677, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6467627484619765}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,366] Trial 671 finished with value: 0.7936710813206824 and parameters: {'C': 0.04131173285118063, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06265583425391952, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6221457406143585}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,468] Trial 672 finished with value: 0.8028531639803915 and parameters: {'C': 0.05798342310584326, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.07257810505844488, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6037925313725399}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:16,757] Trial 673 finished with value: 0.7982688570923864 and parameters: {'C': 0.14690416679393076, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.04500602188718823, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5614204871189573}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:16,883] Trial 674 finished with value: 0.7571431799692669 and parameters: {'C': 0.03513816532045246, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 106, 'tol': 0.049763569955948474, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5164429243384229}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:17,112] Trial 675 finished with value: 0.7893030285187149 and parameters: {'C': 0.023406717068180878, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.0420317099135641, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6590379613646712}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:17,915] Trial 676 finished with value: 0.7982688570923864 and parameters: {'C': 0.0794598532097651, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.05707040821582693, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7272317606289952}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:18,128] Trial 677 finished with value: 0.8028531639803915 and parameters: {'C': 0.05139819706584141, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05987399423701597, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7585854614549505}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:18,345] Trial 678 finished with value: 0.7982688570923864 and parameters: {'C': 0.1206949411416727, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06872165320124675, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.016762988163564363}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:18,649] Trial 679 finished with value: 0.8028531639803915 and parameters: {'C': 0.05990958430792216, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06559944882218308, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6297699984767177}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:18,748] Trial 680 finished with value: 0.6111282988119751 and parameters: {'C': 0.040235492083366096, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 121, 'tol': 0.05412421124751808, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5967233727993163}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:18,925] Trial 681 finished with value: 0.6612434084764641 and parameters: {'C': 0.0014039067020851885, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.08075189631963213, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6148925438136841}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:19,055] Trial 682 finished with value: 0.7982688570923864 and parameters: {'C': 0.02822059089676057, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.03715830823679157, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6431662182392296}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:19,162] Trial 683 finished with value: 0.6111282988119751 and parameters: {'C': 0.08906220926797567, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.07636924302691175, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5802032301429862}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:19,271] Trial 684 finished with value: 0.8028531639803915 and parameters: {'C': 0.04713696511041584, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06124481922442059, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6982962445875307}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:19,728] Trial 685 finished with value: 0.7563267813267813 and parameters: {'C': 0.06639092255390461, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.0640944942546517, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6053483663509578}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:20,659] Trial 686 finished with value: 0.7982688570923864 and parameters: {'C': 0.03454003380968835, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07102438744256911, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6731974856757681}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:21,184] Trial 687 finished with value: 0.7895106372229068 and parameters: {'C': 0.019908088301564732, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05165736779932759, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.629351545340809}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:21,888] Trial 688 finished with value: 0.8028531639803915 and parameters: {'C': 0.04917719701906667, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.06755317266445023, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8596308938575871}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:22,612] Trial 689 finished with value: 0.7982688570923864 and parameters: {'C': 0.10200801845872039, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07413399013023605, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5953804799072726}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,372] Trial 690 finished with value: 0.7982688570923864 and parameters: {'C': 0.06979019327672858, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.05599170018406525, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6205830101734047}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,485] Trial 691 finished with value: 0.7982688570923864 and parameters: {'C': 0.032238658601007095, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.05834887440560741, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6573747357901086}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,571] Trial 692 finished with value: 0.7515784995494071 and parameters: {'C': 0.044521425833437656, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 114, 'tol': 0.062180654776986644, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5779339737399732}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,648] Trial 693 finished with value: 0.7982688570923864 and parameters: {'C': 0.06459851901546988, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.046407506107779946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5535013978301868}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,769] Trial 694 finished with value: 0.7893030285187149 and parameters: {'C': 0.0219702023808469, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.07862723311891646, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6468686960543721}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:23,882] Trial 695 finished with value: 0.7936710813206824 and parameters: {'C': 0.03793098698088933, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06606484909465903, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7122517785081465}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:24,040] Trial 696 finished with value: 0.7982688570923864 and parameters: {'C': 0.09279638632668562, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.06026238277343728, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7789497175352951}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:24,182] Trial 697 finished with value: 0.8028531639803915 and parameters: {'C': 0.05335234411668254, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07038087784131998, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6112870612662841}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:24,411] Trial 698 finished with value: 0.7982688570923864 and parameters: {'C': 0.028600627768825777, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06390429087789547, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9915576187455702}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:24,608] Trial 699 finished with value: 0.7982688570923864 and parameters: {'C': 0.15330379951016862, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 66, 'tol': 0.07714674344780961, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7427830992921587}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:24,765] Trial 700 finished with value: 0.7528261852586178 and parameters: {'C': 0.07424758171089572, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 123, 'tol': 0.06950599195993636, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6359539793790393}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:24,890] Trial 701 finished with value: 0.8028531639803915 and parameters: {'C': 0.04267642902386178, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.07273269080925139, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5914866926139453}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,263] Trial 702 finished with value: 0.7777366958036103 and parameters: {'C': 0.01697661070056423, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06753545715329905, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6150527826970298}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,390] Trial 703 finished with value: 0.8028531639803915 and parameters: {'C': 0.0586883605802272, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.057062705380795685, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6832495691909739}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,716] Trial 704 finished with value: 0.7563267813267813 and parameters: {'C': 0.11744325949274745, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.061916665345688224, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5745431171065275}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,799] Trial 705 finished with value: 0.6111282988119751 and parameters: {'C': 0.02762423289137222, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 120, 'tol': 0.054319919051085234, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.656513097158602}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,864] Trial 706 finished with value: 0.7936710813206824 and parameters: {'C': 0.03949173312172212, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.06543460939865017, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6344554098366306}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:25,958] Trial 707 finished with value: 0.7982688570923864 and parameters: {'C': 0.08028891779754187, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07464239514973249, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6003127305807261}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,042] Trial 708 finished with value: 0.8028531639803915 and parameters: {'C': 0.057822777673854284, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.0796218112435583, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5619913559167384}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,129] Trial 709 finished with value: 0.6198849451861501 and parameters: {'C': 0.045843808689915035, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 113, 'tol': 0.05976568836850627, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6205035923882005}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,317] Trial 710 finished with value: 0.7982688570923864 and parameters: {'C': 0.030631351091306998, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.06313817810170895, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5930506123933026}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,418] Trial 711 finished with value: 0.802641903871957 and parameters: {'C': 0.19673991532688836, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07615275525277385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6669301019709928}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,510] Trial 712 finished with value: 0.7982688570923864 and parameters: {'C': 0.08931549120895002, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 82, 'tol': 0.052206922577025965, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.810720906668633}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,635] Trial 713 finished with value: 0.8028531639803915 and parameters: {'C': 0.05570105719672888, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.08201215117234341, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6415957385074909}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,731] Trial 714 finished with value: 0.7893030285187149 and parameters: {'C': 0.024754711089016418, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.057850188080725645, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7602901827399342}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,853] Trial 715 finished with value: 0.7936710813206824 and parameters: {'C': 0.037867565150526826, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.07253316151041715, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6113339174890028}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:26,999] Trial 716 finished with value: 0.7854029144351726 and parameters: {'C': 0.013200721519540366, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0497175852013235, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5357327562235661}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,165] Trial 717 finished with value: 0.7982688570923864 and parameters: {'C': 0.06545545495324138, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.016886902729358257, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5840510638941592}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,244] Trial 718 finished with value: 0.7606120086567014 and parameters: {'C': 0.10788856941009267, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 128, 'tol': 0.06734774705784773, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6913702673659694}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,439] Trial 719 finished with value: 0.7643951617832215 and parameters: {'C': 0.047240554981170364, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.0651670249654751, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6310072829330323}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,618] Trial 720 finished with value: 0.7982688570923864 and parameters: {'C': 0.03398219859128999, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06943570091692665, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.48827815828066135}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,791] Trial 721 finished with value: 0.7982688570923864 and parameters: {'C': 0.07334269765507533, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06063142860424945, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5990959026827015}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:27,958] Trial 722 finished with value: 0.7895106372229068 and parameters: {'C': 0.020855217780236027, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06201904997267473, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7196643383442773}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:28,460] Trial 723 finished with value: 0.7515784995494071 and parameters: {'C': 0.048562646165349416, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.0741219360943933, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6517568804727913}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:28,744] Trial 724 finished with value: 0.7982688570923864 and parameters: {'C': 0.07942726528838492, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.05557480688312482, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6190820582268984}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:28,857] Trial 725 finished with value: 0.7982688570923864 and parameters: {'C': 0.032740424139240186, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06430933446587034, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5655274538094742}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:28,991] Trial 726 finished with value: 0.7524545461232856 and parameters: {'C': 0.056949873949751026, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 118, 'tol': 0.059272984070353356, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6673907278828406}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,092] Trial 727 finished with value: 0.7936710813206824 and parameters: {'C': 0.04038749793746059, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.03910247869007327, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.42238121827867925}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,193] Trial 728 finished with value: 0.7982688570923864 and parameters: {'C': 0.12180101374705346, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.07740941959008205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6356715894190366}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,299] Trial 729 finished with value: 0.7893030285187149 and parameters: {'C': 0.024931275475922957, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.06690382199679837, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5865414242798085}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,397] Trial 730 finished with value: 0.7982688570923864 and parameters: {'C': 0.06555770048701022, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07134642249249278, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6080818441301646}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,475] Trial 731 finished with value: 0.5844242242037937 and parameters: {'C': 0.09590802277976386, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 128, 'tol': 0.06870659430135222, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6213581711132218}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:29,567] Trial 732 finished with value: 0.8028531639803915 and parameters: {'C': 0.05000154334753978, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.053360813388431, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7942868871865562}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,012] Trial 733 finished with value: 0.7936710813206824 and parameters: {'C': 0.0353141861849444, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.05781509223418746, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6422538844020053}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,106] Trial 734 finished with value: 0.6111282988119751 and parameters: {'C': 0.0701707915229129, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 120, 'tol': 0.06369473365817313, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7350211530522136}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,194] Trial 735 finished with value: 0.7808748507543689 and parameters: {'C': 0.017742958729408686, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06199705414722466, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6859848638283537}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,327] Trial 736 finished with value: 0.8028531639803915 and parameters: {'C': 0.04401597504500916, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.004480052179542969, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5720013167713415}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,428] Trial 737 finished with value: 0.7982688570923864 and parameters: {'C': 0.027854050508505316, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.0479055753384415, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5983991422780683}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,582] Trial 738 finished with value: 0.6021301355423179 and parameters: {'C': 0.00013806038204952837, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.07898871729092552, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7718638735491057}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:30,938] Trial 739 finished with value: 0.8028531639803915 and parameters: {'C': 0.057182190239142235, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.08404523132027092, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5522703894955636}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:31,057] Trial 740 finished with value: 0.7587471277840314 and parameters: {'C': 0.006157993604704134, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.07520671501538906, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.1698428200328923}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:31,853] Trial 741 finished with value: 0.7982688570923864 and parameters: {'C': 0.14696541301397323, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06533463819573598, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6596852094578488}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:31,947] Trial 742 finished with value: 0.7563267813267813 and parameters: {'C': 0.0879399180508341, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.055628053781087365, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6215198749151157}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,039] Trial 743 finished with value: 0.7700724062928126 and parameters: {'C': 0.035733432183758, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 113, 'tol': 0.09597342961683791, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5871907826000894}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,118] Trial 744 finished with value: 0.8028531639803915 and parameters: {'C': 0.04744755353032873, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.05993762203742349, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7050047520328283}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,220] Trial 745 finished with value: 0.7982688570923864 and parameters: {'C': 0.06973528123533475, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07178467005780378, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6438851151096703}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,341] Trial 746 finished with value: 0.7982688570923864 and parameters: {'C': 0.028035301038166868, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.0681998178324413, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6123375550199397}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,456] Trial 747 finished with value: 0.8028531639803915 and parameters: {'C': 0.052557526482540966, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.08079880698547018, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6732285420075609}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,597] Trial 748 finished with value: 0.7982688570923864 and parameters: {'C': 0.10106851254272489, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.05150304652235796, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6322950731206733}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,706] Trial 749 finished with value: 0.7936710813206824 and parameters: {'C': 0.037267314304764, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07352213789196667, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6022041219255488}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,814] Trial 750 finished with value: 0.6461619841901532 and parameters: {'C': 0.0005035373927360675, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06296734976664001, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8345063734317174}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:32,997] Trial 751 finished with value: 0.7982688570923864 and parameters: {'C': 0.0697645203746577, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 90, 'tol': 0.06625542185173774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5700604835801037}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:33,256] Trial 752 finished with value: 0.7893030285187149 and parameters: {'C': 0.022036029500459325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.05858292275830681, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7522117089369892}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:33,366] Trial 753 finished with value: 0.7661378770074423 and parameters: {'C': 0.04298155264742915, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 115, 'tol': 0.07737739961375042, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6507511173931082}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:33,504] Trial 754 finished with value: 0.7982688570923864 and parameters: {'C': 0.1218531185868479, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07055093094838188, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6224750560896088}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:33,987] Trial 755 finished with value: 0.8028531639803915 and parameters: {'C': 0.05695788750854519, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 56, 'tol': 0.06137912477865172, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5870917503243769}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:34,208] Trial 756 finished with value: 0.7982688570923864 and parameters: {'C': 0.03204545296945298, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05674397546500533, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6048302679170228}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:34,309] Trial 757 finished with value: 0.5368900781851924 and parameters: {'C': 0.0823090088751958, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 105, 'tol': 0.07548341813386188, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6341528306847717}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:34,459] Trial 758 finished with value: 0.8028531639803915 and parameters: {'C': 0.04814912503309584, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06415702088537137, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.543523309383985}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:34,764] Trial 759 finished with value: 0.7982688570923864 and parameters: {'C': 0.028147522326232594, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.024940794825352525, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6768248895320436}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:34,860] Trial 760 finished with value: 0.6068202628858366 and parameters: {'C': 0.015711255828753986, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 113, 'tol': 0.08672935077851583, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6078104483967806}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,009] Trial 761 finished with value: 0.7982688570923864 and parameters: {'C': 0.06443974029924944, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 138, 'tol': 0.06894462136194236, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6553533995092937}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,133] Trial 762 finished with value: 0.7515784995494071 and parameters: {'C': 0.04253555526224535, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 134, 'tol': 0.05367085220086837, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7217036348486101}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,523] Trial 763 finished with value: 0.7982688570923864 and parameters: {'C': 0.08466123802183366, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06046508674142673, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5826399407741976}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,754] Trial 764 finished with value: 0.7893030285187149 and parameters: {'C': 0.021748731762106243, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.06648707599047422, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6176059766311277}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,854] Trial 765 finished with value: 0.7982688570923864 and parameters: {'C': 0.03481584527797319, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05849069960009215, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6359519555141937}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:35,958] Trial 766 finished with value: 0.802641903871957 and parameters: {'C': 0.20512963099488124, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.050510886523980045, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5936470154374005}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,058] Trial 767 finished with value: 0.8028531639803915 and parameters: {'C': 0.05441014565462328, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06459668954771489, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6543580686357569}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,167] Trial 768 finished with value: 0.7982688570923864 and parameters: {'C': 0.09643360964928603, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.0796509825164885, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6993412347437935}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,259] Trial 769 finished with value: 0.7515784995494071 and parameters: {'C': 0.06159954807786821, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 129, 'tol': 0.07407081476668133, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5748420825318586}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,383] Trial 770 finished with value: 0.7936710813206824 and parameters: {'C': 0.03877408837347494, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07693310785425544, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5178960681060574}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,681] Trial 771 finished with value: 0.7982688570923864 and parameters: {'C': 0.12840881011312805, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.07234343740571418, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6163827708732253}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,821] Trial 772 finished with value: 0.7893030285187149 and parameters: {'C': 0.0251517994727468, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06205927402145736, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7866938771040588}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:36,940] Trial 773 finished with value: 0.8028531639803915 and parameters: {'C': 0.04782217671714394, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.055302072587904365, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6303532830283638}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:37,049] Trial 774 finished with value: 0.7982688570923864 and parameters: {'C': 0.07477383576843151, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06687116263074311, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7374553363637607}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:37,203] Trial 775 finished with value: 0.7982688570923864 and parameters: {'C': 0.03489057246256737, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.06007050027205034, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5981566236564}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:37,411] Trial 776 finished with value: 0.7595927526039051 and parameters: {'C': 0.06133306572431689, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06900718220912934, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5581776589956884}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:37,903] Trial 777 finished with value: 0.8028531639803915 and parameters: {'C': 0.04247874172082997, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06324605458571197, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6775409626707368}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:38,269] Trial 778 finished with value: 0.7528261852586178 and parameters: {'C': 0.0993596834680912, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 119, 'tol': 0.04673787861506109, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6413143690101064}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:39,032] Trial 779 finished with value: 0.7743766493766494 and parameters: {'C': 0.0299362399082984, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04439803846497087, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6065956566266173}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:39,787] Trial 780 finished with value: 0.7982688570923864 and parameters: {'C': 0.07440485923452557, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07097337055832569, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6643360939760018}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:39,925] Trial 781 finished with value: 0.7631758720057357 and parameters: {'C': 0.011139512749228494, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.04083656599915553, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5802145926884518}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,168] Trial 782 finished with value: 0.7895106372229068 and parameters: {'C': 0.02011629368280446, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.08166841075540394, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.628614403444763}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,255] Trial 783 finished with value: 0.6067286798994115 and parameters: {'C': 0.05393345233565639, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 121, 'tol': 0.05728963700126886, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7728712899773694}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,344] Trial 784 finished with value: 0.7982688570923864 and parameters: {'C': 0.16370885767675705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06479816629826425, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6048425436173797}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,549] Trial 785 finished with value: 0.8028531639803915 and parameters: {'C': 0.046906297483045194, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.07840136630155048, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6517759080440756}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,641] Trial 786 finished with value: 0.6458497713399673 and parameters: {'C': 0.029875229090780372, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 119, 'tol': 0.07609826559456827, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.753562409749135}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,721] Trial 787 finished with value: 0.7982688570923864 and parameters: {'C': 0.07655456775873791, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.0613498089688997, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6208441848748231}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,824] Trial 788 finished with value: 0.7936710813206824 and parameters: {'C': 0.038807145335174036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.04905511622001124, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5673625167915203}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:40,938] Trial 789 finished with value: 0.8028531639803915 and parameters: {'C': 0.05686555565889649, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.0525302463145163, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5899954167046612}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,032] Trial 790 finished with value: 0.7982688570923864 and parameters: {'C': 0.10862751352392204, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07335723458390071, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5384861686565182}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,137] Trial 791 finished with value: 0.7893030285187149 and parameters: {'C': 0.023834993373652736, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.06743472443427528, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6425091957989181}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,295] Trial 792 finished with value: 0.7936710813206824 and parameters: {'C': 0.03840074099740478, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06992627472848117, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7064886187543098}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,397] Trial 793 finished with value: 0.7982688570923864 and parameters: {'C': 0.06530560184424526, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.0593027932273162, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6840197415011656}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,500] Trial 794 finished with value: 0.7643951617832215 and parameters: {'C': 0.04992247774440227, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.06213563329421765, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.8184802514875393}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,592] Trial 795 finished with value: 0.7618143239764861 and parameters: {'C': 0.09488146242091244, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 124, 'tol': 0.05491436639797751, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6159852873451679}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,838] Trial 796 finished with value: 0.7982688570923864 and parameters: {'C': 0.02903767490689183, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06591713807898009, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5926102610800922}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:41,945] Trial 797 finished with value: 0.7982688570923864 and parameters: {'C': 0.07337581754188373, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.057675700751919835, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6622546598110218}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,038] Trial 798 finished with value: 0.7764613692033047 and parameters: {'C': 0.015186060884098887, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07641687422088442, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6278739167288149}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,178] Trial 799 finished with value: 0.7982688570923864 and parameters: {'C': 0.04222525552929212, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06397688082056532, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5670966360025695}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,430] Trial 800 finished with value: 0.7563267813267813 and parameters: {'C': 0.13608279472327325, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.0745503146684096, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6075674938462754}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,666] Trial 801 finished with value: 0.8028531639803915 and parameters: {'C': 0.05635116255826753, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07960936463600018, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6345712121674845}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,852] Trial 802 finished with value: 0.7982688570923864 and parameters: {'C': 0.03368358102205637, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.03509955831857619, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5849016523032914}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:42,967] Trial 803 finished with value: 0.7893030285187149 and parameters: {'C': 0.02236521728564036, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.06830953888745649, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7342478948759916}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:43,077] Trial 804 finished with value: 0.7574866689645383 and parameters: {'C': 0.08299855813097913, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 119, 'tol': 0.060675027744292634, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6492932041465644}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:43,193] Trial 805 finished with value: 0.8028531639803915 and parameters: {'C': 0.048726195201414704, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.07210668914072965, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6063997355072258}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:43,336] Trial 806 finished with value: 0.7982688570923864 and parameters: {'C': 0.06366022779046956, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.08364061822221691, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6200601188662499}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:43,625] Trial 807 finished with value: 0.7982688570923864 and parameters: {'C': 0.03429485866442347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.065756808110578, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5469598260680204}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:43,777] Trial 808 finished with value: 0.7982688570923864 and parameters: {'C': 0.10831798511141312, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 195, 'tol': 0.05892854447410217, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6694911929580727}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:43,871] Trial 809 finished with value: 0.6152963685334819 and parameters: {'C': 0.045664675781010015, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 122, 'tol': 0.06282150178555423, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5930711000192477}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,017] Trial 810 finished with value: 0.7893030285187149 and parameters: {'C': 0.02459247724868723, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.05640761950716849, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8019951209689304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,235] Trial 811 finished with value: 0.7982688570923864 and parameters: {'C': 0.06856237219933414, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07001661048743, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6419895403853897}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,359] Trial 812 finished with value: 0.7936710813206824 and parameters: {'C': 0.03870469140274975, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.051269687507235234, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6936911961647471}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,698] Trial 813 finished with value: 0.8028531639803915 and parameters: {'C': 0.05493088679208409, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.05375315203773401, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5698086808077266}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,869] Trial 814 finished with value: 0.7691765275082738 and parameters: {'C': 0.08664439366100178, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.07710316492713694, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6255855705284336}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:44,960] Trial 815 finished with value: 0.6112509597075283 and parameters: {'C': 0.030103711416434253, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 115, 'tol': 0.06489514958839308, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6056081817453187}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,033] Trial 816 finished with value: 0.7808748507543689 and parameters: {'C': 0.01778112780983452, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06774192352316806, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7201142055711265}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,168] Trial 817 finished with value: 0.7515784995494071 and parameters: {'C': 0.045839911356560764, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.06019362259207411, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7680237392461042}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,299] Trial 818 finished with value: 0.7982688570923864 and parameters: {'C': 0.0652064742295133, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07358839233561866, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.32258747654524295}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,424] Trial 819 finished with value: 0.7982688570923864 and parameters: {'C': 0.1371605651557319, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06288155609917022, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6434050304094804}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,551] Trial 820 finished with value: 0.7936710813206824 and parameters: {'C': 0.036341925874125464, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.07162131906805831, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5845885992976143}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,635] Trial 821 finished with value: 0.7606120086567014 and parameters: {'C': 0.08366775819393152, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 126, 'tol': 0.0805611174815385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6235850526866323}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,842] Trial 822 finished with value: 0.8028531639803915 and parameters: {'C': 0.05541705156051147, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05789530027868265, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6656941768679996}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:45,952] Trial 823 finished with value: 0.7982688570923864 and parameters: {'C': 0.028826804334429433, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.07586845062696398, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6054632596685942}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:46,321] Trial 824 finished with value: 0.8028531639803915 and parameters: {'C': 0.047940648555000014, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06697951927605728, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5585016849663785}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:46,455] Trial 825 finished with value: 0.7982688570923864 and parameters: {'C': 0.10404061582753142, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07877995150432883, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6537094223953309}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:46,570] Trial 826 finished with value: 0.6285520514310458 and parameters: {'C': 1.6815774304075373e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.05591543326347492, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5839369217659789}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:46,782] Trial 827 finished with value: 0.7982688570923864 and parameters: {'C': 0.06882510039102224, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06135534947369688, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.632748467910796}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:47,019] Trial 828 finished with value: 0.7936710813206824 and parameters: {'C': 0.03695216523684202, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.0697036650028287, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.03955970104271245}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:47,136] Trial 829 finished with value: 0.7893030285187149 and parameters: {'C': 0.021601481078111717, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 102, 'tol': 0.06392733124484562, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7435220264965304}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:47,349] Trial 830 finished with value: 0.7524545461232856 and parameters: {'C': 0.2285323210073568, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 127, 'tol': 0.058813104909716946, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.686484299730918}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:47,671] Trial 831 finished with value: 0.8028531639803915 and parameters: {'C': 0.04960600796059589, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06588873363541259, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6146522222193852}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,383] Trial 832 finished with value: 0.7691765275082738 and parameters: {'C': 0.08325801841403391, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.07412843194102567, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5944164235326915}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,489] Trial 833 finished with value: 0.7982688570923864 and parameters: {'C': 0.03185382752972189, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06081959889381232, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.619988008995638}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,602] Trial 834 finished with value: 0.8028531639803915 and parameters: {'C': 0.059334384594486575, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 158, 'tol': 0.04918819879442092, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6515612944110354}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,685] Trial 835 finished with value: 0.6152963685334819 and parameters: {'C': 0.039568600154258685, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 136, 'tol': 0.05365619394164865, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5719567966285103}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,752] Trial 836 finished with value: 0.7743766493766494 and parameters: {'C': 0.024360601776368927, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.07199634275526792, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.600421508000486}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,862] Trial 837 finished with value: 0.7982688570923864 and parameters: {'C': 0.1255711841640113, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.0684833765266308, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7104675796352989}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:48,985] Trial 838 finished with value: 0.7938919441613183 and parameters: {'C': 0.06645263550288834, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06421010061315433, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6342814328598616}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,077] Trial 839 finished with value: 0.6244551002615518 and parameters: {'C': 0.043034604209532513, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 116, 'tol': 0.056826364598132964, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6666365998237164}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,172] Trial 840 finished with value: 0.7982688570923864 and parameters: {'C': 0.02812022296429574, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.0772510469428871, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6132371888512933}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,361] Trial 841 finished with value: 0.7982688570923864 and parameters: {'C': 0.08956154779958923, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.06302349880262541, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5009217135842012}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,522] Trial 842 finished with value: 0.8028531639803915 and parameters: {'C': 0.053243359968059456, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07479521286790165, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5553527756810999}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,653] Trial 843 finished with value: 0.7936710813206824 and parameters: {'C': 0.03798396277327086, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.08236052098133106, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5841605635276937}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:49,948] Trial 844 finished with value: 0.7764613692033047 and parameters: {'C': 0.015231402985783323, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.047226048842393106, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6357111251506299}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:50,275] Trial 845 finished with value: 0.7982688570923864 and parameters: {'C': 0.07600495881433424, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.05094191214436087, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.4696284204704931}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:50,634] Trial 846 finished with value: 0.8028531639803915 and parameters: {'C': 0.053176212915715226, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05925724364373629, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.779739456718363}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:50,734] Trial 847 finished with value: 0.7606120086567014 and parameters: {'C': 0.11159576700113526, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 121, 'tol': 0.06660443172645518, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6846816809365154}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:50,830] Trial 848 finished with value: 0.802641903871957 and parameters: {'C': 0.17948662807332244, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.07008506149148863, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.532724985446993}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:50,930] Trial 849 finished with value: 0.7982688570923864 and parameters: {'C': 0.02989185145438029, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.061803227920926046, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7549383995685346}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,032] Trial 850 finished with value: 0.8028531639803915 and parameters: {'C': 0.04288381579925733, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07880341694716901, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6016088802861262}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,166] Trial 851 finished with value: 0.7729338533936235 and parameters: {'C': 0.01869122592086291, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.055208728388268666, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6444619792709569}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,282] Trial 852 finished with value: 0.7982688570923864 and parameters: {'C': 0.07043184599801548, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.030711273731415484, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6218492456493718}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,422] Trial 853 finished with value: 0.8028531639803915 and parameters: {'C': 0.05919072706652281, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.06543307111285186, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6648742800895436}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,639] Trial 854 finished with value: 0.7936710813206824 and parameters: {'C': 0.037028522597622966, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.06823963739799453, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5847603379308284}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,750] Trial 855 finished with value: 0.7563267813267813 and parameters: {'C': 0.10213222648867315, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06054533581163266, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.606405165020871}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:51,873] Trial 856 finished with value: 0.7667586136668584 and parameters: {'C': 0.02363406223690803, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 127, 'tol': 0.07243894385062939, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.625668217765282}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:51,979] Trial 857 finished with value: 0.8028531639803915 and parameters: {'C': 0.04950566194749664, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 99, 'tol': 0.07562965829936626, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5691217644822046}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,085] Trial 858 finished with value: 0.7982688570923864 and parameters: {'C': 0.07790469831730967, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.04369865181539918, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6516345120304295}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,202] Trial 859 finished with value: 0.7982688570923864 and parameters: {'C': 0.031176102005974215, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06260933278709432, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7288547800878916}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,348] Trial 860 finished with value: 0.8028531639803915 and parameters: {'C': 0.046347962644868505, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.0640490262883594, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5981138331620109}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,438] Trial 861 finished with value: 0.6065720097978163 and parameters: {'C': 0.06268980594718625, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 129, 'tol': 0.05774412705012003, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.795505259181592}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,625] Trial 862 finished with value: 0.7982688570923864 and parameters: {'C': 0.1527575773048729, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.07045592526765196, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6991561317964448}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,800] Trial 863 finished with value: 0.7934145698586808 and parameters: {'C': 12.47614250118396, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.0811444287928935, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6295527374698805}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:52,922] Trial 864 finished with value: 0.7936710813206824 and parameters: {'C': 0.03618297672092703, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.07801473575812108, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6725105919457021}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,037] Trial 865 finished with value: 0.6244551002615518 and parameters: {'C': 0.08843983873336492, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.053161512513515884, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6098188895612671}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,187] Trial 866 finished with value: 0.8028531639803915 and parameters: {'C': 0.056597251750439524, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 95, 'tol': 0.058536294566536286, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5763936834558381}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,339] Trial 867 finished with value: 0.7893030285187149 and parameters: {'C': 0.025566615924329347, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06630603361181484, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6442708472353084}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,516] Trial 868 finished with value: 0.7587471277840314 and parameters: {'C': 0.008585708481146379, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07302014313859656, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5933546530607176}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,632] Trial 869 finished with value: 0.8028531639803915 and parameters: {'C': 0.044635639284946606, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.055360687363864264, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5505250266360091}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:53,937] Trial 870 finished with value: 0.7938919441613183 and parameters: {'C': 0.06713260698630834, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06094928027677517, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6176167248672219}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,210] Trial 871 finished with value: 0.7638512075293685 and parameters: {'C': 0.031840132755303015, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.06786086244371298, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6340715960514821}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,351] Trial 872 finished with value: 0.7982688570923864 and parameters: {'C': 0.11325918696077032, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.019180886842245937, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6557566538561127}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,487] Trial 873 finished with value: 0.8028531639803915 and parameters: {'C': 0.04452713528335049, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06290659646624609, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.7625833731437917}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,576] Trial 874 finished with value: 0.7563267813267813 and parameters: {'C': 0.019893607797462187, 'fit_intercept': False, 'solver': 'liblinear', 'max_iter': 124, 'tol': 0.07580198181646312, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5908522195343249}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,683] Trial 875 finished with value: 0.7982688570923864 and parameters: {'C': 0.08220212667765056, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.0648996904119912, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.614611288058305}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,801] Trial 876 finished with value: 0.8028531639803915 and parameters: {'C': 0.05473313002028322, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 182, 'tol': 0.07064987443412829, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6813181161489885}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:54,999] Trial 877 finished with value: 0.7936710813206824 and parameters: {'C': 0.03582074359206528, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 75, 'tol': 0.05205770187824776, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.11706712703037381}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:55,197] Trial 878 finished with value: 0.7982688570923864 and parameters: {'C': 0.069040477030695, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 101, 'tol': 0.0568528247388094, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6366432426860833}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:55,341] Trial 879 finished with value: 0.7765503863064839 and parameters: {'C': 0.012210180523207883, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.07375227417365858, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5617458625238504}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:55,568] Trial 880 finished with value: 0.7893030285187149 and parameters: {'C': 0.023752605595822044, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 140, 'tol': 0.06007720562930106, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.720504870095458}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:55,688] Trial 881 finished with value: 0.7982688570923864 and parameters: {'C': 0.04181816990611077, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.08885144549508023, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6019819160220125}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:55,845] Trial 882 finished with value: 0.7982688570923864 and parameters: {'C': 0.09677688980361886, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.04954713886916483, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6540660803131246}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:07:55,942] Trial 883 finished with value: 0.7528261852586178 and parameters: {'C': 0.05390244986315362, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 106, 'tol': 0.07896364361029301, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.573737833374964}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,045] Trial 884 finished with value: 0.7982688570923864 and parameters: {'C': 0.03286496804768246, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06859108477941081, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.618643623108012}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,212] Trial 885 finished with value: 0.7982688570923864 and parameters: {'C': 0.07149294508192491, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.06248127222541719, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7405248009828628}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,333] Trial 886 finished with value: 0.7982688570923864 and parameters: {'C': 0.14938866416786364, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06572732866868372, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6330171708831399}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,418] Trial 887 finished with value: 0.6112509597075283 and parameters: {'C': 0.04412384561439794, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 115, 'tol': 0.05961202699961496, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7014682884661037}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,522] Trial 888 finished with value: 0.7936710813206824 and parameters: {'C': 0.02734668272342811, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.07206314658993464, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5939731439415419}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,702] Trial 889 finished with value: 0.7595927526039051 and parameters: {'C': 0.05938487601998365, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07680949595721547, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.820635081650977}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,889] Trial 890 finished with value: 0.7982688570923864 and parameters: {'C': 0.09681130099707132, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.08481775858002993, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6677023631675404}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:56,995] Trial 891 finished with value: 0.6335426335426335 and parameters: {'C': 0.01749067610561709, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 125, 'tol': 0.04117590773884645, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6173049421179747}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,139] Trial 892 finished with value: 0.7936710813206824 and parameters: {'C': 0.04056162362690245, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.04565553206434705, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.5252572302507195}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,331] Trial 893 finished with value: 0.7563267813267813 and parameters: {'C': 0.05976804858978501, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.0801942340468614, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5823782255200312}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,476] Trial 894 finished with value: 0.7936710813206824 and parameters: {'C': 0.027375620787784685, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.05416147070179, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7833193166497294}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,597] Trial 895 finished with value: 0.7982688570923864 and parameters: {'C': 0.08001504355268166, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06427819805889952, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6402717637820885}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,720] Trial 896 finished with value: 0.8028531639803915 and parameters: {'C': 0.04665578983627234, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06926059711055303, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6041928134539555}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,851] Trial 897 finished with value: 0.7982688570923864 and parameters: {'C': 0.12140598917924272, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06679219202703272, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.551090382136205}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:57,975] Trial 898 finished with value: 0.7982688570923864 and parameters: {'C': 0.034275339161441244, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 104, 'tol': 0.058211705667998256, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6566089698255716}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:58,072] Trial 899 finished with value: 0.6641127189727236 and parameters: {'C': 0.0007899624384947435, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 115, 'tol': 0.061294870979779606, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6250672442671582}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:58,213] Trial 900 finished with value: 0.8028531639803915 and parameters: {'C': 0.058589797415589326, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.0748966037325193, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5798807498774126}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:58,530] Trial 901 finished with value: 0.6287980131205215 and parameters: {'C': 4.451143383240689e-05, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.056028271658501244, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.22373419499330682}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:58,768] Trial 902 finished with value: 0.7982688570923864 and parameters: {'C': 0.08348400856873586, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06246813326694162, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6871589084329416}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:58,912] Trial 903 finished with value: 0.7936710813206824 and parameters: {'C': 0.03598170021051537, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 110, 'tol': 0.08204938645298608, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6057440254676492}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:59,035] Trial 904 finished with value: 0.7893030285187149 and parameters: {'C': 0.022112157710217278, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.07134016463312419, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6428817739562462}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:59,174] Trial 905 finished with value: 0.8028531639803915 and parameters: {'C': 0.05029304445107301, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07814451528671425, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.621339289340848}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:59,284] Trial 906 finished with value: 0.7982688570923864 and parameters: {'C': 0.06438755741329183, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06446569555507076, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5930514333628315}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:59,401] Trial 907 finished with value: 0.7982688570923864 and parameters: {'C': 0.03040153748771068, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.06724576854906784, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.751991253441866}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:07:59,882] Trial 908 finished with value: 0.7643951617832215 and parameters: {'C': 0.043030828171562674, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.04845623853172291, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6554775696294273}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:08:00,165] Trial 909 finished with value: 0.7528261852586178 and parameters: {'C': 0.1021801165962544, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 130, 'tol': 0.051041615166496385, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5709810499521789}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:00,309] Trial 910 finished with value: 0.7982688570923864 and parameters: {'C': 0.06786301822295086, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05946363922616312, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8522462322012117}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:00,847] Trial 911 finished with value: 0.8028531639803915 and parameters: {'C': 0.047065421929551245, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.07416500392020295, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.671224515502003}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:01,020] Trial 912 finished with value: 0.7743766493766494 and parameters: {'C': 0.02751385287651804, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05717765005885375, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6141736308548388}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:01,306] Trial 913 finished with value: 0.7982688570923864 and parameters: {'C': 0.13531327640346788, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06944683419184429, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6333612409311836}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:01,402] Trial 914 finished with value: 0.6090577380899962 and parameters: {'C': 0.017639115305389145, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 97, 'tol': 0.07623902017238375, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7168398427787489}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:01,880] Trial 915 finished with value: 0.7982688570923864 and parameters: {'C': 0.07874742287677641, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.061444654019613645, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5983454298928519}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:01,998] Trial 916 finished with value: 0.7936710813206824 and parameters: {'C': 0.037329248733746885, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.05263048598094299, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6412154079295658}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:02,114] Trial 917 finished with value: 0.6111282988119751 and parameters: {'C': 0.05352724408745152, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 101, 'tol': 0.06563181517074425, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.2828843486647974}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:02,203] Trial 918 finished with value: 0.7982688570923864 and parameters: {'C': 0.08670694511307038, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 113, 'tol': 0.07239804870313711, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8002330586688344}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:02,418] Trial 919 finished with value: 0.7934145698586808 and parameters: {'C': 40.04036942229783, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06744545427686092, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5570293244300428}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:02,865] Trial 920 finished with value: 0.7936710813206824 and parameters: {'C': 0.037197326864719174, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06347475909408255, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6173501585030494}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:03,464] Trial 921 finished with value: 0.8028531639803915 and parameters: {'C': 0.05970218052891291, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.058747949488050476, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5952801993186434}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:03,703] Trial 922 finished with value: 0.7936710813206824 and parameters: {'C': 0.025882406581856646, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 106, 'tol': 0.05476639104639603, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7671719732337104}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:03,829] Trial 923 finished with value: 0.8028531639803915 and parameters: {'C': 0.04641496340970635, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06978849796265546, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6748133717624561}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:03,927] Trial 924 finished with value: 0.632883615560909 and parameters: {'C': 0.00026136821773829137, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 132, 'tol': 0.07751945292128114, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5795014670268922}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,015] Trial 925 finished with value: 0.7571431799692669 and parameters: {'C': 0.26175400978104624, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 128, 'tol': 0.061136220078721396, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6250908743963762}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,257] Trial 926 finished with value: 0.7691765275082738 and parameters: {'C': 0.07190727181938089, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.06461046683291014, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6518474817900678}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,368] Trial 927 finished with value: 0.7982688570923864 and parameters: {'C': 0.03402557464717393, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07968626596849043, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6064398118491259}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,516] Trial 928 finished with value: 0.7982688570923864 and parameters: {'C': 0.09726590327121325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.07473101206879217, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5373931295663041}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,646] Trial 929 finished with value: 0.8028531639803915 and parameters: {'C': 0.0549839121548689, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.057149480049319704, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7007165136773614}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,779] Trial 930 finished with value: 0.7982688570923864 and parameters: {'C': 0.1733188571921265, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.06342261761031825, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5802834687553855}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:04,901] Trial 931 finished with value: 0.7606120086567014 and parameters: {'C': 0.02072591860173972, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.05966235414378382, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.741154197285807}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,019] Trial 932 finished with value: 0.8028531639803915 and parameters: {'C': 0.043793189500140016, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06722962833174302, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6335443316373959}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,134] Trial 933 finished with value: 0.7982688570923864 and parameters: {'C': 0.06969691419256059, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.07137926748377775, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6055581789917205}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:08:05,365] Trial 934 finished with value: 0.7571431799692669 and parameters: {'C': 0.125867195557106, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 108, 'tol': 0.06529348927905886, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6591440412242323}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,479] Trial 935 finished with value: 0.7982688570923864 and parameters: {'C': 0.030009492549440814, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.061930977770942565, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6296077617807095}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,600] Trial 936 finished with value: 0.8028531639803915 and parameters: {'C': 0.051987698072203346, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.07644577681761336, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5883980174616581}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,735] Trial 937 finished with value: 0.7854029144351726 and parameters: {'C': 0.013849293695605664, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.07358852279313421, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5611276915774144}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,845] Trial 938 finished with value: 0.7936710813206824 and parameters: {'C': 0.03635632832558262, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.056348962651041674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6103342061340228}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:05,929] Trial 939 finished with value: 0.5036934996733992 and parameters: {'C': 0.08510585168041243, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 121, 'tol': 0.06826307932110941, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6847055154457947}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,010] Trial 940 finished with value: 0.7893030285187149 and parameters: {'C': 0.023920348822875654, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.04702545019245622, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6513000006558807}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,122] Trial 941 finished with value: 0.8028531639803915 and parameters: {'C': 0.05603979644445325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.053012685663371466, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.403811778475928}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,222] Trial 942 finished with value: 0.8028531639803915 and parameters: {'C': 0.042647969269936935, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.059308693547509256, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6203843242066446}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,317] Trial 943 finished with value: 0.6458497713399673 and parameters: {'C': 0.07223979680893436, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 129, 'tol': 0.08269559620435674, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6394281989073035}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,572] Trial 944 finished with value: 0.7982688570923864 and parameters: {'C': 0.02950663288028702, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.0799507229493698, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5952837280635571}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:06,768] Trial 945 finished with value: 0.7982688570923864 and parameters: {'C': 0.099164796563105, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.050271091777685774, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7197658498496196}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:07,551] Trial 946 finished with value: 0.7643951617832215 and parameters: {'C': 0.042462879130165394, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 169, 'tol': 0.06970499645555683, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.5668676097906631}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:07,785] Trial 947 finished with value: 0.8028531639803915 and parameters: {'C': 0.061496167068783116, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.03668512704436369, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7789722145538895}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,048] Trial 948 finished with value: 0.7982688570923864 and parameters: {'C': 0.11854449891955189, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.06305580804938156, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6764524637228001}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,184] Trial 949 finished with value: 0.7563267813267813 and parameters: {'C': 0.038553196765061214, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 135, 'tol': 0.061177113775993636, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6197242471626137}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,458] Trial 950 finished with value: 0.7895106372229068 and parameters: {'C': 0.019708767958278244, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 117, 'tol': 0.06566490880833369, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5935033367154764}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,563] Trial 951 finished with value: 0.7515784995494071 and parameters: {'C': 0.054299380126387034, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 121, 'tol': 0.0779147768788388, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6474163620554412}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,649] Trial 952 finished with value: 0.7982688570923864 and parameters: {'C': 0.02859557942697668, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 105, 'tol': 0.05429861201805323, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6112014422997467}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:08,925] Trial 953 finished with value: 0.7982688570923864 and parameters: {'C': 0.07480102047418492, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 109, 'tol': 0.07291573471392204, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5745844268904596}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:09,031] Trial 954 finished with value: 0.8028531639803915 and parameters: {'C': 0.04488930974624945, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.058258825377680595, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6628121458676267}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:09,206] Trial 955 finished with value: 0.8028531639803915 and parameters: {'C': 0.05942844617278701, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 92, 'tol': 0.07505762778214642, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.632101683182294}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:09,330] Trial 956 finished with value: 0.7982688570923864 and parameters: {'C': 0.034703430043939325, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06663873157652533, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7593740209487208}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:09,444] Trial 957 finished with value: 0.7982688570923864 and parameters: {'C': 0.09981894128178158, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.03845868467413455, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5412724804811325}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:09,767] Trial 958 finished with value: 0.7893030285187149 and parameters: {'C': 0.024272199162032743, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.07101454006960274, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6992636166016274}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:10,214] Trial 959 finished with value: 0.7982688570923864 and parameters: {'C': 0.07058907161750899, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.06359807892879087, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5141466965714641}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:10,449] Trial 960 finished with value: 0.8028531639803915 and parameters: {'C': 0.0478857136279296, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.0617989824565021, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6030680931473593}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:08:10,588] Trial 961 finished with value: 0.7664686441880739 and parameters: {'C': 0.034138621542271375, 'fit_intercept': True, 'solver': 'lbfgs', 'max_iter': 116, 'tol': 0.06864682277841404, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7341285665571263}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:10,705] Trial 962 finished with value: 0.7934145698586808 and parameters: {'C': 3.3960296724128813, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.05629055339260501, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6274544372837849}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:10,847] Trial 963 finished with value: 0.7982688570923864 and parameters: {'C': 0.15841541012444615, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 100, 'tol': 0.06030786730833661, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5890550922983815}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:10,965] Trial 964 finished with value: 0.7982688570923864 and parameters: {'C': 0.07949182420167535, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 130, 'tol': 0.06522707292626927, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6460117104208861}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,062] Trial 965 finished with value: 0.5470683182250782 and parameters: {'C': 0.05422444633343866, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 119, 'tol': 0.08114345960054331, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.6704717739305252}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,190] Trial 966 finished with value: 0.7936710813206824 and parameters: {'C': 0.03847105712918053, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.07678732459777589, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6132270195185674}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,444] Trial 967 finished with value: 0.7764613692033047 and parameters: {'C': 0.017107411161051418, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 114, 'tol': 0.05175443443690249, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.574229169489807}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,588] Trial 968 finished with value: 0.7563267813267813 and parameters: {'C': 0.11196397700488156, 'fit_intercept': False, 'solver': 'newton-cg', 'max_iter': 126, 'tol': 0.05952795257019466, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.8068315136517042}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,688] Trial 969 finished with value: 0.6335426335426335 and parameters: {'C': 0.02725156639912547, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 120, 'tol': 0.04304541859874956, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6331400691059849}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:11,798] Trial 970 finished with value: 0.8028531639803915 and parameters: {'C': 0.06209641903556212, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 107, 'tol': 0.0727925997492179, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5984138322375351}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:12,377] Trial 971 finished with value: 0.8028531639803915 and parameters: {'C': 0.050716920536166256, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.06766847056215719, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.657319261616169}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:12,962] Trial 972 finished with value: 0.7982688570923864 and parameters: {'C': 0.08863109773923847, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.06351974435605748, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5565248941605774}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:13,125] Trial 973 finished with value: 0.7936710813206824 and parameters: {'C': 0.03901407740848891, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 133, 'tol': 0.08569576120356091, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6122926533531985}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:13,238] Trial 974 finished with value: 0.7982688570923864 and parameters: {'C': 0.07235712103469559, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 103, 'tol': 0.0749526055682711, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5794816554319574}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:13,847] Trial 975 finished with value: 0.7982688570923864 and parameters: {'C': 0.03062699038095846, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 123, 'tol': 0.06952057795182487, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6373222100798724}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,030] Trial 976 finished with value: 0.8028531639803915 and parameters: {'C': 0.04951971868186681, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 112, 'tol': 0.056520405382257166, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.9504833434955882}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,135] Trial 977 finished with value: 0.7893030285187149 and parameters: {'C': 0.021801966126801433, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 119, 'tol': 0.06676161827768269, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6881734037758203}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,239] Trial 978 finished with value: 0.7936710813206824 and parameters: {'C': 0.04108880513409426, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.0784402569954746, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6194772349254302}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,329] Trial 979 finished with value: 0.7515784995494071 and parameters: {'C': 0.0671281450543923, 'fit_intercept': True, 'solver': 'liblinear', 'max_iter': 117, 'tol': 0.06165555515243685, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5892459972221474}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,409] Trial 980 finished with value: 0.7318465565181727 and parameters: {'C': 0.00417031347202977, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 125, 'tol': 0.0482609555534677, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6463508895110194}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,506] Trial 981 finished with value: 0.7982688570923864 and parameters: {'C': 0.11145797162621705, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 111, 'tol': 0.05475788881000658, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7519980775837131}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,645] Trial 982 finished with value: 0.7982688570923864 and parameters: {'C': 0.030646758099352914, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 121, 'tol': 0.05839584173132031, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7838536865754933}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,771] Trial 983 finished with value: 0.8028531639803915 and parameters: {'C': 0.05490687071779403, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 129, 'tol': 0.07079045849223332, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.8352469179706173}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,882] Trial 984 finished with value: 0.7691765275082738 and parameters: {'C': 0.07723924271936121, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06433053587046472, 'class_weight': None, 'warm_start': True, 'l1_ratio': 0.7123895086870804}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:14,983] Trial 985 finished with value: 0.7809803062274343 and parameters: {'C': 0.012337046221418391, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 115, 'tol': 0.06027921707235205, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6097183653147975}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:15,080] Trial 986 finished with value: 0.802641903871957 and parameters: {'C': 0.20533851329914998, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 108, 'tol': 0.07593913359857439, 'class_weight': 'balanced', 'warm_start': False, 'l1_ratio': 0.6690846310409564}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-01-12 21:08:15,193] Trial 987 finished with value: 0.7520388695314645 and parameters: {'C': 0.044374029161509614, 'fit_intercept': False, 'solver': 'lbfgs', 'max_iter': 125, 'tol': 0.07296666176859547, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6273689231826387}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:15,301] Trial 988 finished with value: 0.7893030285187149 and parameters: {'C': 0.0239296829299193, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 98, 'tol': 0.06289061788260694, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5680910653651223}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:15,421] Trial 989 finished with value: 0.7982688570923864 and parameters: {'C': 0.09393581722542817, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.05802529161962599, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5946291097784873}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:15,897] Trial 990 finished with value: 0.7982688570923864 and parameters: {'C': 0.033808220821855486, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 131, 'tol': 0.02835705828349666, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6420515248021843}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:16,096] Trial 991 finished with value: 0.8028531639803915 and parameters: {'C': 0.05892652990197646, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 118, 'tol': 0.06556098343410643, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6183699411416651}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:16,723] Trial 992 finished with value: 0.8028531639803915 and parameters: {'C': 0.04436817483983842, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 128, 'tol': 0.08035350181299244, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.5969889231794333}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:16,861] Trial 993 finished with value: 0.6067286798994115 and parameters: {'C': 0.13175129357945584, 'fit_intercept': True, 'solver': 'saga', 'max_iter': 105, 'tol': 0.04541771569266166, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.549906951237666}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:16,958] Trial 994 finished with value: 0.6198849451861501 and parameters: {'C': 0.06907310132878879, 'fit_intercept': True, 'solver': 'sag', 'max_iter': 113, 'tol': 0.05357530677506222, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6621501747748145}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:17,145] Trial 995 finished with value: 0.7982688570923864 and parameters: {'C': 0.034255163905821166, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 124, 'tol': 0.0832996254223565, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6321355076879646}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:17,262] Trial 996 finished with value: 0.8028531639803915 and parameters: {'C': 0.049234080118206694, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 120, 'tol': 0.07113148619874332, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.684828072114125}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:17,381] Trial 997 finished with value: 0.7852816940651992 and parameters: {'C': 0.0182661230166319, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 127, 'tol': 0.06815598539522377, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.7322191701125644}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:17,578] Trial 998 finished with value: 0.7934145698586808 and parameters: {'C': 8.258562943874301, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 116, 'tol': 0.07760117791913718, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.580240392146321}. Best is trial 87 with value: 0.8028531639803915.\n",
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2024-01-12 21:08:17,708] Trial 999 finished with value: 0.7982688570923864 and parameters: {'C': 0.08320809822771631, 'fit_intercept': True, 'solver': 'newton-cg', 'max_iter': 122, 'tol': 0.06193479521717386, 'class_weight': 'balanced', 'warm_start': True, 'l1_ratio': 0.6082806859575841}. Best is trial 87 with value: 0.8028531639803915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.801802\n",
      "Model F1 Score: 0.802853\n",
      "Validation Accuracy: 0.761261\n",
      "Validation F1 Score: 0.762456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 1e-5, 100,log=True),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        # 'penalty': trial.suggest_categorical('penalty', ['l2','none']),\n",
    "        'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 50, 200),\n",
    "        'tol': trial.suggest_float('tol', 1e-5, 1e-1),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'warm_start': trial.suggest_categorical('warm_start', [True, False]),\n",
    "        'l1_ratio': trial.suggest_float('l1_ratio', 0, 1)\n",
    "    }\n",
    "    model = LogisticRegression(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = f1_score(y_test, preds, average='weighted')\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = LogisticRegression(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n",
    "\n",
    "# Now let's use the model with the best parameters on the validation set\n",
    "val_preds = best_model.predict(X_val)\n",
    "\n",
    "# Check the accuracy and F1 score of the best model on the validation set\n",
    "print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n",
    "print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(best_model, open(\"LR\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 21:08:17,790] A new study created in memory with name: no-name-68d98ce2-13a6-42b6-b958-539a6088ea8c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 21:08:18,803] Trial 0 finished with value: 0.7948613738087422 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.015846697716523767, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7948613738087422.\n",
      "[I 2024-01-12 21:08:19,485] Trial 1 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.012172870809366628, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8034347634347635.\n",
      "[I 2024-01-12 21:08:20,307] Trial 2 finished with value: 0.7967460450858784 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.02995624102232285, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8034347634347635.\n",
      "[I 2024-01-12 21:08:20,884] Trial 3 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 99, 'max_depth': 9, 'learning_rate': 0.06686999289669412, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8034347634347635.\n",
      "[I 2024-01-12 21:08:21,164] Trial 4 finished with value: 0.7905782834818402 and parameters: {'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.015143735352413127, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8034347634347635.\n",
      "[I 2024-01-12 21:08:21,922] Trial 5 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.04358253061409662, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8097037845172175.\n",
      "[I 2024-01-12 21:08:22,260] Trial 6 finished with value: 0.7894144144144144 and parameters: {'n_estimators': 69, 'max_depth': 8, 'learning_rate': 0.01624951561683817, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.8097037845172175.\n",
      "[I 2024-01-12 21:08:23,621] Trial 7 finished with value: 0.7942921942921943 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.03642633401275828, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.8097037845172175.\n",
      "[I 2024-01-12 21:08:23,833] Trial 8 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.01793709666115397, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.8097037845172175.\n",
      "[I 2024-01-12 21:08:25,162] Trial 9 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.02131177946759668, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.8097037845172175.\n",
      "[I 2024-01-12 21:08:25,404] Trial 10 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.08342651485634764, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8234879328004447.\n",
      "[I 2024-01-12 21:08:25,654] Trial 11 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 104, 'max_depth': 4, 'learning_rate': 0.0903286155891964, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:25,841] Trial 12 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.09996811153267711, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:26,066] Trial 13 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 97, 'max_depth': 4, 'learning_rate': 0.09883526279463241, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:26,314] Trial 14 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 84, 'max_depth': 5, 'learning_rate': 0.05957820905956114, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:26,555] Trial 15 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.05703609030329345, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:26,868] Trial 16 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.05505250673960739, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:27,093] Trial 17 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.07002078580391687, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:27,190] Trial 18 finished with value: 0.8082763742703633 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.04742151425552431, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:27,748] Trial 19 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 157, 'max_depth': 6, 'learning_rate': 0.02688802755029949, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:27,994] Trial 20 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.07369872119049137, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:28,199] Trial 21 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 88, 'max_depth': 4, 'learning_rate': 0.09997955177209333, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:28,548] Trial 22 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 85, 'max_depth': 6, 'learning_rate': 0.08278716141010363, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:28,827] Trial 23 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.08713501352751898, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:29,100] Trial 24 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 110, 'max_depth': 3, 'learning_rate': 0.0574633084221967, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:29,553] Trial 25 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.04176886959743379, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:30,054] Trial 26 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.03838694938921514, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:30,655] Trial 27 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 166, 'max_depth': 6, 'learning_rate': 0.010199512468834078, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:30,978] Trial 28 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 141, 'max_depth': 4, 'learning_rate': 0.024264624281631425, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:31,220] Trial 29 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.03709788721880486, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:31,632] Trial 30 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 109, 'max_depth': 6, 'learning_rate': 0.08395124857071629, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:32,049] Trial 31 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.03884004755316385, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:32,501] Trial 32 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 147, 'max_depth': 5, 'learning_rate': 0.03457637091198818, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:32,819] Trial 33 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 131, 'max_depth': 4, 'learning_rate': 0.04994160782050578, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.8415917345645018.\n",
      "[I 2024-01-12 21:08:33,239] Trial 34 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.02726531175160867, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:33,969] Trial 35 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 123, 'max_depth': 8, 'learning_rate': 0.028458304441166392, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:34,592] Trial 36 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 140, 'max_depth': 7, 'learning_rate': 0.023574238667177297, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:35,257] Trial 37 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 154, 'max_depth': 7, 'learning_rate': 0.0318420243894474, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:35,696] Trial 38 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.013543537604968887, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:36,384] Trial 39 finished with value: 0.8082763742703633 and parameters: {'n_estimators': 106, 'max_depth': 9, 'learning_rate': 0.077080323888655, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:36,966] Trial 40 finished with value: 0.7991466778070471 and parameters: {'n_estimators': 93, 'max_depth': 8, 'learning_rate': 0.01879367719054857, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:37,376] Trial 41 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.040820117696281424, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:37,854] Trial 42 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.06409260328148159, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:38,270] Trial 43 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.03370394377532081, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:38,605] Trial 44 finished with value: 0.83723505544913 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.05022841438971026, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:38,978] Trial 45 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.04584857303558695, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:39,238] Trial 46 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.051051012914143434, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:39,511] Trial 47 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 93, 'max_depth': 5, 'learning_rate': 0.08710822506419644, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:39,647] Trial 48 finished with value: 0.7991466778070471 and parameters: {'n_estimators': 73, 'max_depth': 3, 'learning_rate': 0.029948735446786136, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:40,241] Trial 49 finished with value: 0.771757588417099 and parameters: {'n_estimators': 146, 'max_depth': 7, 'learning_rate': 0.06595244117931906, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:40,759] Trial 50 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 112, 'max_depth': 7, 'learning_rate': 0.025570089219399815, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:41,114] Trial 51 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.03784406833218936, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:41,456] Trial 52 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.08958495858728117, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:41,695] Trial 53 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.043335830724690765, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:42,203] Trial 54 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.0211468385414035, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:42,692] Trial 55 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.03948885614286063, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:43,004] Trial 56 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 129, 'max_depth': 4, 'learning_rate': 0.03205170328295633, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:43,417] Trial 57 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 147, 'max_depth': 5, 'learning_rate': 0.06092292806217867, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:43,926] Trial 58 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.054011818425540106, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:44,225] Trial 59 finished with value: 0.83723505544913 and parameters: {'n_estimators': 110, 'max_depth': 4, 'learning_rate': 0.07549909956487631, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:44,423] Trial 60 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 107, 'max_depth': 3, 'learning_rate': 0.07599411573615476, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:44,744] Trial 61 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.09103663751105695, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:45,173] Trial 62 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.07306320548764306, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:45,526] Trial 63 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 126, 'max_depth': 4, 'learning_rate': 0.09376942856880484, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:45,759] Trial 64 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.08051743655542429, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:46,005] Trial 65 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 102, 'max_depth': 4, 'learning_rate': 0.03535899738108054, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:46,301] Trial 66 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 89, 'max_depth': 5, 'learning_rate': 0.06950590734129833, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:46,932] Trial 67 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.04601017634633285, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:47,272] Trial 68 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.09646112706195484, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:47,492] Trial 69 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 121, 'max_depth': 3, 'learning_rate': 0.09962746661154177, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:47,788] Trial 70 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.08269586385928646, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:48,032] Trial 71 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.09332230126967678, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:48,299] Trial 72 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.09537256764977094, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:48,664] Trial 73 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.07860506325202468, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:48,922] Trial 74 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 110, 'max_depth': 3, 'learning_rate': 0.09108521324647652, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:49,112] Trial 75 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 57, 'max_depth': 4, 'learning_rate': 0.07018459578856903, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:49,452] Trial 76 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.0851717738313955, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:49,832] Trial 77 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.08541043474073978, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:50,158] Trial 78 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.0860689338806334, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:50,537] Trial 79 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.06469533893065782, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:50,966] Trial 80 finished with value: 0.8222131906342433 and parameters: {'n_estimators': 81, 'max_depth': 7, 'learning_rate': 0.06083331205571018, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:51,271] Trial 81 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 107, 'max_depth': 4, 'learning_rate': 0.07285020658147578, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:51,576] Trial 82 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 95, 'max_depth': 5, 'learning_rate': 0.08661478734210865, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:51,872] Trial 83 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 93, 'max_depth': 5, 'learning_rate': 0.08336187642238159, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:52,283] Trial 84 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.08901542882151402, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:52,735] Trial 85 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.028462973188352902, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:52,999] Trial 86 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.0815836796367794, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:53,239] Trial 87 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.08095065941993512, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:53,620] Trial 88 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 86, 'max_depth': 6, 'learning_rate': 0.08754973666081331, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:53,903] Trial 89 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.022553407500800277, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:54,201] Trial 90 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.07874162649413337, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:54,666] Trial 91 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.09424411566079761, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:54,942] Trial 92 finished with value: 0.83723505544913 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.08578246766930513, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:55,424] Trial 93 finished with value: 0.7766268292584081 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.0937515273328712, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:55,691] Trial 94 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.06872108685623828, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:56,094] Trial 95 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 134, 'max_depth': 5, 'learning_rate': 0.07367864847848113, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:56,367] Trial 96 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.026093110491286795, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:56,764] Trial 97 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.08070676873989774, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:57,147] Trial 98 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.05522600711096081, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:57,516] Trial 99 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.09961219716035724, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:57,835] Trial 100 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 127, 'max_depth': 4, 'learning_rate': 0.05664945570395665, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:58,268] Trial 101 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.048481752021242316, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:59,102] Trial 102 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 113, 'max_depth': 10, 'learning_rate': 0.05274067273224604, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:59,444] Trial 103 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.044140182099504675, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:08:59,926] Trial 104 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.03317305675703792, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:00,340] Trial 105 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.030529541475354565, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:00,634] Trial 106 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.09112073170336703, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:01,169] Trial 107 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.07687582661695229, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:01,540] Trial 108 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 111, 'max_depth': 6, 'learning_rate': 0.0633302345423579, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:01,844] Trial 109 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.07178316620287996, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:02,055] Trial 110 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.08416973559644207, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:02,279] Trial 111 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.07533199860512232, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:02,549] Trial 112 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.06707808079749632, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:02,877] Trial 113 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.08655716733741993, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:03,074] Trial 114 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.09162553169882805, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:03,940] Trial 115 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 179, 'max_depth': 7, 'learning_rate': 0.07868764501130851, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:04,674] Trial 116 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 127, 'max_depth': 9, 'learning_rate': 0.0281123225603494, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:05,009] Trial 117 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.09664132770425227, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:05,239] Trial 118 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.04115597720324994, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:05,577] Trial 119 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.05882094693538878, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:05,930] Trial 120 finished with value: 0.8010650677711588 and parameters: {'n_estimators': 102, 'max_depth': 6, 'learning_rate': 0.08216691210468996, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8462775523686227.\n",
      "[I 2024-01-12 21:09:06,138] Trial 121 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.08682012423331428, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:06,355] Trial 122 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.08913977057286351, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:06,549] Trial 123 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 81, 'max_depth': 4, 'learning_rate': 0.07528696526440916, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:06,740] Trial 124 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.08438338989556987, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:06,945] Trial 125 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.0956018042052933, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:07,125] Trial 126 finished with value: 0.8203604955292878 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.08756924432855481, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:07,271] Trial 127 finished with value: 0.8168820994907952 and parameters: {'n_estimators': 59, 'max_depth': 4, 'learning_rate': 0.010673105954599289, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:07,694] Trial 128 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.08139538668204742, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:07,948] Trial 129 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 153, 'max_depth': 3, 'learning_rate': 0.07626771402587566, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:08,199] Trial 130 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.05057260753710019, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:08,410] Trial 131 finished with value: 0.83723505544913 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.085966861883771, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:08,646] Trial 132 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.09210313817301218, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:08,847] Trial 133 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.09988025923417043, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:08,989] Trial 134 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 61, 'max_depth': 4, 'learning_rate': 0.09959060978058579, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:09,195] Trial 135 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.093151594764673, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 121 with value: 0.8465761215761216.\n",
      "[I 2024-01-12 21:09:09,387] Trial 136 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.09394706738398331, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:09,586] Trial 137 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.09388890072303958, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:09,792] Trial 138 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 54, 'max_depth': 5, 'learning_rate': 0.0900964158785051, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:10,117] Trial 139 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 71, 'max_depth': 6, 'learning_rate': 0.0246384312950499, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:10,439] Trial 140 finished with value: 0.7910991451221336 and parameters: {'n_estimators': 65, 'max_depth': 6, 'learning_rate': 0.09998104258398868, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:10,757] Trial 141 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.035738629172418226, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:11,073] Trial 142 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.03516425538119368, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:11,342] Trial 143 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.09508470824696792, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:11,582] Trial 144 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.038123520108992046, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:11,800] Trial 145 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.03723390149062057, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:12,004] Trial 146 finished with value: 0.833469421937483 and parameters: {'n_estimators': 52, 'max_depth': 5, 'learning_rate': 0.036254272595834657, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:12,225] Trial 147 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.03824447107666804, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:12,466] Trial 148 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.03277486622873984, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:12,691] Trial 149 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.030918778350325023, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:12,949] Trial 150 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03207751587161001, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:13,209] Trial 151 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.033181113108864145, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:13,465] Trial 152 finished with value: 0.8247312950015653 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.029877766524672028, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:13,737] Trial 153 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.027342744702246572, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:13,964] Trial 154 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.03199726108436227, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:14,182] Trial 155 finished with value: 0.833469421937483 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.02921824147604991, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:14,456] Trial 156 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.01975944771712101, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:14,682] Trial 157 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 68, 'max_depth': 4, 'learning_rate': 0.08941697963073665, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:15,000] Trial 158 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.09561700894603431, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:15,285] Trial 159 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03239213400391941, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:15,499] Trial 160 finished with value: 0.7974628104645064 and parameters: {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.08676385180074192, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:15,803] Trial 161 finished with value: 0.833469421937483 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.04025733077461493, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:16,070] Trial 162 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.03464652735362849, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:16,334] Trial 163 finished with value: 0.833469421937483 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.033333400615058975, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:16,584] Trial 164 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.03477494297995075, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:16,816] Trial 165 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.035706494958677164, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:17,116] Trial 166 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 54, 'max_depth': 8, 'learning_rate': 0.09067329311544482, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:17,347] Trial 167 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.0160562011855091, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:17,637] Trial 168 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 85, 'max_depth': 5, 'learning_rate': 0.02624398498930041, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:17,868] Trial 169 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 80, 'max_depth': 4, 'learning_rate': 0.02637397007886994, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:18,216] Trial 170 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 87, 'max_depth': 5, 'learning_rate': 0.023158371989693453, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:18,542] Trial 171 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.025118573403413776, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:18,804] Trial 172 finished with value: 0.833469421937483 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03154127933409515, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:19,004] Trial 173 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.02926355527091063, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:19,208] Trial 174 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.027957469165369127, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:19,576] Trial 175 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.0836553658968716, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:19,850] Trial 176 finished with value: 0.845595020307664 and parameters: {'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.0941874621430829, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:20,077] Trial 177 finished with value: 0.83723505544913 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.09332654508595842, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:20,342] Trial 178 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 91, 'max_depth': 5, 'learning_rate': 0.09930654752667796, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:20,658] Trial 179 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 85, 'max_depth': 5, 'learning_rate': 0.08716267445574162, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:21,055] Trial 180 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08009150304364827, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:21,410] Trial 181 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 95, 'max_depth': 5, 'learning_rate': 0.03425809562549658, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:21,736] Trial 182 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 98, 'max_depth': 5, 'learning_rate': 0.09279941891061301, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:22,013] Trial 183 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.09608590558832321, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:22,240] Trial 184 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.0879207860782422, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:22,429] Trial 185 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 76, 'max_depth': 4, 'learning_rate': 0.08388094225678809, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:22,778] Trial 186 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.09067679732428864, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:22,945] Trial 187 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 68, 'max_depth': 4, 'learning_rate': 0.039244104182867785, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:23,268] Trial 188 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.03707471650265202, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:23,598] Trial 189 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.04252731925634023, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:23,906] Trial 190 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.09566579214049553, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:24,100] Trial 191 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.030779990309041567, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:24,309] Trial 192 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.030897959141439908, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:24,482] Trial 193 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.026491905342308025, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:24,671] Trial 194 finished with value: 0.833469421937483 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.030011259349939288, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:24,864] Trial 195 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03375885784457477, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:25,044] Trial 196 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03186553313868338, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:25,296] Trial 197 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 73, 'max_depth': 6, 'learning_rate': 0.09060390745923809, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:25,525] Trial 198 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 91, 'max_depth': 4, 'learning_rate': 0.023907532220278117, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:25,789] Trial 199 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.02827704212140414, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:26,106] Trial 200 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.0854381938282903, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:26,491] Trial 201 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.08289661977490746, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:26,852] Trial 202 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.08545713135739286, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:27,205] Trial 203 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.08738623490965046, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:27,543] Trial 204 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.0784208858916771, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:27,868] Trial 205 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.07850140495893136, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:28,210] Trial 206 finished with value: 0.836512374443409 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.08544002171616102, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:28,541] Trial 207 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.07988750858625379, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:28,805] Trial 208 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.09248398973055866, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:29,100] Trial 209 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.08367185862318278, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:29,425] Trial 210 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.09876203934154916, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:29,761] Trial 211 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.08913759835865563, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:30,083] Trial 212 finished with value: 0.836512374443409 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.09383800443832419, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:30,392] Trial 213 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.08577076237084441, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:30,721] Trial 214 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.08194544811754094, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:31,042] Trial 215 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.080279682348865, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:31,402] Trial 216 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.08987752341863385, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:31,724] Trial 217 finished with value: 0.8503124686024315 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.0754697247064192, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:31,973] Trial 218 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.08280368771405122, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:32,289] Trial 219 finished with value: 0.83723505544913 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.07423897901479701, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:32,736] Trial 220 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 124, 'max_depth': 6, 'learning_rate': 0.07751196680267432, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:33,036] Trial 221 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.08707482657647667, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:33,364] Trial 222 finished with value: 0.8269994515719551 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.09359417805407691, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:33,671] Trial 223 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.07122461299474983, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:34,080] Trial 224 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 98, 'max_depth': 7, 'learning_rate': 0.08185529494279309, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:34,402] Trial 225 finished with value: 0.8317656008930031 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.0856271521554029, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:34,708] Trial 226 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.09960295211195366, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:35,137] Trial 227 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.07782703360451344, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:35,499] Trial 228 finished with value: 0.83723505544913 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.08950723127585487, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:35,830] Trial 229 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.09358732067256219, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:36,225] Trial 230 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.021387334107279124, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:36,491] Trial 231 finished with value: 0.8061394798155086 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.017259618691984266, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:36,766] Trial 232 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03423992895050883, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:37,057] Trial 233 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.08837899103025332, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:37,441] Trial 234 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.082985132549683, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:37,659] Trial 235 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.09585080907442478, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:37,870] Trial 236 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.09040944987544282, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:38,216] Trial 237 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.05482728616174691, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:38,576] Trial 238 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.05294027865630771, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:38,934] Trial 239 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.07901931569546679, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:39,289] Trial 240 finished with value: 0.8269994515719551 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.07488804190017544, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:39,666] Trial 241 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.04781241656047038, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:40,020] Trial 242 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.0556110739008621, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:40,395] Trial 243 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.06262116654253176, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:40,708] Trial 244 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 130, 'max_depth': 4, 'learning_rate': 0.07952845914328191, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:41,082] Trial 245 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.014381538600358856, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:41,408] Trial 246 finished with value: 0.84191359062235 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.0838079742923259, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:41,741] Trial 247 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.06701896639370113, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:42,076] Trial 248 finished with value: 0.827429728579154 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.0771534287731092, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:42,395] Trial 249 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.0816144805929264, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:42,730] Trial 250 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.08479517982408534, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:43,061] Trial 251 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.06599815764282453, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:43,325] Trial 252 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.06947176454672893, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:43,651] Trial 253 finished with value: 0.8503124686024315 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.05749895615169327, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:43,995] Trial 254 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.07351213761875443, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:44,561] Trial 255 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.06083123907404656, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:44,872] Trial 256 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.056436019186732876, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:45,143] Trial 257 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 123, 'max_depth': 4, 'learning_rate': 0.05946513592534817, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:45,470] Trial 258 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.0661859548347115, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:45,972] Trial 259 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 113, 'max_depth': 6, 'learning_rate': 0.06300855745723323, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:46,380] Trial 260 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.05934592400376845, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:46,767] Trial 261 finished with value: 0.84191359062235 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.05426836791796523, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:47,118] Trial 262 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.05272493424262492, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:47,490] Trial 263 finished with value: 0.83723505544913 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.05358044316379211, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:47,833] Trial 264 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.051353301402986294, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:48,170] Trial 265 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.04949692102987864, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:48,560] Trial 266 finished with value: 0.83723505544913 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.05560456513848421, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:48,838] Trial 267 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 126, 'max_depth': 4, 'learning_rate': 0.057572380602312664, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:49,156] Trial 268 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.05412902976663991, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:49,888] Trial 269 finished with value: 0.8087888675268976 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.06729605395505289, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:50,217] Trial 270 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.05767573471696684, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:50,532] Trial 271 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.051686250349115816, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:50,875] Trial 272 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.06558914866161891, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:51,123] Trial 273 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.05494686610870529, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:51,387] Trial 274 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 93, 'max_depth': 5, 'learning_rate': 0.05188241958857278, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:51,713] Trial 275 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.07103613797872155, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:51,953] Trial 276 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 86, 'max_depth': 5, 'learning_rate': 0.02631120198749205, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:52,130] Trial 277 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.06032181740770145, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:52,528] Trial 278 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.045826619809934584, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:52,775] Trial 279 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.025051366371434243, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:53,089] Trial 280 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.062218871800372375, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:53,257] Trial 281 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.05668701827305157, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:53,598] Trial 282 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.09661122751342421, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:53,901] Trial 283 finished with value: 0.836512374443409 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.09132062970550767, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:54,408] Trial 284 finished with value: 0.7905782834818402 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.08847200515711816, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:54,660] Trial 285 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.0960629465069002, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:54,966] Trial 286 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.05320662986288888, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:55,282] Trial 287 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.09247351332940205, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:55,653] Trial 288 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.08830642301501718, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:55,977] Trial 289 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.06855684071020185, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:56,194] Trial 290 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.04560570258871935, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:56,512] Trial 291 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.058280800844556335, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:56,768] Trial 292 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.027169249995492865, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:57,054] Trial 293 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.08342900225782711, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:57,355] Trial 294 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.05049337614577747, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:57,702] Trial 295 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.09956765895006932, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:58,136] Trial 296 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.081869134898847, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:58,331] Trial 297 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 67, 'max_depth': 4, 'learning_rate': 0.07332090659870771, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:58,751] Trial 298 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.0828007844938033, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:59,100] Trial 299 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.0865272368497008, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:59,389] Trial 300 finished with value: 0.827429728579154 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.09546330644441713, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:09:59,816] Trial 301 finished with value: 0.790016981343731 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.09113511337253369, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:00,158] Trial 302 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.06260673747387259, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:00,687] Trial 303 finished with value: 0.8317656008930031 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.05492286855505946, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:00,926] Trial 304 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.06516549233892008, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:01,295] Trial 305 finished with value: 0.827429728579154 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.08513243911442332, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:01,632] Trial 306 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.022181546772737898, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:02,012] Trial 307 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.07479201124444462, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:02,242] Trial 308 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 102, 'max_depth': 4, 'learning_rate': 0.01182690621914441, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:02,517] Trial 309 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 97, 'max_depth': 5, 'learning_rate': 0.04976995700337863, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:02,823] Trial 310 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.02855816037608786, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:03,164] Trial 311 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.08058326346964283, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:03,276] Trial 312 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 54, 'max_depth': 3, 'learning_rate': 0.08947303069773213, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:03,951] Trial 313 finished with value: 0.799683575504369 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.048070010856985534, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:04,534] Trial 314 finished with value: 0.7936822228311452 and parameters: {'n_estimators': 84, 'max_depth': 10, 'learning_rate': 0.09438911420422844, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:04,864] Trial 315 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.02539906782422396, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:05,112] Trial 316 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.07811585432666879, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:05,311] Trial 317 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.05713877170059284, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:05,653] Trial 318 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.0700803921110929, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:05,864] Trial 319 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.087101939217767, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:06,109] Trial 320 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.091435378394442, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:06,421] Trial 321 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.054183573760431605, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:06,667] Trial 322 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.09925480683204337, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:06,941] Trial 323 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.09341340436075077, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:07,176] Trial 324 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.09903411821370965, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:07,385] Trial 325 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.09941811585045018, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:07,629] Trial 326 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.0946099761475983, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:07,867] Trial 327 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 103, 'max_depth': 4, 'learning_rate': 0.09905952224833031, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:08,043] Trial 328 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 74, 'max_depth': 4, 'learning_rate': 0.09994108454295393, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:08,285] Trial 329 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.09583285762473871, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:08,559] Trial 330 finished with value: 0.836512374443409 and parameters: {'n_estimators': 119, 'max_depth': 4, 'learning_rate': 0.09940882046869177, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:08,724] Trial 331 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 70, 'max_depth': 4, 'learning_rate': 0.09098359013209548, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:09,011] Trial 332 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 127, 'max_depth': 4, 'learning_rate': 0.036867570205731955, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:09,253] Trial 333 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 64, 'max_depth': 6, 'learning_rate': 0.02955721964542222, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:09,507] Trial 334 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 91, 'max_depth': 5, 'learning_rate': 0.032182693450360386, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:09,751] Trial 335 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.058245514731089174, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:09,930] Trial 336 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.02359404911072115, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:10,151] Trial 337 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.09619278993047506, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:10,430] Trial 338 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.04374720861544832, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:10,743] Trial 339 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.06178871361099193, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:11,073] Trial 340 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.09401004979175043, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:11,396] Trial 341 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.05331449167720943, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:11,564] Trial 342 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 67, 'max_depth': 4, 'learning_rate': 0.038927255396926125, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:11,879] Trial 343 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.08897684997121384, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:12,189] Trial 344 finished with value: 0.84191359062235 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.0669510571263319, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:12,421] Trial 345 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.09957749584112575, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:12,723] Trial 346 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.08908886636340524, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:13,003] Trial 347 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 81, 'max_depth': 6, 'learning_rate': 0.03548665853699928, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:13,308] Trial 348 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.027015919660266417, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:13,489] Trial 349 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.09404362876968074, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:13,729] Trial 350 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 107, 'max_depth': 4, 'learning_rate': 0.059728353838071395, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:14,006] Trial 351 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.0919473840038061, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:14,210] Trial 352 finished with value: 0.833469421937483 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.08458065009149747, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:14,490] Trial 353 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.03386268261981174, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:14,741] Trial 354 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.05079520270912977, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:15,260] Trial 355 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.02452043462907716, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:15,556] Trial 356 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.055641677883588904, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:15,879] Trial 357 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.030491591663589345, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:16,097] Trial 358 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.0724550357672059, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:16,443] Trial 359 finished with value: 0.8178941595494262 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.08702062112922473, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:16,689] Trial 360 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.09609393970725114, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:16,886] Trial 361 finished with value: 0.8203604955292878 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.08152635253213042, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:17,100] Trial 362 finished with value: 0.7967460450858784 and parameters: {'n_estimators': 92, 'max_depth': 4, 'learning_rate': 0.041354681921549175, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:17,368] Trial 363 finished with value: 0.7971227114348347 and parameters: {'n_estimators': 95, 'max_depth': 5, 'learning_rate': 0.04752626068520859, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:17,672] Trial 364 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.0679904111939935, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:17,836] Trial 365 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.07604988249248303, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:18,192] Trial 366 finished with value: 0.7910991451221336 and parameters: {'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.09141091753009861, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:18,383] Trial 367 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.09996099905419611, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:18,621] Trial 368 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 85, 'max_depth': 5, 'learning_rate': 0.06406732988456466, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:18,941] Trial 369 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.08650973356954608, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:19,201] Trial 370 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.0531990660582716, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:19,533] Trial 371 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.09562063376404707, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:19,824] Trial 372 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.031642305303597316, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:20,008] Trial 373 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 79, 'max_depth': 4, 'learning_rate': 0.027715783790565465, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:20,323] Trial 374 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.07874254205026299, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:20,865] Trial 375 finished with value: 0.7802585193889541 and parameters: {'n_estimators': 135, 'max_depth': 7, 'learning_rate': 0.08970537203899441, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:21,080] Trial 376 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 61, 'max_depth': 6, 'learning_rate': 0.08394234493569583, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:21,414] Trial 377 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.059401461248512824, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:21,727] Trial 378 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.026058090158114007, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:21,877] Trial 379 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 51, 'max_depth': 5, 'learning_rate': 0.0936468381794253, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:22,048] Trial 380 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 72, 'max_depth': 4, 'learning_rate': 0.0558411091660706, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:22,320] Trial 381 finished with value: 0.827429728579154 and parameters: {'n_estimators': 98, 'max_depth': 5, 'learning_rate': 0.08820488071424301, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:22,655] Trial 382 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.05131105662401101, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:22,910] Trial 383 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.08165427296354741, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:23,103] Trial 384 finished with value: 0.7894144144144144 and parameters: {'n_estimators': 109, 'max_depth': 3, 'learning_rate': 0.020065855671787338, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:23,384] Trial 385 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.09584164084096683, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:23,582] Trial 386 finished with value: 0.83723505544913 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.09152921632050913, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:23,945] Trial 387 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.075893253854559, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:24,142] Trial 388 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 87, 'max_depth': 4, 'learning_rate': 0.032941944927399346, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:24,469] Trial 389 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.06928696641676152, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:24,782] Trial 390 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.02926175785567456, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:25,108] Trial 391 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.08500743162672257, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:25,470] Trial 392 finished with value: 0.7942921942921943 and parameters: {'n_estimators': 107, 'max_depth': 6, 'learning_rate': 0.09993153721185498, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:25,719] Trial 393 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.05731129350739491, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:25,906] Trial 394 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.061361651407306664, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:26,245] Trial 395 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.0919611565538875, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:26,418] Trial 396 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.07981502939347625, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:26,670] Trial 397 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.0874545784488607, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:26,936] Trial 398 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.03531345583759159, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:27,137] Trial 399 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.09547973039058345, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:27,462] Trial 400 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.037645586494767104, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:27,801] Trial 401 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 102, 'max_depth': 6, 'learning_rate': 0.05276745793410794, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:28,036] Trial 402 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.07182303686126666, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:28,243] Trial 403 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.06482357115689485, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:28,858] Trial 404 finished with value: 0.7985703094398747 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.08833094088214911, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:29,174] Trial 405 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.0918755780916202, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:29,449] Trial 406 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 119, 'max_depth': 4, 'learning_rate': 0.09991883477402187, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:29,638] Trial 407 finished with value: 0.8201060592364939 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.04884431927094758, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:30,063] Trial 408 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 159, 'max_depth': 5, 'learning_rate': 0.09578188198568133, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:30,337] Trial 409 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08120579692499653, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:30,648] Trial 410 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.054973527663432616, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:30,852] Trial 411 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 88, 'max_depth': 4, 'learning_rate': 0.08501783613593752, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:31,069] Trial 412 finished with value: 0.84191359062235 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.07835645877788959, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:31,211] Trial 413 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 75, 'max_depth': 3, 'learning_rate': 0.075038553476342, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:31,428] Trial 414 finished with value: 0.84191359062235 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.07786350662289773, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:31,652] Trial 415 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.0785344319811403, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:31,880] Trial 416 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.07237312908944814, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:32,121] Trial 417 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.08189038254219352, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:32,340] Trial 418 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.07672465659884131, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:32,534] Trial 419 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 82, 'max_depth': 4, 'learning_rate': 0.07686436845441573, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:32,754] Trial 420 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.07898659541336409, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:32,962] Trial 421 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.07344310425906407, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:33,237] Trial 422 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 77, 'max_depth': 6, 'learning_rate': 0.06896341253235976, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:33,461] Trial 423 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.07575308714407379, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:33,647] Trial 424 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 83, 'max_depth': 4, 'learning_rate': 0.07212833109033241, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:33,859] Trial 425 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.030482909922266162, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:34,077] Trial 426 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.027131111923538443, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:34,309] Trial 427 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.03049185884247017, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:34,518] Trial 428 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.028783753158552538, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:34,738] Trial 429 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.032295326374911365, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:34,950] Trial 430 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.028131790231302363, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:35,162] Trial 431 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.030787893430311495, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:35,381] Trial 432 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.030710619589988296, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:35,585] Trial 433 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.031139805508363788, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:35,784] Trial 434 finished with value: 0.84709015035102 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.03150758414024033, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:35,983] Trial 435 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.030474764839513193, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:36,186] Trial 436 finished with value: 0.84709015035102 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.031103900112951135, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:36,386] Trial 437 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03208285264723205, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:36,595] Trial 438 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.033242920889479194, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:36,800] Trial 439 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03415935875236643, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:36,994] Trial 440 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.031235747735837035, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:37,192] Trial 441 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.029677911701349924, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:37,422] Trial 442 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 66, 'max_depth': 6, 'learning_rate': 0.03158124250805448, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:37,619] Trial 443 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.03177759590044873, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:37,833] Trial 444 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.02960376678449172, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:38,033] Trial 445 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.032820295767328075, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:38,270] Trial 446 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03270263583629222, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:38,470] Trial 447 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.034441953650913876, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:38,675] Trial 448 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03287297975210967, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:38,887] Trial 449 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.030548799739456768, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:39,150] Trial 450 finished with value: 0.8044843469837604 and parameters: {'n_estimators': 63, 'max_depth': 7, 'learning_rate': 0.03590932221825045, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:39,395] Trial 451 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.028659078979774384, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:39,615] Trial 452 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.033975827152630415, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:39,826] Trial 453 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.030412117913436648, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:40,053] Trial 454 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.029567028658319446, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:40,304] Trial 455 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.032329607447066706, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:40,557] Trial 456 finished with value: 0.833469421937483 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.027990089959114763, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:40,825] Trial 457 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.033313834078132654, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:41,117] Trial 458 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.031694925917108055, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:41,415] Trial 459 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03521659695329868, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:41,703] Trial 460 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.030206400339813148, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:41,938] Trial 461 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.02925073339326374, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:42,198] Trial 462 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.026798212903689222, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:42,499] Trial 463 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.03141837705398367, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:42,778] Trial 464 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.025809818889699264, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:43,016] Trial 465 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.0326656244856908, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:43,276] Trial 466 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.036253418328779485, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:43,497] Trial 467 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.034004717170121455, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:43,693] Trial 468 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.03294789916383853, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:43,893] Trial 469 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03820316959160143, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:44,090] Trial 470 finished with value: 0.833469421937483 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.035158760986536586, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:44,435] Trial 471 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 58, 'max_depth': 9, 'learning_rate': 0.028514292761130957, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:44,632] Trial 472 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.032131630030028606, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:44,835] Trial 473 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03363084937137, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:45,080] Trial 474 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.03243320824168522, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:45,353] Trial 475 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.03624227119160448, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:45,776] Trial 476 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 80, 'max_depth': 7, 'learning_rate': 0.03380781657756398, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:46,062] Trial 477 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 84, 'max_depth': 5, 'learning_rate': 0.03248558651566587, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:46,279] Trial 478 finished with value: 0.8001817909863886 and parameters: {'n_estimators': 53, 'max_depth': 6, 'learning_rate': 0.024058043812416084, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:46,513] Trial 479 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.03446005121894366, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:46,712] Trial 480 finished with value: 0.833469421937483 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.03153939902346742, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:46,937] Trial 481 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.0397829121368228, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:47,161] Trial 482 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.027326982653668317, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:47,397] Trial 483 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.036850955285918495, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:47,592] Trial 484 finished with value: 0.833469421937483 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.02990047138928524, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:47,807] Trial 485 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.03303847868600294, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:48,014] Trial 486 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03485274310267445, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:48,278] Trial 487 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.028445193367280783, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:48,706] Trial 488 finished with value: 0.8222131906342433 and parameters: {'n_estimators': 71, 'max_depth': 8, 'learning_rate': 0.032398325405049916, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:48,941] Trial 489 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 61, 'max_depth': 6, 'learning_rate': 0.02944042948796736, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:49,144] Trial 490 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.03095680557528215, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:49,355] Trial 491 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.03173907853930376, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:49,613] Trial 492 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.03319662495515697, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:49,890] Trial 493 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.03502197015718105, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:50,054] Trial 494 finished with value: 0.7936822228311452 and parameters: {'n_estimators': 72, 'max_depth': 3, 'learning_rate': 0.0265174078069995, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:50,260] Trial 495 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.037804905432806186, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:50,444] Trial 496 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.025265417045892868, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:50,663] Trial 497 finished with value: 0.833469421937483 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.02980567603487361, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:51,058] Trial 498 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.022722278527405604, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:51,310] Trial 499 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.04287130769528079, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:51,631] Trial 500 finished with value: 0.83723505544913 and parameters: {'n_estimators': 85, 'max_depth': 6, 'learning_rate': 0.03231297913820404, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:51,883] Trial 501 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.030830400892332094, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:52,144] Trial 502 finished with value: 0.833469421937483 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.02822284929337907, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:52,415] Trial 503 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.033945197965582964, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:52,683] Trial 504 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03280670453086589, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:52,923] Trial 505 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.03554782148819705, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:53,220] Trial 506 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.09963320488821144, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:53,787] Trial 507 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.0313436643219825, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:54,117] Trial 508 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 74, 'max_depth': 6, 'learning_rate': 0.030264727258695414, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:54,384] Trial 509 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.02914877112967608, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:54,636] Trial 510 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.024961646605493413, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:54,889] Trial 511 finished with value: 0.833469421937483 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.02773909950239906, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:55,073] Trial 512 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 54, 'max_depth': 5, 'learning_rate': 0.03668650600295832, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:55,292] Trial 513 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.09663773205506314, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:55,672] Trial 514 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.03455071212447227, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:55,904] Trial 515 finished with value: 0.833469421937483 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.031284024679086905, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:56,091] Trial 516 finished with value: 0.84709015035102 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.032247203699119695, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:56,270] Trial 517 finished with value: 0.7838319257674097 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.010157065119882474, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:56,435] Trial 518 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 64, 'max_depth': 4, 'learning_rate': 0.03286669690813008, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:56,633] Trial 519 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.034409711992363166, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:56,829] Trial 520 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.04035720564679108, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,044] Trial 521 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 59, 'max_depth': 6, 'learning_rate': 0.03820251532466207, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,252] Trial 522 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.036013056631063155, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,426] Trial 523 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 65, 'max_depth': 4, 'learning_rate': 0.037540326273369375, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,669] Trial 524 finished with value: 0.833469421937483 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.03607921170999127, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,864] Trial 525 finished with value: 0.833469421937483 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03550195821417726, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:57,988] Trial 526 finished with value: 0.8034347634347635 and parameters: {'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.04499283844311455, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:58,198] Trial 527 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.03367461617661759, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:58,501] Trial 528 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 68, 'max_depth': 7, 'learning_rate': 0.03442725412175881, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:58,684] Trial 529 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.03709927638345553, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:58,894] Trial 530 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.04130107591410882, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:59,159] Trial 531 finished with value: 0.84191359062235 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03286066323226279, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:59,674] Trial 532 finished with value: 0.7825186108768198 and parameters: {'n_estimators': 61, 'max_depth': 10, 'learning_rate': 0.03906368667109756, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:10:59,913] Trial 533 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.09530541187206122, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:00,333] Trial 534 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.036385289818569054, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:00,551] Trial 535 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 64, 'max_depth': 4, 'learning_rate': 0.09985540595074568, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:00,798] Trial 536 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.017213422828529445, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:01,034] Trial 537 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.013020744087343022, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:01,438] Trial 538 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.03192302754468999, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:01,644] Trial 539 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.03478608552624463, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:01,786] Trial 540 finished with value: 0.8014514514514515 and parameters: {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.09154484856912473, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:02,024] Trial 541 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.03313509217004063, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:02,416] Trial 542 finished with value: 0.8178941595494262 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.09590220279555997, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:02,743] Trial 543 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 66, 'max_depth': 6, 'learning_rate': 0.032057338096210676, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:02,972] Trial 544 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03422221144808919, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:03,199] Trial 545 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.0912245713764088, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:03,467] Trial 546 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.09560611164886812, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:03,746] Trial 547 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.036248255153162594, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:03,963] Trial 548 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 66, 'max_depth': 4, 'learning_rate': 0.03216283414617766, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:04,221] Trial 549 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.03424723881434008, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:04,419] Trial 550 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 63, 'max_depth': 4, 'learning_rate': 0.03602513945807658, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:04,716] Trial 551 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 65, 'max_depth': 6, 'learning_rate': 0.031008667146702522, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:05,319] Trial 552 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.08937633459472888, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:05,750] Trial 553 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.06314910700648535, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:05,982] Trial 554 finished with value: 0.84709015035102 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03351958305879064, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:06,212] Trial 555 finished with value: 0.8293424707528233 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.02975324274946611, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:06,437] Trial 556 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03233556901414235, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:06,650] Trial 557 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.033084041043217556, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:07,032] Trial 558 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 72, 'max_depth': 7, 'learning_rate': 0.030916959574621868, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:07,260] Trial 559 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.09410490961613027, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:07,617] Trial 560 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.09896343976380224, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:07,915] Trial 561 finished with value: 0.8061394798155086 and parameters: {'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.03317320914001151, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:08,160] Trial 562 finished with value: 0.83723505544913 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.031350540327418054, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:08,577] Trial 563 finished with value: 0.8222131906342433 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.08792152945153928, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:08,868] Trial 564 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 71, 'max_depth': 6, 'learning_rate': 0.04696523233369412, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:09,047] Trial 565 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 66, 'max_depth': 4, 'learning_rate': 0.09988449499644114, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:09,273] Trial 566 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.09209213665179423, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:09,506] Trial 567 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.030078796536115265, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:09,737] Trial 568 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.033909153113134145, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:09,973] Trial 569 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.02916406879477191, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:10,382] Trial 570 finished with value: 0.84191359062235 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.02155613650280526, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:10,654] Trial 571 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.01939449939245177, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:11,084] Trial 572 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.08575037829390318, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:11,343] Trial 573 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.06928177948552214, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:11,696] Trial 574 finished with value: 0.8014514514514515 and parameters: {'n_estimators': 128, 'max_depth': 4, 'learning_rate': 0.03171172249683962, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:11,963] Trial 575 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.0605448620492742, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:12,150] Trial 576 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 78, 'max_depth': 3, 'learning_rate': 0.09472971978457705, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:12,386] Trial 577 finished with value: 0.8337194337194337 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.035171890126321874, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:12,641] Trial 578 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03344575576088677, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:13,053] Trial 579 finished with value: 0.840859352196084 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.06520370650311769, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:13,303] Trial 580 finished with value: 0.83723505544913 and parameters: {'n_estimators': 67, 'max_depth': 6, 'learning_rate': 0.09977395888510121, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:13,659] Trial 581 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.08973144701221954, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:13,909] Trial 582 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.08369998977105032, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:14,135] Trial 583 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.032115118495429314, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:14,340] Trial 584 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 75, 'max_depth': 4, 'learning_rate': 0.09328661802007547, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:14,665] Trial 585 finished with value: 0.8057795541931729 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.015361864670822583, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:15,069] Trial 586 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.030242193385468637, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:15,381] Trial 587 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.03379862911053422, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:15,600] Trial 588 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.05074541329529039, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:15,880] Trial 589 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.010935482731203452, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:16,134] Trial 590 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.03547928310964638, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:16,410] Trial 591 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.0314789637311177, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:16,707] Trial 592 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.08792885491903964, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:16,978] Trial 593 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.028901735030050894, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:17,435] Trial 594 finished with value: 0.827429728579154 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.0949301850943382, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:17,827] Trial 595 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.08138330753077257, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:18,171] Trial 596 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 73, 'max_depth': 6, 'learning_rate': 0.03254180095885152, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:18,388] Trial 597 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.09150634686660372, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:18,827] Trial 598 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.07442955162346221, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:19,237] Trial 599 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.03045871390460844, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:19,518] Trial 600 finished with value: 0.84191359062235 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.0340955663222398, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:19,738] Trial 601 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 60, 'max_depth': 4, 'learning_rate': 0.08537909173051311, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:20,031] Trial 602 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.07082598339298483, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:20,471] Trial 603 finished with value: 0.83723505544913 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.05844165065510357, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:20,812] Trial 604 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 67, 'max_depth': 6, 'learning_rate': 0.03214563050169627, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:21,226] Trial 605 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.09576554762153965, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:21,466] Trial 606 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.03492310266278812, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:21,695] Trial 607 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.06652664817129464, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:21,965] Trial 608 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.09947068633307905, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:22,203] Trial 609 finished with value: 0.833469421937483 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.028700869797773865, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:22,569] Trial 610 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.03075083883474436, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:22,869] Trial 611 finished with value: 0.83723505544913 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.08885782057470133, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:23,533] Trial 612 finished with value: 0.836512374443409 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03876729918194784, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:23,752] Trial 613 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.03352370048163206, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:23,921] Trial 614 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 65, 'max_depth': 4, 'learning_rate': 0.0803702701505308, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:24,221] Trial 615 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.036977277644610194, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:24,438] Trial 616 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.09322304618252712, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:24,743] Trial 617 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 71, 'max_depth': 6, 'learning_rate': 0.049493023655885385, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:24,952] Trial 618 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.03254159520964164, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:25,255] Trial 619 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.09684422713728054, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:25,685] Trial 620 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.029703056309728228, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:25,967] Trial 621 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.09996042040429648, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:26,479] Trial 622 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 71, 'max_depth': 8, 'learning_rate': 0.03150981282463573, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:26,915] Trial 623 finished with value: 0.83723505544913 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.056996898564351646, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:27,159] Trial 624 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.03478347659193763, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:27,436] Trial 625 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.06198210605512476, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:27,893] Trial 626 finished with value: 0.827429728579154 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.08540345899661177, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:28,317] Trial 627 finished with value: 0.7991466778070471 and parameters: {'n_estimators': 69, 'max_depth': 9, 'learning_rate': 0.03323127828563473, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:28,608] Trial 628 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.05283142835322458, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:29,043] Trial 629 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.09069606334633358, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:29,238] Trial 630 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 60, 'max_depth': 4, 'learning_rate': 0.027766915178595558, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:29,769] Trial 631 finished with value: 0.790016981343731 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.07726962537459343, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:30,233] Trial 632 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 147, 'max_depth': 5, 'learning_rate': 0.031238072582715867, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:30,451] Trial 633 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.03587268762571457, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:30,690] Trial 634 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 58, 'max_depth': 6, 'learning_rate': 0.07314227372999213, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:30,897] Trial 635 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.04428749688650067, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:31,159] Trial 636 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.08321359724415536, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:31,315] Trial 637 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 56, 'max_depth': 4, 'learning_rate': 0.09437626634695062, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:31,656] Trial 638 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.029732445455307635, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:32,059] Trial 639 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.0880773991149085, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:32,427] Trial 640 finished with value: 0.8061394798155086 and parameters: {'n_estimators': 139, 'max_depth': 4, 'learning_rate': 0.03312639043335045, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:32,810] Trial 641 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.035556250927761886, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:33,009] Trial 642 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.09180995228831551, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:33,285] Trial 643 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.03764926985150116, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:33,607] Trial 644 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.08022269531723865, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:33,825] Trial 645 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.031882441883023464, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:34,042] Trial 646 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.09628865591237075, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:34,543] Trial 647 finished with value: 0.7905782834818402 and parameters: {'n_estimators': 73, 'max_depth': 10, 'learning_rate': 0.03411333111535645, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:34,914] Trial 648 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 99, 'max_depth': 6, 'learning_rate': 0.029103223508975123, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:35,126] Trial 649 finished with value: 0.833469421937483 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.027195064190223866, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:35,329] Trial 650 finished with value: 0.833469421937483 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.03063911135633306, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:35,691] Trial 651 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.08921971398608661, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:35,993] Trial 652 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.06730598829538918, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:36,233] Trial 653 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.055698322929578936, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:36,552] Trial 654 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.02066230309252628, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:36,919] Trial 655 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.024030819803257556, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:37,272] Trial 656 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.022450089727866034, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:37,639] Trial 657 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.021297222582981123, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:37,955] Trial 658 finished with value: 0.833469421937483 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.020954875231562933, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:38,255] Trial 659 finished with value: 0.833469421937483 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.022032881966295544, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:38,574] Trial 660 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.02064278710615691, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:38,826] Trial 661 finished with value: 0.8140245822030209 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.022983561739106408, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:39,120] Trial 662 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.018056410037749812, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:39,371] Trial 663 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.01667543302456123, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:39,677] Trial 664 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.023385641857774926, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:39,988] Trial 665 finished with value: 0.833469421937483 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.01853122629409199, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:40,274] Trial 666 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 98, 'max_depth': 5, 'learning_rate': 0.018788691849356606, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:40,479] Trial 667 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.02613957834732281, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:40,804] Trial 668 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.01989901085094856, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:41,109] Trial 669 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.025606502029273972, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:41,439] Trial 670 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.020419417180674963, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:41,742] Trial 671 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.019770727248658606, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:42,032] Trial 672 finished with value: 0.833469421937483 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.02440575273271166, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:42,344] Trial 673 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.023532155612081017, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:42,606] Trial 674 finished with value: 0.8006420599704182 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.02437009352109369, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:42,960] Trial 675 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 95, 'max_depth': 6, 'learning_rate': 0.022436296197302193, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:43,267] Trial 676 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.05935505872581705, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:43,730] Trial 677 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 151, 'max_depth': 5, 'learning_rate': 0.027418391442834256, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:44,088] Trial 678 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.014505065352542843, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:44,359] Trial 679 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 110, 'max_depth': 4, 'learning_rate': 0.09990499430419114, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:44,686] Trial 680 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.08389631725566447, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:45,012] Trial 681 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.08131980674131602, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:45,324] Trial 682 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.07676900638319943, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:45,668] Trial 683 finished with value: 0.8321685254027262 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.08473924499710876, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:45,969] Trial 684 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.08620229751061782, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:46,511] Trial 685 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 112, 'max_depth': 7, 'learning_rate': 0.0791286639137046, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:46,860] Trial 686 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.08392222731945452, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:47,153] Trial 687 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.09035917044457988, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:47,468] Trial 688 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.08185299964550792, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:47,755] Trial 689 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.07149088607481131, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:48,024] Trial 690 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.07656942145977617, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:48,300] Trial 691 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.08733670208456831, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:48,554] Trial 692 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.08888354731128977, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:48,819] Trial 693 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.0825639972226139, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:49,082] Trial 694 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.08943560628755554, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:49,369] Trial 695 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 119, 'max_depth': 4, 'learning_rate': 0.07412182703398996, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:49,653] Trial 696 finished with value: 0.83723505544913 and parameters: {'n_estimators': 125, 'max_depth': 4, 'learning_rate': 0.09283441594407513, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:49,927] Trial 697 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.08567572416509925, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:50,219] Trial 698 finished with value: 0.827429728579154 and parameters: {'n_estimators': 130, 'max_depth': 4, 'learning_rate': 0.08034465063664067, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:50,619] Trial 699 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 191, 'max_depth': 3, 'learning_rate': 0.06384116298882357, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:50,919] Trial 700 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.025410681446150687, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:51,190] Trial 701 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.09129960876395943, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:51,455] Trial 702 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 113, 'max_depth': 4, 'learning_rate': 0.017302082776710654, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:51,828] Trial 703 finished with value: 0.7953905956806795 and parameters: {'n_estimators': 109, 'max_depth': 6, 'learning_rate': 0.08462770008689188, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:52,127] Trial 704 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.0691998230130343, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:52,454] Trial 705 finished with value: 0.83723505544913 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.0676196168190789, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:52,805] Trial 706 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.06861308439866723, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:53,140] Trial 707 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.07013695731855006, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:53,504] Trial 708 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.07380586273245458, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:53,879] Trial 709 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07391705503640207, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:54,279] Trial 710 finished with value: 0.8506436354465302 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.0702954676414322, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:54,658] Trial 711 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07317011153372335, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:54,989] Trial 712 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.07885031402818372, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:55,355] Trial 713 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.07552541436725022, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:55,742] Trial 714 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.07112902407197345, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:56,152] Trial 715 finished with value: 0.84191359062235 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07550364001363996, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:56,513] Trial 716 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.07295892448846229, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:56,991] Trial 717 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 111, 'max_depth': 6, 'learning_rate': 0.07066710430055294, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:57,384] Trial 718 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.07813211850268331, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:57,778] Trial 719 finished with value: 0.84191359062235 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.0755981870118456, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:58,171] Trial 720 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.07124364161598778, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:58,546] Trial 721 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.07953725555599886, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:58,942] Trial 722 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.0686237317962184, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:59,301] Trial 723 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08095130097572148, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:11:59,887] Trial 724 finished with value: 0.790016981343731 and parameters: {'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.06368688348892877, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:00,271] Trial 725 finished with value: 0.8412404970025789 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07322304511805476, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:00,623] Trial 726 finished with value: 0.836512374443409 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.07648896475136406, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:01,043] Trial 727 finished with value: 0.8462775523686227 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.0679200531361235, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:01,486] Trial 728 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.023708688087127228, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:01,869] Trial 729 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.06641312744434699, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:02,309] Trial 730 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.07746740453197658, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:02,690] Trial 731 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.08356827926486363, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:03,102] Trial 732 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.06578539498306639, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:03,591] Trial 733 finished with value: 0.8459506827044141 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.07426174468836716, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:04,012] Trial 734 finished with value: 0.83723505544913 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.07907549015716708, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:04,420] Trial 735 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.01916769379952884, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:04,715] Trial 736 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 97, 'max_depth': 5, 'learning_rate': 0.028148298056432344, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:05,143] Trial 737 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.021490537426861304, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:05,482] Trial 738 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.026294196040958895, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:05,852] Trial 739 finished with value: 0.83723505544913 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07157069260688603, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:06,099] Trial 740 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.08200328032936281, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:06,343] Trial 741 finished with value: 0.8339402262496793 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.07633107366342005, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:06,560] Trial 742 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.08440468659378833, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:06,877] Trial 743 finished with value: 0.8503124686024315 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.07959274632483133, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:07,185] Trial 744 finished with value: 0.8415917345645018 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.07366100542771552, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:07,483] Trial 745 finished with value: 0.83723505544913 and parameters: {'n_estimators': 97, 'max_depth': 5, 'learning_rate': 0.07891598068090325, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:07,805] Trial 746 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.07498921930083095, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:08,114] Trial 747 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.07094851841223865, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:08,417] Trial 748 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0815940153208514, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:08,730] Trial 749 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.06506387097403556, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:09,043] Trial 750 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.07824016713667267, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:09,379] Trial 751 finished with value: 0.84191359062235 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.024460900037458603, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:09,690] Trial 752 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.042687041931811984, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:10,010] Trial 753 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07538423556466042, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:10,408] Trial 754 finished with value: 0.8092644368506438 and parameters: {'n_estimators': 97, 'max_depth': 6, 'learning_rate': 0.07154562452362773, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:10,635] Trial 755 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.07971667971871692, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:10,967] Trial 756 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.02203085327618998, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:11,209] Trial 757 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.02795537274144473, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:11,517] Trial 758 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.06855401408312435, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:11,761] Trial 759 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.018077408284210332, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:12,079] Trial 760 finished with value: 0.833469421937483 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.020708109120568256, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:12,338] Trial 761 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 67, 'max_depth': 6, 'learning_rate': 0.08365317032521893, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:12,569] Trial 762 finished with value: 0.84191359062235 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.07939466416898601, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:12,835] Trial 763 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.07621952894865172, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:13,161] Trial 764 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.030420947240007736, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:13,466] Trial 765 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.045977579914722184, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:13,688] Trial 766 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.061518623853136445, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:13,920] Trial 767 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.027098813510168945, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:14,216] Trial 768 finished with value: 0.8191500616101444 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.08605134132827286, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:14,466] Trial 769 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.06884906024378777, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:14,772] Trial 770 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.0295103905475536, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:14,970] Trial 771 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.07244887656084384, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:15,307] Trial 772 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.02272386413045313, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:15,526] Trial 773 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.025541181045378163, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:15,843] Trial 774 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.07746532055294304, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:16,163] Trial 775 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.0848904175343474, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:16,483] Trial 776 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.02897784602911486, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:16,758] Trial 777 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 74, 'max_depth': 6, 'learning_rate': 0.08095078451702069, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:16,965] Trial 778 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.06582472057088191, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:17,245] Trial 779 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 94, 'max_depth': 5, 'learning_rate': 0.031166598734185542, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:17,542] Trial 780 finished with value: 0.83723505544913 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.0816333258959906, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:17,769] Trial 781 finished with value: 0.8104763854763856 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.07477963621652173, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:18,105] Trial 782 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.016008259503050862, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:18,402] Trial 783 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 64, 'max_depth': 7, 'learning_rate': 0.03187947017654665, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:18,753] Trial 784 finished with value: 0.8183470827148989 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.07074623154155946, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:18,972] Trial 785 finished with value: 0.8201060592364939 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.08665531882387859, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:19,285] Trial 786 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.029679470581504525, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:19,532] Trial 787 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.04044653664167258, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:20,247] Trial 788 finished with value: 0.8039786460839093 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.024589898240973938, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:20,478] Trial 789 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.0631869394434842, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:20,863] Trial 790 finished with value: 0.8049526106031681 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.07809633261692844, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:21,094] Trial 791 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.08748794420939954, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:21,293] Trial 792 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.026777937334876496, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:21,601] Trial 793 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.028418201169806295, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:22,059] Trial 794 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.0736773634583464, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:22,385] Trial 795 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 175, 'max_depth': 3, 'learning_rate': 0.03362039583981324, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:22,721] Trial 796 finished with value: 0.8368889581576149 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.08276694375594415, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:22,950] Trial 797 finished with value: 0.8383244459763589 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.030836260782929142, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:23,275] Trial 798 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.09324734416462664, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:23,456] Trial 799 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 53, 'max_depth': 5, 'learning_rate': 0.03270679259323529, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:23,708] Trial 800 finished with value: 0.8064644633327506 and parameters: {'n_estimators': 65, 'max_depth': 6, 'learning_rate': 0.07721414982694291, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:24,020] Trial 801 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.023570307032484743, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:24,219] Trial 802 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03502296641550275, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:24,451] Trial 803 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.07331676379652982, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:24,783] Trial 804 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.01920004756670518, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:25,031] Trial 805 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.08736194388644405, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:25,625] Trial 806 finished with value: 0.8082763742703633 and parameters: {'n_estimators': 119, 'max_depth': 8, 'learning_rate': 0.08194576467482571, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:25,979] Trial 807 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.04766753992889439, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:26,320] Trial 808 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.01252490632887038, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:26,641] Trial 809 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.029875534284627133, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:26,865] Trial 810 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.0686443511964949, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:27,081] Trial 811 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03192517520106178, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:27,288] Trial 812 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.09485945322733472, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:27,580] Trial 813 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 97, 'max_depth': 5, 'learning_rate': 0.02156286459306851, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:27,982] Trial 814 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.07836054478726007, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:28,321] Trial 815 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.08812097182117769, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:28,624] Trial 816 finished with value: 0.83723505544913 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.06587807031120768, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:28,857] Trial 817 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.033228728689931604, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:29,119] Trial 818 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.03669843083564854, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:29,453] Trial 819 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.03111501866168454, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:29,652] Trial 820 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.08305489513817248, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:29,883] Trial 821 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.028664023541976325, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:30,088] Trial 822 finished with value: 0.8291007562746693 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.09215234271286227, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:30,408] Trial 823 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.07070253422250583, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:30,626] Trial 824 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.07511527279123993, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:30,978] Trial 825 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.03250656312161338, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:31,164] Trial 826 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.0908362729958995, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:31,480] Trial 827 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.020146899915908695, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:31,637] Trial 828 finished with value: 0.8135780982868414 and parameters: {'n_estimators': 75, 'max_depth': 3, 'learning_rate': 0.034720255491804526, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:31,966] Trial 829 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.07974792656384744, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:32,209] Trial 830 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 63, 'max_depth': 6, 'learning_rate': 0.02554455577336442, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:32,561] Trial 831 finished with value: 0.8226718495899223 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.0957843694609392, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:32,774] Trial 832 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.06047187476975069, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:33,127] Trial 833 finished with value: 0.8317656008930031 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.08546751424038286, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:33,349] Trial 834 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.03930456289947728, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:33,652] Trial 835 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.033903413917622985, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:34,033] Trial 836 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.02734965804270202, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:34,271] Trial 837 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.07229978693347486, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:34,593] Trial 838 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.030955478642937018, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:34,797] Trial 839 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.07603395108413628, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:35,144] Trial 840 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.029231848331461887, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 136 with value: 0.8506436354465302.\n",
      "[I 2024-01-12 21:12:35,368] Trial 841 finished with value: 0.8512233217188787 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.09683347008099488, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:35,562] Trial 842 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.08292006638238844, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:35,773] Trial 843 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.0886450560603144, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:35,966] Trial 844 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.02283034060036809, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:36,173] Trial 845 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.08004557180081717, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:36,387] Trial 846 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.06835613588021724, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:36,606] Trial 847 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.06339321014131416, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:36,795] Trial 848 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.03574089720159869, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:37,020] Trial 849 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03262456318802532, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:37,232] Trial 850 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.030055985447689372, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:38,007] Trial 851 finished with value: 0.7862968443775985 and parameters: {'n_estimators': 186, 'max_depth': 7, 'learning_rate': 0.08541947588751223, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:38,227] Trial 852 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.08999033421070673, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:38,460] Trial 853 finished with value: 0.833469421937483 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.031615905621567165, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:38,668] Trial 854 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.0768405095909312, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:38,883] Trial 855 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.07203603060618978, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:39,117] Trial 856 finished with value: 0.8053841310363877 and parameters: {'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.02651462619361794, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:39,334] Trial 857 finished with value: 0.8509470997296442 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.09592592732307668, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:39,578] Trial 858 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.09611750622146703, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:39,810] Trial 859 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.09544373599913596, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:40,054] Trial 860 finished with value: 0.8278272336108157 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.09991571443149572, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:40,282] Trial 861 finished with value: 0.8230965538028735 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.09132341647193025, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:40,540] Trial 862 finished with value: 0.8201060592364939 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.09624379877278254, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:40,821] Trial 863 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.09350941219023245, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:41,035] Trial 864 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.0910127581584899, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:41,242] Trial 865 finished with value: 0.8151562481961826 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.08649734402704468, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:41,555] Trial 866 finished with value: 0.8187655090640165 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.09989330066583564, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:41,841] Trial 867 finished with value: 0.8101075646906518 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.016935789512604157, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:42,067] Trial 868 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.09341952487539965, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:42,285] Trial 869 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.0875583278071991, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:42,543] Trial 870 finished with value: 0.8244677690692389 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.09602674707769927, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:42,778] Trial 871 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.0868751411513332, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:42,991] Trial 872 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.08229277628429499, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:43,216] Trial 873 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.09223675384448575, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:43,423] Trial 874 finished with value: 0.8234879328004447 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.09188775218857914, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:43,644] Trial 875 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.011263910255983754, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:43,890] Trial 876 finished with value: 0.8281925585296372 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.0883051708728569, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:44,301] Trial 877 finished with value: 0.8125773325773327 and parameters: {'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.08236613857006744, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:44,522] Trial 878 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.03450020766368662, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:44,746] Trial 879 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.014057306500712066, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:45,031] Trial 880 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.020882342718308227, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:45,308] Trial 881 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.024144363321157766, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:45,647] Trial 882 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 86, 'max_depth': 5, 'learning_rate': 0.09540816559576978, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:45,948] Trial 883 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.09981719354974705, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:46,181] Trial 884 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.028536717844117054, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:46,398] Trial 885 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.030531375526264788, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:46,648] Trial 886 finished with value: 0.8465761215761216 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03285932360685815, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:46,929] Trial 887 finished with value: 0.8144360319184163 and parameters: {'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.03293732971356722, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:47,142] Trial 888 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.036202935447693416, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:47,332] Trial 889 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.03374912710902754, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:47,589] Trial 890 finished with value: 0.8097037845172175 and parameters: {'n_estimators': 62, 'max_depth': 6, 'learning_rate': 0.03244333583433395, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:47,810] Trial 891 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.037289249216347894, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:48,046] Trial 892 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.03157988964159545, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:48,268] Trial 893 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.034806603505790616, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:48,479] Trial 894 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.02977125094947098, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:48,894] Trial 895 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 145, 'max_depth': 5, 'learning_rate': 0.03343316646448709, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:49,132] Trial 896 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03486098837612805, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:49,331] Trial 897 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.03189515897949835, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 841 with value: 0.8512233217188787.\n",
      "[I 2024-01-12 21:12:49,570] Trial 898 finished with value: 0.8514727276739713 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.03097843797890941, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:49,821] Trial 899 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.031010745562319197, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:50,072] Trial 900 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.027813146550284714, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:50,328] Trial 901 finished with value: 0.84191359062235 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.02991183394081844, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:50,571] Trial 902 finished with value: 0.8512233217188787 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.03085093418320966, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:50,814] Trial 903 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.031229160074099076, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:51,060] Trial 904 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.03290057756188267, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:51,299] Trial 905 finished with value: 0.83723505544913 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.030830119946792876, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:51,538] Trial 906 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.018280959472420425, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:51,786] Trial 907 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.030619793940226455, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:52,026] Trial 908 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.032362284168872366, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:52,293] Trial 909 finished with value: 0.8154661162009946 and parameters: {'n_estimators': 86, 'max_depth': 5, 'learning_rate': 0.03383714359723184, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:52,734] Trial 910 finished with value: 0.8195013195013195 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.029533072277043947, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:52,993] Trial 911 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.032217696687407274, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:53,235] Trial 912 finished with value: 0.84191359062235 and parameters: {'n_estimators': 77, 'max_depth': 5, 'learning_rate': 0.03365029298042896, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:53,480] Trial 913 finished with value: 0.8241730165768567 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.03824147129475014, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:53,708] Trial 914 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.035542497229418143, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:53,942] Trial 915 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.03180104450729078, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:54,203] Trial 916 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 84, 'max_depth': 5, 'learning_rate': 0.028689813364077662, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:54,433] Trial 917 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.03068274447963142, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:54,677] Trial 918 finished with value: 0.8247312950015653 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.033239803741093206, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:54,906] Trial 919 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 75, 'max_depth': 5, 'learning_rate': 0.03693070698087566, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:55,165] Trial 920 finished with value: 0.8325398336824732 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.02989535984754091, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:55,392] Trial 921 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.031896156838555734, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:55,631] Trial 922 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.03546642290776051, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:55,864] Trial 923 finished with value: 0.83723505544913 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.03370144318161316, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:56,089] Trial 924 finished with value: 0.84709015035102 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03107473268515434, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:56,339] Trial 925 finished with value: 0.84191359062235 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.028993712776238807, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:56,569] Trial 926 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.030665411293778227, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:56,799] Trial 927 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.017552806045215284, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:57,024] Trial 928 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.02958530814208165, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:57,241] Trial 929 finished with value: 0.8238465724077614 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.04207490265114568, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:57,475] Trial 930 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.028337127029504135, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:57,725] Trial 931 finished with value: 0.8375511875511874 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.03058312183896147, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:57,945] Trial 932 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.019540849066387558, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:58,177] Trial 933 finished with value: 0.8057795541931729 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.01640503289756845, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:58,427] Trial 934 finished with value: 0.83723505544913 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.029789320688907592, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:58,655] Trial 935 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03141130356408144, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:58,874] Trial 936 finished with value: 0.8057795541931729 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.01534221676652164, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:59,095] Trial 937 finished with value: 0.84709015035102 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.031131896157204016, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:59,330] Trial 938 finished with value: 0.84709015035102 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.03152052875845262, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:59,563] Trial 939 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.03131720053893756, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:12:59,791] Trial 940 finished with value: 0.833469421937483 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.030828929118504673, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:00,007] Trial 941 finished with value: 0.8427075724373022 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.029345745151454123, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:00,242] Trial 942 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.03148354780578412, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:00,465] Trial 943 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.03188030870218587, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:00,703] Trial 944 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.02960055526538985, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:00,944] Trial 945 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.028653484045065798, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:01,172] Trial 946 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.031287228120363865, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:01,391] Trial 947 finished with value: 0.7887697006185347 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.01361632902692915, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:01,652] Trial 948 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.03175454843245471, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:01,870] Trial 949 finished with value: 0.84709015035102 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.030183544551318612, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:02,087] Trial 950 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.028036319396734517, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:02,298] Trial 951 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.02985032658489863, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:02,511] Trial 952 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.030536141167284668, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:02,726] Trial 953 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03188426952230218, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:02,953] Trial 954 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.02904615599772335, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:03,171] Trial 955 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.030761916945697243, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:03,389] Trial 956 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.028134804050554088, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:03,595] Trial 957 finished with value: 0.84709015035102 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.03214998226334343, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:03,802] Trial 958 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03215992357488555, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:04,015] Trial 959 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.03201483350011049, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:04,211] Trial 960 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.030890290346990142, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:04,419] Trial 961 finished with value: 0.8380954533128446 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.0335370592626295, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:04,782] Trial 962 finished with value: 0.791580335423619 and parameters: {'n_estimators': 61, 'max_depth': 9, 'learning_rate': 0.029715922989204138, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:04,990] Trial 963 finished with value: 0.8514727276739713 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03241403829469689, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:05,187] Trial 964 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.03439034804329045, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:05,396] Trial 965 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.03305057166367765, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:05,822] Trial 966 finished with value: 0.792022570851666 and parameters: {'n_estimators': 63, 'max_depth': 10, 'learning_rate': 0.030499023320822532, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:06,008] Trial 967 finished with value: 0.8328800815150558 and parameters: {'n_estimators': 57, 'max_depth': 5, 'learning_rate': 0.028991115763197055, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:06,188] Trial 968 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 53, 'max_depth': 5, 'learning_rate': 0.03230608815312897, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:06,411] Trial 969 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03407335528045788, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:06,616] Trial 970 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.027501130948871844, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:06,830] Trial 971 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.0300450701432077, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:07,044] Trial 972 finished with value: 0.84709015035102 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03130581551075346, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:07,248] Trial 973 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.033016751392385246, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:07,463] Trial 974 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.030351223852695272, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:07,671] Trial 975 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.02868759393773909, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:07,886] Trial 976 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03456519246773981, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:08,084] Trial 977 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03201873758851945, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:08,297] Trial 978 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03079135971836206, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:08,491] Trial 979 finished with value: 0.833469421937483 and parameters: {'n_estimators': 58, 'max_depth': 5, 'learning_rate': 0.0327805587244179, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:08,704] Trial 980 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.029194516484503955, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:08,930] Trial 981 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.031305119223797015, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:09,137] Trial 982 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.0336137740636475, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:09,334] Trial 983 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 60, 'max_depth': 5, 'learning_rate': 0.02745071128376458, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:09,546] Trial 984 finished with value: 0.8148130633004671 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.0354255869139177, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:09,731] Trial 985 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 54, 'max_depth': 5, 'learning_rate': 0.030696427593264006, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:09,947] Trial 986 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.029563699506525192, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:10,168] Trial 987 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.032788439376786035, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:10,382] Trial 988 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03180098325640833, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:10,591] Trial 989 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.028312837919800465, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:10,805] Trial 990 finished with value: 0.8422065533382046 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.03433881801493163, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:11,009] Trial 991 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 59, 'max_depth': 5, 'learning_rate': 0.0307054120943527, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:11,234] Trial 992 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.032112116291608185, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:11,445] Trial 993 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.02975062948729431, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:11,668] Trial 994 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.03382670902331086, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:11,879] Trial 995 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.03134787013066786, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:12,111] Trial 996 finished with value: 0.8331897849575306 and parameters: {'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.032764582136296856, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:12,315] Trial 997 finished with value: 0.833469421937483 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.03543679435423598, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:12,526] Trial 998 finished with value: 0.8285262535262534 and parameters: {'n_estimators': 68, 'max_depth': 5, 'learning_rate': 0.028944507697813256, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n",
      "[I 2024-01-12 21:13:12,748] Trial 999 finished with value: 0.8424710748057271 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.030206533450992546, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 898 with value: 0.8514727276739713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.851351\n",
      "Model F1 Score: 0.851473\n",
      "Validation Accuracy: 0.815315\n",
      "Validation F1 Score: 0.815695\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1,log=True),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "    }\n",
    "    model = GradientBoostingClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = f1_score(y_test, preds,average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = GradientBoostingClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n",
    "\n",
    "# Now let's use the model with the best parameters on the validation set\n",
    "val_preds = best_model.predict(X_val)\n",
    "\n",
    "# Check the accuracy and F1 score of the best model on the validation set\n",
    "print(\"Validation Accuracy: %f\" % accuracy_score(y_val, val_preds))\n",
    "print(\"Validation F1 Score: %f\" % f1_score(y_val, val_preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"GB\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 21:56:45,523] A new study created in memory with name: no-name-9f92c10e-329d-434c-8717-d6585cd62fc2\n",
      "[I 2024-01-12 21:56:48,273] Trial 0 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 767, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 38, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:56:53,488] Trial 1 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 1312, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 1355, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:56:55,172] Trial 2 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 488, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 981, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:56:59,033] Trial 3 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 1053, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1052, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:02,127] Trial 4 finished with value: 0.7891754645052336 and parameters: {'n_estimators': 1173, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 420, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:04,185] Trial 5 finished with value: 0.7971407701137431 and parameters: {'n_estimators': 559, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 1127, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:09,294] Trial 6 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 1021, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 821, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:12,263] Trial 7 finished with value: 0.7578801894678183 and parameters: {'n_estimators': 634, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1424, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:14,952] Trial 8 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 802, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 517, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:15,886] Trial 9 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 219, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 659, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:17,813] Trial 10 finished with value: 0.7421375327809796 and parameters: {'n_estimators': 1462, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 8, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:20,767] Trial 11 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 917, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 27, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:24,524] Trial 12 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 1089, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 350, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:27,037] Trial 13 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 741, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 1132, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:28,587] Trial 14 finished with value: 0.7490970232905718 and parameters: {'n_estimators': 284, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 239, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8108108108108109.\n",
      "[I 2024-01-12 21:57:31,434] Trial 15 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 888, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 819, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:32,696] Trial 16 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 394, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 710, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:35,218] Trial 17 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 787, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 889, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:39,508] Trial 18 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 887, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 889, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:43,846] Trial 19 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 1266, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1268, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:45,951] Trial 20 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 657, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 582, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:48,103] Trial 21 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 662, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 602, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:49,780] Trial 22 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 491, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 823, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:52,878] Trial 23 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 915, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 522, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:56,128] Trial 24 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 951, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 485, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:56,516] Trial 25 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 116, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 296, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:57:59,835] Trial 26 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 663, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 586, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:02,637] Trial 27 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 872, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 151, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:06,753] Trial 28 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 1175, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 728, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:09,207] Trial 29 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 736, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 179, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:11,076] Trial 30 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 583, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 405, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:13,716] Trial 31 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 820, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 886, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:16,837] Trial 32 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 974, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 541, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:19,280] Trial 33 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 751, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 976, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:23,593] Trial 34 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 1124, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 646, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:25,089] Trial 35 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 438, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 815, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:28,206] Trial 36 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 859, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 990, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:31,620] Trial 37 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 1025, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 446, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:33,572] Trial 38 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 572, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 1081, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:37,167] Trial 39 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 719, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1207, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:41,293] Trial 40 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 1226, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 767, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:45,698] Trial 41 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 1258, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1297, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:50,630] Trial 42 finished with value: 0.7971407701137431 and parameters: {'n_estimators': 1373, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 1473, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:55,169] Trial 43 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 1365, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1302, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:58:58,276] Trial 44 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 972, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 897, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:03,062] Trial 45 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 1484, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 663, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:05,950] Trial 46 finished with value: 0.7924636174636174 and parameters: {'n_estimators': 834, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1213, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:11,254] Trial 47 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 1069, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 544, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:13,425] Trial 48 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 678, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 962, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:15,154] Trial 49 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 521, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 363, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:17,767] Trial 50 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 802, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 751, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:20,332] Trial 51 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 805, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 798, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:23,265] Trial 52 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 903, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 921, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:25,227] Trial 53 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 615, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1031, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:27,190] Trial 54 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 701, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1142, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:31,794] Trial 55 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 946, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 863, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:35,414] Trial 56 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 1135, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 673, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:37,879] Trial 57 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 771, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 615, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:41,220] Trial 58 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 1016, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1382, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:43,248] Trial 59 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 625, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 849, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:45,138] Trial 60 finished with value: 0.7622616940165399 and parameters: {'n_estimators': 378, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 446, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:45,849] Trial 61 finished with value: 0.6733421686920041 and parameters: {'n_estimators': 588, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1035, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:47,849] Trial 62 finished with value: 0.8011367629688241 and parameters: {'n_estimators': 630, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1040, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:50,512] Trial 63 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 841, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 931, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:52,227] Trial 64 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 523, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 722, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:54,684] Trial 65 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 774, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 506, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 21:59:57,297] Trial 66 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 772, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 505, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:00,209] Trial 67 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 910, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 590, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:02,448] Trial 68 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 692, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 316, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:05,206] Trial 69 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 826, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 553, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:08,376] Trial 70 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 999, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 400, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:10,781] Trial 71 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 752, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1098, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:12,897] Trial 72 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 649, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 995, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:15,697] Trial 73 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 873, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 683, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:17,158] Trial 74 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 456, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 776, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:19,112] Trial 75 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 610, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 468, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:21,614] Trial 76 finished with value: 0.7968007577956703 and parameters: {'n_estimators': 723, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 856, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:28,588] Trial 77 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 1422, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1256, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:32,793] Trial 78 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 1300, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 938, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:34,583] Trial 79 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 547, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 1148, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:37,064] Trial 80 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 779, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 627, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:38,424] Trial 81 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 421, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 794, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:39,486] Trial 82 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 330, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 784, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:41,053] Trial 83 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 478, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 751, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:43,200] Trial 84 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 670, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 889, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:43,938] Trial 85 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 215, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 999, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:46,750] Trial 86 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 878, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 718, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:49,356] Trial 87 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 807, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 841, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:52,363] Trial 88 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 945, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 582, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:54,536] Trial 89 finished with value: 0.7668475898578992 and parameters: {'n_estimators': 458, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1486, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:00:56,960] Trial 90 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 710, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 516, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:01,043] Trial 91 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 1283, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 935, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:05,333] Trial 92 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 1346, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 902, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:09,310] Trial 93 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 1243, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 946, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:13,400] Trial 94 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 1292, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 818, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:17,219] Trial 95 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 1200, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 875, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:21,412] Trial 96 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 1328, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 1067, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:24,107] Trial 97 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 850, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 696, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:28,640] Trial 98 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 1426, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 1425, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n",
      "[I 2024-01-12 22:01:32,181] Trial 99 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 1118, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 763, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 15 with value: 0.8198198198198198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.801802\n",
      "Model F1 Score: 0.800642\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "        'max_features': trial.suggest_int('max_features', 1,1500),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    }\n",
    "    model = RandomForestClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = f1_score(y_val, preds,average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"RF\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 22:12:58,203] A new study created in memory with name: no-name-e30f7a7a-107f-4c73-a346-5c61c1974de0\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:58,288] Trial 0 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 312, 'max_depth': 4, 'learning_rate': 1.0094965210249998e-05, 'n_estimators': 407, 'min_child_samples': 97, 'min_child_weight': 0.00036242937197519717, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.12754193825382878, 'reg_lambda': 5.9855642696916e-05}. Best is trial 0 with value: 0.42711942711942713.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:58,306] Trial 1 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 135, 'max_depth': 114, 'learning_rate': 0.0007096805690272914, 'n_estimators': 29, 'min_child_samples': 52, 'min_child_weight': 0.00037800034695658686, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1.796123976058097e-05, 'reg_lambda': 5.062542923689284}. Best is trial 0 with value: 0.42711942711942713.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:58,347] Trial 2 finished with value: 0.7794400238895547 and parameters: {'num_leaves': 159, 'max_depth': 122, 'learning_rate': 0.2623071512684629, 'n_estimators': 181, 'min_child_samples': 60, 'min_child_weight': 0.00014584402463295958, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 2.8214294366787507, 'reg_lambda': 3.476661955162125}. Best is trial 2 with value: 0.7794400238895547.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:58,412] Trial 3 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 443, 'max_depth': 66, 'learning_rate': 0.025576763191988244, 'n_estimators': 151, 'min_child_samples': 78, 'min_child_weight': 0.024813513142541647, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.00011376721923183853, 'reg_lambda': 0.014210183320091215}. Best is trial 3 with value: 0.8110781160149511.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:58,733] Trial 4 finished with value: 0.8134278644842026 and parameters: {'num_leaves': 318, 'max_depth': 78, 'learning_rate': 0.0007763502366055425, 'n_estimators': 495, 'min_child_samples': 23, 'min_child_weight': 0.030786683951611653, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 6.070870296707211e-05, 'reg_lambda': 0.03008604327185637}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:59,267] Trial 5 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 333, 'max_depth': 22, 'learning_rate': 2.7231665872942695e-06, 'n_estimators': 932, 'min_child_samples': 16, 'min_child_weight': 0.005526410202902829, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.46150720137504275, 'reg_lambda': 1.0374556717119134}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:59,478] Trial 6 finished with value: 0.7707421707421708 and parameters: {'num_leaves': 189, 'max_depth': 10, 'learning_rate': 0.0745163556881353, 'n_estimators': 806, 'min_child_samples': 90, 'min_child_weight': 0.029738552903686277, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 6.147282450393135e-05, 'reg_lambda': 0.002530484680811853}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:59,651] Trial 7 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 347, 'max_depth': 88, 'learning_rate': 3.1767042566857225e-06, 'n_estimators': 779, 'min_child_samples': 53, 'min_child_weight': 0.008885417769940758, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.421754093650087, 'reg_lambda': 0.01714118788480672}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:59,825] Trial 8 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 215, 'max_depth': 69, 'learning_rate': 2.0971090487905115e-07, 'n_estimators': 640, 'min_child_samples': 78, 'min_child_weight': 0.03447798265375081, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1.3121003580756026e-05, 'reg_lambda': 0.18279969332262552}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:12:59,866] Trial 9 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 20, 'max_depth': 32, 'learning_rate': 0.04018923078366772, 'n_estimators': 143, 'min_child_samples': 97, 'min_child_weight': 0.007793327489923202, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.37460862882426704, 'reg_lambda': 5.913553958728863}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:00,473] Trial 10 finished with value: 0.6869701117695355 and parameters: {'num_leaves': 498, 'max_depth': 41, 'learning_rate': 0.0004050942209781843, 'n_estimators': 445, 'min_child_samples': 9, 'min_child_weight': 0.9961997846421528, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 0.002534327932104223, 'reg_lambda': 0.0001842588654413977}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:00,639] Trial 11 finished with value: 0.8050772180423282 and parameters: {'num_leaves': 469, 'max_depth': 70, 'learning_rate': 0.002588834643806093, 'n_estimators': 296, 'min_child_samples': 35, 'min_child_weight': 0.28735738806734573, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.0005301283868153656, 'reg_lambda': 0.01499294442272153}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:00,994] Trial 12 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 411, 'max_depth': 95, 'learning_rate': 0.009038484312500981, 'n_estimators': 601, 'min_child_samples': 29, 'min_child_weight': 1.616904741920487e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00023940270052352186, 'reg_lambda': 0.0009570522933194825}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,096] Trial 13 finished with value: 0.7391078744968372 and parameters: {'num_leaves': 431, 'max_depth': 59, 'learning_rate': 0.9954323282181613, 'n_estimators': 271, 'min_child_samples': 73, 'min_child_weight': 0.09542537256533683, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 0.004076593260010142, 'reg_lambda': 0.07207790758029058}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,139] Trial 14 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 274, 'max_depth': 48, 'learning_rate': 7.280390491091458e-05, 'n_estimators': 15, 'min_child_samples': 36, 'min_child_weight': 0.10479525886436794, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.00036449854613157794, 'reg_lambda': 0.15495416256802858}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,327] Trial 15 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 409, 'max_depth': 90, 'learning_rate': 0.01307338879290546, 'n_estimators': 582, 'min_child_samples': 79, 'min_child_weight': 0.0013865861149709514, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0.012634616329107458, 'reg_lambda': 0.00243816509892654}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,461] Trial 16 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 380, 'max_depth': 75, 'learning_rate': 6.240013758757634e-05, 'n_estimators': 357, 'min_child_samples': 65, 'min_child_weight': 0.0013269544465430501, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 9.967226413588034e-05, 'reg_lambda': 0.04281326599881935}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,748] Trial 17 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 266, 'max_depth': 106, 'learning_rate': 1.5621296328980688e-08, 'n_estimators': 507, 'min_child_samples': 23, 'min_child_weight': 0.03340545701012393, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014497129430647052, 'reg_lambda': 0.7552892444197961}. Best is trial 4 with value: 0.8134278644842026.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:01,854] Trial 18 finished with value: 0.8177299444429534 and parameters: {'num_leaves': 84, 'max_depth': 54, 'learning_rate': 0.001528543529082631, 'n_estimators': 185, 'min_child_samples': 41, 'min_child_weight': 0.9593476252767232, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.02436651626654378, 'reg_lambda': 1.2377736795036073e-05}. Best is trial 18 with value: 0.8177299444429534.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,154] Trial 19 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 72, 'max_depth': 50, 'learning_rate': 0.0008426119358727817, 'n_estimators': 702, 'min_child_samples': 42, 'min_child_weight': 0.8617704049242148, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 0.02017543116985828, 'reg_lambda': 1.3659003272312786e-05}. Best is trial 18 with value: 0.8177299444429534.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,343] Trial 20 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 16, 'max_depth': 80, 'learning_rate': 2.1639124869250625e-05, 'n_estimators': 486, 'min_child_samples': 7, 'min_child_weight': 0.1908750216498314, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.04775528666118922, 'reg_lambda': 0.0002713852247319504}. Best is trial 18 with value: 0.8177299444429534.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,458] Trial 21 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 100, 'max_depth': 56, 'learning_rate': 0.005420315450192469, 'n_estimators': 175, 'min_child_samples': 47, 'min_child_weight': 0.019453663445722497, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 8.28067106993072e-05, 'reg_lambda': 0.0038738619619509314}. Best is trial 18 with value: 0.8177299444429534.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,593] Trial 22 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 116, 'max_depth': 57, 'learning_rate': 0.0032698141978786586, 'n_estimators': 260, 'min_child_samples': 47, 'min_child_weight': 0.40888711278235196, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008619268298272094, 'reg_lambda': 2.1720990526958048e-05}. Best is trial 22 with value: 0.8192152390625673.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,743] Trial 23 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 89, 'max_depth': 52, 'learning_rate': 0.0054213144336764585, 'n_estimators': 256, 'min_child_samples': 46, 'min_child_weight': 0.4243941177726434, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008760594204416054, 'reg_lambda': 1.4519426649959456e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:02,928] Trial 24 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 93, 'max_depth': 35, 'learning_rate': 0.0002473555480321135, 'n_estimators': 271, 'min_child_samples': 40, 'min_child_weight': 0.39329962143611114, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0012617806868220158, 'reg_lambda': 1.1284632745549812e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,128] Trial 25 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 54, 'max_depth': 21, 'learning_rate': 0.004181513684808879, 'n_estimators': 321, 'min_child_samples': 60, 'min_child_weight': 0.42704535873622473, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00547094540210013, 'reg_lambda': 4.183281118392105e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,387] Trial 26 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 47, 'max_depth': 25, 'learning_rate': 0.07255073825805673, 'n_estimators': 345, 'min_child_samples': 62, 'min_child_weight': 0.07250108619236746, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0045617119781832, 'reg_lambda': 4.7849205374364496e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,514] Trial 27 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 132, 'max_depth': 17, 'learning_rate': 0.24893553237338684, 'n_estimators': 94, 'min_child_samples': 56, 'min_child_weight': 0.3481846363223263, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.007040903813606584, 'reg_lambda': 7.126359611572509e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,650] Trial 28 finished with value: 0.8171238954412691 and parameters: {'num_leaves': 220, 'max_depth': 37, 'learning_rate': 0.003048447169205687, 'n_estimators': 223, 'min_child_samples': 69, 'min_child_weight': 0.1332596142539124, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0009493097648283723, 'reg_lambda': 0.00029730414004396235}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,770] Trial 29 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 39, 'max_depth': 3, 'learning_rate': 0.00023178216126531573, 'n_estimators': 347, 'min_child_samples': 47, 'min_child_weight': 0.4073511134062032, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 0.07636137443955877, 'reg_lambda': 4.492677023205818e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:03,988] Trial 30 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 123, 'max_depth': 45, 'learning_rate': 0.008941791823193252, 'n_estimators': 396, 'min_child_samples': 47, 'min_child_weight': 1.5268624695418184e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005640973776896447, 'reg_lambda': 9.592403818534119e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,075] Trial 31 finished with value: 0.7408927781794855 and parameters: {'num_leaves': 51, 'max_depth': 56, 'learning_rate': 0.0021768450689082022, 'n_estimators': 83, 'min_child_samples': 32, 'min_child_weight': 0.5710815348923021, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.029639860106944763, 'reg_lambda': 2.0705661137976992e-05}. Best is trial 23 with value: 0.8195335804031456.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,210] Trial 32 finished with value: 0.8197564133048003 and parameters: {'num_leaves': 163, 'max_depth': 29, 'learning_rate': 0.0017395872623808737, 'n_estimators': 247, 'min_child_samples': 42, 'min_child_weight': 0.20391666242081743, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.011611041949956692, 'reg_lambda': 2.4734861814517906e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,332] Trial 33 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 160, 'max_depth': 29, 'learning_rate': 0.020212509772106268, 'n_estimators': 249, 'min_child_samples': 56, 'min_child_weight': 0.2323566643363235, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.15867717443562843, 'reg_lambda': 2.939871528831076e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,496] Trial 34 finished with value: 0.7530469235454438 and parameters: {'num_leaves': 163, 'max_depth': 16, 'learning_rate': 0.1795594580867704, 'n_estimators': 313, 'min_child_samples': 50, 'min_child_weight': 0.0638179400292832, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.002427016742588917, 'reg_lambda': 0.0007819754766143136}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,676] Trial 35 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 114, 'max_depth': 11, 'learning_rate': 0.0001393362174203108, 'n_estimators': 419, 'min_child_samples': 59, 'min_child_weight': 0.14896472415223463, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 0.011249594672247587, 'reg_lambda': 0.00012948977866162714}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,723] Trial 36 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 3, 'max_depth': 62, 'learning_rate': 0.0008116181693302161, 'n_estimators': 106, 'min_child_samples': 66, 'min_child_weight': 0.000104232021344314, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00020428454647204738, 'reg_lambda': 2.6319202852010386e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:04,912] Trial 37 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 190, 'max_depth': 42, 'learning_rate': 0.004814891679187672, 'n_estimators': 232, 'min_child_samples': 27, 'min_child_weight': 0.051835860854475294, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 2.750269588734635e-05, 'reg_lambda': 0.0005443693530421825}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,279] Trial 38 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 65, 'max_depth': 27, 'learning_rate': 1.5994390450454442e-05, 'n_estimators': 991, 'min_child_samples': 52, 'min_child_weight': 0.014707780352597748, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0062390806789243605, 'reg_lambda': 5.406448192556241e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,406] Trial 39 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 149, 'max_depth': 20, 'learning_rate': 0.020447293172591252, 'n_estimators': 221, 'min_child_samples': 44, 'min_child_weight': 0.6089089261130118, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.002675994228954442, 'reg_lambda': 1.0171721176039864e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,611] Trial 40 finished with value: 0.7578801894678183 and parameters: {'num_leaves': 188, 'max_depth': 10, 'learning_rate': 0.07601290991009899, 'n_estimators': 385, 'min_child_samples': 37, 'min_child_weight': 0.2558891872730398, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.0007390890385667073, 'reg_lambda': 2.81924181954814e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,771] Trial 41 finished with value: 0.7777756850927582 and parameters: {'num_leaves': 88, 'max_depth': 53, 'learning_rate': 0.0016256616976524814, 'n_estimators': 174, 'min_child_samples': 44, 'min_child_weight': 0.6477224785884704, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 0.02679700060010939, 'reg_lambda': 2.0048163697660233e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,872] Trial 42 finished with value: 0.6728532329798153 and parameters: {'num_leaves': 69, 'max_depth': 64, 'learning_rate': 0.0012430355276261077, 'n_estimators': 131, 'min_child_samples': 40, 'min_child_weight': 0.9603781787907355, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.12763795767960062, 'reg_lambda': 9.379114397550807e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:05,927] Trial 43 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 115, 'max_depth': 128, 'learning_rate': 0.00036815512040071376, 'n_estimators': 49, 'min_child_samples': 56, 'min_child_weight': 0.4437852802905288, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.088769934916264, 'reg_lambda': 3.533930190121394e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,052] Trial 44 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 30, 'max_depth': 38, 'learning_rate': 0.04281244863136827, 'n_estimators': 199, 'min_child_samples': 21, 'min_child_weight': 0.17343046602827372, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.01750843461723514, 'reg_lambda': 0.00016103413240549017}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,258] Trial 45 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 84, 'max_depth': 72, 'learning_rate': 0.004898534581668802, 'n_estimators': 307, 'min_child_samples': 31, 'min_child_weight': 0.26309161245699736, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.05366379720182648, 'reg_lambda': 1.2738171250338699e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,349] Trial 46 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 232, 'max_depth': 32, 'learning_rate': 0.0006732627009201359, 'n_estimators': 136, 'min_child_samples': 50, 'min_child_weight': 0.003505293697093191, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.0015264798722730165, 'reg_lambda': 0.00034855321463317645}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,570] Trial 47 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 177, 'max_depth': 83, 'learning_rate': 3.493107902832741e-05, 'n_estimators': 446, 'min_child_samples': 35, 'min_child_weight': 0.04808383853862782, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.29424150615937167, 'reg_lambda': 6.705568267401694e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,880] Trial 48 finished with value: 0.7927927927927928 and parameters: {'num_leaves': 145, 'max_depth': 45, 'learning_rate': 0.010433756179793656, 'n_estimators': 285, 'min_child_samples': 14, 'min_child_weight': 0.09011175240489186, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.007223107268342816, 'reg_lambda': 1.862939781615565e-05}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:06,975] Trial 49 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 107, 'max_depth': 51, 'learning_rate': 1.6602250257407301e-06, 'n_estimators': 193, 'min_child_samples': 73, 'min_child_weight': 0.5786792744296656, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.00027380226778668976, 'reg_lambda': 0.00016408097476371773}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,131] Trial 50 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 298, 'max_depth': 58, 'learning_rate': 0.0001293921968607179, 'n_estimators': 352, 'min_child_samples': 60, 'min_child_weight': 0.0003313931719795693, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0030208415358123535, 'reg_lambda': 0.006307482710104223}. Best is trial 32 with value: 0.8197564133048003.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,235] Trial 51 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 223, 'max_depth': 36, 'learning_rate': 0.0028803917401127484, 'n_estimators': 232, 'min_child_samples': 71, 'min_child_weight': 0.11054210052171809, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008484676267259811, 'reg_lambda': 4.6165401694662365e-05}. Best is trial 51 with value: 0.8219374163746324.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,324] Trial 52 finished with value: 0.8089657669881551 and parameters: {'num_leaves': 206, 'max_depth': 66, 'learning_rate': 0.0038552005489038772, 'n_estimators': 255, 'min_child_samples': 82, 'min_child_weight': 0.9777758095738447, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0003913708267519255, 'reg_lambda': 3.93672936209034e-05}. Best is trial 51 with value: 0.8219374163746324.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,382] Trial 53 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 247, 'max_depth': 23, 'learning_rate': 0.0018399232593972953, 'n_estimators': 54, 'min_child_samples': 73, 'min_child_weight': 0.1588153851971944, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.0018055850746577797, 'reg_lambda': 1.043754734196509e-05}. Best is trial 51 with value: 0.8219374163746324.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,509] Trial 54 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 135, 'max_depth': 42, 'learning_rate': 0.03597606965760729, 'n_estimators': 310, 'min_child_samples': 64, 'min_child_weight': 0.30831882004958927, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 3.838860914012052e-05, 'reg_lambda': 1.9229414698102245e-05}. Best is trial 51 with value: 0.8219374163746324.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,583] Trial 55 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 55, 'max_depth': 30, 'learning_rate': 0.009823565448055542, 'n_estimators': 154, 'min_child_samples': 86, 'min_child_weight': 0.11926816852181857, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00016200993961183792, 'reg_lambda': 7.972114528456432e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,653] Trial 56 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 56, 'max_depth': 34, 'learning_rate': 0.01063095036983445, 'n_estimators': 150, 'min_child_samples': 94, 'min_child_weight': 0.1107041344310679, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.00017691246562711287, 'reg_lambda': 9.820622475717084e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,840] Trial 57 finished with value: 0.7585214080059439 and parameters: {'num_leaves': 26, 'max_depth': 29, 'learning_rate': 0.0004855922679685157, 'n_estimators': 856, 'min_child_samples': 99, 'min_child_weight': 0.01676892930446747, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011948747346991661, 'reg_lambda': 3.3214469113646707}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:07,946] Trial 58 finished with value: 0.7574019108208914 and parameters: {'num_leaves': 176, 'max_depth': 10, 'learning_rate': 0.15589274928616076, 'n_estimators': 267, 'min_child_samples': 85, 'min_child_weight': 0.08453467864487821, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 0.0008249097493717334, 'reg_lambda': 0.00023754002471067316}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,052] Trial 59 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 7, 'max_depth': 47, 'learning_rate': 0.006509049586699019, 'n_estimators': 556, 'min_child_samples': 69, 'min_child_weight': 0.028074052238623966, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0038718094446287413, 'reg_lambda': 0.0021409696921766462}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,173] Trial 60 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 290, 'max_depth': 18, 'learning_rate': 0.021966657356898373, 'n_estimators': 325, 'min_child_samples': 91, 'min_child_weight': 0.010489135443063949, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.0561133706365755e-05, 'reg_lambda': 5.263968250530832e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,267] Trial 61 finished with value: 0.7119190428013957 and parameters: {'num_leaves': 76, 'max_depth': 39, 'learning_rate': 0.0011200392290509492, 'n_estimators': 199, 'min_child_samples': 87, 'min_child_weight': 0.49888205485336407, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0004026455407945951, 'reg_lambda': 1.713570579314129e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,339] Trial 62 finished with value: 0.7219685902118335 and parameters: {'num_leaves': 99, 'max_depth': 33, 'learning_rate': 0.0027437333218396473, 'n_estimators': 107, 'min_child_samples': 39, 'min_child_weight': 0.22526065246279525, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 9.495435685259181, 'reg_lambda': 3.124489344237343e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,429] Trial 63 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 39, 'max_depth': 54, 'learning_rate': 0.012924801279306576, 'n_estimators': 160, 'min_child_samples': 77, 'min_child_weight': 0.7387812620066673, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.012801132088396481, 'reg_lambda': 6.694681462897322e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,542] Trial 64 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 42, 'max_depth': 24, 'learning_rate': 0.017514343606584947, 'n_estimators': 227, 'min_child_samples': 77, 'min_child_weight': 0.39505150754462004, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.010442614401552992, 'reg_lambda': 8.997253315766493e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,635] Trial 65 finished with value: 0.7121190339275445 and parameters: {'num_leaves': 63, 'max_depth': 61, 'learning_rate': 0.9198694976369342, 'n_estimators': 167, 'min_child_samples': 81, 'min_child_weight': 0.12875847727900427, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.67334343225731e-05, 'reg_lambda': 0.0004893181250569701}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,775] Trial 66 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 126, 'max_depth': 50, 'learning_rate': 0.06884168208058632, 'n_estimators': 373, 'min_child_samples': 67, 'min_child_weight': 0.04113758621491663, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011013345777933544, 'reg_lambda': 5.43211984328091e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:08,902] Trial 67 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 32, 'max_depth': 28, 'learning_rate': 0.007584314417478931, 'n_estimators': 275, 'min_child_samples': 75, 'min_child_weight': 0.6907112883895083, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 0.0053733471259586035, 'reg_lambda': 0.00012084177112875997}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,024] Trial 68 finished with value: 0.8098075348075349 and parameters: {'num_leaves': 17, 'max_depth': 15, 'learning_rate': 0.0029857388422094176, 'n_estimators': 426, 'min_child_samples': 86, 'min_child_weight': 0.342062723892775, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.016166650266878944, 'reg_lambda': 3.4237666780780794e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,069] Trial 69 finished with value: 0.8166014877049655 and parameters: {'num_leaves': 205, 'max_depth': 69, 'learning_rate': 0.03916484861895702, 'n_estimators': 12, 'min_child_samples': 55, 'min_child_weight': 0.19173088652801493, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.0006263680122428146, 'reg_lambda': 0.00021140072604556025}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,130] Trial 70 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 336, 'max_depth': 42, 'learning_rate': 0.0002481540136952722, 'n_estimators': 68, 'min_child_samples': 71, 'min_child_weight': 4.177036245002266e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0020005070133421975, 'reg_lambda': 7.083678589189961e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,249] Trial 71 finished with value: 0.7884491634491634 and parameters: {'num_leaves': 77, 'max_depth': 55, 'learning_rate': 0.001588058778149872, 'n_estimators': 207, 'min_child_samples': 45, 'min_child_weight': 0.6900804842991078, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.03459639777776635, 'reg_lambda': 1.567391125115317e-05}. Best is trial 55 with value: 0.8235677855869861.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,327] Trial 72 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 52, 'max_depth': 45, 'learning_rate': 0.01452379766131046, 'n_estimators': 121, 'min_child_samples': 50, 'min_child_weight': 0.42874909570736963, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013650201690936433, 'reg_lambda': 2.6553369987980765e-05}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,408] Trial 73 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 47, 'max_depth': 48, 'learning_rate': 0.013402937495631774, 'n_estimators': 112, 'min_child_samples': 49, 'min_child_weight': 0.44161116072191486, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00014773125071920257, 'reg_lambda': 2.519900387732693e-05}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,485] Trial 74 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 52, 'max_depth': 46, 'learning_rate': 0.10495283331955528, 'n_estimators': 108, 'min_child_samples': 50, 'min_child_weight': 0.24376920886859962, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00012884094558586018, 'reg_lambda': 2.4096684322093676e-05}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,577] Trial 75 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 39, 'max_depth': 105, 'learning_rate': 0.013380963565859445, 'n_estimators': 142, 'min_child_samples': 53, 'min_child_weight': 0.05995954635536014, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 5.144607114230935e-05, 'reg_lambda': 3.7810643625355336e-05}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,628] Trial 76 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 17, 'max_depth': 109, 'learning_rate': 0.45877925577070905, 'n_estimators': 36, 'min_child_samples': 54, 'min_child_weight': 0.06854950718163531, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 7.64580510188106e-05, 'reg_lambda': 6.287321849669078e-05}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,703] Trial 77 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 41, 'max_depth': 97, 'learning_rate': 0.01420933202595176, 'n_estimators': 137, 'min_child_samples': 90, 'min_child_weight': 0.12421235260691603, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 5.0950758316587555e-05, 'reg_lambda': 0.29906607606400226}. Best is trial 72 with value: 0.8285569013829883.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,782] Trial 78 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 94, 'max_depth': 38, 'learning_rate': 0.02547442109029333, 'n_estimators': 78, 'min_child_samples': 43, 'min_child_weight': 0.19151793955558782, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.478938901928847e-05, 'reg_lambda': 0.026245488230200797}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,864] Trial 79 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 98, 'max_depth': 37, 'learning_rate': 0.02977703806412908, 'n_estimators': 117, 'min_child_samples': 42, 'min_child_weight': 0.19487243356643866, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0110173247398665e-05, 'reg_lambda': 0.046084964727718974}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:09,919] Trial 80 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 6, 'max_depth': 43, 'learning_rate': 1.3253908444032425e-08, 'n_estimators': 83, 'min_child_samples': 38, 'min_child_weight': 0.05846057355393996, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0449131101319856e-05, 'reg_lambda': 0.010452612544067076}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,016] Trial 81 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 58, 'max_depth': 49, 'learning_rate': 0.06069710275964377, 'n_estimators': 161, 'min_child_samples': 49, 'min_child_weight': 0.2987014923667707, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013807424645044297, 'reg_lambda': 0.023617704639604505}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,083] Trial 82 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 90, 'max_depth': 31, 'learning_rate': 0.01364310763399922, 'n_estimators': 72, 'min_child_samples': 45, 'min_child_weight': 0.0968801761148098, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.0451353892797555e-05, 'reg_lambda': 4.479217893194877e-05}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,177] Trial 83 finished with value: 0.828254477109439 and parameters: {'num_leaves': 36, 'max_depth': 120, 'learning_rate': 0.005937256486318965, 'n_estimators': 158, 'min_child_samples': 51, 'min_child_weight': 0.0017187594193865808, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.526420181817345e-05, 'reg_lambda': 0.0485952811062585}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,266] Trial 84 finished with value: 0.828254477109439 and parameters: {'num_leaves': 34, 'max_depth': 107, 'learning_rate': 0.007131150834329271, 'n_estimators': 156, 'min_child_samples': 51, 'min_child_weight': 0.0008263575199327403, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 8.325431428461859e-05, 'reg_lambda': 0.19164561390637896}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,317] Trial 85 finished with value: 0.748003003003003 and parameters: {'num_leaves': 36, 'max_depth': 118, 'learning_rate': 0.008304165644258666, 'n_estimators': 32, 'min_child_samples': 58, 'min_child_weight': 0.001429503469018427, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.243501647305292e-05, 'reg_lambda': 0.08617824625741889}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,414] Trial 86 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 361, 'max_depth': 113, 'learning_rate': 0.1083169157024401, 'n_estimators': 151, 'min_child_samples': 53, 'min_child_weight': 0.0010093468312173106, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.580358177282798e-05, 'reg_lambda': 0.27527666346130375}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,495] Trial 87 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 26, 'max_depth': 98, 'learning_rate': 0.025860247100957953, 'n_estimators': 125, 'min_child_samples': 49, 'min_child_weight': 0.0009033651336017129, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.4765562278571454e-05, 'reg_lambda': 0.03778672828674289}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,564] Trial 88 finished with value: 0.8062192382206252 and parameters: {'num_leaves': 45, 'max_depth': 103, 'learning_rate': 0.006368072515199227, 'n_estimators': 91, 'min_child_samples': 63, 'min_child_weight': 0.0025442747696384116, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 7.499092731626144e-05, 'reg_lambda': 0.14288407025381714}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,657] Trial 89 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 75, 'max_depth': 124, 'learning_rate': 0.01503947783738088, 'n_estimators': 179, 'min_child_samples': 79, 'min_child_weight': 0.0005688424537753528, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.105130183159669e-05, 'reg_lambda': 0.07648670509896713}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,719] Trial 90 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 75, 'max_depth': 127, 'learning_rate': 0.05494970817959108, 'n_estimators': 61, 'min_child_samples': 82, 'min_child_weight': 0.00044661045302987404, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.503874966714097e-05, 'reg_lambda': 0.08178402345749676}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,804] Trial 91 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 64, 'max_depth': 123, 'learning_rate': 0.01796990393329859, 'n_estimators': 186, 'min_child_samples': 78, 'min_child_weight': 0.00046638238074415, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.000267836873289212, 'reg_lambda': 0.022350509907445432}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,896] Trial 92 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 19, 'max_depth': 117, 'learning_rate': 0.011746410654764325, 'n_estimators': 169, 'min_child_samples': 52, 'min_child_weight': 0.0006957447103506329, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.000169154204196432, 'reg_lambda': 0.6688678081561683}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:10,964] Trial 93 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 11, 'max_depth': 118, 'learning_rate': 0.02635413012461638, 'n_estimators': 130, 'min_child_samples': 58, 'min_child_weight': 0.0006822955436902792, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0001833534173387832, 'reg_lambda': 1.1706497116555954}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,218] Trial 94 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 25, 'max_depth': 120, 'learning_rate': 0.0047493038210437615, 'n_estimators': 684, 'min_child_samples': 51, 'min_child_weight': 0.0020648368888667623, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.161180133758987e-05, 'reg_lambda': 0.46117008287008276}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,305] Trial 95 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 48, 'max_depth': 113, 'learning_rate': 5.9174227337888583e-08, 'n_estimators': 182, 'min_child_samples': 61, 'min_child_weight': 0.006267105105898378, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3706195401219998e-05, 'reg_lambda': 1.3499241201528067}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,359] Trial 96 finished with value: 0.6836194302410519 and parameters: {'num_leaves': 2, 'max_depth': 109, 'learning_rate': 0.009016753825060665, 'n_estimators': 211, 'min_child_samples': 53, 'min_child_weight': 0.0002514853300742282, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00015305053514586933, 'reg_lambda': 0.06118988200177611}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,446] Trial 97 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 476, 'max_depth': 124, 'learning_rate': 5.258090474359538e-06, 'n_estimators': 96, 'min_child_samples': 34, 'min_child_weight': 0.0042375672907178875, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.4804572303097315e-05, 'reg_lambda': 0.13856389143430564}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,574] Trial 98 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 69, 'max_depth': 116, 'learning_rate': 0.04543154443888653, 'n_estimators': 233, 'min_child_samples': 48, 'min_child_weight': 0.00018221575259176837, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 3.9941698778163136e-05, 'reg_lambda': 0.6612003590909521}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,630] Trial 99 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 107, 'max_depth': 104, 'learning_rate': 0.10300804076389022, 'n_estimators': 45, 'min_child_samples': 57, 'min_child_weight': 0.001970861293837349, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0003021287898333954, 'reg_lambda': 0.012566424145523433}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,728] Trial 100 finished with value: 0.8091338930177462 and parameters: {'num_leaves': 21, 'max_depth': 126, 'learning_rate': 0.0025806607308794696, 'n_estimators': 143, 'min_child_samples': 44, 'min_child_weight': 0.00048122458548378525, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.637376298976068e-05, 'reg_lambda': 0.11676964105323578}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,813] Trial 101 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 37, 'max_depth': 111, 'learning_rate': 0.013335208832840693, 'n_estimators': 174, 'min_child_samples': 76, 'min_child_weight': 0.0006466173985949772, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00023491021368574094, 'reg_lambda': 0.05399312558670858}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,901] Trial 102 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 59, 'max_depth': 39, 'learning_rate': 0.012068512443837106, 'n_estimators': 158, 'min_child_samples': 80, 'min_child_weight': 0.0010293744555215068, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 6.478558051042804e-05, 'reg_lambda': 0.25477707735931693}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:11,972] Trial 103 finished with value: 0.8098436842623904 and parameters: {'num_leaves': 55, 'max_depth': 120, 'learning_rate': 0.005753181911421576, 'n_estimators': 116, 'min_child_samples': 94, 'min_child_weight': 0.0012970394400822522, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 7.701444914554131e-05, 'reg_lambda': 0.25601474139970787}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,041] Trial 104 finished with value: 0.748003003003003 and parameters: {'num_leaves': 84, 'max_depth': 35, 'learning_rate': 0.003773288423298301, 'n_estimators': 75, 'min_child_samples': 84, 'min_child_weight': 0.0006859617741996923, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.6535408845156022e-05, 'reg_lambda': 0.1998867143514976}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,138] Trial 105 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 61, 'max_depth': 116, 'learning_rate': 0.019012356051583214, 'n_estimators': 157, 'min_child_samples': 53, 'min_child_weight': 0.00030946261168441426, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010653693335451436, 'reg_lambda': 1.6643638062535147}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,238] Trial 106 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 60, 'max_depth': 115, 'learning_rate': 0.033007959016447375, 'n_estimators': 157, 'min_child_samples': 52, 'min_child_weight': 0.0001409972615027714, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011082542340324436, 'reg_lambda': 0.4261854447456998}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,322] Trial 107 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 79, 'max_depth': 107, 'learning_rate': 0.021056416224125313, 'n_estimators': 192, 'min_child_samples': 80, 'min_child_weight': 0.0003287904432344319, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0004767362203776621, 'reg_lambda': 4.578214595875422}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,389] Trial 108 finished with value: 0.8098075348075349 and parameters: {'num_leaves': 31, 'max_depth': 100, 'learning_rate': 0.010127969196302567, 'n_estimators': 96, 'min_child_samples': 55, 'min_child_weight': 0.0008677495110795753, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 5.5587461710708953e-05, 'reg_lambda': 2.6703975460412535}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,461] Trial 109 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 50, 'max_depth': 122, 'learning_rate': 0.015602701061171018, 'n_estimators': 128, 'min_child_samples': 47, 'min_child_weight': 0.00022564965973763412, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00017592594034804694, 'reg_lambda': 8.681109878288213}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,547] Trial 110 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 68, 'max_depth': 120, 'learning_rate': 0.3222063081975929, 'n_estimators': 173, 'min_child_samples': 88, 'min_child_weight': 0.001673265908374139, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 3.4268537691425616e-05, 'reg_lambda': 1.8140175323076604}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,636] Trial 111 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 19, 'max_depth': 39, 'learning_rate': 0.006677298481626559, 'n_estimators': 218, 'min_child_samples': 84, 'min_child_weight': 0.0009557111455692723, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 6.565573358812084e-05, 'reg_lambda': 0.10269730109535485}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,766] Trial 112 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 32, 'max_depth': 88, 'learning_rate': 0.030512695908737588, 'n_estimators': 244, 'min_child_samples': 52, 'min_child_weight': 0.001128552887501701, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010770283183695218, 'reg_lambda': 0.5758510304357819}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,851] Trial 113 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 44, 'max_depth': 125, 'learning_rate': 0.009850862676046563, 'n_estimators': 110, 'min_child_samples': 41, 'min_child_weight': 0.00266662407461381, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 4.6192633229264266e-05, 'reg_lambda': 0.007548737202483693}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:12,942] Trial 114 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 58, 'max_depth': 92, 'learning_rate': 0.0038744183153623974, 'n_estimators': 142, 'min_child_samples': 43, 'min_child_weight': 0.0006146623349260913, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.1450428411743533e-05, 'reg_lambda': 0.9082712239709984}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,060] Trial 115 finished with value: 0.8019307272857932 and parameters: {'num_leaves': 91, 'max_depth': 26, 'learning_rate': 0.0022754637159631444, 'n_estimators': 205, 'min_child_samples': 47, 'min_child_weight': 7.123225380716337e-05, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013742233830565102, 'reg_lambda': 0.19033596915114384}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,150] Trial 116 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 71, 'max_depth': 35, 'learning_rate': 0.02065286530377925, 'n_estimators': 160, 'min_child_samples': 55, 'min_child_weight': 0.0003492302904373679, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 0.0003524326859061763, 'reg_lambda': 0.0335789472608831}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,251] Trial 117 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 265, 'max_depth': 39, 'learning_rate': 0.047479627776681944, 'n_estimators': 182, 'min_child_samples': 51, 'min_child_weight': 0.0005588984288675224, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00022436059213649785, 'reg_lambda': 2.2992001346160325}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,309] Trial 118 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 10, 'max_depth': 117, 'learning_rate': 0.0010975592846760567, 'n_estimators': 80, 'min_child_samples': 59, 'min_child_weight': 0.000771009732042613, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 9.414719133491776e-05, 'reg_lambda': 0.06505852543116553}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,355] Trial 119 finished with value: 0.6728532329798153 and parameters: {'num_leaves': 108, 'max_depth': 44, 'learning_rate': 0.011816804134857651, 'n_estimators': 18, 'min_child_samples': 68, 'min_child_weight': 0.0002971237943556715, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.8491161553261422e-05, 'reg_lambda': 0.01728452487785219}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,433] Trial 120 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 386, 'max_depth': 111, 'learning_rate': 0.007358420802828313, 'n_estimators': 123, 'min_child_samples': 71, 'min_child_weight': 0.14451226750548393, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.578586950277048e-05, 'reg_lambda': 0.4510543798761478}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,509] Trial 121 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 314, 'max_depth': 110, 'learning_rate': 0.0062335563071084866, 'n_estimators': 121, 'min_child_samples': 71, 'min_child_weight': 0.17665204254027553, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7917259945878456e-05, 'reg_lambda': 0.42219463502831867}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,595] Trial 122 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 417, 'max_depth': 106, 'learning_rate': 0.01675157604563667, 'n_estimators': 142, 'min_child_samples': 62, 'min_child_weight': 0.13636383989814171, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.174531943329413e-05, 'reg_lambda': 0.3785581696398206}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,649] Trial 123 finished with value: 0.6999570586474776 and parameters: {'num_leaves': 49, 'max_depth': 113, 'learning_rate': 0.004178684273652418, 'n_estimators': 60, 'min_child_samples': 80, 'min_child_weight': 0.09538888429154871, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 8.416029701091919e-05, 'reg_lambda': 1.5793687730737764}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,720] Trial 124 finished with value: 0.8180626352268143 and parameters: {'num_leaves': 38, 'max_depth': 31, 'learning_rate': 0.008775338923389659, 'n_estimators': 113, 'min_child_samples': 75, 'min_child_weight': 0.07991727326862326, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 4.867613837704038e-05, 'reg_lambda': 0.028013935725768168}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,831] Trial 125 finished with value: 0.8071179781643625 and parameters: {'num_leaves': 382, 'max_depth': 121, 'learning_rate': 0.027242844733841386, 'n_estimators': 163, 'min_child_samples': 50, 'min_child_weight': 0.0015841237735285628, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0001563742946100413, 'reg_lambda': 0.21705551391542463}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,908] Trial 126 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 445, 'max_depth': 41, 'learning_rate': 0.013153347706216472, 'n_estimators': 93, 'min_child_samples': 46, 'min_child_weight': 0.04162584883849394, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.7765924338777064e-05, 'reg_lambda': 0.7359308830639197}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:13,996] Trial 127 finished with value: 0.7968007577956703 and parameters: {'num_leaves': 235, 'max_depth': 103, 'learning_rate': 0.0068743351367507545, 'n_estimators': 198, 'min_child_samples': 89, 'min_child_weight': 0.5330436604677601, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011126079181196528, 'reg_lambda': 0.9835003566524959}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,087] Trial 128 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 26, 'max_depth': 114, 'learning_rate': 0.0821058301879402, 'n_estimators': 141, 'min_child_samples': 54, 'min_child_weight': 0.0012251206145916526, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.0407710650770584e-05, 'reg_lambda': 0.10424127235871099}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,171] Trial 129 finished with value: 0.8048474005920815 and parameters: {'num_leaves': 79, 'max_depth': 46, 'learning_rate': 0.0029796533263473086, 'n_estimators': 176, 'min_child_samples': 92, 'min_child_weight': 0.2919338031958921, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00021811956244531118, 'reg_lambda': 0.0034105568823079844}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,281] Trial 130 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 149, 'max_depth': 117, 'learning_rate': 0.04013215976157083, 'n_estimators': 235, 'min_child_samples': 71, 'min_child_weight': 0.0004249998777812932, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 6.955673630593438e-05, 'reg_lambda': 0.5592565500756717}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,364] Trial 131 finished with value: 0.8166014877049655 and parameters: {'num_leaves': 300, 'max_depth': 111, 'learning_rate': 0.00477127436631031, 'n_estimators': 114, 'min_child_samples': 71, 'min_child_weight': 0.1622456912637022, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9044063200661968e-05, 'reg_lambda': 0.3876239854633008}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,453] Trial 132 finished with value: 0.8271595034654736 and parameters: {'num_leaves': 332, 'max_depth': 110, 'learning_rate': 0.007282848309095545, 'n_estimators': 127, 'min_child_samples': 72, 'min_child_weight': 0.2279260570119654, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5676509508654336e-05, 'reg_lambda': 0.8435046387166083}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,544] Trial 133 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 374, 'max_depth': 101, 'learning_rate': 0.019673825399001126, 'n_estimators': 155, 'min_child_samples': 75, 'min_child_weight': 0.22682019560942943, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0049768792593881e-05, 'reg_lambda': 2.9288923954105887e-05}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,627] Trial 134 finished with value: 0.8271595034654736 and parameters: {'num_leaves': 336, 'max_depth': 77, 'learning_rate': 0.009265472107786306, 'n_estimators': 94, 'min_child_samples': 73, 'min_child_weight': 0.35930245499254343, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6743249069838272e-05, 'reg_lambda': 0.2909574835359988}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,701] Trial 135 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 398, 'max_depth': 81, 'learning_rate': 0.008639503904874658, 'n_estimators': 88, 'min_child_samples': 65, 'min_child_weight': 0.35505496031795725, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6397791273333743e-05, 'reg_lambda': 0.30983104588239535}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,764] Trial 136 finished with value: 0.8223949706477587 and parameters: {'num_leaves': 347, 'max_depth': 107, 'learning_rate': 0.014541170926635864, 'n_estimators': 63, 'min_child_samples': 82, 'min_child_weight': 0.2612252216700276, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.1382900937567284e-05, 'reg_lambda': 0.15594470040014982}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,824] Trial 137 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 341, 'max_depth': 128, 'learning_rate': 0.026005678101825348, 'n_estimators': 34, 'min_child_samples': 73, 'min_child_weight': 0.4751494793135485, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3461430928917753e-05, 'reg_lambda': 0.04909331625597077}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:14,927] Trial 138 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 280, 'max_depth': 72, 'learning_rate': 0.011745151669542323, 'n_estimators': 135, 'min_child_samples': 49, 'min_child_weight': 0.30882981711025037, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1729705200588457e-05, 'reg_lambda': 0.8608383066188445}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,014] Trial 139 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 358, 'max_depth': 75, 'learning_rate': 0.05444317985661127, 'n_estimators': 132, 'min_child_samples': 49, 'min_child_weight': 0.4537293248276566, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6431080268645154e-05, 'reg_lambda': 1.1382016632619518}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,078] Trial 140 finished with value: 0.7869306541228919 and parameters: {'num_leaves': 269, 'max_depth': 77, 'learning_rate': 0.006336906244494394, 'n_estimators': 50, 'min_child_samples': 45, 'min_child_weight': 0.34826003959748275, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8796720004742742, 'reg_lambda': 0.8433648823923063}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,168] Trial 141 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 327, 'max_depth': 69, 'learning_rate': 0.010604673758452091, 'n_estimators': 98, 'min_child_samples': 57, 'min_child_weight': 0.2091657900840479, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.31618482329497e-05, 'reg_lambda': 0.5630073376764393}. Best is trial 78 with value: 0.8288288288288288.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,259] Trial 142 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 322, 'max_depth': 112, 'learning_rate': 0.01877184098894729, 'n_estimators': 126, 'min_child_samples': 53, 'min_child_weight': 0.8080820305858896, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4736427471304954e-05, 'reg_lambda': 0.3184880747767442}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,355] Trial 143 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 282, 'max_depth': 111, 'learning_rate': 0.02062902137049455, 'n_estimators': 125, 'min_child_samples': 53, 'min_child_weight': 0.7661214070255848, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7003537940861478e-05, 'reg_lambda': 0.3160911877113005}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,448] Trial 144 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 281, 'max_depth': 111, 'learning_rate': 0.03273606075856293, 'n_estimators': 129, 'min_child_samples': 52, 'min_child_weight': 0.7078610266422991, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7786738765543953e-05, 'reg_lambda': 0.3526048272306457}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,522] Trial 145 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 308, 'max_depth': 115, 'learning_rate': 0.01794462040168719, 'n_estimators': 78, 'min_child_samples': 48, 'min_child_weight': 0.5779020149917754, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2024338262747576e-05, 'reg_lambda': 0.5203394136869044}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,609] Trial 146 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 285, 'max_depth': 106, 'learning_rate': 0.02328998391691693, 'n_estimators': 103, 'min_child_samples': 54, 'min_child_weight': 0.9387625368558636, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.0466061297720264e-05, 'reg_lambda': 1.5947914193826283}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,696] Trial 147 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 308, 'max_depth': 118, 'learning_rate': 6.907315362070327e-07, 'n_estimators': 125, 'min_child_samples': 51, 'min_child_weight': 0.4495682911819279, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4441387612652385e-05, 'reg_lambda': 0.6710307622807895}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,770] Trial 148 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 337, 'max_depth': 73, 'learning_rate': 0.14432423670121577, 'n_estimators': 73, 'min_child_samples': 56, 'min_child_weight': 0.8479013932070376, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.374373068721772e-05, 'reg_lambda': 0.0015102209603346632}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:15,883] Trial 149 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 258, 'max_depth': 109, 'learning_rate': 0.037273080716325575, 'n_estimators': 182, 'min_child_samples': 49, 'min_child_weight': 0.7365056868503582, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.355994344146574e-05, 'reg_lambda': 0.1672470821056345}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,156] Trial 150 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 359, 'max_depth': 63, 'learning_rate': 0.005046497522579837, 'n_estimators': 758, 'min_child_samples': 60, 'min_child_weight': 0.54181599713384, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 4.169281010641203e-05, 'reg_lambda': 0.25871599440637366}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,248] Trial 151 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 319, 'max_depth': 113, 'learning_rate': 0.013189650433082338, 'n_estimators': 152, 'min_child_samples': 53, 'min_child_weight': 0.2809374203470403, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.23548852249598e-05, 'reg_lambda': 0.8612631354069848}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,336] Trial 152 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 328, 'max_depth': 113, 'learning_rate': 0.018151514693298645, 'n_estimators': 141, 'min_child_samples': 54, 'min_child_weight': 0.3635497152869878, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.277644068004669e-05, 'reg_lambda': 0.7900412267788739}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,425] Trial 153 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 327, 'max_depth': 113, 'learning_rate': 0.007905598614781247, 'n_estimators': 111, 'min_child_samples': 51, 'min_child_weight': 0.31081529311056455, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 8.653896107027213e-05, 'reg_lambda': 0.7726097254198404}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,514] Trial 154 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 328, 'max_depth': 113, 'learning_rate': 0.007754064978665075, 'n_estimators': 147, 'min_child_samples': 53, 'min_child_weight': 0.3038510884466679, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9945688408373006e-05, 'reg_lambda': 2.063399165561854}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,622] Trial 155 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 325, 'max_depth': 114, 'learning_rate': 0.0072087106911584995, 'n_estimators': 205, 'min_child_samples': 57, 'min_child_weight': 0.29568956727259027, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.961392490319692e-05, 'reg_lambda': 2.027482851765307}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,714] Trial 156 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 294, 'max_depth': 119, 'learning_rate': 0.008796287202685714, 'n_estimators': 148, 'min_child_samples': 51, 'min_child_weight': 0.30597016277025013, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.5994759435935016e-05, 'reg_lambda': 2.8702168902846292}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,810] Trial 157 finished with value: 0.8083827621066946 and parameters: {'num_leaves': 323, 'max_depth': 123, 'learning_rate': 0.0021203263722353117, 'n_estimators': 169, 'min_child_samples': 46, 'min_child_weight': 0.3785966111908435, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.564150131760336e-05, 'reg_lambda': 1.3304733893723075}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:16,889] Trial 158 finished with value: 0.7969915828977976 and parameters: {'num_leaves': 331, 'max_depth': 116, 'learning_rate': 0.00490061887715319, 'n_estimators': 98, 'min_child_samples': 48, 'min_child_weight': 0.23323194692453403, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7648871153717988e-05, 'reg_lambda': 0.9656564962855344}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,109] Trial 159 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 304, 'max_depth': 113, 'learning_rate': 0.0032813160729637573, 'n_estimators': 510, 'min_child_samples': 54, 'min_child_weight': 0.1928478406388163, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.3505846948775536e-05, 'reg_lambda': 0.7475853467862248}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,197] Trial 160 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 355, 'max_depth': 125, 'learning_rate': 0.016775653472037667, 'n_estimators': 145, 'min_child_samples': 56, 'min_child_weight': 0.3340398523990296, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.457988512706383e-05, 'reg_lambda': 1.3855041267173085}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,294] Trial 161 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 347, 'max_depth': 122, 'learning_rate': 0.013107423225077722, 'n_estimators': 149, 'min_child_samples': 56, 'min_child_weight': 0.2835909460610039, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.695682237608543e-05, 'reg_lambda': 4.227420026369712}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,416] Trial 162 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 318, 'max_depth': 126, 'learning_rate': 0.018356048905697437, 'n_estimators': 187, 'min_child_samples': 51, 'min_child_weight': 0.37252179662886886, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.739428255931964e-05, 'reg_lambda': 1.294128752030499}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,493] Trial 163 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 348, 'max_depth': 119, 'learning_rate': 0.007895017357395727, 'n_estimators': 107, 'min_child_samples': 55, 'min_child_weight': 0.16429740765646556, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00012259495706772839, 'reg_lambda': 0.9302969363310724}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,581] Trial 164 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 374, 'max_depth': 66, 'learning_rate': 0.027801956601451502, 'n_estimators': 136, 'min_child_samples': 53, 'min_child_weight': 0.5517610910321206, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.391668258413418e-05, 'reg_lambda': 1.9970971403515951}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,687] Trial 165 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 314, 'max_depth': 124, 'learning_rate': 0.01133320369271599, 'n_estimators': 167, 'min_child_samples': 43, 'min_child_weight': 0.2434016733615835, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.781402158796494e-05, 'reg_lambda': 0.7232671444495752}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,759] Trial 166 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 365, 'max_depth': 108, 'learning_rate': 0.016322545223972643, 'n_estimators': 84, 'min_child_samples': 58, 'min_child_weight': 0.3678090558631222, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3421413295096045e-05, 'reg_lambda': 0.46993650093347994}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,852] Trial 167 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 338, 'max_depth': 115, 'learning_rate': 0.007528688839863938, 'n_estimators': 127, 'min_child_samples': 49, 'min_child_weight': 0.4320157848476675, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.311782209295134e-05, 'reg_lambda': 1.5049561509753129}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:17,956] Trial 168 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 319, 'max_depth': 112, 'learning_rate': 0.04452880992574494, 'n_estimators': 192, 'min_child_samples': 51, 'min_child_weight': 0.0005661157267988223, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.392605766645977e-05, 'reg_lambda': 1.1622273471060862}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,055] Trial 169 finished with value: 0.8223949706477587 and parameters: {'num_leaves': 394, 'max_depth': 121, 'learning_rate': 0.004916201368437785, 'n_estimators': 153, 'min_child_samples': 47, 'min_child_weight': 0.2763308671030464, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.2277400095682336e-05, 'reg_lambda': 2.4691446432050816}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,338] Trial 170 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 331, 'max_depth': 116, 'learning_rate': 0.010267455369748891, 'n_estimators': 871, 'min_child_samples': 61, 'min_child_weight': 0.1481549133346729, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.83366125164574e-05, 'reg_lambda': 3.418878919804509}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,425] Trial 171 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 349, 'max_depth': 110, 'learning_rate': 0.024063926456067298, 'n_estimators': 120, 'min_child_samples': 53, 'min_child_weight': 0.6285322377818428, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7391779354042676e-05, 'reg_lambda': 0.4782785406823676}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,504] Trial 172 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 275, 'max_depth': 112, 'learning_rate': 0.017403602004241077, 'n_estimators': 108, 'min_child_samples': 54, 'min_child_weight': 0.8121256751921344, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8414241723265126e-05, 'reg_lambda': 0.33199812282363217}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,591] Trial 173 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 247, 'max_depth': 118, 'learning_rate': 0.014755480920652412, 'n_estimators': 107, 'min_child_samples': 55, 'min_child_weight': 0.3343958133591408, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7139554644085878e-05, 'reg_lambda': 0.643848028533221}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,666] Trial 174 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 298, 'max_depth': 108, 'learning_rate': 0.0655396112330963, 'n_estimators': 60, 'min_child_samples': 50, 'min_child_weight': 0.9881019391466032, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.066652007500309e-05, 'reg_lambda': 0.873938798750533}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,761] Trial 175 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 355, 'max_depth': 85, 'learning_rate': 0.006297739694180891, 'n_estimators': 166, 'min_child_samples': 58, 'min_child_weight': 0.2044737237394366, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0527095386956495e-05, 'reg_lambda': 6.252910056053392}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,864] Trial 176 finished with value: 0.7969915828977976 and parameters: {'num_leaves': 356, 'max_depth': 84, 'learning_rate': 0.0034522170350582367, 'n_estimators': 141, 'min_child_samples': 59, 'min_child_weight': 0.20962408220169312, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3025822160371282e-05, 'reg_lambda': 1.8881007190500825}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:18,939] Trial 177 finished with value: 0.7792513009904314 and parameters: {'num_leaves': 340, 'max_depth': 85, 'learning_rate': 0.006750418467574882, 'n_estimators': 94, 'min_child_samples': 57, 'min_child_weight': 0.004382182242940242, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2555447138461657e-05, 'reg_lambda': 6.665812793644751}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,039] Trial 178 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 327, 'max_depth': 113, 'learning_rate': 0.009340672079244524, 'n_estimators': 165, 'min_child_samples': 69, 'min_child_weight': 0.45937084175299936, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9283703196049297e-05, 'reg_lambda': 0.37012277316116515}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,113] Trial 179 finished with value: 0.7854420441568328 and parameters: {'num_leaves': 368, 'max_depth': 77, 'learning_rate': 0.00539554559503043, 'n_estimators': 79, 'min_child_samples': 53, 'min_child_weight': 0.1870527055948987, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.100132783392413e-05, 'reg_lambda': 5.7518566532720135}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,200] Trial 180 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 354, 'max_depth': 104, 'learning_rate': 0.02263155678071623, 'n_estimators': 115, 'min_child_samples': 56, 'min_child_weight': 0.25970042204857424, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1947591157670645e-05, 'reg_lambda': 1.0444420207732121}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,296] Trial 181 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 390, 'max_depth': 116, 'learning_rate': 0.016375348004469274, 'n_estimators': 175, 'min_child_samples': 64, 'min_child_weight': 0.00026363293756209174, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.035124521149046e-05, 'reg_lambda': 0.2078365830327067}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,438] Trial 182 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 319, 'max_depth': 121, 'learning_rate': 0.011741304183043566, 'n_estimators': 215, 'min_child_samples': 52, 'min_child_weight': 0.3571224186635748, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.729073443724135e-05, 'reg_lambda': 0.5521235675007162}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,527] Trial 183 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 331, 'max_depth': 71, 'learning_rate': 0.0312441788514963, 'n_estimators': 137, 'min_child_samples': 67, 'min_child_weight': 0.13034532337678933, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8456384025514354e-05, 'reg_lambda': 0.07488963370800646}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,624] Trial 184 finished with value: 0.828254477109439 and parameters: {'num_leaves': 308, 'max_depth': 112, 'learning_rate': 0.008353807223429046, 'n_estimators': 156, 'min_child_samples': 54, 'min_child_weight': 0.0001865210426992889, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00012501525350360238, 'reg_lambda': 0.7719554406295425}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,723] Trial 185 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 290, 'max_depth': 109, 'learning_rate': 0.007420598017069677, 'n_estimators': 150, 'min_child_samples': 55, 'min_child_weight': 0.00017807134823285642, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00012820590535770072, 'reg_lambda': 0.7804164085177477}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,805] Trial 186 finished with value: 0.7667848306052532 and parameters: {'num_leaves': 337, 'max_depth': 112, 'learning_rate': 0.003953677535905863, 'n_estimators': 126, 'min_child_samples': 50, 'min_child_weight': 0.5925777667761501, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010339813151401517, 'reg_lambda': 9.292702251454632}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:19,905] Trial 187 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 314, 'max_depth': 114, 'learning_rate': 0.009527011230275557, 'n_estimators': 162, 'min_child_samples': 59, 'min_child_weight': 0.2302807270854211, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.855874683818392e-05, 'reg_lambda': 1.3772139481299857}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,003] Trial 188 finished with value: 0.7945431727399606 and parameters: {'num_leaves': 308, 'max_depth': 102, 'learning_rate': 0.005858734999645457, 'n_estimators': 106, 'min_child_samples': 54, 'min_child_weight': 0.00010135563988875436, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00018322165041436336, 'reg_lambda': 0.6420591550620943}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,111] Trial 189 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 279, 'max_depth': 79, 'learning_rate': 0.018202989686716114, 'n_estimators': 191, 'min_child_samples': 52, 'min_child_weight': 0.00012583833739196614, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 1.615287146421855e-05, 'reg_lambda': 0.3830561039674115}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,176] Trial 190 finished with value: 0.8166014877049655 and parameters: {'num_leaves': 323, 'max_depth': 111, 'learning_rate': 0.012085522564544841, 'n_estimators': 46, 'min_child_samples': 45, 'min_child_weight': 2.4457996991170597e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.071857442871439e-05, 'reg_lambda': 1.0344530552582103}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,280] Trial 191 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 297, 'max_depth': 117, 'learning_rate': 0.015390441885214386, 'n_estimators': 142, 'min_child_samples': 49, 'min_child_weight': 0.0001816456882187984, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.904046981600781e-05, 'reg_lambda': 0.26959621979115916}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,386] Trial 192 finished with value: 0.788723176958471 and parameters: {'num_leaves': 274, 'max_depth': 74, 'learning_rate': 0.03468920911065376, 'n_estimators': 167, 'min_child_samples': 56, 'min_child_weight': 0.00045782453146685876, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2578483170952622e-05, 'reg_lambda': 0.12215111842889231}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,631] Trial 193 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 343, 'max_depth': 124, 'learning_rate': 0.008779348135276109, 'n_estimators': 622, 'min_child_samples': 51, 'min_child_weight': 0.0008163998612017107, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013495857451082866, 'reg_lambda': 0.041743296493880575}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,731] Trial 194 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 309, 'max_depth': 106, 'learning_rate': 0.023401713773130446, 'n_estimators': 123, 'min_child_samples': 53, 'min_child_weight': 0.00037822642494455107, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.342705548453211e-05, 'reg_lambda': 0.021054354401977504}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,818] Trial 195 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 255, 'max_depth': 115, 'learning_rate': 0.01116523463739831, 'n_estimators': 190, 'min_child_samples': 77, 'min_child_weight': 0.31288910924621205, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.265916754534446e-05, 'reg_lambda': 0.5027605196805037}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,917] Trial 196 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 332, 'max_depth': 118, 'learning_rate': 0.005884701316007925, 'n_estimators': 156, 'min_child_samples': 48, 'min_child_weight': 0.00021584648302112847, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1839268338129994e-05, 'reg_lambda': 0.7518652024042428}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:20,995] Trial 197 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 333, 'max_depth': 119, 'learning_rate': 6.224142253481777e-05, 'n_estimators': 93, 'min_child_samples': 49, 'min_child_weight': 0.000222808998309314, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7753189511102375e-05, 'reg_lambda': 0.7694092414327799}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,099] Trial 198 finished with value: 0.8048474005920815 and parameters: {'num_leaves': 367, 'max_depth': 91, 'learning_rate': 0.0027448847222190445, 'n_estimators': 153, 'min_child_samples': 47, 'min_child_weight': 0.5354446738536485, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.134807305505953e-05, 'reg_lambda': 1.6726701999291693}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,189] Trial 199 finished with value: 0.7988362849853958 and parameters: {'num_leaves': 382, 'max_depth': 95, 'learning_rate': 0.004619035576417404, 'n_estimators': 134, 'min_child_samples': 54, 'min_child_weight': 0.00010691606291948142, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 4.276883976675093e-05, 'reg_lambda': 1.1910173949559404}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,265] Trial 200 finished with value: 0.6728532329798153 and parameters: {'num_leaves': 353, 'max_depth': 67, 'learning_rate': 0.001772008842408712, 'n_estimators': 111, 'min_child_samples': 73, 'min_child_weight': 0.00020820984523945663, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1075693798462634e-05, 'reg_lambda': 0.005886736160101527}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,374] Trial 201 finished with value: 0.828254477109439 and parameters: {'num_leaves': 327, 'max_depth': 113, 'learning_rate': 0.00678912522142285, 'n_estimators': 173, 'min_child_samples': 51, 'min_child_weight': 0.00029511941832123225, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.520159598369544e-05, 'reg_lambda': 0.4568974572916239}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,482] Trial 202 finished with value: 0.828254477109439 and parameters: {'num_leaves': 318, 'max_depth': 112, 'learning_rate': 0.00634589179351078, 'n_estimators': 167, 'min_child_samples': 51, 'min_child_weight': 0.0001369711632027898, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3591328074568392e-05, 'reg_lambda': 0.604969544818782}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,598] Trial 203 finished with value: 0.828254477109439 and parameters: {'num_leaves': 314, 'max_depth': 113, 'learning_rate': 0.006686544600864873, 'n_estimators': 215, 'min_child_samples': 51, 'min_child_weight': 0.0002944475651445777, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3812507552966364e-05, 'reg_lambda': 0.6600683896407097}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,721] Trial 204 finished with value: 0.828254477109439 and parameters: {'num_leaves': 304, 'max_depth': 113, 'learning_rate': 0.0057212728736762445, 'n_estimators': 212, 'min_child_samples': 51, 'min_child_weight': 0.0002921784884534959, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2137686475823978e-05, 'reg_lambda': 0.6137726412475347}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,853] Trial 205 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 303, 'max_depth': 116, 'learning_rate': 0.004688999175456572, 'n_estimators': 205, 'min_child_samples': 48, 'min_child_weight': 7.114876190034571e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3375994116810686e-05, 'reg_lambda': 0.4632805314838767}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:21,973] Trial 206 finished with value: 0.8128060018297418 and parameters: {'num_leaves': 293, 'max_depth': 112, 'learning_rate': 0.0031456225383517337, 'n_estimators': 186, 'min_child_samples': 52, 'min_child_weight': 0.0002534823258579967, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0442458773433523e-05, 'reg_lambda': 0.6302590233903315}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,100] Trial 207 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 312, 'max_depth': 108, 'learning_rate': 0.005453781140766033, 'n_estimators': 208, 'min_child_samples': 46, 'min_child_weight': 0.00030605692446755093, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.352287253951633e-05, 'reg_lambda': 0.5319156098396274}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,213] Trial 208 finished with value: 0.828254477109439 and parameters: {'num_leaves': 321, 'max_depth': 114, 'learning_rate': 0.006583859541887601, 'n_estimators': 170, 'min_child_samples': 50, 'min_child_weight': 0.00018181069856394288, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9350376954850763e-05, 'reg_lambda': 0.4548747033999732}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,346] Trial 209 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 321, 'max_depth': 120, 'learning_rate': 0.003993970380998585, 'n_estimators': 228, 'min_child_samples': 50, 'min_child_weight': 0.00018078211058660887, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7394889244121538e-05, 'reg_lambda': 0.3717555883751791}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,473] Trial 210 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 301, 'max_depth': 114, 'learning_rate': 0.013533248008780675, 'n_estimators': 258, 'min_child_samples': 57, 'min_child_weight': 0.0001461074687599727, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.1232090352059348e-05, 'reg_lambda': 0.9433044533714826}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,602] Trial 211 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 324, 'max_depth': 118, 'learning_rate': 0.00377948336859959, 'n_estimators': 235, 'min_child_samples': 51, 'min_child_weight': 0.0001788479811824948, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8753643666554902e-05, 'reg_lambda': 0.3385970478643342}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,728] Trial 212 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 316, 'max_depth': 120, 'learning_rate': 0.005515968338593415, 'n_estimators': 221, 'min_child_samples': 49, 'min_child_weight': 0.00012777997266105935, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5591215481229187e-05, 'reg_lambda': 0.5917910429032364}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,833] Trial 213 finished with value: 0.8134278644842026 and parameters: {'num_leaves': 318, 'max_depth': 60, 'learning_rate': 0.002407907359081087, 'n_estimators': 168, 'min_child_samples': 54, 'min_child_weight': 0.00015584471321003932, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0054310185046473e-05, 'reg_lambda': 0.3592247832198373}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:22,950] Trial 214 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 292, 'max_depth': 116, 'learning_rate': 0.011617612262218142, 'n_estimators': 176, 'min_child_samples': 50, 'min_child_weight': 0.0003215348775488663, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.243338313815527e-05, 'reg_lambda': 0.6419428155101808}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,053] Trial 215 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 287, 'max_depth': 115, 'learning_rate': 0.018354676339989953, 'n_estimators': 177, 'min_child_samples': 53, 'min_child_weight': 0.00030638897745586326, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3007264886223506e-05, 'reg_lambda': 0.6973119691474278}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,160] Trial 216 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 287, 'max_depth': 115, 'learning_rate': 0.01929080537906715, 'n_estimators': 183, 'min_child_samples': 55, 'min_child_weight': 0.0003360930407199286, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4246849693280194e-05, 'reg_lambda': 1.2295904445351198}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,284] Trial 217 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 264, 'max_depth': 110, 'learning_rate': 0.01190282832614919, 'n_estimators': 201, 'min_child_samples': 53, 'min_child_weight': 0.00028369399331385734, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.210188621380433e-05, 'reg_lambda': 0.58890780628979}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,403] Trial 218 finished with value: 0.8018018018018018 and parameters: {'num_leaves': 276, 'max_depth': 109, 'learning_rate': 0.02095545452261806, 'n_estimators': 207, 'min_child_samples': 53, 'min_child_weight': 0.0002836778293992687, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0021244093528867e-05, 'reg_lambda': 0.9576691063612244}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,507] Trial 219 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 268, 'max_depth': 111, 'learning_rate': 0.013778002212455011, 'n_estimators': 198, 'min_child_samples': 58, 'min_child_weight': 0.00038145511292103385, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3438906914610646e-05, 'reg_lambda': 0.6300791400446296}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,606] Trial 220 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 263, 'max_depth': 106, 'learning_rate': 0.013061779267168396, 'n_estimators': 187, 'min_child_samples': 58, 'min_child_weight': 0.00040389603813628915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4342115367113456e-05, 'reg_lambda': 2.404470172580531}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,722] Trial 221 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 269, 'max_depth': 111, 'learning_rate': 0.010950230059592513, 'n_estimators': 215, 'min_child_samples': 56, 'min_child_weight': 0.0003815017278319663, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2467621022101575e-05, 'reg_lambda': 0.6224688881857623}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,830] Trial 222 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 247, 'max_depth': 112, 'learning_rate': 0.03218625263625748, 'n_estimators': 174, 'min_child_samples': 53, 'min_child_weight': 0.0003237893918637663, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0144878730118516e-05, 'reg_lambda': 0.6557340990977479}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:23,927] Trial 223 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 289, 'max_depth': 115, 'learning_rate': 0.01631361041970614, 'n_estimators': 158, 'min_child_samples': 55, 'min_child_weight': 0.0004966182066444636, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2886216251465467e-05, 'reg_lambda': 0.9255580935636075}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,020] Trial 224 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 281, 'max_depth': 109, 'learning_rate': 0.016433143516162617, 'n_estimators': 147, 'min_child_samples': 60, 'min_child_weight': 0.000584080344617791, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2289333945398105e-05, 'reg_lambda': 1.5413153168044054}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,117] Trial 225 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 270, 'max_depth': 114, 'learning_rate': 0.024119981991747027, 'n_estimators': 153, 'min_child_samples': 55, 'min_child_weight': 0.00047609364337894243, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.596308281090251e-05, 'reg_lambda': 0.9721444423005277}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,213] Trial 226 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 290, 'max_depth': 117, 'learning_rate': 0.017931039740554287, 'n_estimators': 171, 'min_child_samples': 58, 'min_child_weight': 0.0002679852958913062, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3586707655879355e-05, 'reg_lambda': 1.2026720341264459}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,332] Trial 227 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 288, 'max_depth': 116, 'learning_rate': 0.043970180418268556, 'n_estimators': 186, 'min_child_samples': 53, 'min_child_weight': 0.00038994259830514284, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.274166260894724e-05, 'reg_lambda': 0.7736287611404653}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,441] Trial 228 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 274, 'max_depth': 109, 'learning_rate': 0.011133744293913405, 'n_estimators': 148, 'min_child_samples': 56, 'min_child_weight': 0.0005176878450061141, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5981659880346585e-05, 'reg_lambda': 0.47727648695917074}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,561] Trial 229 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 282, 'max_depth': 111, 'learning_rate': 0.015421846881716186, 'n_estimators': 194, 'min_child_samples': 54, 'min_child_weight': 0.0003840651788794875, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7374918065822e-05, 'reg_lambda': 0.21986000563959762}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,674] Trial 230 finished with value: 0.788723176958471 and parameters: {'num_leaves': 261, 'max_depth': 105, 'learning_rate': 0.02779767605609089, 'n_estimators': 163, 'min_child_samples': 54, 'min_child_weight': 0.00046115092118804025, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.207068667578177e-05, 'reg_lambda': 0.21493238446049004}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,776] Trial 231 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 296, 'max_depth': 111, 'learning_rate': 0.014615469400454103, 'n_estimators': 196, 'min_child_samples': 57, 'min_child_weight': 0.0007313182927686555, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.6550353605949896, 'reg_lambda': 0.27096520502337856}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,868] Trial 232 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 252, 'max_depth': 113, 'learning_rate': 0.010039906475150627, 'n_estimators': 141, 'min_child_samples': 53, 'min_child_weight': 0.0002727751179396773, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0069603873071847e-05, 'reg_lambda': 0.8646948908822703}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:24,962] Trial 233 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 246, 'max_depth': 115, 'learning_rate': 0.010292755060936902, 'n_estimators': 139, 'min_child_samples': 55, 'min_child_weight': 0.00022888731589446216, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0782178706657719e-05, 'reg_lambda': 0.9429883761567455}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,065] Trial 234 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 232, 'max_depth': 111, 'learning_rate': 0.01779523864566908, 'n_estimators': 163, 'min_child_samples': 52, 'min_child_weight': 0.0003812357960734919, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.397206411035223e-05, 'reg_lambda': 1.930335966443183}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,156] Trial 235 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 237, 'max_depth': 110, 'learning_rate': 0.021773380797792594, 'n_estimators': 137, 'min_child_samples': 53, 'min_child_weight': 0.0004113013805791141, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.81907700811405e-05, 'reg_lambda': 3.895510114645211}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,256] Trial 236 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 258, 'max_depth': 108, 'learning_rate': 0.015001289234478818, 'n_estimators': 157, 'min_child_samples': 58, 'min_child_weight': 0.00033972405100163484, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.666791204365032e-05, 'reg_lambda': 1.788824325429584}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,373] Trial 237 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 281, 'max_depth': 117, 'learning_rate': 0.028798035056349203, 'n_estimators': 181, 'min_child_samples': 55, 'min_child_weight': 0.0006400155532467758, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2447142967381206e-05, 'reg_lambda': 2.8306391484695252}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,468] Trial 238 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 264, 'max_depth': 122, 'learning_rate': 0.018434402572010337, 'n_estimators': 140, 'min_child_samples': 52, 'min_child_weight': 0.00024528591550138063, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.6770138178889346e-05, 'reg_lambda': 1.4762685211579623}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,558] Trial 239 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 267, 'max_depth': 121, 'learning_rate': 0.01779353514121514, 'n_estimators': 136, 'min_child_samples': 61, 'min_child_weight': 0.0002395320209267889, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0089039595891293e-05, 'reg_lambda': 2.161981447515032}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,661] Trial 240 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 252, 'max_depth': 122, 'learning_rate': 0.04341918034354704, 'n_estimators': 151, 'min_child_samples': 53, 'min_child_weight': 0.0004996951050496799, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00013699102297004133, 'reg_lambda': 1.483866970697128}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,767] Trial 241 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 273, 'max_depth': 118, 'learning_rate': 0.010364944726260802, 'n_estimators': 172, 'min_child_samples': 52, 'min_child_weight': 0.00029540258871241145, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.6217250113685204e-05, 'reg_lambda': 1.256641128247509}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,863] Trial 242 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 224, 'max_depth': 126, 'learning_rate': 0.023740781542703128, 'n_estimators': 140, 'min_child_samples': 54, 'min_child_weight': 0.0003621395604655034, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.304226937161881e-05, 'reg_lambda': 1.9085759080053875}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:25,982] Trial 243 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 286, 'max_depth': 115, 'learning_rate': 0.014208588902662866, 'n_estimators': 193, 'min_child_samples': 52, 'min_child_weight': 0.00023187980397576237, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0307335170301527e-05, 'reg_lambda': 1.102370001292818}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,105] Trial 244 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 287, 'max_depth': 116, 'learning_rate': 0.01628089202134103, 'n_estimators': 191, 'min_child_samples': 56, 'min_child_weight': 0.00021679322313552957, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8827411732695397e-05, 'reg_lambda': 1.0668665299065625}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,194] Trial 245 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 264, 'max_depth': 115, 'learning_rate': 0.01291357958362231, 'n_estimators': 118, 'min_child_samples': 52, 'min_child_weight': 0.00035843783140533474, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5032885870155206e-05, 'reg_lambda': 1.4766505810213335}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,304] Trial 246 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 281, 'max_depth': 119, 'learning_rate': 0.03330242186708707, 'n_estimators': 160, 'min_child_samples': 54, 'min_child_weight': 0.0002425623990482535, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010593484563313809, 'reg_lambda': 0.892807382102413}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,391] Trial 247 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 239, 'max_depth': 110, 'learning_rate': 0.020393404901031375, 'n_estimators': 121, 'min_child_samples': 58, 'min_child_weight': 0.00045646404187000487, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.44313363090814e-05, 'reg_lambda': 1.280568454110929}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,479] Trial 248 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 14, 'max_depth': 122, 'learning_rate': 0.010745381213760483, 'n_estimators': 148, 'min_child_samples': 50, 'min_child_weight': 0.0007604253564268119, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6598262955715306e-05, 'reg_lambda': 0.824035364097889}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,590] Trial 249 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 274, 'max_depth': 111, 'learning_rate': 0.016573155273449103, 'n_estimators': 202, 'min_child_samples': 56, 'min_child_weight': 0.00037957676443465865, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.48239336259329e-05, 'reg_lambda': 0.012456679115073059}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,683] Trial 250 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 257, 'max_depth': 114, 'learning_rate': 0.024094061335466082, 'n_estimators': 131, 'min_child_samples': 52, 'min_child_weight': 0.0019425990524392892, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9932213433882948e-05, 'reg_lambda': 2.924424994471692}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,795] Trial 251 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 30, 'max_depth': 106, 'learning_rate': 0.009527126531899407, 'n_estimators': 187, 'min_child_samples': 48, 'min_child_weight': 0.00025939116314485736, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.464712455344221e-05, 'reg_lambda': 1.634824674004718}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:26,900] Trial 252 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 296, 'max_depth': 117, 'learning_rate': 0.013781624024773679, 'n_estimators': 160, 'min_child_samples': 54, 'min_child_weight': 0.0002099178518583424, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3907331276861185e-05, 'reg_lambda': 1.0123100186812852}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,014] Trial 253 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 294, 'max_depth': 118, 'learning_rate': 0.014810977272192629, 'n_estimators': 162, 'min_child_samples': 52, 'min_child_weight': 0.012921214600313832, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3084364813051604e-05, 'reg_lambda': 1.1342120991917122}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,219] Trial 254 finished with value: 0.780204207675669 and parameters: {'num_leaves': 293, 'max_depth': 128, 'learning_rate': 0.026333627199070408, 'n_estimators': 469, 'min_child_samples': 55, 'min_child_weight': 0.02004497820397116, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.376232456967223e-05, 'reg_lambda': 1.1662215778215865}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,323] Trial 255 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 277, 'max_depth': 124, 'learning_rate': 0.013615574578679965, 'n_estimators': 174, 'min_child_samples': 57, 'min_child_weight': 0.7080616500994711, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2323451071298142e-05, 'reg_lambda': 2.0541411522448954}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,543] Trial 256 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 291, 'max_depth': 118, 'learning_rate': 0.039066878339351505, 'n_estimators': 198, 'min_child_samples': 11, 'min_child_weight': 0.00031512376902758846, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0357386401621233e-05, 'reg_lambda': 1.1475533682159627}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,634] Trial 257 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 263, 'max_depth': 122, 'learning_rate': 0.017370160338973997, 'n_estimators': 130, 'min_child_samples': 52, 'min_child_weight': 0.4396162887663014, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.684718951491322e-05, 'reg_lambda': 6.882242233880093}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,732] Trial 258 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 283, 'max_depth': 120, 'learning_rate': 0.02148861739029205, 'n_estimators': 155, 'min_child_samples': 49, 'min_child_weight': 0.0032184617276554664, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.233497787794564e-05, 'reg_lambda': 1.6684051424154165}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,814] Trial 259 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 301, 'max_depth': 116, 'learning_rate': 0.01286617212696459, 'n_estimators': 104, 'min_child_samples': 60, 'min_child_weight': 0.00021936072637942567, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.6116353375853437e-05, 'reg_lambda': 0.8846785828220601}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:27,926] Trial 260 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 269, 'max_depth': 117, 'learning_rate': 0.0360189473293386, 'n_estimators': 179, 'min_child_samples': 54, 'min_child_weight': 0.00026705694726045573, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.08701778473158674, 'reg_lambda': 1.0743435058909638}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,027] Trial 261 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 285, 'max_depth': 120, 'learning_rate': 0.01486028207004039, 'n_estimators': 141, 'min_child_samples': 50, 'min_child_weight': 0.00038130388312546343, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0341524502945513e-05, 'reg_lambda': 2.4009345548989565}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,113] Trial 262 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 298, 'max_depth': 115, 'learning_rate': 0.02684219782713282, 'n_estimators': 120, 'min_child_samples': 53, 'min_child_weight': 0.005538426424808821, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0836454207653312e-05, 'reg_lambda': 4.904778566134296}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,235] Trial 263 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 276, 'max_depth': 118, 'learning_rate': 0.055958745161677224, 'n_estimators': 165, 'min_child_samples': 56, 'min_child_weight': 0.00053408003804302, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4499384982804328e-05, 'reg_lambda': 0.008599383804902737}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,348] Trial 264 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 250, 'max_depth': 125, 'learning_rate': 0.010240180125240323, 'n_estimators': 203, 'min_child_samples': 59, 'min_child_weight': 0.007145685965989741, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 2.8094220837312943e-05, 'reg_lambda': 0.7657439799316953}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,475] Trial 265 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 248, 'max_depth': 125, 'learning_rate': 0.019330887856703952, 'n_estimators': 235, 'min_child_samples': 62, 'min_child_weight': 0.004307413427363683, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.382274856408891e-05, 'reg_lambda': 0.7671696096559099}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,595] Trial 266 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 255, 'max_depth': 123, 'learning_rate': 0.010885329845034956, 'n_estimators': 200, 'min_child_samples': 58, 'min_child_weight': 0.010091285116459136, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.194587375986536e-05, 'reg_lambda': 0.0006140182394727929}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,707] Trial 267 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 240, 'max_depth': 128, 'learning_rate': 0.013705267290447487, 'n_estimators': 224, 'min_child_samples': 59, 'min_child_weight': 0.012865380149245825, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.8871907513553075e-05, 'reg_lambda': 1.4032353926766485}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,828] Trial 268 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 223, 'max_depth': 113, 'learning_rate': 0.009184249411254501, 'n_estimators': 245, 'min_child_samples': 55, 'min_child_weight': 0.006994072130149329, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 2.771941428489325e-05, 'reg_lambda': 0.5663985888668956}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:28,973] Trial 269 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 259, 'max_depth': 114, 'learning_rate': 0.027847475013575533, 'n_estimators': 291, 'min_child_samples': 57, 'min_child_weight': 0.7687040126906982, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1.2859221456436317e-05, 'reg_lambda': 0.9960454714714884}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,098] Trial 270 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 266, 'max_depth': 87, 'learning_rate': 2.236188493071475e-08, 'n_estimators': 194, 'min_child_samples': 40, 'min_child_weight': 0.27755601117461015, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 3.536063500681749e-05, 'reg_lambda': 0.8017362624426425}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,454] Trial 271 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 205, 'max_depth': 52, 'learning_rate': 0.016013013019684042, 'n_estimators': 958, 'min_child_samples': 52, 'min_child_weight': 0.03110503232655218, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.662995646929458e-05, 'reg_lambda': 3.4375362621351866}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,561] Trial 272 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 290, 'max_depth': 111, 'learning_rate': 0.02078841450563732, 'n_estimators': 177, 'min_child_samples': 60, 'min_child_weight': 0.42810508530269176, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.613044619663736e-05, 'reg_lambda': 0.001190070456193834}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,656] Trial 273 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 133, 'max_depth': 116, 'learning_rate': 0.009793964009996506, 'n_estimators': 141, 'min_child_samples': 54, 'min_child_weight': 0.008645129672482868, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9466788399920933e-05, 'reg_lambda': 1.5025462885313292}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,744] Trial 274 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 280, 'max_depth': 124, 'learning_rate': 0.012724340644922671, 'n_estimators': 106, 'min_child_samples': 56, 'min_child_weight': 0.9993458660431916, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 1.4656499804739887e-05, 'reg_lambda': 0.6912305677040783}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:29,872] Trial 275 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 300, 'max_depth': 120, 'learning_rate': 0.03298822069399683, 'n_estimators': 202, 'min_child_samples': 49, 'min_child_weight': 0.022160611341727122, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0184234936193866e-05, 'reg_lambda': 1.0815572310012755}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,119] Trial 276 finished with value: 0.7893478279020448 and parameters: {'num_leaves': 181, 'max_depth': 108, 'learning_rate': 0.019483506910516254, 'n_estimators': 564, 'min_child_samples': 47, 'min_child_weight': 0.00032042031107869587, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 2.6989346173423733e-05, 'reg_lambda': 2.0845972152263803}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,236] Trial 277 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 252, 'max_depth': 113, 'learning_rate': 0.009615100193341332, 'n_estimators': 166, 'min_child_samples': 52, 'min_child_weight': 0.00022974689159079627, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.8929577412844385e-05, 'reg_lambda': 0.4484495692582035}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,336] Trial 278 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 271, 'max_depth': 117, 'learning_rate': 0.056884432082270654, 'n_estimators': 125, 'min_child_samples': 54, 'min_child_weight': 0.3452202614711977, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3282403577086581e-05, 'reg_lambda': 0.5735635742419091}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,414] Trial 279 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 288, 'max_depth': 126, 'learning_rate': 1.3586191165470516e-05, 'n_estimators': 82, 'min_child_samples': 59, 'min_child_weight': 0.5698732052674256, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.902324738081679e-05, 'reg_lambda': 1.2868559313833052}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,529] Trial 280 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 232, 'max_depth': 111, 'learning_rate': 0.013816519935555266, 'n_estimators': 155, 'min_child_samples': 50, 'min_child_weight': 0.00044104569597589426, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0106933845507087e-05, 'reg_lambda': 0.8703129887014986}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,638] Trial 281 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 303, 'max_depth': 82, 'learning_rate': 0.023417031483558486, 'n_estimators': 184, 'min_child_samples': 63, 'min_child_weight': 1.1857865744498438e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3916668592766674e-05, 'reg_lambda': 0.7337741711374338}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,767] Trial 282 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 263, 'max_depth': 115, 'learning_rate': 0.019118706208216117, 'n_estimators': 214, 'min_child_samples': 57, 'min_child_weight': 0.19977183831733658, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.505486823104396e-05, 'reg_lambda': 0.004272508858605494}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,870] Trial 283 finished with value: 0.828254477109439 and parameters: {'num_leaves': 276, 'max_depth': 94, 'learning_rate': 0.008201070625647141, 'n_estimators': 143, 'min_child_samples': 53, 'min_child_weight': 0.00015984473613863157, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5901402036661723e-05, 'reg_lambda': 1.763889041015418}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:30,952] Trial 284 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 293, 'max_depth': 119, 'learning_rate': 0.034714825791305075, 'n_estimators': 100, 'min_child_samples': 55, 'min_child_weight': 0.00029736423910090183, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.120028250748549e-05, 'reg_lambda': 1.0720939935574918}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,061] Trial 285 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 284, 'max_depth': 122, 'learning_rate': 0.012714669331415589, 'n_estimators': 172, 'min_child_samples': 51, 'min_child_weight': 0.2530036757779077, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3350617474938706e-05, 'reg_lambda': 0.3451414061306965}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,161] Trial 286 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 245, 'max_depth': 113, 'learning_rate': 0.015514398153323644, 'n_estimators': 125, 'min_child_samples': 52, 'min_child_weight': 0.012076142955877804, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 1.7266876327122616e-05, 'reg_lambda': 0.5053828761178553}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,265] Trial 287 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 306, 'max_depth': 109, 'learning_rate': 0.008572061739305286, 'n_estimators': 152, 'min_child_samples': 47, 'min_child_weight': 0.0002525583902352892, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1408815067691175e-05, 'reg_lambda': 1.356322449987918}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,381] Trial 288 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 272, 'max_depth': 115, 'learning_rate': 0.02640233248277414, 'n_estimators': 193, 'min_child_samples': 56, 'min_child_weight': 0.0003891825635578368, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.7867398697467045e-05, 'reg_lambda': 2.6632059183545147}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,485] Trial 289 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 255, 'max_depth': 117, 'learning_rate': 0.0183186839534172, 'n_estimators': 138, 'min_child_samples': 54, 'min_child_weight': 0.00019157128780919458, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.0936141033052825e-05, 'reg_lambda': 0.626016959517051}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,587] Trial 290 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 295, 'max_depth': 6, 'learning_rate': 0.04693326825264419, 'n_estimators': 221, 'min_child_samples': 44, 'min_child_weight': 0.00020316429296303898, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.43351437270601e-05, 'reg_lambda': 0.6251466350454022}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,680] Trial 291 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 348, 'max_depth': 118, 'learning_rate': 0.019866215309540438, 'n_estimators': 113, 'min_child_samples': 50, 'min_child_weight': 0.3749337244213991, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.862994268238931e-05, 'reg_lambda': 0.38582812335572314}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,761] Trial 292 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 369, 'max_depth': 121, 'learning_rate': 0.07495251355994557, 'n_estimators': 70, 'min_child_samples': 49, 'min_child_weight': 0.4693175174329685, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.876519579426171e-05, 'reg_lambda': 0.30857865928806116}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,872] Trial 293 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 346, 'max_depth': 118, 'learning_rate': 0.028599781703496877, 'n_estimators': 111, 'min_child_samples': 36, 'min_child_weight': 0.6318839835486288, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9122981469735613e-05, 'reg_lambda': 0.4241200556794623}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:31,958] Trial 294 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 355, 'max_depth': 119, 'learning_rate': 0.019778814543327607, 'n_estimators': 102, 'min_child_samples': 58, 'min_child_weight': 9.612228624402962e-05, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 4.7708816005480205e-05, 'reg_lambda': 0.23475953643243594}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,463] Trial 295 finished with value: 0.7620270354165186 and parameters: {'num_leaves': 494, 'max_depth': 125, 'learning_rate': 0.03690106773215164, 'n_estimators': 669, 'min_child_samples': 21, 'min_child_weight': 0.017173970313242103, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7510422952772414e-05, 'reg_lambda': 0.42697286352142794}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,551] Trial 296 finished with value: 0.828254477109439 and parameters: {'num_leaves': 359, 'max_depth': 122, 'learning_rate': 0.01984786965173982, 'n_estimators': 83, 'min_child_samples': 50, 'min_child_weight': 0.3871502640963489, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.4888690142905946e-05, 'reg_lambda': 0.5485142564941671}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,643] Trial 297 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 263, 'max_depth': 100, 'learning_rate': 0.02707010287085824, 'n_estimators': 122, 'min_child_samples': 46, 'min_child_weight': 0.00019378337945992924, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.4968199413291096e-05, 'reg_lambda': 0.3418715248586445}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,756] Trial 298 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 341, 'max_depth': 58, 'learning_rate': 0.014812130069327743, 'n_estimators': 174, 'min_child_samples': 61, 'min_child_weight': 0.00015789948799426305, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.194873089885387e-05, 'reg_lambda': 0.6045982336274729}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,845] Trial 299 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 281, 'max_depth': 117, 'learning_rate': 0.01643814324992257, 'n_estimators': 133, 'min_child_samples': 55, 'min_child_weight': 0.48727817297672477, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.18173815945913416, 'reg_lambda': 2.047550433568708}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:32,947] Trial 300 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 123, 'max_depth': 117, 'learning_rate': 0.041264812753686944, 'n_estimators': 167, 'min_child_samples': 55, 'min_child_weight': 0.7243562168068595, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.19800746323053836, 'reg_lambda': 2.6672768112923664}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,059] Trial 301 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 269, 'max_depth': 120, 'learning_rate': 0.019553897698486533, 'n_estimators': 194, 'min_child_samples': 59, 'min_child_weight': 0.524480353105821, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.04084422996220177, 'reg_lambda': 2.006305489388169}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,140] Trial 302 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 285, 'max_depth': 117, 'learning_rate': 0.027761351985721137, 'n_estimators': 92, 'min_child_samples': 57, 'min_child_weight': 0.0005531672250594362, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6351372162713112e-05, 'reg_lambda': 1.7550049535411267}. Best is trial 142 with value: 0.8332046332046333.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,236] Trial 303 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 350, 'max_depth': 116, 'learning_rate': 0.015429587069000146, 'n_estimators': 141, 'min_child_samples': 54, 'min_child_weight': 0.4607086976177821, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0992479570823494e-05, 'reg_lambda': 0.0023708890974515743}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,349] Trial 304 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 349, 'max_depth': 115, 'learning_rate': 0.017596727115872964, 'n_estimators': 135, 'min_child_samples': 54, 'min_child_weight': 0.8239771379818307, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9724843975086506e-05, 'reg_lambda': 0.0033911599047681306}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,460] Trial 305 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 351, 'max_depth': 116, 'learning_rate': 2.1518736738246692e-07, 'n_estimators': 155, 'min_child_samples': 54, 'min_child_weight': 0.6858775993832885, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2415436939698962e-05, 'reg_lambda': 0.0052823237075418}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,743] Trial 306 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 343, 'max_depth': 123, 'learning_rate': 0.010968971318013478, 'n_estimators': 736, 'min_child_samples': 56, 'min_child_weight': 0.963143714991483, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8415894823330866e-05, 'reg_lambda': 0.0028642951578962015}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,852] Trial 307 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 364, 'max_depth': 111, 'learning_rate': 0.02310648888254541, 'n_estimators': 180, 'min_child_samples': 58, 'min_child_weight': 0.8705994689882263, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3367575724946931e-05, 'reg_lambda': 0.0017635925983779553}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:33,992] Trial 308 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 164, 'max_depth': 115, 'learning_rate': 0.055259458340428565, 'n_estimators': 242, 'min_child_samples': 52, 'min_child_weight': 0.0004308380044801341, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4909043165484846e-05, 'reg_lambda': 0.0023615530439233413}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,121] Trial 309 finished with value: 0.7250130439319629 and parameters: {'num_leaves': 373, 'max_depth': 119, 'learning_rate': 0.7611294024309405, 'n_estimators': 202, 'min_child_samples': 54, 'min_child_weight': 0.00032394489872858754, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.2435506945398336e-05, 'reg_lambda': 0.003459532946531737}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,264] Trial 310 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 354, 'max_depth': 114, 'learning_rate': 0.015430961448266113, 'n_estimators': 262, 'min_child_samples': 52, 'min_child_weight': 0.0025578992074688713, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 1.4926803072616393e-05, 'reg_lambda': 0.0008814560590563157}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,365] Trial 311 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 340, 'max_depth': 108, 'learning_rate': 0.03530220379430792, 'n_estimators': 158, 'min_child_samples': 56, 'min_child_weight': 0.7274829224491364, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9683778183488613e-05, 'reg_lambda': 3.956117020158756}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,515] Trial 312 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 363, 'max_depth': 120, 'learning_rate': 0.007805594823381932, 'n_estimators': 335, 'min_child_samples': 60, 'min_child_weight': 0.00021763931053417478, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.610764596914045e-05, 'reg_lambda': 0.0012545632879675053}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,619] Trial 313 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 348, 'max_depth': 111, 'learning_rate': 0.011439146333418686, 'n_estimators': 137, 'min_child_samples': 54, 'min_child_weight': 0.00045318452134511934, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2713770529946114e-05, 'reg_lambda': 0.0019439053659940642}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,750] Trial 314 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 256, 'max_depth': 115, 'learning_rate': 0.023797988625502572, 'n_estimators': 215, 'min_child_samples': 51, 'min_child_weight': 0.00026285749203421553, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.437769844953346e-05, 'reg_lambda': 0.004304988967918539}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,844] Trial 315 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 228, 'max_depth': 117, 'learning_rate': 0.016202344251736583, 'n_estimators': 118, 'min_child_samples': 53, 'min_child_weight': 0.0003417886187862924, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.779595388510749e-05, 'reg_lambda': 0.42026605608818657}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:34,992] Trial 316 finished with value: 0.805472173852318 and parameters: {'num_leaves': 337, 'max_depth': 124, 'learning_rate': 0.008141514340443459, 'n_estimators': 180, 'min_child_samples': 29, 'min_child_weight': 0.8348698770778743, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.296563831517742e-05, 'reg_lambda': 0.27883055879265534}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,141] Trial 317 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 346, 'max_depth': 121, 'learning_rate': 0.019265330755286785, 'n_estimators': 404, 'min_child_samples': 56, 'min_child_weight': 0.0001389560434315738, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.791284546361974, 'reg_lambda': 0.002493129101939894}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,255] Trial 318 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 381, 'max_depth': 113, 'learning_rate': 0.011504168911354116, 'n_estimators': 148, 'min_child_samples': 57, 'min_child_weight': 0.0006128778061402504, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3893852277955417e-05, 'reg_lambda': 0.6971170232233488}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,358] Trial 319 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 361, 'max_depth': 104, 'learning_rate': 0.0005925136607317362, 'n_estimators': 165, 'min_child_samples': 62, 'min_child_weight': 0.5862007167929095, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.9281288128773266e-05, 'reg_lambda': 1.1163549337318026}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,482] Trial 320 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 310, 'max_depth': 127, 'learning_rate': 0.03705356500121731, 'n_estimators': 193, 'min_child_samples': 54, 'min_child_weight': 0.39733745346430677, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9164756115424956e-05, 'reg_lambda': 1.3630959449147821}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,584] Trial 321 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 331, 'max_depth': 119, 'learning_rate': 0.023784032624164637, 'n_estimators': 113, 'min_child_samples': 52, 'min_child_weight': 0.00019748751709738023, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8711530221337007e-05, 'reg_lambda': 0.15682000315744204}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,679] Trial 322 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 295, 'max_depth': 110, 'learning_rate': 0.01326632679534689, 'n_estimators': 137, 'min_child_samples': 59, 'min_child_weight': 0.00035669109260860825, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4621100055919217e-05, 'reg_lambda': 0.5276293241650752}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:35,790] Trial 323 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 213, 'max_depth': 107, 'learning_rate': 0.008626352838501793, 'n_estimators': 165, 'min_child_samples': 50, 'min_child_weight': 0.00024256484930307716, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.019877951379398e-05, 'reg_lambda': 0.9325668519743935}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,092] Trial 324 finished with value: 0.77581499024798 and parameters: {'num_leaves': 241, 'max_depth': 113, 'learning_rate': 0.031224009986053416, 'n_estimators': 825, 'min_child_samples': 55, 'min_child_weight': 0.0002881804722931864, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.0383360466139137e-05, 'reg_lambda': 0.37514452623542}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,177] Trial 325 finished with value: 0.828254477109439 and parameters: {'num_leaves': 266, 'max_depth': 116, 'learning_rate': 0.016640231311726334, 'n_estimators': 68, 'min_child_samples': 53, 'min_child_weight': 0.32016083850528554, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2822317564010604e-05, 'reg_lambda': 0.7181556697430282}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,338] Trial 326 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 250, 'max_depth': 118, 'learning_rate': 0.01148738044854927, 'n_estimators': 364, 'min_child_samples': 57, 'min_child_weight': 0.58351931691217, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.601703582719059e-05, 'reg_lambda': 1.5098381286831353}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,486] Trial 327 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 355, 'max_depth': 122, 'learning_rate': 0.027060977185933477, 'n_estimators': 229, 'min_child_samples': 48, 'min_child_weight': 0.0005070155979083962, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.641217683535304e-05, 'reg_lambda': 0.48449771096503813}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,600] Trial 328 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 277, 'max_depth': 114, 'learning_rate': 0.018228653268539303, 'n_estimators': 182, 'min_child_samples': 51, 'min_child_weight': 0.00016548951647966313, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 6.324106121496001e-05, 'reg_lambda': 1.081123814538736}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,694] Trial 329 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 290, 'max_depth': 111, 'learning_rate': 0.04398365671537884, 'n_estimators': 132, 'min_child_samples': 55, 'min_child_weight': 0.00011643663084095126, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.37452238654954e-05, 'reg_lambda': 9.52336243292048}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,786] Trial 330 finished with value: 0.8036745872848512 and parameters: {'num_leaves': 259, 'max_depth': 118, 'learning_rate': 0.007245843935069355, 'n_estimators': 91, 'min_child_samples': 58, 'min_child_weight': 0.00036459631966241136, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0329450914694447e-05, 'reg_lambda': 0.740278885088856}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:36,898] Trial 331 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 372, 'max_depth': 115, 'learning_rate': 0.012823684938240239, 'n_estimators': 152, 'min_child_samples': 53, 'min_child_weight': 0.005455345445061714, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7472595605152387e-05, 'reg_lambda': 0.25745910091035584}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,020] Trial 332 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 304, 'max_depth': 19, 'learning_rate': 0.010228416382686798, 'n_estimators': 203, 'min_child_samples': 38, 'min_child_weight': 0.00021620887569355861, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8603686206884247e-05, 'reg_lambda': 5.503975345795583}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,132] Trial 333 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 272, 'max_depth': 110, 'learning_rate': 0.013154306100884389, 'n_estimators': 151, 'min_child_samples': 53, 'min_child_weight': 0.0037092877479139672, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8108170822276e-05, 'reg_lambda': 0.28274868248235535}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,249] Trial 334 finished with value: 0.828254477109439 and parameters: {'num_leaves': 375, 'max_depth': 108, 'learning_rate': 0.006788519473419979, 'n_estimators': 161, 'min_child_samples': 52, 'min_child_weight': 0.004080650989096958, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7902968540394698e-05, 'reg_lambda': 0.22148535148066947}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,389] Trial 335 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 443, 'max_depth': 110, 'learning_rate': 0.012644813238287266, 'n_estimators': 176, 'min_child_samples': 56, 'min_child_weight': 0.0035998906426494867, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3521659803976708e-05, 'reg_lambda': 0.16820919585703403}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,500] Trial 336 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 270, 'max_depth': 106, 'learning_rate': 0.008871028122111182, 'n_estimators': 157, 'min_child_samples': 53, 'min_child_weight': 0.003265995620068194, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.144194751810441e-05, 'reg_lambda': 0.20133938981563038}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,622] Trial 337 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 284, 'max_depth': 112, 'learning_rate': 0.012098039376866375, 'n_estimators': 199, 'min_child_samples': 59, 'min_child_weight': 0.00640355953584774, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.6252086695604583e-05, 'reg_lambda': 0.3162357677242741}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,737] Trial 338 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 146, 'max_depth': 114, 'learning_rate': 0.0001703609336975655, 'n_estimators': 177, 'min_child_samples': 55, 'min_child_weight': 0.004742237577689435, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2063287636154453e-05, 'reg_lambda': 0.27171494638728655}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,852] Trial 339 finished with value: 0.828254477109439 and parameters: {'num_leaves': 371, 'max_depth': 108, 'learning_rate': 0.006911117985518617, 'n_estimators': 149, 'min_child_samples': 51, 'min_child_weight': 0.005920470730700332, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2343878727804099e-05, 'reg_lambda': 1.5039251139171659}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:37,984] Trial 340 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 298, 'max_depth': 111, 'learning_rate': 0.014612462172885513, 'n_estimators': 216, 'min_child_samples': 53, 'min_child_weight': 0.008471142077335507, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0102426570935319e-05, 'reg_lambda': 0.015265297879957016}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,101] Trial 341 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 98, 'max_depth': 104, 'learning_rate': 0.02456862531329913, 'n_estimators': 193, 'min_child_samples': 61, 'min_child_weight': 0.0050936953809262745, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.682472751173918e-05, 'reg_lambda': 0.11165110018245747}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,208] Trial 342 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 279, 'max_depth': 115, 'learning_rate': 0.005312116658327923, 'n_estimators': 150, 'min_child_samples': 57, 'min_child_weight': 0.00308567262669545, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6821259708335807e-05, 'reg_lambda': 3.3685527002291225}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,326] Trial 343 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 290, 'max_depth': 113, 'learning_rate': 0.009436521269654883, 'n_estimators': 171, 'min_child_samples': 54, 'min_child_weight': 0.006798236761724743, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.9757527110381347e-05, 'reg_lambda': 0.0015422837178232598}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,426] Trial 344 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 406, 'max_depth': 110, 'learning_rate': 0.013781790938651476, 'n_estimators': 123, 'min_child_samples': 49, 'min_child_weight': 0.004847260204745198, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9650543965372397e-05, 'reg_lambda': 2.267212806295404}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,546] Trial 345 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 387, 'max_depth': 125, 'learning_rate': 0.09433177056577056, 'n_estimators': 142, 'min_child_samples': 42, 'min_child_weight': 0.007112422793022407, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5025618918916009e-05, 'reg_lambda': 1.293068589362874}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,673] Trial 346 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 311, 'max_depth': 115, 'learning_rate': 0.02996813703389284, 'n_estimators': 190, 'min_child_samples': 52, 'min_child_weight': 0.00906202262484273, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2258723932816143e-05, 'reg_lambda': 0.003035960638333086}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,793] Trial 347 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 273, 'max_depth': 112, 'learning_rate': 2.5545429831185988e-05, 'n_estimators': 224, 'min_child_samples': 57, 'min_child_weight': 0.0026791168266605296, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.210900571948183e-05, 'reg_lambda': 0.9238619333089061}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:38,904] Trial 348 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 363, 'max_depth': 128, 'learning_rate': 2.191229841441334e-06, 'n_estimators': 165, 'min_child_samples': 55, 'min_child_weight': 0.0038349015697131577, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.475366038232351e-05, 'reg_lambda': 0.2307592468957209}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,020] Trial 349 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 304, 'max_depth': 109, 'learning_rate': 0.018020048499940863, 'n_estimators': 141, 'min_child_samples': 51, 'min_child_weight': 0.0006907070182531285, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5689213633509166e-05, 'reg_lambda': 0.0003777760412022342}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,134] Trial 350 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 304, 'max_depth': 106, 'learning_rate': 0.05061818077767725, 'n_estimators': 129, 'min_child_samples': 50, 'min_child_weight': 0.000705009025494047, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.402836496137606e-05, 'reg_lambda': 0.13314678432283236}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,226] Trial 351 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 315, 'max_depth': 102, 'learning_rate': 0.020871130560906018, 'n_estimators': 106, 'min_child_samples': 48, 'min_child_weight': 0.0005006666277614418, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.018573346955525e-05, 'reg_lambda': 0.29220153626706763}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,330] Trial 352 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 324, 'max_depth': 103, 'learning_rate': 0.023296097499890853, 'n_estimators': 98, 'min_child_samples': 50, 'min_child_weight': 0.0006786243702265758, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.1585455824531088e-05, 'reg_lambda': 0.000525811518865158}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,437] Trial 353 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 315, 'max_depth': 108, 'learning_rate': 0.03859562725585097, 'n_estimators': 126, 'min_child_samples': 48, 'min_child_weight': 0.0005210294779251171, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0454940061242901e-05, 'reg_lambda': 0.19219784097606235}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,532] Trial 354 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 329, 'max_depth': 109, 'learning_rate': 0.01939219783194392, 'n_estimators': 107, 'min_child_samples': 47, 'min_child_weight': 0.0010594962793747963, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8224039628604977e-05, 'reg_lambda': 0.30670003439993765}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,626] Trial 355 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 331, 'max_depth': 106, 'learning_rate': 0.021625208169172738, 'n_estimators': 51, 'min_child_samples': 47, 'min_child_weight': 0.0004629831594496576, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7926523275633382e-05, 'reg_lambda': 0.2685638928282668}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,727] Trial 356 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 328, 'max_depth': 109, 'learning_rate': 4.828924267578953e-06, 'n_estimators': 86, 'min_child_samples': 45, 'min_child_weight': 0.0014753910764326759, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2298019316378496e-05, 'reg_lambda': 0.011256831851923334}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:39,827] Trial 357 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 338, 'max_depth': 97, 'learning_rate': 0.031292479037086346, 'n_estimators': 102, 'min_child_samples': 46, 'min_child_weight': 0.0010366260538478495, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7294857417999557e-05, 'reg_lambda': 0.0003744933642751983}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,090] Trial 358 finished with value: 0.7530469235454438 and parameters: {'num_leaves': 324, 'max_depth': 109, 'learning_rate': 0.05387913763904776, 'n_estimators': 513, 'min_child_samples': 43, 'min_child_weight': 0.0011186211290564912, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5298531224255364e-05, 'reg_lambda': 0.3098539273675042}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,170] Trial 359 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 310, 'max_depth': 106, 'learning_rate': 0.01896327147819407, 'n_estimators': 65, 'min_child_samples': 48, 'min_child_weight': 0.0007972541713668283, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0009195228835653e-05, 'reg_lambda': 0.0007515162984260084}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,264] Trial 360 finished with value: 0.8061567358864657 and parameters: {'num_leaves': 113, 'max_depth': 113, 'learning_rate': 0.029080386434847283, 'n_estimators': 107, 'min_child_samples': 45, 'min_child_weight': 0.0005438005462835094, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7542934385454544e-05, 'reg_lambda': 0.17733352449788353}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,376] Trial 361 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 340, 'max_depth': 99, 'learning_rate': 0.017926042935315606, 'n_estimators': 114, 'min_child_samples': 47, 'min_child_weight': 0.0006407665434013564, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.216442253450014e-05, 'reg_lambda': 0.24222574410858488}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,448] Trial 362 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 344, 'max_depth': 97, 'learning_rate': 7.166983747476709e-05, 'n_estimators': 20, 'min_child_samples': 47, 'min_child_weight': 0.0008375259214682461, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0915259999377167e-05, 'reg_lambda': 0.23656908273503385}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,547] Trial 363 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 339, 'max_depth': 103, 'learning_rate': 0.01704067690237797, 'n_estimators': 84, 'min_child_samples': 42, 'min_child_weight': 0.0009024367687678109, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.003148538988866354, 'reg_lambda': 0.00013668441100539634}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,659] Trial 364 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 332, 'max_depth': 110, 'learning_rate': 0.02495589073545682, 'n_estimators': 119, 'min_child_samples': 45, 'min_child_weight': 0.0006253935246112215, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5652591234454595e-05, 'reg_lambda': 0.007876586444451281}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,742] Trial 365 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 350, 'max_depth': 106, 'learning_rate': 0.07495339372838639, 'n_estimators': 73, 'min_child_samples': 49, 'min_child_weight': 0.0006676874922972738, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7972110935204923e-05, 'reg_lambda': 0.31694766590095996}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,843] Trial 366 finished with value: 0.788723176958471 and parameters: {'num_leaves': 320, 'max_depth': 103, 'learning_rate': 0.040217347207963, 'n_estimators': 115, 'min_child_samples': 44, 'min_child_weight': 0.0005844544565405005, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.413679585146498e-05, 'reg_lambda': 0.02798014488318314}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:40,939] Trial 367 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 335, 'max_depth': 93, 'learning_rate': 0.01121462447026143, 'n_estimators': 87, 'min_child_samples': 48, 'min_child_weight': 0.0008524268875625081, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1406201922976137e-05, 'reg_lambda': 0.1372606398899977}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,012] Trial 368 finished with value: 0.6836194302410519 and parameters: {'num_leaves': 2, 'max_depth': 108, 'learning_rate': 0.016200237824584515, 'n_estimators': 106, 'min_child_samples': 50, 'min_child_weight': 0.00043428188531178, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.008123517012431495, 'reg_lambda': 0.23409845923732492}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,131] Trial 369 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 357, 'max_depth': 88, 'learning_rate': 0.007867582462031479, 'n_estimators': 136, 'min_child_samples': 40, 'min_child_weight': 0.0005762099116077876, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.605771512365182e-05, 'reg_lambda': 0.0003179586457142792}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,230] Trial 370 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 322, 'max_depth': 101, 'learning_rate': 0.022206886368294265, 'n_estimators': 105, 'min_child_samples': 47, 'min_child_weight': 0.00043365098346490093, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.023872992424024398, 'reg_lambda': 0.17534553216469687}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,301] Trial 371 finished with value: 0.8111432515980821 and parameters: {'num_leaves': 315, 'max_depth': 100, 'learning_rate': 0.012296602524035846, 'n_estimators': 42, 'min_child_samples': 51, 'min_child_weight': 0.0012913655003591437, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0195848973556169e-05, 'reg_lambda': 0.3922503197469218}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,413] Trial 372 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 345, 'max_depth': 111, 'learning_rate': 0.03625165262056056, 'n_estimators': 144, 'min_child_samples': 49, 'min_child_weight': 0.0006497433662891517, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5553520981473282e-05, 'reg_lambda': 0.09498061796732934}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,536] Trial 373 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 308, 'max_depth': 14, 'learning_rate': 0.01858515756163421, 'n_estimators': 122, 'min_child_samples': 52, 'min_child_weight': 0.001038273526082043, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.051794119184818e-05, 'reg_lambda': 0.3777290452295167}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,649] Trial 374 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 364, 'max_depth': 109, 'learning_rate': 0.005299247283935803, 'n_estimators': 147, 'min_child_samples': 46, 'min_child_weight': 0.00039345953735281906, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.109058559691706e-05, 'reg_lambda': 0.3552217240298678}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,738] Trial 375 finished with value: 0.8322757457573522 and parameters: {'num_leaves': 327, 'max_depth': 112, 'learning_rate': 0.009094293813433081, 'n_estimators': 97, 'min_child_samples': 53, 'min_child_weight': 0.0004954573065404991, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.358151242302713e-05, 'reg_lambda': 0.28124560210228955}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,816] Trial 376 finished with value: 0.7982616364754621 and parameters: {'num_leaves': 328, 'max_depth': 112, 'learning_rate': 0.007764777153496611, 'n_estimators': 66, 'min_child_samples': 54, 'min_child_weight': 0.8136699214415504, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0014512448324285158, 'reg_lambda': 0.263264779248783}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:41,902] Trial 377 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 337, 'max_depth': 98, 'learning_rate': 0.009915042866454365, 'n_estimators': 90, 'min_child_samples': 50, 'min_child_weight': 0.0007534183874456915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2089012172547405e-05, 'reg_lambda': 0.0002201817736242137}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,002] Trial 378 finished with value: 0.7532904371869753 and parameters: {'num_leaves': 316, 'max_depth': 113, 'learning_rate': 0.23013232444571674, 'n_estimators': 97, 'min_child_samples': 53, 'min_child_weight': 0.0004645172220978473, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4146798634015787e-05, 'reg_lambda': 0.20099103641740573}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,083] Trial 379 finished with value: 0.7969915828977976 and parameters: {'num_leaves': 329, 'max_depth': 106, 'learning_rate': 0.006896010004289464, 'n_estimators': 69, 'min_child_samples': 56, 'min_child_weight': 0.16672314741344782, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7408196826087662e-05, 'reg_lambda': 0.2642036020062712}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,184] Trial 380 finished with value: 0.7927182029735046 and parameters: {'num_leaves': 352, 'max_depth': 110, 'learning_rate': 0.004252964653351697, 'n_estimators': 117, 'min_child_samples': 51, 'min_child_weight': 2.5134923327830477e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4506252237294775e-05, 'reg_lambda': 0.4581510650208058}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,283] Trial 381 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 310, 'max_depth': 114, 'learning_rate': 0.0127299581945736, 'n_estimators': 130, 'min_child_samples': 55, 'min_child_weight': 0.0005700567862918807, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.164716994814157e-05, 'reg_lambda': 0.28251985199547}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,376] Trial 382 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 341, 'max_depth': 112, 'learning_rate': 0.02668139522317554, 'n_estimators': 106, 'min_child_samples': 43, 'min_child_weight': 0.0007548154536117307, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.8080412935569144e-05, 'reg_lambda': 7.29928219166348}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,465] Trial 383 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 374, 'max_depth': 91, 'learning_rate': 0.010647223360622687, 'n_estimators': 82, 'min_child_samples': 48, 'min_child_weight': 0.9923372616543824, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5526979272432417e-05, 'reg_lambda': 0.13773631436734662}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,578] Trial 384 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 302, 'max_depth': 105, 'learning_rate': 0.014823494022045764, 'n_estimators': 129, 'min_child_samples': 53, 'min_child_weight': 0.0005127825191299015, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4381309229329863e-05, 'reg_lambda': 0.4509934245199647}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,679] Trial 385 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 300, 'max_depth': 102, 'learning_rate': 0.0003939373817138485, 'n_estimators': 120, 'min_child_samples': 51, 'min_child_weight': 0.000882998257239932, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2649603318387906e-05, 'reg_lambda': 0.488389886585601}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,785] Trial 386 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 322, 'max_depth': 100, 'learning_rate': 0.0060312611268487715, 'n_estimators': 95, 'min_child_samples': 53, 'min_child_weight': 0.0005009154714596522, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2739590651264026e-05, 'reg_lambda': 0.4808193966428218}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,898] Trial 387 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 309, 'max_depth': 105, 'learning_rate': 0.01526620350546633, 'n_estimators': 137, 'min_child_samples': 50, 'min_child_weight': 0.24206018872739363, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6684158277823673e-05, 'reg_lambda': 0.35695743540059927}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:42,972] Trial 388 finished with value: 0.8098436842623904 and parameters: {'num_leaves': 330, 'max_depth': 104, 'learning_rate': 0.01045143655078408, 'n_estimators': 42, 'min_child_samples': 53, 'min_child_weight': 0.6161976237066036, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0484338787918604e-05, 'reg_lambda': 0.0054643735018425526}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,071] Trial 389 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 317, 'max_depth': 107, 'learning_rate': 0.02711764884098227, 'n_estimators': 117, 'min_child_samples': 57, 'min_child_weight': 0.4964878135152881, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8693215711673772e-05, 'reg_lambda': 0.5537761302117912}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,187] Trial 390 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 356, 'max_depth': 108, 'learning_rate': 0.0077271253443408, 'n_estimators': 145, 'min_child_samples': 46, 'min_child_weight': 0.0019896856439387653, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3923099648278783e-05, 'reg_lambda': 0.38016765153861326}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,296] Trial 391 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 298, 'max_depth': 115, 'learning_rate': 0.021121495573505438, 'n_estimators': 105, 'min_child_samples': 48, 'min_child_weight': 0.0006945844032875045, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0224290866861118e-05, 'reg_lambda': 0.0010966418552721226}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,387] Trial 392 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 321, 'max_depth': 115, 'learning_rate': 0.04656982388252581, 'n_estimators': 77, 'min_child_samples': 48, 'min_child_weight': 0.0012156432687716722, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0243391232814058e-05, 'reg_lambda': 0.00039539460080872073}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,477] Trial 393 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 301, 'max_depth': 115, 'learning_rate': 0.02306917033428182, 'n_estimators': 56, 'min_child_samples': 49, 'min_child_weight': 0.0007581218521733227, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005955611009704498, 'reg_lambda': 0.001096831150553991}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,578] Trial 394 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 302, 'max_depth': 101, 'learning_rate': 0.036001757351525894, 'n_estimators': 99, 'min_child_samples': 47, 'min_child_weight': 0.0006155909601420686, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.073390932286357e-05, 'reg_lambda': 0.000737274639736394}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,680] Trial 395 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 337, 'max_depth': 115, 'learning_rate': 0.019902060270986722, 'n_estimators': 108, 'min_child_samples': 44, 'min_child_weight': 0.0009772097169727938, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0492885405637546e-05, 'reg_lambda': 0.0013864605910638389}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,786] Trial 396 finished with value: 0.798311750118979 and parameters: {'num_leaves': 293, 'max_depth': 109, 'learning_rate': 0.06261302448115585, 'n_estimators': 131, 'min_child_samples': 50, 'min_child_weight': 0.0006498125763490227, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0139716213882568e-05, 'reg_lambda': 0.00102915152322504}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,902] Trial 397 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 308, 'max_depth': 113, 'learning_rate': 0.014968065891443361, 'n_estimators': 124, 'min_child_samples': 52, 'min_child_weight': 0.7510837579701028, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.579950257119892e-05, 'reg_lambda': 0.3142619261430734}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:43,992] Trial 398 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 343, 'max_depth': 115, 'learning_rate': 0.02955737339549952, 'n_estimators': 83, 'min_child_samples': 46, 'min_child_weight': 0.10810019923507498, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2653688559139635e-05, 'reg_lambda': 0.0023651001146238046}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,235] Trial 399 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 380, 'max_depth': 104, 'learning_rate': 0.009528891120044758, 'n_estimators': 439, 'min_child_samples': 41, 'min_child_weight': 0.0009017941264070005, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5986943498645462e-05, 'reg_lambda': 0.43190116015416047}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,346] Trial 400 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 325, 'max_depth': 112, 'learning_rate': 0.021429292542941434, 'n_estimators': 148, 'min_child_samples': 51, 'min_child_weight': 0.19373527460585488, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 9.109066971206817e-05, 'reg_lambda': 0.0019109653083121403}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,617] Trial 401 finished with value: 0.7920975249219525 and parameters: {'num_leaves': 366, 'max_depth': 107, 'learning_rate': 0.014208658769298225, 'n_estimators': 110, 'min_child_samples': 5, 'min_child_weight': 0.0005133457838323187, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.105824910918753e-05, 'reg_lambda': 0.004149902744946042}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,704] Trial 402 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 351, 'max_depth': 116, 'learning_rate': 0.031084820292266307, 'n_estimators': 92, 'min_child_samples': 54, 'min_child_weight': 0.3044524616097946, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.3898603624989488e-05, 'reg_lambda': 0.0005417283768759816}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,809] Trial 403 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 313, 'max_depth': 110, 'learning_rate': 0.018797341108538822, 'n_estimators': 131, 'min_child_samples': 48, 'min_child_weight': 0.4620071516713733, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0094496646417602e-05, 'reg_lambda': 0.2989654230930739}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:44,946] Trial 404 finished with value: 0.828254477109439 and parameters: {'num_leaves': 287, 'max_depth': 98, 'learning_rate': 0.005383840683551255, 'n_estimators': 155, 'min_child_samples': 55, 'min_child_weight': 0.0006586763474631034, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9312642107764112e-05, 'reg_lambda': 0.4958326773823057}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,028] Trial 405 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 86, 'max_depth': 113, 'learning_rate': 6.520449117053031e-07, 'n_estimators': 63, 'min_child_samples': 52, 'min_child_weight': 0.0005279893621462382, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.060806798447084e-05, 'reg_lambda': 0.2207407380498457}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,127] Trial 406 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 300, 'max_depth': 117, 'learning_rate': 0.008489708594935646, 'n_estimators': 112, 'min_child_samples': 50, 'min_child_weight': 0.0007454183293726093, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7062300553423665e-05, 'reg_lambda': 0.17504792012362544}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,237] Trial 407 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 334, 'max_depth': 24, 'learning_rate': 0.013004187657730811, 'n_estimators': 153, 'min_child_samples': 53, 'min_child_weight': 0.001547844201017915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4509955489676558e-05, 'reg_lambda': 0.3144678001682098}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,343] Trial 408 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 398, 'max_depth': 109, 'learning_rate': 0.02099237764493631, 'n_estimators': 131, 'min_child_samples': 44, 'min_child_weight': 0.8297653082122193, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4083305246012901e-05, 'reg_lambda': 0.0069796792839822985}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,461] Trial 409 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 315, 'max_depth': 105, 'learning_rate': 0.04282707924614024, 'n_estimators': 171, 'min_child_samples': 49, 'min_child_weight': 0.6421743718729688, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.66664710500847e-05, 'reg_lambda': 0.0002888891370535813}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,553] Trial 410 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 18, 'max_depth': 112, 'learning_rate': 0.011830234769530965, 'n_estimators': 95, 'min_child_samples': 55, 'min_child_weight': 0.04471145497195504, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.392401611217313e-05, 'reg_lambda': 0.6051817149160755}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,659] Trial 411 finished with value: 0.8122888649204439 and parameters: {'num_leaves': 294, 'max_depth': 119, 'learning_rate': 0.003936078217628236, 'n_estimators': 142, 'min_child_samples': 51, 'min_child_weight': 0.0003102041983563864, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0443490306729625e-05, 'reg_lambda': 0.3925313045789934}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,762] Trial 412 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 357, 'max_depth': 115, 'learning_rate': 0.028263323680769625, 'n_estimators': 119, 'min_child_samples': 53, 'min_child_weight': 0.384852618391038, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4447905257777735e-05, 'reg_lambda': 0.25064595316369864}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,843] Trial 413 finished with value: 0.7982616364754621 and parameters: {'num_leaves': 345, 'max_depth': 108, 'learning_rate': 0.007427225646388845, 'n_estimators': 76, 'min_child_samples': 56, 'min_child_weight': 0.00045268655956648873, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.549391467674625, 'reg_lambda': 0.5288183209832348}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:45,967] Trial 414 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 325, 'max_depth': 102, 'learning_rate': 0.017277118679032342, 'n_estimators': 163, 'min_child_samples': 47, 'min_child_weight': 0.2392108801669111, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0065520992763568e-05, 'reg_lambda': 0.0031331191475778017}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,072] Trial 415 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 333, 'max_depth': 111, 'learning_rate': 0.01031342285128688, 'n_estimators': 130, 'min_child_samples': 49, 'min_child_weight': 0.0005776837156772658, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.452331163359534e-05, 'reg_lambda': 0.36151407048761935}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,170] Trial 416 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 288, 'max_depth': 116, 'learning_rate': 0.015640994081380158, 'n_estimators': 105, 'min_child_samples': 54, 'min_child_weight': 0.0010308343166107734, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8024454395645827e-05, 'reg_lambda': 0.6584230846867543}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,295] Trial 417 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 304, 'max_depth': 113, 'learning_rate': 0.022885610994512962, 'n_estimators': 174, 'min_child_samples': 51, 'min_child_weight': 0.5113268624162335, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.0010696291708770652, 'reg_lambda': 0.00016868344495671875}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,550] Trial 418 finished with value: 0.7668475898578992 and parameters: {'num_leaves': 317, 'max_depth': 107, 'learning_rate': 0.05946518899658929, 'n_estimators': 603, 'min_child_samples': 56, 'min_child_weight': 0.0003319234015944915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8297764538275405e-05, 'reg_lambda': 0.0007376956871327731}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,670] Trial 419 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 196, 'max_depth': 95, 'learning_rate': 0.03571989255014931, 'n_estimators': 148, 'min_child_samples': 53, 'min_child_weight': 0.00044284552715971267, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3677558084741067e-05, 'reg_lambda': 0.1749351026420185}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,745] Trial 420 finished with value: 0.7982033166125134 and parameters: {'num_leaves': 62, 'max_depth': 119, 'learning_rate': 0.008931304194243034, 'n_estimators': 35, 'min_child_samples': 51, 'min_child_weight': 0.0007504893172891197, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3679879742648143e-05, 'reg_lambda': 0.00044020164575797144}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,869] Trial 421 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 368, 'max_depth': 110, 'learning_rate': 0.012952297463268194, 'n_estimators': 133, 'min_child_samples': 46, 'min_child_weight': 0.3165674677937302, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2533380823567142e-05, 'reg_lambda': 0.0015105385118753688}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:46,960] Trial 422 finished with value: 0.8166014877049655 and parameters: {'num_leaves': 341, 'max_depth': 116, 'learning_rate': 0.006092388421030392, 'n_estimators': 88, 'min_child_samples': 48, 'min_child_weight': 0.16120408840770126, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7206128483576657e-05, 'reg_lambda': 0.4458483197646213}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,072] Trial 423 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 298, 'max_depth': 113, 'learning_rate': 0.02239966221231044, 'n_estimators': 158, 'min_child_samples': 55, 'min_child_weight': 0.0003472220476727103, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.203644069736437e-05, 'reg_lambda': 0.018839032824973283}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,192] Trial 424 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 307, 'max_depth': 117, 'learning_rate': 0.015578315715097983, 'n_estimators': 179, 'min_child_samples': 58, 'min_child_weight': 0.6652626880328882, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.015522424239489584, 'reg_lambda': 0.800721211947067}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,307] Trial 425 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 355, 'max_depth': 63, 'learning_rate': 0.028669689228546687, 'n_estimators': 111, 'min_child_samples': 53, 'min_child_weight': 0.0005391226222511544, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.353286617609202e-05, 'reg_lambda': 0.31969084264951103}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,385] Trial 426 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 282, 'max_depth': 104, 'learning_rate': 0.0009239104730868332, 'n_estimators': 58, 'min_child_samples': 50, 'min_child_weight': 0.853292446190474, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1264634564143075e-05, 'reg_lambda': 4.909927254648466}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,485] Trial 427 finished with value: 0.7881248043410206 and parameters: {'num_leaves': 331, 'max_depth': 110, 'learning_rate': 0.1264846428080873, 'n_estimators': 144, 'min_child_samples': 99, 'min_child_weight': 0.42349819164404623, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.1868147829283748, 'reg_lambda': 0.2652771966757223}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,589] Trial 428 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 322, 'max_depth': 114, 'learning_rate': 0.0104930453682169, 'n_estimators': 123, 'min_child_samples': 45, 'min_child_weight': 0.0012049569452749806, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.354972197816374e-05, 'reg_lambda': 0.5784414941832586}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,690] Trial 429 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 345, 'max_depth': 86, 'learning_rate': 0.017040222119327115, 'n_estimators': 105, 'min_child_samples': 52, 'min_child_weight': 0.00042114044915188156, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 3.924432031531687e-05, 'reg_lambda': 0.4687172776508512}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:47,799] Trial 430 finished with value: 0.8246851893910718 and parameters: {'num_leaves': 291, 'max_depth': 6, 'learning_rate': 0.04286552318751868, 'n_estimators': 162, 'min_child_samples': 56, 'min_child_weight': 0.2605058980150498, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7717128095257417e-05, 'reg_lambda': 0.7319039910499014}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,144] Trial 431 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 311, 'max_depth': 107, 'learning_rate': 0.00766457240285068, 'n_estimators': 902, 'min_child_samples': 54, 'min_child_weight': 0.002524591379436192, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6324255702503534e-05, 'reg_lambda': 0.19862642936140368}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,231] Trial 432 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 277, 'max_depth': 120, 'learning_rate': 0.02269811510806286, 'n_estimators': 75, 'min_child_samples': 49, 'min_child_weight': 0.00030829030923701015, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0149568977968462e-05, 'reg_lambda': 0.4006393825441673}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,352] Trial 433 finished with value: 0.805472173852318 and parameters: {'num_leaves': 377, 'max_depth': 112, 'learning_rate': 0.005118245621889822, 'n_estimators': 182, 'min_child_samples': 43, 'min_child_weight': 0.0006348680828627806, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00021666314864261362, 'reg_lambda': 0.9502194948292988}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,471] Trial 434 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 330, 'max_depth': 117, 'learning_rate': 0.01278028879021956, 'n_estimators': 134, 'min_child_samples': 52, 'min_child_weight': 0.0009116163565710819, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3185048396352133e-05, 'reg_lambda': 0.2686745305875683}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,559] Trial 435 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 301, 'max_depth': 114, 'learning_rate': 0.03353910290844626, 'n_estimators': 92, 'min_child_samples': 57, 'min_child_weight': 0.5388013013770219, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8449640356005352e-05, 'reg_lambda': 0.00496940162295016}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,677] Trial 436 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 359, 'max_depth': 100, 'learning_rate': 0.016885897185693135, 'n_estimators': 149, 'min_child_samples': 54, 'min_child_weight': 0.000511156633947384, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.137578452884477e-05, 'reg_lambda': 0.150908350331201}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,783] Trial 437 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 319, 'max_depth': 109, 'learning_rate': 0.009431620134156682, 'n_estimators': 118, 'min_child_samples': 48, 'min_child_weight': 0.21037349972910344, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.002190099919867274, 'reg_lambda': 0.5980525712310052}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:48,903] Trial 438 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 291, 'max_depth': 105, 'learning_rate': 0.025895528882365185, 'n_estimators': 174, 'min_child_samples': 51, 'min_child_weight': 0.9782817439666365, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.148370437380484e-05, 'reg_lambda': 0.00011481710111563763}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,027] Trial 439 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 348, 'max_depth': 111, 'learning_rate': 0.014081508374527015, 'n_estimators': 153, 'min_child_samples': 55, 'min_child_weight': 0.3815328591708767, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3099698050260715e-05, 'reg_lambda': 0.002205290055662929}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,131] Trial 440 finished with value: 0.8036745872848512 and parameters: {'num_leaves': 349, 'max_depth': 111, 'learning_rate': 0.0037815469587746337, 'n_estimators': 152, 'min_child_samples': 57, 'min_child_weight': 0.3922132841114812, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.11391548557122e-05, 'reg_lambda': 0.002013480519013968}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,240] Trial 441 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 364, 'max_depth': 107, 'learning_rate': 0.006762561022545489, 'n_estimators': 126, 'min_child_samples': 59, 'min_child_weight': 0.4408817982753582, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9214257666068202e-05, 'reg_lambda': 0.0019253355393991129}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,337] Trial 442 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 343, 'max_depth': 80, 'learning_rate': 0.011746563731201778, 'n_estimators': 105, 'min_child_samples': 55, 'min_child_weight': 0.34776085210950125, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2762773988920735e-05, 'reg_lambda': 0.003126864421239386}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,449] Trial 443 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 338, 'max_depth': 109, 'learning_rate': 0.013162421360620584, 'n_estimators': 136, 'min_child_samples': 60, 'min_child_weight': 0.28039610957101196, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011372589590844357, 'reg_lambda': 0.002653715301503741}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,564] Trial 444 finished with value: 0.7445282168173735 and parameters: {'num_leaves': 353, 'max_depth': 102, 'learning_rate': 0.44604566432072507, 'n_estimators': 95, 'min_child_samples': 39, 'min_child_weight': 0.05902787561295864, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2669509660103298e-05, 'reg_lambda': 0.0015846558553724338}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,682] Trial 445 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 370, 'max_depth': 112, 'learning_rate': 0.008223265827219104, 'n_estimators': 156, 'min_child_samples': 55, 'min_child_weight': 0.5803080491445857, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.725743579405902e-05, 'reg_lambda': 0.0010416377678893682}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,773] Trial 446 finished with value: 0.828254477109439 and parameters: {'num_leaves': 330, 'max_depth': 105, 'learning_rate': 0.018932545225572223, 'n_estimators': 57, 'min_child_samples': 50, 'min_child_weight': 0.02573591158991065, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0003109674402818547, 'reg_lambda': 0.004383604155097778}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,882] Trial 447 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 389, 'max_depth': 114, 'learning_rate': 0.07626569727848942, 'n_estimators': 113, 'min_child_samples': 46, 'min_child_weight': 0.7515288529399626, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 3.230029987213643e-05, 'reg_lambda': 0.0024754049113873836}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:49,986] Trial 448 finished with value: 0.828254477109439 and parameters: {'num_leaves': 46, 'max_depth': 110, 'learning_rate': 0.010898243816212082, 'n_estimators': 135, 'min_child_samples': 52, 'min_child_weight': 0.2813688002578939, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7151289330920458e-05, 'reg_lambda': 0.21168627990161773}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,069] Trial 449 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 348, 'max_depth': 117, 'learning_rate': 0.023549955603669535, 'n_estimators': 77, 'min_child_samples': 58, 'min_child_weight': 0.3411270625488557, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4060625178517296e-05, 'reg_lambda': 2.926365592027755}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,204] Trial 450 finished with value: 0.828254477109439 and parameters: {'num_leaves': 361, 'max_depth': 54, 'learning_rate': 0.00549553870263133, 'n_estimators': 161, 'min_child_samples': 56, 'min_child_weight': 0.524589420279716, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.430044289939e-05, 'reg_lambda': 0.009000333305993513}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,327] Trial 451 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 339, 'max_depth': 120, 'learning_rate': 0.04135269160433151, 'n_estimators': 140, 'min_child_samples': 53, 'min_child_weight': 0.0009676673979888569, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6698448802124535e-05, 'reg_lambda': 0.3286231433081027}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,437] Trial 452 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 325, 'max_depth': 108, 'learning_rate': 0.015133831155319867, 'n_estimators': 123, 'min_child_samples': 48, 'min_child_weight': 0.20355358214592553, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.3098357111786451, 'reg_lambda': 0.0013275285149374324}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,581] Trial 453 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 315, 'max_depth': 112, 'learning_rate': 0.008730530589545682, 'n_estimators': 180, 'min_child_samples': 51, 'min_child_weight': 0.0007230684077660412, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.519893836087819e-05, 'reg_lambda': 0.003390087087604513}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,685] Trial 454 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 334, 'max_depth': 115, 'learning_rate': 0.031584627006906944, 'n_estimators': 96, 'min_child_samples': 54, 'min_child_weight': 0.0809228315086698, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 1.3464826019771568e-05, 'reg_lambda': 0.002166098313550498}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,796] Trial 455 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 356, 'max_depth': 110, 'learning_rate': 0.017868067645096217, 'n_estimators': 152, 'min_child_samples': 57, 'min_child_weight': 0.6498765089565549, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0631264564015053e-05, 'reg_lambda': 0.10323767682295064}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:50,911] Trial 456 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 68, 'max_depth': 113, 'learning_rate': 0.01231834833690197, 'n_estimators': 117, 'min_child_samples': 49, 'min_child_weight': 0.40010306214978525, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.621830109073201e-05, 'reg_lambda': 0.273625152613844}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,117] Trial 457 finished with value: 0.7937497910281415 and parameters: {'num_leaves': 348, 'max_depth': 98, 'learning_rate': 0.024816328026744324, 'n_estimators': 384, 'min_child_samples': 44, 'min_child_weight': 0.0006518219274886685, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 8.211681250779719e-05, 'reg_lambda': 0.36587646343273184}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,228] Trial 458 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 309, 'max_depth': 118, 'learning_rate': 0.049603246493833464, 'n_estimators': 167, 'min_child_samples': 54, 'min_child_weight': 0.1292212596193334, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00017063514880674436, 'reg_lambda': 3.82195178074241}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,333] Trial 459 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 374, 'max_depth': 106, 'learning_rate': 0.006815169750329027, 'n_estimators': 139, 'min_child_samples': 41, 'min_child_weight': 0.0004169781535070723, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6482404684895934e-05, 'reg_lambda': 7.335254973112617}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,441] Trial 460 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 322, 'max_depth': 115, 'learning_rate': 0.01602423705277911, 'n_estimators': 85, 'min_child_samples': 51, 'min_child_weight': 0.0005426238043029994, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.2503595327882586e-05, 'reg_lambda': 0.43965445588043056}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,527] Trial 461 finished with value: 0.8228188195813411 and parameters: {'num_leaves': 323, 'max_depth': 103, 'learning_rate': 0.02075319428605622, 'n_estimators': 32, 'min_child_samples': 52, 'min_child_weight': 0.0009266932627836852, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.0314397876964743e-05, 'reg_lambda': 0.23366903227964342}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,629] Trial 462 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 334, 'max_depth': 111, 'learning_rate': 0.03455283107775855, 'n_estimators': 73, 'min_child_samples': 55, 'min_child_weight': 0.0007329936637346325, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.084015015379799e-05, 'reg_lambda': 0.1493605399260216}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:51,719] Trial 463 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 325, 'max_depth': 114, 'learning_rate': 0.014577164556855393, 'n_estimators': 86, 'min_child_samples': 53, 'min_child_weight': 0.0005038511414545989, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 5.405295770369067e-05, 'reg_lambda': 0.5265472108002219}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,101] Trial 464 finished with value: 0.7937497910281415 and parameters: {'num_leaves': 339, 'max_depth': 108, 'learning_rate': 0.017174072014539674, 'n_estimators': 994, 'min_child_samples': 56, 'min_child_weight': 0.0006038978169203685, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.8429819782288787e-05, 'reg_lambda': 0.032486191887755166}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,190] Trial 465 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 318, 'max_depth': 116, 'learning_rate': 0.024299338559922393, 'n_estimators': 65, 'min_child_samples': 51, 'min_child_weight': 0.0013077216410225677, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 1.3021483191104722e-05, 'reg_lambda': 0.3336608403605829}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,291] Trial 466 finished with value: 0.8101760010156956 and parameters: {'num_leaves': 348, 'max_depth': 111, 'learning_rate': 0.010038133742072783, 'n_estimators': 103, 'min_child_samples': 46, 'min_child_weight': 0.03521973064546854, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 3.7083536343231814e-05, 'reg_lambda': 0.06788312906964249}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,369] Trial 467 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 329, 'max_depth': 83, 'learning_rate': 0.030390346115987274, 'n_estimators': 50, 'min_child_samples': 59, 'min_child_weight': 0.0008100531237355713, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1.7355697598812143e-05, 'reg_lambda': 0.418763140716874}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,592] Trial 468 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 312, 'max_depth': 120, 'learning_rate': 0.01413762576699555, 'n_estimators': 536, 'min_child_samples': 53, 'min_child_weight': 0.3204827371255948, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.0071647107635482e-05, 'reg_lambda': 0.00024855681271610636}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,693] Trial 469 finished with value: 0.8105131524486363 and parameters: {'num_leaves': 25, 'max_depth': 113, 'learning_rate': 0.0030381405967087986, 'n_estimators': 94, 'min_child_samples': 24, 'min_child_weight': 0.23779897479625345, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 2.4381536374092252e-05, 'reg_lambda': 0.0006385044418197113}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,798] Trial 470 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 367, 'max_depth': 69, 'learning_rate': 0.0002870243541610559, 'n_estimators': 118, 'min_child_samples': 49, 'min_child_weight': 0.4908747752867713, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.4257866057499829e-05, 'reg_lambda': 0.18749969534403815}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:52,898] Trial 471 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 305, 'max_depth': 107, 'learning_rate': 0.05497325136140544, 'n_estimators': 82, 'min_child_samples': 57, 'min_child_weight': 0.7280368692986705, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 2.004254436248608e-05, 'reg_lambda': 0.25136511864722855}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,004] Trial 472 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 343, 'max_depth': 109, 'learning_rate': 0.021095014152749295, 'n_estimators': 117, 'min_child_samples': 50, 'min_child_weight': 0.0005164851824458617, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 3.433219414355567e-05, 'reg_lambda': 0.4445905347242252}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,116] Trial 473 finished with value: 0.8007507507507506 and parameters: {'num_leaves': 360, 'max_depth': 49, 'learning_rate': 0.00886582004005333, 'n_estimators': 133, 'min_child_samples': 34, 'min_child_weight': 0.9998021713838432, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.004359758046239594, 'reg_lambda': 1.7648363899141235}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,211] Trial 474 finished with value: 0.776113437381043 and parameters: {'num_leaves': 324, 'max_depth': 114, 'learning_rate': 0.004986666475007596, 'n_estimators': 102, 'min_child_samples': 55, 'min_child_weight': 0.0006886809830067138, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6770252395933943e-05, 'reg_lambda': 9.92397887667057}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,294] Trial 475 finished with value: 0.8322757457573522 and parameters: {'num_leaves': 76, 'max_depth': 90, 'learning_rate': 0.01557368750894891, 'n_estimators': 47, 'min_child_samples': 52, 'min_child_weight': 0.4643699345977536, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.346977413276795e-05, 'reg_lambda': 0.0066920808715734015}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,381] Trial 476 finished with value: 0.8141433939473363 and parameters: {'num_leaves': 90, 'max_depth': 88, 'learning_rate': 0.011381453383275602, 'n_estimators': 74, 'min_child_samples': 47, 'min_child_weight': 0.3823059003102576, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.710247410642732e-05, 'reg_lambda': 0.011225395827536788}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,484] Trial 477 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 96, 'max_depth': 89, 'learning_rate': 0.016625034372540672, 'n_estimators': 73, 'min_child_samples': 51, 'min_child_weight': 0.15763549271099597, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 8.376138063901664e-05, 'reg_lambda': 0.008298855489090247}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,571] Trial 478 finished with value: 0.7294556025538453 and parameters: {'num_leaves': 99, 'max_depth': 84, 'learning_rate': 0.006687860332378209, 'n_estimators': 32, 'min_child_samples': 48, 'min_child_weight': 0.12766188082548552, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 9.447172589375453e-05, 'reg_lambda': 0.005335619797688396}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,640] Trial 479 finished with value: 0.8141403815162681 and parameters: {'num_leaves': 110, 'max_depth': 90, 'learning_rate': 0.029538277122562875, 'n_estimators': 11, 'min_child_samples': 51, 'min_child_weight': 0.18689775468130285, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 5.8639882328534385e-05, 'reg_lambda': 0.00861672957811067}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,738] Trial 480 finished with value: 0.8228188195813411 and parameters: {'num_leaves': 67, 'max_depth': 95, 'learning_rate': 0.016420676291361104, 'n_estimators': 46, 'min_child_samples': 50, 'min_child_weight': 0.001802417444901329, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.00011716396818075035, 'reg_lambda': 0.007126203568502556}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,825] Trial 481 finished with value: 0.8068448883666274 and parameters: {'num_leaves': 78, 'max_depth': 92, 'learning_rate': 0.010871429441075588, 'n_estimators': 52, 'min_child_samples': 52, 'min_child_weight': 0.24870815310764774, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0001437973895399185, 'reg_lambda': 0.0042115160136278395}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,907] Trial 482 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 56, 'max_depth': 93, 'learning_rate': 4.435509344182041e-05, 'n_estimators': 33, 'min_child_samples': 47, 'min_child_weight': 0.1509055520402515, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 8.903333270618484e-05, 'reg_lambda': 0.013475512291145625}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:53,996] Trial 483 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 88, 'max_depth': 90, 'learning_rate': 6.456947568666501e-08, 'n_estimators': 66, 'min_child_samples': 49, 'min_child_weight': 8.158823938599939e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.4048580559080474e-05, 'reg_lambda': 0.0058374160927947265}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,078] Trial 484 finished with value: 0.8148130709106318 and parameters: {'num_leaves': 101, 'max_depth': 87, 'learning_rate': 0.02199556650867193, 'n_estimators': 16, 'min_child_samples': 51, 'min_child_weight': 0.0005299893044343415, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 5.185357428569424e-05, 'reg_lambda': 0.00730967581424651}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,167] Trial 485 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 71, 'max_depth': 95, 'learning_rate': 0.039568490456975046, 'n_estimators': 49, 'min_child_samples': 45, 'min_child_weight': 0.17583165119193117, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 7.246022032337072e-05, 'reg_lambda': 0.010707064546184366}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,259] Trial 486 finished with value: 0.8036745872848512 and parameters: {'num_leaves': 98, 'max_depth': 98, 'learning_rate': 0.008628078823936281, 'n_estimators': 71, 'min_child_samples': 53, 'min_child_weight': 4.6271714609243244e-05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.7714598341608993e-05, 'reg_lambda': 0.003096570837678562}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,360] Trial 487 finished with value: 0.828254477109439 and parameters: {'num_leaves': 86, 'max_depth': 76, 'learning_rate': 0.013855598843975437, 'n_estimators': 90, 'min_child_samples': 52, 'min_child_weight': 0.09661806585302395, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.998412944660099e-05, 'reg_lambda': 0.0035603859641787686}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,451] Trial 488 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 76, 'max_depth': 82, 'learning_rate': 0.02075447179369282, 'n_estimators': 57, 'min_child_samples': 49, 'min_child_weight': 0.0003970569018249795, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4419010453533545e-05, 'reg_lambda': 0.007157789549612104}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,557] Trial 489 finished with value: 0.8101760010156956 and parameters: {'num_leaves': 71, 'max_depth': 85, 'learning_rate': 0.01373554250922327, 'n_estimators': 75, 'min_child_samples': 43, 'min_child_weight': 0.0008619685257370081, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2615126782352844e-05, 'reg_lambda': 0.01611744049465559}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,659] Trial 490 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 458, 'max_depth': 91, 'learning_rate': 0.028925297679349263, 'n_estimators': 46, 'min_child_samples': 54, 'min_child_weight': 0.0006023912707541283, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 2.0345312539211985e-05, 'reg_lambda': 0.005275894630229699}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,759] Trial 491 finished with value: 0.8188643188643188 and parameters: {'num_leaves': 109, 'max_depth': 102, 'learning_rate': 0.008916960464708362, 'n_estimators': 89, 'min_child_samples': 47, 'min_child_weight': 0.0022691684090749053, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7752849475888464e-05, 'reg_lambda': 0.0017084051759686273}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:54,865] Trial 492 finished with value: 0.7920266307363081 and parameters: {'num_leaves': 38, 'max_depth': 87, 'learning_rate': 0.004790799384553956, 'n_estimators': 104, 'min_child_samples': 51, 'min_child_weight': 0.22115063277116254, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.4893654042324846, 'reg_lambda': 0.0025043741456150384}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,142] Trial 493 finished with value: 0.7847823906380608 and parameters: {'num_leaves': 318, 'max_depth': 99, 'learning_rate': 0.01839655239929042, 'n_estimators': 646, 'min_child_samples': 53, 'min_child_weight': 0.0032559209493549924, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.7419271290147844e-05, 'reg_lambda': 0.0011755144929628243}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,261] Trial 494 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 123, 'max_depth': 88, 'learning_rate': 0.006532459543680466, 'n_estimators': 125, 'min_child_samples': 50, 'min_child_weight': 0.00045476366363359394, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 4.1859074994655465e-05, 'reg_lambda': 0.004073577076663795}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,348] Trial 495 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 87, 'max_depth': 117, 'learning_rate': 0.0015440930704690304, 'n_estimators': 63, 'min_child_samples': 48, 'min_child_weight': 0.0011279961099929915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00010934562475960331, 'reg_lambda': 0.008463983061897717}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,432] Trial 496 finished with value: 0.8134278644842026 and parameters: {'num_leaves': 80, 'max_depth': 105, 'learning_rate': 0.01173136720381773, 'n_estimators': 31, 'min_child_samples': 52, 'min_child_weight': 0.31040690680934335, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0201897959205356e-05, 'reg_lambda': 0.005595101065439897}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,550] Trial 497 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 58, 'max_depth': 21, 'learning_rate': 0.05171055471563107, 'n_estimators': 151, 'min_child_samples': 55, 'min_child_weight': 0.45637463856627186, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5879195979894573e-05, 'reg_lambda': 0.0021631253347502467}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,750] Trial 498 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 335, 'max_depth': 28, 'learning_rate': 0.025611495943094708, 'n_estimators': 317, 'min_child_samples': 45, 'min_child_weight': 0.0007783970862240478, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 2.3565080014462133e-05, 'reg_lambda': 0.012796400486325332}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:55,842] Trial 499 finished with value: 0.828254477109439 and parameters: {'num_leaves': 158, 'max_depth': 95, 'learning_rate': 0.015878866695200746, 'n_estimators': 84, 'min_child_samples': 50, 'min_child_weight': 0.15581692850693818, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2291095313154579e-05, 'reg_lambda': 5.365015342042138}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,056] Trial 500 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 311, 'max_depth': 103, 'learning_rate': 0.00012054782524028035, 'n_estimators': 472, 'min_child_samples': 54, 'min_child_weight': 0.0006319431793358453, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.129398618276485e-05, 'reg_lambda': 0.0030560894318258846}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,186] Trial 501 finished with value: 0.828254477109439 and parameters: {'num_leaves': 101, 'max_depth': 115, 'learning_rate': 0.009509897660719295, 'n_estimators': 136, 'min_child_samples': 52, 'min_child_weight': 0.00039020559178182783, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.09528250498509865, 'reg_lambda': 0.00635320582782954}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,264] Trial 502 finished with value: 0.8115146396396395 and parameters: {'num_leaves': 7, 'max_depth': 118, 'learning_rate': 0.03672909247177128, 'n_estimators': 108, 'min_child_samples': 56, 'min_child_weight': 0.2567667679683677, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7934754521814912e-05, 'reg_lambda': 0.022051736187061504}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,395] Trial 503 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 51, 'max_depth': 109, 'learning_rate': 0.022157082085952712, 'n_estimators': 191, 'min_child_samples': 49, 'min_child_weight': 0.0005244915567301496, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1514302266790913e-05, 'reg_lambda': 0.003757079227772941}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,521] Trial 504 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 329, 'max_depth': 112, 'learning_rate': 0.01301901982954889, 'n_estimators': 167, 'min_child_samples': 53, 'min_child_weight': 0.541272377030203, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0163285907388499e-05, 'reg_lambda': 0.04572973915562849}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,656] Trial 505 finished with value: 0.780204207675669 and parameters: {'num_leaves': 305, 'max_depth': 105, 'learning_rate': 0.08818370312460838, 'n_estimators': 118, 'min_child_samples': 42, 'min_child_weight': 0.0009896761970889607, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.322704622692801e-05, 'reg_lambda': 0.30260718043353674}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,777] Trial 506 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 419, 'max_depth': 90, 'learning_rate': 0.007275860482929058, 'n_estimators': 154, 'min_child_samples': 47, 'min_child_weight': 0.3817026049517452, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.441272507315262e-05, 'reg_lambda': 0.5059359167681711}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,904] Trial 507 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 319, 'max_depth': 115, 'learning_rate': 0.016593770615143034, 'n_estimators': 78, 'min_child_samples': 51, 'min_child_weight': 0.00036376983599115424, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.434221641611169e-05, 'reg_lambda': 0.009883771925706386}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:56,990] Trial 508 finished with value: 0.7408927781794855 and parameters: {'num_leaves': 317, 'max_depth': 112, 'learning_rate': 0.003822760458611034, 'n_estimators': 53, 'min_child_samples': 50, 'min_child_weight': 0.0004120496190697871, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 4.929373140344389e-05, 'reg_lambda': 0.008641805965264239}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,121] Trial 509 finished with value: 0.8089657669881551 and parameters: {'num_leaves': 322, 'max_depth': 13, 'learning_rate': 0.01614142663093255, 'n_estimators': 69, 'min_child_samples': 13, 'min_child_weight': 0.0005919459675979658, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 6.474315626470736e-05, 'reg_lambda': 0.005467843271296713}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,233] Trial 510 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 128, 'max_depth': 115, 'learning_rate': 0.010706007029023343, 'n_estimators': 87, 'min_child_samples': 48, 'min_child_weight': 0.0007221301473425916, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.8595475708639505e-05, 'reg_lambda': 0.015601353857709175}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,334] Trial 511 finished with value: 0.8132870204245668 and parameters: {'num_leaves': 335, 'max_depth': 101, 'learning_rate': 0.028392640906085714, 'n_estimators': 27, 'min_child_samples': 18, 'min_child_weight': 0.00046860854666354627, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6952087046077356e-05, 'reg_lambda': 0.0130620897068976}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,432] Trial 512 finished with value: 0.8019307272857932 and parameters: {'num_leaves': 298, 'max_depth': 107, 'learning_rate': 0.005965370153286015, 'n_estimators': 79, 'min_child_samples': 45, 'min_child_weight': 0.28979028793395745, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6137141295692138e-05, 'reg_lambda': 0.006599283986824194}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,542] Trial 513 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 314, 'max_depth': 112, 'learning_rate': 0.019023552242194236, 'n_estimators': 98, 'min_child_samples': 51, 'min_child_weight': 0.0013183776846209488, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.0432933837864204e-05, 'reg_lambda': 0.008171946626650413}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,646] Trial 514 finished with value: 0.8275562882304457 and parameters: {'num_leaves': 326, 'max_depth': 109, 'learning_rate': 0.013025138805356124, 'n_estimators': 58, 'min_child_samples': 52, 'min_child_weight': 0.21155858799372973, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.217204729559105e-05, 'reg_lambda': 0.0008714756071506045}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,748] Trial 515 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 307, 'max_depth': 118, 'learning_rate': 0.00874740240652932, 'n_estimators': 106, 'min_child_samples': 55, 'min_child_weight': 0.0003667206888216151, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.088823349691721e-05, 'reg_lambda': 0.020633107553350297}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,859] Trial 516 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 340, 'max_depth': 116, 'learning_rate': 0.03500422472164219, 'n_estimators': 81, 'min_child_samples': 58, 'min_child_weight': 0.46314597923632417, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.29956387388843e-05, 'reg_lambda': 0.2408823701971487}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:57,945] Trial 517 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 140, 'max_depth': 110, 'learning_rate': 0.021467878858066603, 'n_estimators': 41, 'min_child_samples': 49, 'min_child_weight': 0.00029517638731471147, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0004637249031186187, 'reg_lambda': 0.01256000913367322}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,059] Trial 518 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 117, 'max_depth': 114, 'learning_rate': 0.014262577955144958, 'n_estimators': 117, 'min_child_samples': 54, 'min_child_weight': 0.0007815884544663122, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2925122985649647e-05, 'reg_lambda': 0.010572668418647525}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,160] Trial 519 finished with value: 0.8223949706477587 and parameters: {'num_leaves': 330, 'max_depth': 107, 'learning_rate': 0.008454340654704559, 'n_estimators': 92, 'min_child_samples': 63, 'min_child_weight': 0.6556289604330336, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 1.5704974097751676e-05, 'reg_lambda': 0.4310725733410463}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,340] Trial 520 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 349, 'max_depth': 113, 'learning_rate': 0.04635026507480252, 'n_estimators': 276, 'min_child_samples': 46, 'min_child_weight': 0.0005085796439942433, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 3.713178395028125e-05, 'reg_lambda': 0.0014908645937779458}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,455] Trial 521 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 299, 'max_depth': 78, 'learning_rate': 0.02465433644297373, 'n_estimators': 131, 'min_child_samples': 51, 'min_child_weight': 0.12146541489912635, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4504388960438752e-05, 'reg_lambda': 0.2053966093658924}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,583] Trial 522 finished with value: 0.8372937151563106 and parameters: {'num_leaves': 317, 'max_depth': 104, 'learning_rate': 0.016604874755013536, 'n_estimators': 102, 'min_child_samples': 53, 'min_child_weight': 0.0006152564531186261, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2437772610298628e-05, 'reg_lambda': 0.13090789266328282}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,675] Trial 523 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 321, 'max_depth': 101, 'learning_rate': 0.018314611023930727, 'n_estimators': 62, 'min_child_samples': 57, 'min_child_weight': 0.0005972156584971562, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3733950017940852e-05, 'reg_lambda': 0.1389014688734875}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,797] Trial 524 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 317, 'max_depth': 99, 'learning_rate': 0.030703015726794687, 'n_estimators': 94, 'min_child_samples': 54, 'min_child_weight': 0.3687046835129339, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 1.2213887116189916e-05, 'reg_lambda': 0.10646438389007146}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,904] Trial 525 finished with value: 0.8148629126582771 and parameters: {'num_leaves': 311, 'max_depth': 103, 'learning_rate': 0.01449156935416455, 'n_estimators': 106, 'min_child_samples': 60, 'min_child_weight': 0.0003674954930702087, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.7346488227846958e-05, 'reg_lambda': 0.009833314263883276}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:58,997] Trial 526 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 335, 'max_depth': 96, 'learning_rate': 0.05975143188765918, 'n_estimators': 74, 'min_child_samples': 56, 'min_child_weight': 0.17437695834931624, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0616610054089159e-05, 'reg_lambda': 0.16423209799156097}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,114] Trial 527 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 301, 'max_depth': 105, 'learning_rate': 0.02565091685279871, 'n_estimators': 113, 'min_child_samples': 52, 'min_child_weight': 0.0004962018679445043, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.669474939714192e-05, 'reg_lambda': 0.07722605153002345}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,231] Trial 528 finished with value: 0.828254477109439 and parameters: {'num_leaves': 320, 'max_depth': 104, 'learning_rate': 0.011615409905093346, 'n_estimators': 83, 'min_child_samples': 48, 'min_child_weight': 0.28752345128835866, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.036050811926531e-05, 'reg_lambda': 0.29881403704144005}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,308] Trial 529 finished with value: 0.7119190428013957 and parameters: {'num_leaves': 331, 'max_depth': 107, 'learning_rate': 0.019109098811862797, 'n_estimators': 11, 'min_child_samples': 50, 'min_child_weight': 0.562872848517625, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0186172288744292e-05, 'reg_lambda': 0.1312968726887567}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,396] Trial 530 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 313, 'max_depth': 101, 'learning_rate': 0.03429373337114208, 'n_estimators': 48, 'min_child_samples': 53, 'min_child_weight': 0.00027037615493058015, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.383529006919919e-05, 'reg_lambda': 0.18687624790057059}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,508] Trial 531 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 343, 'max_depth': 110, 'learning_rate': 0.011063150873093302, 'n_estimators': 125, 'min_child_samples': 55, 'min_child_weight': 0.00044792446762430364, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0211297188372853e-05, 'reg_lambda': 0.241681953031028}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,612] Trial 532 finished with value: 0.8122888649204439 and parameters: {'num_leaves': 305, 'max_depth': 105, 'learning_rate': 0.00663844654792138, 'n_estimators': 98, 'min_child_samples': 51, 'min_child_weight': 0.003789785325857069, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7927083962796486e-05, 'reg_lambda': 0.34230512992353995}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,731] Trial 533 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 325, 'max_depth': 93, 'learning_rate': 0.01732164611079716, 'n_estimators': 65, 'min_child_samples': 47, 'min_child_weight': 0.0006418883438895378, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.564950839181714e-05, 'reg_lambda': 0.004245345387167712}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,857] Trial 534 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 293, 'max_depth': 108, 'learning_rate': 0.04277387105388524, 'n_estimators': 134, 'min_child_samples': 44, 'min_child_weight': 0.0009545559865654549, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5294173986289453e-05, 'reg_lambda': 0.009946935487387936}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:13:59,981] Trial 535 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 348, 'max_depth': 111, 'learning_rate': 0.021639864007832306, 'n_estimators': 116, 'min_child_samples': 58, 'min_child_weight': 0.4612374089589172, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2914273865192677e-05, 'reg_lambda': 0.02826986631442821}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,087] Trial 536 finished with value: 0.828254477109439 and parameters: {'num_leaves': 332, 'max_depth': 97, 'learning_rate': 0.013513677833969444, 'n_estimators': 97, 'min_child_samples': 53, 'min_child_weight': 0.00034640892135432143, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.163143126287288e-05, 'reg_lambda': 0.002636587709443295}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,216] Trial 537 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 309, 'max_depth': 65, 'learning_rate': 1.0779955450134559e-05, 'n_estimators': 138, 'min_child_samples': 38, 'min_child_weight': 0.0016215431271877634, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 3.060523511597562e-05, 'reg_lambda': 0.2160971499099484}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,318] Trial 538 finished with value: 0.8089657669881551 and parameters: {'num_leaves': 353, 'max_depth': 104, 'learning_rate': 0.008815963793395637, 'n_estimators': 76, 'min_child_samples': 55, 'min_child_weight': 0.3230402820786478, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.06694386546353823, 'reg_lambda': 0.058006223102803615}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,434] Trial 539 finished with value: 0.8171238954412691 and parameters: {'num_leaves': 384, 'max_depth': 60, 'learning_rate': 0.005288499721746315, 'n_estimators': 117, 'min_child_samples': 50, 'min_child_weight': 0.20677546091703872, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7236944924737447e-05, 'reg_lambda': 0.3519751565878208}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,573] Trial 540 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 338, 'max_depth': 109, 'learning_rate': 0.01683266908350702, 'n_estimators': 147, 'min_child_samples': 53, 'min_child_weight': 0.0028722435773237327, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.016203015336713e-05, 'reg_lambda': 0.2900280746606626}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:00,916] Trial 541 finished with value: 0.77581499024798 and parameters: {'num_leaves': 321, 'max_depth': 114, 'learning_rate': 0.026902862080677357, 'n_estimators': 720, 'min_child_samples': 49, 'min_child_weight': 0.0005875483404427951, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4001061886591916e-05, 'reg_lambda': 0.0019435592901127217}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,028] Trial 542 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 285, 'max_depth': 111, 'learning_rate': 0.01115596214131543, 'n_estimators': 94, 'min_child_samples': 56, 'min_child_weight': 0.0007385939152134368, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3794442348714043e-05, 'reg_lambda': 0.4183498236725809}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,150] Trial 543 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 300, 'max_depth': 107, 'learning_rate': 0.023349204431702603, 'n_estimators': 130, 'min_child_samples': 52, 'min_child_weight': 0.01598791372701842, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.6199897304936994e-05, 'reg_lambda': 0.1595167927979756}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,241] Trial 544 finished with value: 0.4372529368274049 and parameters: {'num_leaves': 360, 'max_depth': 89, 'learning_rate': 0.0028485720797458156, 'n_estimators': 41, 'min_child_samples': 46, 'min_child_weight': 0.6315062435525769, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0017908897158824e-05, 'reg_lambda': 0.015269849978590154}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,328] Trial 545 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 326, 'max_depth': 85, 'learning_rate': 0.03748858109673708, 'n_estimators': 63, 'min_child_samples': 54, 'min_child_weight': 0.00043183343700988744, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3826909580942234e-05, 'reg_lambda': 0.27716377477025317}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,438] Trial 546 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 314, 'max_depth': 41, 'learning_rate': 0.015720899634005827, 'n_estimators': 107, 'min_child_samples': 50, 'min_child_weight': 0.0002828042817660474, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0224548953781992e-05, 'reg_lambda': 0.00019342612508176741}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,558] Trial 547 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 313, 'max_depth': 81, 'learning_rate': 0.006815987303950376, 'n_estimators': 147, 'min_child_samples': 49, 'min_child_weight': 0.0002385633581811231, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.3018005635027724e-05, 'reg_lambda': 0.00022770703212829127}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:01,675] Trial 548 finished with value: 0.828254477109439 and parameters: {'num_leaves': 304, 'max_depth': 102, 'learning_rate': 0.010438401642946932, 'n_estimators': 109, 'min_child_samples': 51, 'min_child_weight': 0.000267393713727684, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.451225684125565e-05, 'reg_lambda': 8.208590780207689e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,013] Trial 549 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 315, 'max_depth': 73, 'learning_rate': 8.791840944186916e-07, 'n_estimators': 771, 'min_child_samples': 51, 'min_child_weight': 0.0003195743866415088, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8494682094327745e-05, 'reg_lambda': 0.0002893565629643089}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,143] Trial 550 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 295, 'max_depth': 115, 'learning_rate': 0.014844250320204406, 'n_estimators': 128, 'min_child_samples': 48, 'min_child_weight': 0.0003603210417803227, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0054090335653541e-05, 'reg_lambda': 0.0003713592595500179}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,279] Trial 551 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 291, 'max_depth': 116, 'learning_rate': 0.007880793582093693, 'n_estimators': 131, 'min_child_samples': 47, 'min_child_weight': 0.00032851021664200903, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.2489005327473358e-05, 'reg_lambda': 0.0006740444805207562}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,410] Trial 552 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 304, 'max_depth': 119, 'learning_rate': 0.004073490564494745, 'n_estimators': 158, 'min_child_samples': 48, 'min_child_weight': 0.0002754892165144941, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2760256031585544e-05, 'reg_lambda': 0.00019844131158681719}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,523] Trial 553 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 279, 'max_depth': 41, 'learning_rate': 0.013270853360107158, 'n_estimators': 124, 'min_child_samples': 49, 'min_child_weight': 0.00039868860997915704, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.702659433431999e-05, 'reg_lambda': 0.00013581444175675045}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,645] Trial 554 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 299, 'max_depth': 113, 'learning_rate': 0.017291613515913573, 'n_estimators': 145, 'min_child_samples': 49, 'min_child_weight': 0.0001877642360642741, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.2317771544834966e-05, 'reg_lambda': 0.0003857255580552557}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,759] Trial 555 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 292, 'max_depth': 114, 'learning_rate': 0.00964343145807115, 'n_estimators': 114, 'min_child_samples': 47, 'min_child_weight': 0.0002515964599771171, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.7908402553708556e-05, 'reg_lambda': 0.00033748021077759777}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:02,887] Trial 556 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 321, 'max_depth': 116, 'learning_rate': 0.013166142426568444, 'n_estimators': 168, 'min_child_samples': 50, 'min_child_weight': 0.00035011864811406617, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0008266158576271e-05, 'reg_lambda': 0.0004993246565021001}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,046] Trial 557 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 311, 'max_depth': 119, 'learning_rate': 0.02039438519973275, 'n_estimators': 177, 'min_child_samples': 45, 'min_child_weight': 0.0003191482947408492, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.1422623108281452e-05, 'reg_lambda': 0.00038961678582794353}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,188] Trial 558 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 286, 'max_depth': 117, 'learning_rate': 0.014218978498725004, 'n_estimators': 189, 'min_child_samples': 47, 'min_child_weight': 0.00021420194031115312, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0148334809597358e-05, 'reg_lambda': 0.00049516952366275}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,326] Trial 559 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 319, 'max_depth': 122, 'learning_rate': 0.026995291520994894, 'n_estimators': 161, 'min_child_samples': 50, 'min_child_weight': 0.0003384919739042057, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0453856948803972e-05, 'reg_lambda': 0.0007001432002916127}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,468] Trial 560 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 296, 'max_depth': 116, 'learning_rate': 0.01802963687503767, 'n_estimators': 206, 'min_child_samples': 49, 'min_child_weight': 0.0002710585653381878, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.0108772462537959e-05, 'reg_lambda': 0.00028428650562101285}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,607] Trial 561 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 308, 'max_depth': 120, 'learning_rate': 0.012872647347975996, 'n_estimators': 176, 'min_child_samples': 51, 'min_child_weight': 0.00042446854408348264, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5679617681693215e-05, 'reg_lambda': 0.00017640179436744215}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,745] Trial 562 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 274, 'max_depth': 116, 'learning_rate': 0.029729430048449298, 'n_estimators': 161, 'min_child_samples': 46, 'min_child_weight': 0.00035810290272577516, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.079399172633464e-05, 'reg_lambda': 0.0004906808990403369}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,881] Trial 563 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 325, 'max_depth': 110, 'learning_rate': 0.021317313652614255, 'n_estimators': 142, 'min_child_samples': 48, 'min_child_weight': 0.00024558795877429733, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4823290983916723e-05, 'reg_lambda': 0.0004490494380583687}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:03,998] Trial 564 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 339, 'max_depth': 115, 'learning_rate': 0.011178641648031147, 'n_estimators': 144, 'min_child_samples': 50, 'min_child_weight': 0.0004420866095478354, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.143450630910279e-05, 'reg_lambda': 0.00032095803495008264}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,135] Trial 565 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 315, 'max_depth': 118, 'learning_rate': 0.015898099784513987, 'n_estimators': 188, 'min_child_samples': 54, 'min_child_weight': 0.0005928313070526451, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.358185924909833e-05, 'reg_lambda': 0.00046535459526643994}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,256] Trial 566 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 299, 'max_depth': 112, 'learning_rate': 0.006009185224933254, 'n_estimators': 155, 'min_child_samples': 58, 'min_child_weight': 0.0003733105904307691, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0213623214217785e-05, 'reg_lambda': 0.0009248930602309556}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,388] Trial 567 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 284, 'max_depth': 114, 'learning_rate': 0.03610496505563588, 'n_estimators': 128, 'min_child_samples': 52, 'min_child_weight': 0.0002760902083192421, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 1.006021330070508e-05, 'reg_lambda': 0.0001689957705815883}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,503] Trial 568 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 334, 'max_depth': 106, 'learning_rate': 0.008392517861878378, 'n_estimators': 127, 'min_child_samples': 61, 'min_child_weight': 0.00018140941605929332, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6980538954737332e-05, 'reg_lambda': 0.00025944988610064384}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,637] Trial 569 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 308, 'max_depth': 109, 'learning_rate': 0.01906596140631307, 'n_estimators': 165, 'min_child_samples': 56, 'min_child_weight': 0.0004670474665000206, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6021836572160863e-05, 'reg_lambda': 0.0005131626157487926}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,779] Trial 570 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 346, 'max_depth': 118, 'learning_rate': 0.012454186105420881, 'n_estimators': 175, 'min_child_samples': 48, 'min_child_weight': 0.0001513097639317002, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6096113946280586e-05, 'reg_lambda': 0.0006128399855150001}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:04,932] Trial 571 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 352, 'max_depth': 120, 'learning_rate': 0.01179122905178289, 'n_estimators': 210, 'min_child_samples': 45, 'min_child_weight': 9.682029097847482e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5700957812488247e-05, 'reg_lambda': 0.0005934002572532685}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,079] Trial 572 finished with value: 0.8098075348075349 and parameters: {'num_leaves': 363, 'max_depth': 119, 'learning_rate': 0.004773524606325056, 'n_estimators': 175, 'min_child_samples': 47, 'min_child_weight': 0.00013103932630825616, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 1.0050512152535037e-05, 'reg_lambda': 0.0005996009386138138}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,238] Trial 573 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 346, 'max_depth': 35, 'learning_rate': 0.0085711577785022, 'n_estimators': 193, 'min_child_samples': 48, 'min_child_weight': 0.00015490789995761204, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.222632967510448e-05, 'reg_lambda': 0.000755235240949177}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,418] Trial 574 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 342, 'max_depth': 117, 'learning_rate': 0.024662466291564537, 'n_estimators': 240, 'min_child_samples': 45, 'min_child_weight': 0.0001259335241845831, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7598797997505782e-05, 'reg_lambda': 0.0012023653407129305}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,578] Trial 575 finished with value: 0.8105102594233028 and parameters: {'num_leaves': 362, 'max_depth': 122, 'learning_rate': 0.012412257792899348, 'n_estimators': 213, 'min_child_samples': 49, 'min_child_weight': 0.00019853857073167072, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.3435630427446425e-05, 'reg_lambda': 0.00035490912659534633}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,709] Trial 576 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 353, 'max_depth': 112, 'learning_rate': 0.007175152818854138, 'n_estimators': 173, 'min_child_samples': 47, 'min_child_weight': 0.0001621963644010768, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9937609296856213e-05, 'reg_lambda': 0.0010024733265016712}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,837] Trial 577 finished with value: 0.7893478279020448 and parameters: {'num_leaves': 334, 'max_depth': 100, 'learning_rate': 0.07025665303519706, 'n_estimators': 151, 'min_child_samples': 54, 'min_child_weight': 0.005234875783237501, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5550364262947382e-05, 'reg_lambda': 0.0008160352680575854}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:05,974] Trial 578 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 344, 'max_depth': 107, 'learning_rate': 0.012998859804428624, 'n_estimators': 178, 'min_child_samples': 50, 'min_child_weight': 0.0001471819869966995, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3845157774969542e-05, 'reg_lambda': 0.00032845973778879427}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,099] Trial 579 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 370, 'max_depth': 121, 'learning_rate': 0.02485822333720473, 'n_estimators': 143, 'min_child_samples': 57, 'min_child_weight': 0.000840222099235444, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.707423985019205e-05, 'reg_lambda': 0.0004209511941580335}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,259] Trial 580 finished with value: 0.7576616795366797 and parameters: {'num_leaves': 269, 'max_depth': 104, 'learning_rate': 0.1813153501479785, 'n_estimators': 196, 'min_child_samples': 44, 'min_child_weight': 7.787416042626366e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.059524159518538e-05, 'reg_lambda': 0.0001110113539283241}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,410] Trial 581 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 324, 'max_depth': 110, 'learning_rate': 0.04597514311142134, 'n_estimators': 163, 'min_child_samples': 52, 'min_child_weight': 0.00021498463950751285, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3056736395477657e-05, 'reg_lambda': 0.0009606946801061009}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,528] Trial 582 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 376, 'max_depth': 117, 'learning_rate': 0.00911943462590924, 'n_estimators': 139, 'min_child_samples': 65, 'min_child_weight': 0.002312037781322011, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0107478555985871e-05, 'reg_lambda': 0.0004186266008052559}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,677] Trial 583 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 289, 'max_depth': 114, 'learning_rate': 0.017304039458389844, 'n_estimators': 165, 'min_child_samples': 48, 'min_child_weight': 0.0012326569539578467, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.0591555095707965e-05, 'reg_lambda': 0.0005669924929962902}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,799] Trial 584 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 335, 'max_depth': 112, 'learning_rate': 0.025771996267524803, 'n_estimators': 120, 'min_child_samples': 55, 'min_child_weight': 0.00011667017068341493, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.6241783152430953e-05, 'reg_lambda': 0.0002517730459623955}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:06,931] Trial 585 finished with value: 0.836977886977887 and parameters: {'num_leaves': 356, 'max_depth': 108, 'learning_rate': 0.005861169980226098, 'n_estimators': 144, 'min_child_samples': 50, 'min_child_weight': 0.0005507257807070512, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.618120020089237e-05, 'reg_lambda': 0.0014895367758106359}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,081] Trial 586 finished with value: 0.8091338930177462 and parameters: {'num_leaves': 370, 'max_depth': 56, 'learning_rate': 0.0020602593753853886, 'n_estimators': 190, 'min_child_samples': 46, 'min_child_weight': 0.0006650539511877978, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4617234202043072e-05, 'reg_lambda': 0.0010935454793004615}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,218] Trial 587 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 354, 'max_depth': 106, 'learning_rate': 0.00421701282270012, 'n_estimators': 150, 'min_child_samples': 49, 'min_child_weight': 0.0004965791676051501, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.220255267720506e-05, 'reg_lambda': 0.0015031359527512337}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,340] Trial 588 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 389, 'max_depth': 109, 'learning_rate': 0.005635690631684017, 'n_estimators': 168, 'min_child_samples': 59, 'min_child_weight': 0.0008701907323661093, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 3.12677984918458e-05, 'reg_lambda': 0.0014559245382830001}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,462] Trial 589 finished with value: 0.8134278644842026 and parameters: {'num_leaves': 357, 'max_depth': 108, 'learning_rate': 0.0027390542358814093, 'n_estimators': 138, 'min_child_samples': 53, 'min_child_weight': 0.0005863485502288312, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6025238036897674e-05, 'reg_lambda': 0.0017371051095585552}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,625] Trial 590 finished with value: 0.828254477109439 and parameters: {'num_leaves': 348, 'max_depth': 111, 'learning_rate': 0.0062487709476604794, 'n_estimators': 216, 'min_child_samples': 50, 'min_child_weight': 4.5656372853779e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.323327050552173e-05, 'reg_lambda': 0.0006749656275222865}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,762] Trial 591 finished with value: 0.8128060018297418 and parameters: {'num_leaves': 366, 'max_depth': 114, 'learning_rate': 0.004091805253787086, 'n_estimators': 150, 'min_child_samples': 43, 'min_child_weight': 0.0007313641904478964, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0454201800387464e-05, 'reg_lambda': 0.0012432486475759063}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:07,927] Trial 592 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 378, 'max_depth': 104, 'learning_rate': 0.007600144995824536, 'n_estimators': 178, 'min_child_samples': 48, 'min_child_weight': 0.0011147177271503858, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8737017379057516e-05, 'reg_lambda': 0.00021991418667588163}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,050] Trial 593 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 341, 'max_depth': 118, 'learning_rate': 0.010347185847296245, 'n_estimators': 126, 'min_child_samples': 53, 'min_child_weight': 0.0005387371695114037, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0012586367082871e-05, 'reg_lambda': 0.0008789226810688904}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,140] Trial 594 finished with value: 0.7634640950580954 and parameters: {'num_leaves': 329, 'max_depth': 2, 'learning_rate': 0.0068908674938319035, 'n_estimators': 159, 'min_child_samples': 55, 'min_child_weight': 0.00043186253450758493, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7700628501388317e-05, 'reg_lambda': 0.0019063353532901548}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,266] Trial 595 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 355, 'max_depth': 110, 'learning_rate': 0.010601183687043228, 'n_estimators': 132, 'min_child_samples': 51, 'min_child_weight': 0.0005597399522288618, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3847009013385124e-05, 'reg_lambda': 0.0004647204886013902}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,435] Trial 596 finished with value: 0.814519979719652 and parameters: {'num_leaves': 340, 'max_depth': 106, 'learning_rate': 0.004742801804864839, 'n_estimators': 193, 'min_child_samples': 47, 'min_child_weight': 0.0003063057271421664, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5091244674220196e-05, 'reg_lambda': 0.0007765597905063794}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,564] Trial 597 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 304, 'max_depth': 116, 'learning_rate': 0.013545326867287993, 'n_estimators': 148, 'min_child_samples': 57, 'min_child_weight': 0.0008019590722424513, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2996032953183199e-05, 'reg_lambda': 0.0014242411193052305}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,682] Trial 598 finished with value: 0.828254477109439 and parameters: {'num_leaves': 280, 'max_depth': 113, 'learning_rate': 0.008250018396137327, 'n_estimators': 112, 'min_child_samples': 52, 'min_child_weight': 0.00022064287305094185, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9283097415012622e-05, 'reg_lambda': 0.0005935992699768785}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,822] Trial 599 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 330, 'max_depth': 108, 'learning_rate': 0.031151189101697566, 'n_estimators': 174, 'min_child_samples': 46, 'min_child_weight': 0.0009686857086556195, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.437872222778164e-05, 'reg_lambda': 0.0001525597312506579}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:08,946] Trial 600 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 319, 'max_depth': 102, 'learning_rate': 0.019634388472818367, 'n_estimators': 116, 'min_child_samples': 50, 'min_child_weight': 0.7913146416695697, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.58977299602408e-05, 'reg_lambda': 0.0003392692779962671}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,072] Trial 601 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 299, 'max_depth': 111, 'learning_rate': 1.060249010325069e-08, 'n_estimators': 138, 'min_child_samples': 54, 'min_child_weight': 0.0006372218091856503, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.301897945128516e-05, 'reg_lambda': 0.0011435763467577895}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,269] Trial 602 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 343, 'max_depth': 121, 'learning_rate': 0.011994912980526032, 'n_estimators': 351, 'min_child_samples': 49, 'min_child_weight': 0.0003982395541065462, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3076454846708873e-05, 'reg_lambda': 0.0019355876012835688}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,406] Trial 603 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 354, 'max_depth': 116, 'learning_rate': 0.015753926910320303, 'n_estimators': 155, 'min_child_samples': 56, 'min_child_weight': 0.00017203794630636096, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0067941503214975e-05, 'reg_lambda': 0.0024175413541214982}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,534] Trial 604 finished with value: 0.8012698915924722 and parameters: {'num_leaves': 312, 'max_depth': 114, 'learning_rate': 0.0033436330066502406, 'n_estimators': 129, 'min_child_samples': 61, 'min_child_weight': 0.00047831536908140475, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.901002283846564e-05, 'reg_lambda': 0.5711840974590002}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,694] Trial 605 finished with value: 0.828254477109439 and parameters: {'num_leaves': 295, 'max_depth': 108, 'learning_rate': 0.006351957707197411, 'n_estimators': 227, 'min_child_samples': 52, 'min_child_weight': 0.000271330032745998, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.793161195856628e-05, 'reg_lambda': 0.00024915543170972497}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,832] Trial 606 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 364, 'max_depth': 119, 'learning_rate': 0.01030516855736617, 'n_estimators': 185, 'min_child_samples': 44, 'min_child_weight': 0.0006966164110329466, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3223153446467962e-05, 'reg_lambda': 0.711539636308905}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:09,941] Trial 607 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 328, 'max_depth': 46, 'learning_rate': 0.022220098965746612, 'n_estimators': 104, 'min_child_samples': 54, 'min_child_weight': 0.0003425153024749454, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6987581200224055e-05, 'reg_lambda': 0.0005845895915884292}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,050] Trial 608 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 346, 'max_depth': 103, 'learning_rate': 0.04672909826335218, 'n_estimators': 109, 'min_child_samples': 59, 'min_child_weight': 0.00026270937584045335, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.687931965943561e-05, 'reg_lambda': 0.0005356500900536345}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,189] Trial 609 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 332, 'max_depth': 48, 'learning_rate': 0.03562375064141381, 'n_estimators': 164, 'min_child_samples': 57, 'min_child_weight': 0.00035414774426757533, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.621862358585653e-05, 'reg_lambda': 0.0006835407203187117}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,306] Trial 610 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 278, 'max_depth': 47, 'learning_rate': 0.024429311994262688, 'n_estimators': 138, 'min_child_samples': 55, 'min_child_weight': 0.0002267484908724647, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.986582636823866e-05, 'reg_lambda': 0.00038071607636613875}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,420] Trial 611 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 361, 'max_depth': 105, 'learning_rate': 0.022605530534406143, 'n_estimators': 119, 'min_child_samples': 54, 'min_child_weight': 0.004413312683942358, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4500749915930344e-05, 'reg_lambda': 0.0010397953559224931}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,583] Trial 612 finished with value: 0.780204207675669 and parameters: {'num_leaves': 377, 'max_depth': 42, 'learning_rate': 0.05903048761090279, 'n_estimators': 198, 'min_child_samples': 57, 'min_child_weight': 0.0003077715348707742, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.495940544820881e-05, 'reg_lambda': 0.0008781073604761656}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,722] Trial 613 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 400, 'max_depth': 111, 'learning_rate': 0.03655681874510678, 'n_estimators': 149, 'min_child_samples': 53, 'min_child_weight': 0.00015128892128796144, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.715258007605943e-05, 'reg_lambda': 0.0005374744812702789}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,834] Trial 614 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 338, 'max_depth': 39, 'learning_rate': 0.014585363629791048, 'n_estimators': 107, 'min_child_samples': 55, 'min_child_weight': 0.0003124230518339835, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6879688238404183e-05, 'reg_lambda': 0.0005490086380303113}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:10,968] Trial 615 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 325, 'max_depth': 37, 'learning_rate': 0.020746085703116427, 'n_estimators': 169, 'min_child_samples': 59, 'min_child_weight': 0.0003627608985651256, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2334810717123442e-05, 'reg_lambda': 0.0003155651768845295}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:11,365] Trial 616 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 349, 'max_depth': 30, 'learning_rate': 0.010454577555569684, 'n_estimators': 961, 'min_child_samples': 53, 'min_child_weight': 6.437142675764783e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1121382531716775e-05, 'reg_lambda': 0.0007971078224599436}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:11,490] Trial 617 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 265, 'max_depth': 43, 'learning_rate': 0.02597990491490179, 'n_estimators': 136, 'min_child_samples': 56, 'min_child_weight': 0.0004217079460699593, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5623000747285798e-05, 'reg_lambda': 6.698542581860882}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:11,706] Trial 618 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 307, 'max_depth': 41, 'learning_rate': 1.8775089290606104e-05, 'n_estimators': 421, 'min_child_samples': 51, 'min_child_weight': 0.00020586077983653973, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0065603819780025e-05, 'reg_lambda': 0.00043007247951228685}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:11,824] Trial 619 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 285, 'max_depth': 44, 'learning_rate': 5.052936876093616e-06, 'n_estimators': 128, 'min_child_samples': 49, 'min_child_weight': 0.00023529444695093106, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0102813530223728e-05, 'reg_lambda': 0.0013280656284192244}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:11,953] Trial 620 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 316, 'max_depth': 107, 'learning_rate': 0.008275079671415594, 'n_estimators': 159, 'min_child_samples': 54, 'min_child_weight': 0.7043514483859136, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.030059091544501742, 'reg_lambda': 0.0006733262279028132}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,082] Trial 621 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 333, 'max_depth': 45, 'learning_rate': 0.014431446091229956, 'n_estimators': 106, 'min_child_samples': 46, 'min_child_weight': 0.0004810341721256357, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.473061887882221e-05, 'reg_lambda': 0.00019605363966734718}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,222] Trial 622 finished with value: 0.828254477109439 and parameters: {'num_leaves': 351, 'max_depth': 41, 'learning_rate': 0.005180916225911453, 'n_estimators': 184, 'min_child_samples': 52, 'min_child_weight': 0.8084734844939353, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.512369529748022e-05, 'reg_lambda': 0.0016890003782426381}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,386] Trial 623 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 297, 'max_depth': 110, 'learning_rate': 0.01909146151776762, 'n_estimators': 204, 'min_child_samples': 48, 'min_child_weight': 0.0033089972390053135, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.685006231902958e-05, 'reg_lambda': 0.00223498264563966}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,504] Trial 624 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 327, 'max_depth': 100, 'learning_rate': 0.03843413946261741, 'n_estimators': 145, 'min_child_samples': 57, 'min_child_weight': 0.00029980244203198307, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3014707271566591e-05, 'reg_lambda': 0.0009582225926627059}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,628] Trial 625 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 340, 'max_depth': 37, 'learning_rate': 0.01262440444603486, 'n_estimators': 121, 'min_child_samples': 50, 'min_child_weight': 0.0015927197597525062, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.095997678255263e-05, 'reg_lambda': 0.0002903902180306327}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,767] Trial 626 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 309, 'max_depth': 34, 'learning_rate': 0.031366427383591515, 'n_estimators': 175, 'min_child_samples': 54, 'min_child_weight': 0.00036901865658756864, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7238983432327945e-05, 'reg_lambda': 0.00040426841040876513}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:12,898] Trial 627 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 366, 'max_depth': 68, 'learning_rate': 0.008220039570798025, 'n_estimators': 148, 'min_child_samples': 53, 'min_child_weight': 0.00018809063458152995, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7753900173767338e-05, 'reg_lambda': 4.700298893274227}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,014] Trial 628 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 272, 'max_depth': 51, 'learning_rate': 0.020028027181213704, 'n_estimators': 102, 'min_child_samples': 51, 'min_child_weight': 0.0005485891768620674, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4163460101874645e-05, 'reg_lambda': 0.0006879860617247818}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,141] Trial 629 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 258, 'max_depth': 45, 'learning_rate': 0.02846812956554472, 'n_estimators': 101, 'min_child_samples': 50, 'min_child_weight': 0.0006463246110228042, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0845923377055455e-05, 'reg_lambda': 0.0007405770139535591}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,257] Trial 630 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 267, 'max_depth': 46, 'learning_rate': 0.020568541632790732, 'n_estimators': 107, 'min_child_samples': 48, 'min_child_weight': 0.0004920802377745458, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.061349512172761e-05, 'reg_lambda': 0.0009445505351534221}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,381] Trial 631 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 266, 'max_depth': 50, 'learning_rate': 0.07441903202419262, 'n_estimators': 100, 'min_child_samples': 44, 'min_child_weight': 0.000496978303638181, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6551529649775388e-05, 'reg_lambda': 0.000791007478586175}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,497] Trial 632 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 254, 'max_depth': 39, 'learning_rate': 0.055421942467142465, 'n_estimators': 102, 'min_child_samples': 47, 'min_child_weight': 0.0005627719826103052, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1012827363227857e-05, 'reg_lambda': 0.001050682428641671}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:13,615] Trial 633 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 273, 'max_depth': 41, 'learning_rate': 0.025186355476382195, 'n_estimators': 112, 'min_child_samples': 45, 'min_child_weight': 3.055009480517133e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3217034154236016e-05, 'reg_lambda': 0.001187286840328863}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,031] Trial 634 finished with value: 0.7486861861861861 and parameters: {'num_leaves': 269, 'max_depth': 52, 'learning_rate': 0.10926565871313747, 'n_estimators': 802, 'min_child_samples': 42, 'min_child_weight': 0.0007633733249995274, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.755433124091196e-05, 'reg_lambda': 0.0005427975938332716}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,143] Trial 635 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 261, 'max_depth': 50, 'learning_rate': 0.041973800112368814, 'n_estimators': 95, 'min_child_samples': 47, 'min_child_weight': 0.0004220548426474205, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3789396235284572e-05, 'reg_lambda': 0.0005916341487179545}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,245] Trial 636 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 244, 'max_depth': 42, 'learning_rate': 0.019531720991046792, 'n_estimators': 123, 'min_child_samples': 48, 'min_child_weight': 0.0009702668286109751, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 8.34452734015745, 'reg_lambda': 0.0008948693003099751}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,361] Trial 637 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 280, 'max_depth': 38, 'learning_rate': 0.032650884909275806, 'n_estimators': 114, 'min_child_samples': 49, 'min_child_weight': 0.0005510118708840688, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2940329613758623e-05, 'reg_lambda': 0.0013151759542741456}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,475] Trial 638 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 277, 'max_depth': 47, 'learning_rate': 0.017995706932009792, 'n_estimators': 93, 'min_child_samples': 47, 'min_child_weight': 0.00041517966667599105, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0007053326630615281, 'reg_lambda': 0.0006093324253560308}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,596] Trial 639 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 264, 'max_depth': 53, 'learning_rate': 0.02345379286760657, 'n_estimators': 124, 'min_child_samples': 45, 'min_child_weight': 0.0006445430958432462, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.005865041588681088, 'reg_lambda': 0.0008374911976984947}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,712] Trial 640 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 287, 'max_depth': 47, 'learning_rate': 0.04548085267443002, 'n_estimators': 93, 'min_child_samples': 50, 'min_child_weight': 0.0005091273949915269, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5854427129747784e-05, 'reg_lambda': 0.00040942335310774043}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,825] Trial 641 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 252, 'max_depth': 47, 'learning_rate': 0.01984809922706065, 'n_estimators': 129, 'min_child_samples': 51, 'min_child_weight': 0.0003733632092762685, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1263525492495333e-05, 'reg_lambda': 0.0007143814856660593}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:14,942] Trial 642 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 274, 'max_depth': 46, 'learning_rate': 0.015826809960674152, 'n_estimators': 118, 'min_child_samples': 48, 'min_child_weight': 0.0008274180858932592, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.008852351550505068, 'reg_lambda': 0.0015194008416111028}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,049] Trial 643 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 289, 'max_depth': 44, 'learning_rate': 0.031249422296009216, 'n_estimators': 102, 'min_child_samples': 51, 'min_child_weight': 0.0002770834901387544, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5779559769664174e-05, 'reg_lambda': 0.0010410822426798595}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,185] Trial 644 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 270, 'max_depth': 107, 'learning_rate': 0.021953683625073363, 'n_estimators': 137, 'min_child_samples': 46, 'min_child_weight': 0.00045786092204991877, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7240979922277464e-05, 'reg_lambda': 0.0005599241125852256}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,291] Trial 645 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 287, 'max_depth': 58, 'learning_rate': 0.012918465232055245, 'n_estimators': 90, 'min_child_samples': 49, 'min_child_weight': 0.0006860947408088754, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.248967148256127e-05, 'reg_lambda': 0.0012420447959273428}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,431] Trial 646 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 292, 'max_depth': 43, 'learning_rate': 0.030300937734003237, 'n_estimators': 130, 'min_child_samples': 42, 'min_child_weight': 0.0003427641780360863, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.099380708771735e-05, 'reg_lambda': 0.0007695779152468307}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,545] Trial 647 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 275, 'max_depth': 46, 'learning_rate': 0.01627656816143763, 'n_estimators': 109, 'min_child_samples': 51, 'min_child_weight': 0.0005791832299057723, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.784377277592168e-05, 'reg_lambda': 0.001704794233844745}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,670] Trial 648 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 257, 'max_depth': 48, 'learning_rate': 0.022747937257964677, 'n_estimators': 147, 'min_child_samples': 49, 'min_child_weight': 0.0011589607424326292, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0086057765092005e-05, 'reg_lambda': 0.00040297926049706}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,787] Trial 649 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 298, 'max_depth': 50, 'learning_rate': 0.045341423624621006, 'n_estimators': 117, 'min_child_samples': 53, 'min_child_weight': 0.00043456921365521585, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7151053554409506e-05, 'reg_lambda': 0.00032472348266609266}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:15,920] Trial 650 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 279, 'max_depth': 51, 'learning_rate': 0.01290239438026865, 'n_estimators': 135, 'min_child_samples': 46, 'min_child_weight': 0.0008493958676627553, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3125108849733821e-05, 'reg_lambda': 0.0009691329835968125}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,023] Trial 651 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 263, 'max_depth': 45, 'learning_rate': 0.030033993746013798, 'n_estimators': 91, 'min_child_samples': 52, 'min_child_weight': 1.7746169030909877e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6247253696255113e-05, 'reg_lambda': 0.0005815176134199838}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,151] Trial 652 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 304, 'max_depth': 44, 'learning_rate': 0.01834155177776936, 'n_estimators': 153, 'min_child_samples': 50, 'min_child_weight': 0.00010876477490945169, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8877695607906944e-05, 'reg_lambda': 0.0020220723040391526}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,271] Trial 653 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 285, 'max_depth': 56, 'learning_rate': 0.011927193942871636, 'n_estimators': 114, 'min_child_samples': 48, 'min_child_weight': 0.00026547937475466285, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2777799355034965e-05, 'reg_lambda': 0.00019512461327038483}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,441] Trial 654 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 296, 'max_depth': 43, 'learning_rate': 0.01641784210373422, 'n_estimators': 251, 'min_child_samples': 51, 'min_child_weight': 0.0005108463775086403, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.008959185664925e-05, 'reg_lambda': 0.0004962728005315764}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,600] Trial 655 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 312, 'max_depth': 49, 'learning_rate': 0.02300446765820873, 'n_estimators': 137, 'min_child_samples': 44, 'min_child_weight': 0.9654760462453765, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0121129170056326e-05, 'reg_lambda': 0.0013949341010964528}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,778] Trial 656 finished with value: 0.7894847929579429 and parameters: {'num_leaves': 319, 'max_depth': 33, 'learning_rate': 0.03185653281251166, 'n_estimators': 291, 'min_child_samples': 53, 'min_child_weight': 0.00034135716140828293, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.090159810455373e-05, 'reg_lambda': 0.0028395899122510924}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:16,900] Trial 657 finished with value: 0.8089657669881551 and parameters: {'num_leaves': 239, 'max_depth': 53, 'learning_rate': 0.010895570884741707, 'n_estimators': 84, 'min_child_samples': 31, 'min_child_weight': 0.0006476710654927304, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.540918770310062e-05, 'reg_lambda': 0.0007065538932126615}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,033] Trial 658 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 292, 'max_depth': 112, 'learning_rate': 0.014503397884408957, 'n_estimators': 165, 'min_child_samples': 55, 'min_child_weight': 0.00039688456298884496, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.831707251119533e-05, 'reg_lambda': 0.00010281172879639728}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,170] Trial 659 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 275, 'max_depth': 112, 'learning_rate': 0.010694572757000127, 'n_estimators': 167, 'min_child_samples': 55, 'min_child_weight': 0.00044372804422902415, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.980266526335299e-05, 'reg_lambda': 3.025135832124764e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,306] Trial 660 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 288, 'max_depth': 109, 'learning_rate': 0.043798322195589504, 'n_estimators': 198, 'min_child_samples': 55, 'min_child_weight': 0.0007267206341402143, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3269147380441645e-05, 'reg_lambda': 0.0010335747657815911}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,449] Trial 661 finished with value: 0.7207207207207207 and parameters: {'num_leaves': 262, 'max_depth': 112, 'learning_rate': 0.9724748929805382, 'n_estimators': 182, 'min_child_samples': 56, 'min_child_weight': 0.0005212222137207589, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0030483670940891e-05, 'reg_lambda': 0.2096942564376908}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,586] Trial 662 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 285, 'max_depth': 117, 'learning_rate': 0.021104487960717875, 'n_estimators': 161, 'min_child_samples': 54, 'min_child_weight': 0.0010935099763006713, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8880691726517376e-05, 'reg_lambda': 0.0023607041787499826}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,746] Trial 663 finished with value: 0.7712329508461043 and parameters: {'num_leaves': 295, 'max_depth': 114, 'learning_rate': 0.07013350855957368, 'n_estimators': 216, 'min_child_samples': 53, 'min_child_weight': 0.0003963428796431571, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.512844767793076e-05, 'reg_lambda': 0.3756112093633494}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:17,877] Trial 664 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 268, 'max_depth': 109, 'learning_rate': 0.013698766076768655, 'n_estimators': 158, 'min_child_samples': 56, 'min_child_weight': 0.0006227587555657541, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.3292886634565434e-05, 'reg_lambda': 0.001585825720895384}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:18,002] Trial 665 finished with value: 0.7843572540630146 and parameters: {'num_leaves': 270, 'max_depth': 105, 'learning_rate': 0.027804155497052105, 'n_estimators': 182, 'min_child_samples': 58, 'min_child_weight': 0.0008057774821837346, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.3035445074057975e-05, 'reg_lambda': 1.8000398965910063e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:18,354] Trial 666 finished with value: 0.7893478279020448 and parameters: {'num_leaves': 302, 'max_depth': 108, 'learning_rate': 0.015920456948799424, 'n_estimators': 856, 'min_child_samples': 56, 'min_child_weight': 0.0005951166669552968, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.787126148927054e-05, 'reg_lambda': 4.222116597796351e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:18,615] Trial 667 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 281, 'max_depth': 122, 'learning_rate': 0.009382825475330042, 'n_estimators': 582, 'min_child_samples': 58, 'min_child_weight': 0.0006623112012084541, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.251352126276909e-05, 'reg_lambda': 6.584396412226046e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:18,746] Trial 668 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 247, 'max_depth': 119, 'learning_rate': 0.02144560991404541, 'n_estimators': 163, 'min_child_samples': 60, 'min_child_weight': 0.000512519296586596, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.4440718947650974e-05, 'reg_lambda': 0.0015652700398080446}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:18,887] Trial 669 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 292, 'max_depth': 103, 'learning_rate': 0.014368331925582949, 'n_estimators': 201, 'min_child_samples': 55, 'min_child_weight': 0.0007462114785884945, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0423249382918348e-05, 'reg_lambda': 5.217233514398416e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,052] Trial 670 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 303, 'max_depth': 113, 'learning_rate': 3.724837181977628e-08, 'n_estimators': 234, 'min_child_samples': 57, 'min_child_weight': 0.0008959809573721125, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.032504742279284e-05, 'reg_lambda': 9.209650385439773e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,193] Trial 671 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 252, 'max_depth': 110, 'learning_rate': 0.03651250619725491, 'n_estimators': 161, 'min_child_samples': 56, 'min_child_weight': 0.0004099232129956645, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4449990788011228e-05, 'reg_lambda': 0.0017461472310404118}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,331] Trial 672 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 261, 'max_depth': 116, 'learning_rate': 0.023917987975869633, 'n_estimators': 137, 'min_child_samples': 52, 'min_child_weight': 0.0005885046935391739, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3381774710158205e-05, 'reg_lambda': 0.0012505654819487727}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,465] Trial 673 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 278, 'max_depth': 106, 'learning_rate': 0.010687575727539466, 'n_estimators': 186, 'min_child_samples': 54, 'min_child_weight': 0.00035513711133673573, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.001742833813830097, 'reg_lambda': 0.0024367631366561645}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,593] Trial 674 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 304, 'max_depth': 113, 'learning_rate': 0.016243135845178436, 'n_estimators': 152, 'min_child_samples': 46, 'min_child_weight': 0.001070887896179352, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.787341487041782, 'reg_lambda': 0.0018739918577778075}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,732] Trial 675 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 291, 'max_depth': 118, 'learning_rate': 0.00018982191041609368, 'n_estimators': 169, 'min_child_samples': 52, 'min_child_weight': 0.00048283582381092674, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6442286782162917e-05, 'reg_lambda': 0.0009908521415858066}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,866] Trial 676 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 326, 'max_depth': 109, 'learning_rate': 0.0511173061716241, 'n_estimators': 132, 'min_child_samples': 55, 'min_child_weight': 0.0006535348356586945, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.45790967788023e-05, 'reg_lambda': 0.0012971037656000714}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:19,992] Trial 677 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 342, 'max_depth': 115, 'learning_rate': 0.029697954301535726, 'n_estimators': 147, 'min_child_samples': 58, 'min_child_weight': 0.00046427780484890093, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.358229766725846e-05, 'reg_lambda': 0.0032220411177772065}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,241] Trial 678 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 271, 'max_depth': 107, 'learning_rate': 0.012777297902061146, 'n_estimators': 493, 'min_child_samples': 48, 'min_child_weight': 0.0008883311294266649, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2925706090834445e-05, 'reg_lambda': 0.0008595421708071439}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,392] Trial 679 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 383, 'max_depth': 111, 'learning_rate': 0.019982871857796448, 'n_estimators': 211, 'min_child_samples': 51, 'min_child_weight': 0.000360850683016321, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.01279522261115319, 'reg_lambda': 0.0023646808725597324}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,543] Trial 680 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 357, 'max_depth': 103, 'learning_rate': 0.008350568231344044, 'n_estimators': 178, 'min_child_samples': 54, 'min_child_weight': 0.0005550889572594727, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9779104987797798e-05, 'reg_lambda': 0.001430650681273447}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,664] Trial 681 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 312, 'max_depth': 116, 'learning_rate': 0.01430890812397265, 'n_estimators': 121, 'min_child_samples': 44, 'min_child_weight': 0.03685464494657948, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.6793019868998554e-05, 'reg_lambda': 0.0006698380129462613}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,776] Trial 682 finished with value: 0.7710071472875935 and parameters: {'num_leaves': 281, 'max_depth': 120, 'learning_rate': 0.3178187039911336, 'n_estimators': 144, 'min_child_samples': 49, 'min_child_weight': 0.0003217565137793358, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6547937291422297, 'reg_lambda': 0.0010511468964543266}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:20,924] Trial 683 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 334, 'max_depth': 112, 'learning_rate': 0.02171731725017155, 'n_estimators': 164, 'min_child_samples': 56, 'min_child_weight': 0.06937707857298131, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0034268659402640596, 'reg_lambda': 0.0019386138582023604}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,040] Trial 684 finished with value: 0.828254477109439 and parameters: {'num_leaves': 295, 'max_depth': 61, 'learning_rate': 0.009177066271659866, 'n_estimators': 122, 'min_child_samples': 53, 'min_child_weight': 0.0007104585618650775, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.465323269977167e-05, 'reg_lambda': 1.1813350549051064e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,197] Trial 685 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 347, 'max_depth': 106, 'learning_rate': 0.03409557693003524, 'n_estimators': 184, 'min_child_samples': 47, 'min_child_weight': 0.00045983234023712507, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8039636576627007e-05, 'reg_lambda': 0.9931417015747378}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,310] Trial 686 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 320, 'max_depth': 114, 'learning_rate': 0.014463763781390911, 'n_estimators': 106, 'min_child_samples': 51, 'min_child_weight': 0.0013659266237577303, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.66115786254747e-05, 'reg_lambda': 0.0004587451939747514}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,523] Trial 687 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 371, 'max_depth': 109, 'learning_rate': 0.02129874347237181, 'n_estimators': 452, 'min_child_samples': 59, 'min_child_weight': 0.000232349246494629, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.276050958902027e-05, 'reg_lambda': 0.7446189125942144}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,654] Trial 688 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 303, 'max_depth': 117, 'learning_rate': 0.01029731627756092, 'n_estimators': 136, 'min_child_samples': 49, 'min_child_weight': 0.0005724160846443425, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3485476774287357e-05, 'reg_lambda': 0.0017905774899093921}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,814] Trial 689 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 334, 'max_depth': 122, 'learning_rate': 0.02889540714595872, 'n_estimators': 154, 'min_child_samples': 52, 'min_child_weight': 0.00040366301435691763, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.506637278444114e-05, 'reg_lambda': 0.0008196777256565255}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:21,926] Trial 690 finished with value: 0.8089657669881551 and parameters: {'num_leaves': 260, 'max_depth': 111, 'learning_rate': 0.0068167284739304446, 'n_estimators': 95, 'min_child_samples': 55, 'min_child_weight': 0.0009139885419177997, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8878094060103488e-05, 'reg_lambda': 0.0030546663920533656}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,056] Trial 691 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 285, 'max_depth': 104, 'learning_rate': 0.016963860635685755, 'n_estimators': 123, 'min_child_samples': 57, 'min_child_weight': 0.00030302103939693265, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0167285150132852e-05, 'reg_lambda': 0.0012608468808390618}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,295] Trial 692 finished with value: 0.7799872591586683 and parameters: {'num_leaves': 292, 'max_depth': 100, 'learning_rate': 0.039220540071950305, 'n_estimators': 536, 'min_child_samples': 60, 'min_child_weight': 0.0002834419788116371, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0379409139421434e-05, 'reg_lambda': 0.0011365222172509432}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,406] Trial 693 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 303, 'max_depth': 103, 'learning_rate': 0.020137547977365212, 'n_estimators': 81, 'min_child_samples': 62, 'min_child_weight': 0.00017397625001147062, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0308264666427892e-05, 'reg_lambda': 0.000756788583942206}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,521] Trial 694 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 284, 'max_depth': 101, 'learning_rate': 0.0591123934695205, 'n_estimators': 110, 'min_child_samples': 46, 'min_child_weight': 0.0002972266682074688, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2885109158450856e-05, 'reg_lambda': 0.0005392885611197638}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,670] Trial 695 finished with value: 0.546300794486571 and parameters: {'num_leaves': 312, 'max_depth': 104, 'learning_rate': 0.001150487549569232, 'n_estimators': 126, 'min_child_samples': 41, 'min_child_weight': 0.00023153655869641643, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2651771157955636e-05, 'reg_lambda': 0.5546706023011796}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,781] Trial 696 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 322, 'max_depth': 105, 'learning_rate': 0.00047798202877263164, 'n_estimators': 86, 'min_child_samples': 50, 'min_child_weight': 0.00033647064102091295, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.5128538845827873e-05, 'reg_lambda': 0.0006913869991820465}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:22,898] Trial 697 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 293, 'max_depth': 101, 'learning_rate': 0.02834566229283359, 'n_estimators': 108, 'min_child_samples': 53, 'min_child_weight': 0.00019593362746653638, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0126857847402662e-05, 'reg_lambda': 0.8166250060181479}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,026] Trial 698 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 356, 'max_depth': 118, 'learning_rate': 0.01700002909748267, 'n_estimators': 128, 'min_child_samples': 58, 'min_child_weight': 0.0002454740438650415, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0036076588885113e-05, 'reg_lambda': 0.0009425658923551154}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,141] Trial 699 finished with value: 0.7974449198985706 and parameters: {'num_leaves': 309, 'max_depth': 114, 'learning_rate': 0.04305864054325242, 'n_estimators': 99, 'min_child_samples': 48, 'min_child_weight': 0.0003697556481115576, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6573613297202915e-05, 'reg_lambda': 0.00045054784401415374}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,261] Trial 700 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 343, 'max_depth': 106, 'learning_rate': 0.01098034644092692, 'n_estimators': 134, 'min_child_samples': 52, 'min_child_weight': 0.00015421457793877953, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3650208949218924e-05, 'reg_lambda': 0.0012271844370561752}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,379] Trial 701 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 328, 'max_depth': 115, 'learning_rate': 0.0236849622534236, 'n_estimators': 113, 'min_child_samples': 54, 'min_child_weight': 0.0002895989520734836, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8700688154371876e-05, 'reg_lambda': 0.5485909438551297}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,479] Trial 702 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 298, 'max_depth': 123, 'learning_rate': 0.017729864101828554, 'n_estimators': 77, 'min_child_samples': 45, 'min_child_weight': 0.00013023400344904093, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3497762261623967e-05, 'reg_lambda': 0.9428183510445669}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,603] Trial 703 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 285, 'max_depth': 98, 'learning_rate': 0.012151630880416465, 'n_estimators': 132, 'min_child_samples': 50, 'min_child_weight': 0.00041769156157105516, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0551352366105248e-05, 'reg_lambda': 0.0006533934605514888}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,747] Trial 704 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 316, 'max_depth': 119, 'learning_rate': 0.02921614661839643, 'n_estimators': 150, 'min_child_samples': 57, 'min_child_weight': 0.0003187127283483739, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.581868166552188e-05, 'reg_lambda': 0.0010854815764593756}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:23,877] Trial 705 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 365, 'max_depth': 112, 'learning_rate': 0.016928878933343283, 'n_estimators': 93, 'min_child_samples': 48, 'min_child_weight': 0.00042693442173435015, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0322269180833763e-05, 'reg_lambda': 0.00033650202472414154}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,025] Trial 706 finished with value: 0.8094043185704923 and parameters: {'num_leaves': 281, 'max_depth': 103, 'learning_rate': 0.00820842453264256, 'n_estimators': 123, 'min_child_samples': 52, 'min_child_weight': 0.00023586133614826533, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.3138150653366828e-05, 'reg_lambda': 0.0005018597230856268}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,169] Trial 707 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 349, 'max_depth': 107, 'learning_rate': 0.02374729886589321, 'n_estimators': 147, 'min_child_samples': 55, 'min_child_weight': 0.00047806001751055153, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0024725649461614e-05, 'reg_lambda': 0.3733295253595793}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,309] Trial 708 finished with value: 0.8115146396396395 and parameters: {'num_leaves': 336, 'max_depth': 117, 'learning_rate': 0.039871991971187105, 'n_estimators': 171, 'min_child_samples': 50, 'min_child_weight': 0.8247797006086994, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2309394167422293e-05, 'reg_lambda': 0.10849116038167171}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,586] Trial 709 finished with value: 0.7960110421373203 and parameters: {'num_leaves': 323, 'max_depth': 109, 'learning_rate': 0.01252512256565816, 'n_estimators': 116, 'min_child_samples': 8, 'min_child_weight': 0.00034665676246821355, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8185522378702465e-05, 'reg_lambda': 2.1902601883116536e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,730] Trial 710 finished with value: 0.7668475898578992 and parameters: {'num_leaves': 304, 'max_depth': 113, 'learning_rate': 0.08292546953906986, 'n_estimators': 196, 'min_child_samples': 47, 'min_child_weight': 0.6338004126589333, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0029590971564924e-05, 'reg_lambda': 0.0009290908395498969}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,841] Trial 711 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 296, 'max_depth': 116, 'learning_rate': 0.007286151706200209, 'n_estimators': 107, 'min_child_samples': 54, 'min_child_weight': 9.06265362630346e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5518190675435283e-05, 'reg_lambda': 0.48631425294277375}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:24,948] Trial 712 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 313, 'max_depth': 111, 'learning_rate': 0.01821223268131477, 'n_estimators': 85, 'min_child_samples': 57, 'min_child_weight': 0.000537737531284817, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.628406326311671e-05, 'reg_lambda': 0.0014784123540519218}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,091] Trial 713 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 276, 'max_depth': 105, 'learning_rate': 1.3749878919452674e-07, 'n_estimators': 153, 'min_child_samples': 44, 'min_child_weight': 0.00019162179278618894, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.308951252444532e-05, 'reg_lambda': 0.0024185133213993075}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,214] Trial 714 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 337, 'max_depth': 119, 'learning_rate': 0.011285228777372452, 'n_estimators': 135, 'min_child_samples': 52, 'min_child_weight': 0.00027147354111313276, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0741919224411697e-05, 'reg_lambda': 0.6479089523834887}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,349] Trial 715 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 327, 'max_depth': 99, 'learning_rate': 0.02852795305052385, 'n_estimators': 168, 'min_child_samples': 50, 'min_child_weight': 0.0007656339027854108, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5767986663088295e-05, 'reg_lambda': 1.0914840155211238}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,459] Trial 716 finished with value: 0.828254477109439 and parameters: {'num_leaves': 360, 'max_depth': 114, 'learning_rate': 0.017060351585226907, 'n_estimators': 69, 'min_child_samples': 54, 'min_child_weight': 0.00039391193145036805, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4082029186191845e-05, 'reg_lambda': 0.1816377944964432}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,615] Trial 717 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 290, 'max_depth': 108, 'learning_rate': 0.009210158791710242, 'n_estimators': 215, 'min_child_samples': 48, 'min_child_weight': 0.0005899822445170703, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2818172910956236e-05, 'reg_lambda': 6.420434076102419e-05}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,727] Trial 718 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 348, 'max_depth': 110, 'learning_rate': 0.023617855643465687, 'n_estimators': 103, 'min_child_samples': 60, 'min_child_weight': 0.00046207518734458234, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.764908515442704e-05, 'reg_lambda': 0.0006415457382995689}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,859] Trial 719 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 374, 'max_depth': 102, 'learning_rate': 0.05313314472043826, 'n_estimators': 125, 'min_child_samples': 43, 'min_child_weight': 0.019563254339675186, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0036479740556517e-05, 'reg_lambda': 0.0008826858872884675}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:25,991] Trial 720 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 306, 'max_depth': 121, 'learning_rate': 0.014574735227945978, 'n_estimators': 142, 'min_child_samples': 52, 'min_child_weight': 0.0003179772127249178, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.9280532355081493e-05, 'reg_lambda': 0.00011034128758305273}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,136] Trial 721 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 320, 'max_depth': 116, 'learning_rate': 0.0348726397819385, 'n_estimators': 182, 'min_child_samples': 56, 'min_child_weight': 0.0005087660653140422, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.2201175681875506, 'reg_lambda': 0.00042085137923403504}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,267] Trial 722 finished with value: 0.8223949706477587 and parameters: {'num_leaves': 288, 'max_depth': 113, 'learning_rate': 0.006327972817604638, 'n_estimators': 100, 'min_child_samples': 46, 'min_child_weight': 0.9924905026485741, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0769126288444126e-05, 'reg_lambda': 0.00028004753338947436}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,380] Trial 723 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 332, 'max_depth': 105, 'learning_rate': 0.019148804645227623, 'n_estimators': 123, 'min_child_samples': 95, 'min_child_weight': 0.04992727748823666, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.4723341308660961e-05, 'reg_lambda': 0.23784700318712362}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,514] Trial 724 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 274, 'max_depth': 52, 'learning_rate': 0.010467022950608263, 'n_estimators': 161, 'min_child_samples': 50, 'min_child_weight': 0.00023301367482279838, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 2.7647859828587122e-05, 'reg_lambda': 0.0012531950301440773}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,663] Trial 725 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 345, 'max_depth': 111, 'learning_rate': 0.024724478851335864, 'n_estimators': 144, 'min_child_samples': 54, 'min_child_weight': 0.0003497977254773001, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2896029550414422e-05, 'reg_lambda': 0.34633391248919654}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,768] Trial 726 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 299, 'max_depth': 108, 'learning_rate': 0.014250395029313728, 'n_estimators': 81, 'min_child_samples': 48, 'min_child_weight': 0.0007012825250905335, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7622526722498898e-05, 'reg_lambda': 0.6909814034234715}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:26,917] Trial 727 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 356, 'max_depth': 48, 'learning_rate': 0.008977475269765021, 'n_estimators': 190, 'min_child_samples': 52, 'min_child_weight': 0.0004288488483456661, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.05474973177497, 'reg_lambda': 0.001982814879588349}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,031] Trial 728 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 309, 'max_depth': 115, 'learning_rate': 4.281497218793119e-05, 'n_estimators': 118, 'min_child_samples': 58, 'min_child_weight': 0.000970348972000092, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2320110051978872e-05, 'reg_lambda': 0.47902924030750527}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,187] Trial 729 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 316, 'max_depth': 118, 'learning_rate': 0.037826465192516555, 'n_estimators': 169, 'min_child_samples': 50, 'min_child_weight': 0.00017307601841073892, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3246921443489356e-05, 'reg_lambda': 0.0035972954425612202}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,324] Trial 730 finished with value: 0.8375802223628311 and parameters: {'num_leaves': 284, 'max_depth': 112, 'learning_rate': 0.014530270919728088, 'n_estimators': 140, 'min_child_samples': 56, 'min_child_weight': 0.0005752193778108689, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7265969035917123e-05, 'reg_lambda': 0.0007267061175675075}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,438] Trial 731 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 384, 'max_depth': 120, 'learning_rate': 0.02154554013031059, 'n_estimators': 99, 'min_child_samples': 57, 'min_child_weight': 0.0007799337887635438, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6735032039279478e-05, 'reg_lambda': 0.0005852384166586098}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,775] Trial 732 finished with value: 0.7937497910281415 and parameters: {'num_leaves': 273, 'max_depth': 55, 'learning_rate': 0.012093904331757804, 'n_estimators': 671, 'min_child_samples': 46, 'min_child_weight': 0.000584931245662592, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2557811700536668e-05, 'reg_lambda': 0.0003919918699639046}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:27,893] Trial 733 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 339, 'max_depth': 115, 'learning_rate': 0.0058887196887770525, 'n_estimators': 132, 'min_child_samples': 61, 'min_child_weight': 5.667250560199195e-05, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.6812739892164597e-05, 'reg_lambda': 0.0004988605184762478}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,013] Trial 734 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 281, 'max_depth': 107, 'learning_rate': 0.02908696182774615, 'n_estimators': 114, 'min_child_samples': 53, 'min_child_weight': 0.0007078476854258703, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.020080462682942734, 'reg_lambda': 0.0007308971855561079}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,110] Trial 735 finished with value: 0.828254477109439 and parameters: {'num_leaves': 264, 'max_depth': 104, 'learning_rate': 0.017963584194354044, 'n_estimators': 70, 'min_child_samples': 59, 'min_child_weight': 0.0011466956486209858, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0094149812384196e-05, 'reg_lambda': 0.0008068763041722101}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,293] Trial 736 finished with value: 0.7756126662376662 and parameters: {'num_leaves': 322, 'max_depth': 110, 'learning_rate': 0.05754540226973252, 'n_estimators': 262, 'min_child_samples': 49, 'min_child_weight': 0.0005642891319554617, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2747470936838515e-05, 'reg_lambda': 0.000579756415866788}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,430] Trial 737 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 329, 'max_depth': 123, 'learning_rate': 0.009096803515093907, 'n_estimators': 142, 'min_child_samples': 56, 'min_child_weight': 0.000983284432120495, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5906438354996456e-05, 'reg_lambda': 0.0003474265322825444}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,555] Trial 738 finished with value: 0.828254477109439 and parameters: {'num_leaves': 361, 'max_depth': 113, 'learning_rate': 0.014646660592344936, 'n_estimators': 95, 'min_child_samples': 51, 'min_child_weight': 0.0007526656788525694, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.175733906160773e-05, 'reg_lambda': 0.00045462821995426357}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,711] Trial 739 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 349, 'max_depth': 117, 'learning_rate': 0.02470439808515158, 'n_estimators': 121, 'min_child_samples': 54, 'min_child_weight': 0.02612680951844405, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.017275536495683e-05, 'reg_lambda': 0.0008644287696282894}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,845] Trial 740 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 493, 'max_depth': 108, 'learning_rate': 1.1899092000547977e-06, 'n_estimators': 145, 'min_child_samples': 48, 'min_child_weight': 0.0005406753951751434, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5813567595996404e-05, 'reg_lambda': 0.0012498666616829247}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:28,980] Trial 741 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 283, 'max_depth': 102, 'learning_rate': 0.03357403723859969, 'n_estimators': 108, 'min_child_samples': 52, 'min_child_weight': 0.593446243786726, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5165758169502308e-05, 'reg_lambda': 0.0006259300310311842}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,101] Trial 742 finished with value: 0.8108108108108109 and parameters: {'num_leaves': 299, 'max_depth': 112, 'learning_rate': 0.0187590105057138, 'n_estimators': 84, 'min_child_samples': 45, 'min_child_weight': 0.7486908115706932, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0074369207161518e-05, 'reg_lambda': 0.0008801289577295028}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,235] Trial 743 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 255, 'max_depth': 99, 'learning_rate': 0.007370718037226132, 'n_estimators': 127, 'min_child_samples': 56, 'min_child_weight': 0.00013808774812937443, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.923243063179474e-05, 'reg_lambda': 0.00027907178591286705}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,381] Trial 744 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 341, 'max_depth': 115, 'learning_rate': 0.01119514509321883, 'n_estimators': 139, 'min_child_samples': 51, 'min_child_weight': 0.0014942760090957319, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3455743248133894e-05, 'reg_lambda': 0.0015576239351226318}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,510] Trial 745 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 268, 'max_depth': 118, 'learning_rate': 0.014378822445485, 'n_estimators': 106, 'min_child_samples': 47, 'min_child_weight': 0.0008209651695712003, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.13098925884322912, 'reg_lambda': 0.0004792912265908475}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,669] Trial 746 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 308, 'max_depth': 110, 'learning_rate': 0.02483026646421751, 'n_estimators': 152, 'min_child_samples': 54, 'min_child_weight': 0.00048177299664375596, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.481135511371376e-05, 'reg_lambda': 0.8819664331175275}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,777] Trial 747 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 328, 'max_depth': 64, 'learning_rate': 0.046245659362415134, 'n_estimators': 69, 'min_child_samples': 50, 'min_child_weight': 1.0845467152918285e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5787491967495814e-05, 'reg_lambda': 0.2931878992402235}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:29,981] Trial 748 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 375, 'max_depth': 107, 'learning_rate': 0.019006145885813126, 'n_estimators': 386, 'min_child_samples': 53, 'min_child_weight': 0.0005906655132044, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.249745650529963e-05, 'reg_lambda': 1.2597330707655932}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,108] Trial 749 finished with value: 0.8101760010156956 and parameters: {'num_leaves': 284, 'max_depth': 105, 'learning_rate': 0.009965003071560159, 'n_estimators': 128, 'min_child_samples': 43, 'min_child_weight': 0.00035324392381973197, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0063337501159803e-05, 'reg_lambda': 0.0011725740923136253}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,218] Trial 750 finished with value: 0.8019307272857932 and parameters: {'num_leaves': 318, 'max_depth': 113, 'learning_rate': 0.005472383278597508, 'n_estimators': 89, 'min_child_samples': 49, 'min_child_weight': 0.0002815433121606127, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9922546482628328e-05, 'reg_lambda': 0.12842511193617862}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,347] Trial 751 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 337, 'max_depth': 49, 'learning_rate': 3.046971455275702e-06, 'n_estimators': 162, 'min_child_samples': 58, 'min_child_weight': 0.0006650540320152609, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9511354731092505e-05, 'reg_lambda': 0.0007294842138332592}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,472] Trial 752 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 355, 'max_depth': 115, 'learning_rate': 0.013752521844975463, 'n_estimators': 114, 'min_child_samples': 55, 'min_child_weight': 0.000444728649725327, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.550580337195337e-05, 'reg_lambda': 0.2230539475474606}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,609] Trial 753 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 392, 'max_depth': 121, 'learning_rate': 0.02702719471728064, 'n_estimators': 137, 'min_child_samples': 52, 'min_child_weight': 0.00022107112305848133, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2594686330219327e-05, 'reg_lambda': 0.0003739510282188717}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,772] Trial 754 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 273, 'max_depth': 110, 'learning_rate': 2.4954756951011863e-07, 'n_estimators': 176, 'min_child_samples': 46, 'min_child_weight': 0.0008355874851788367, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.084334752142298e-05, 'reg_lambda': 0.3948286247387637}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:30,942] Trial 755 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 368, 'max_depth': 117, 'learning_rate': 0.008039889337617631, 'n_estimators': 225, 'min_child_samples': 49, 'min_child_weight': 0.00011174791220898829, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7901605537505257e-05, 'reg_lambda': 0.0010065294355569082}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,057] Trial 756 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 297, 'max_depth': 102, 'learning_rate': 0.03816685486623899, 'n_estimators': 95, 'min_child_samples': 62, 'min_child_weight': 0.5226169631459343, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7977659516892304e-05, 'reg_lambda': 0.0005735437799947366}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,202] Trial 757 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 310, 'max_depth': 113, 'learning_rate': 0.019136941709727403, 'n_estimators': 153, 'min_child_samples': 51, 'min_child_weight': 0.0005239709833238347, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.359884311095271e-05, 'reg_lambda': 0.5014856997665035}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,352] Trial 758 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 328, 'max_depth': 109, 'learning_rate': 0.012077958878500859, 'n_estimators': 116, 'min_child_samples': 56, 'min_child_weight': 0.0011228315388899857, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0015868030419971e-05, 'reg_lambda': 0.0029037684860655257}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,475] Trial 759 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 344, 'max_depth': 119, 'learning_rate': 0.01901584020597212, 'n_estimators': 141, 'min_child_samples': 53, 'min_child_weight': 0.0006641367348329185, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2894993122856723e-05, 'reg_lambda': 0.6850921616421896}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,578] Trial 760 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 291, 'max_depth': 111, 'learning_rate': 0.030352882664908962, 'n_estimators': 71, 'min_child_samples': 47, 'min_child_weight': 0.010473382402158287, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6354732461226545e-05, 'reg_lambda': 0.0006925642579473266}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,728] Trial 761 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 301, 'max_depth': 105, 'learning_rate': 0.00029462312058471673, 'n_estimators': 199, 'min_child_samples': 58, 'min_child_weight': 0.9820457676570816, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2873724240362632e-05, 'reg_lambda': 0.2990637025572916}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:31,874] Trial 762 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 318, 'max_depth': 115, 'learning_rate': 0.010686796704639996, 'n_estimators': 127, 'min_child_samples': 54, 'min_child_weight': 0.00029271279809994457, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9176580825815273e-05, 'reg_lambda': 0.002129466013514464}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,013] Trial 763 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 246, 'max_depth': 107, 'learning_rate': 0.015167685180863281, 'n_estimators': 175, 'min_child_samples': 51, 'min_child_weight': 0.0004010847147804153, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.983959484760966e-05, 'reg_lambda': 0.15900554692871116}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,153] Trial 764 finished with value: 0.8176107141624382 and parameters: {'num_leaves': 279, 'max_depth': 46, 'learning_rate': 0.006737696556760415, 'n_estimators': 102, 'min_child_samples': 48, 'min_child_weight': 0.00048623080616519123, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0011288921462917782, 'reg_lambda': 0.0004348423660959845}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,318] Trial 765 finished with value: 0.7668475898578992 and parameters: {'num_leaves': 350, 'max_depth': 113, 'learning_rate': 0.11411370674687789, 'n_estimators': 148, 'min_child_samples': 56, 'min_child_weight': 0.7106389055203601, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5422661106091165e-05, 'reg_lambda': 0.00143542444931213}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,456] Trial 766 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 329, 'max_depth': 117, 'learning_rate': 7.489718834767116e-06, 'n_estimators': 116, 'min_child_samples': 45, 'min_child_weight': 0.00017933350674679174, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.416158129058108e-05, 'reg_lambda': 0.8519846485227637}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,605] Trial 767 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 363, 'max_depth': 110, 'learning_rate': 0.023691933318735127, 'n_estimators': 159, 'min_child_samples': 53, 'min_child_weight': 0.0003585928743888651, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2405554625281991e-05, 'reg_lambda': 0.0009930754641614443}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,732] Trial 768 finished with value: 0.788723176958471 and parameters: {'num_leaves': 264, 'max_depth': 100, 'learning_rate': 0.05362273243759151, 'n_estimators': 88, 'min_child_samples': 49, 'min_child_weight': 0.0006414901582197283, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.272306004293759e-05, 'reg_lambda': 0.00032201304471519607}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:32,892] Trial 769 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 309, 'max_depth': 120, 'learning_rate': 0.015068220760028016, 'n_estimators': 185, 'min_child_samples': 51, 'min_child_weight': 0.0002483900058728224, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.809960947588602e-05, 'reg_lambda': 0.0857716357578771}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,023] Trial 770 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 339, 'max_depth': 104, 'learning_rate': 0.009767489314618369, 'n_estimators': 133, 'min_child_samples': 55, 'min_child_weight': 0.0009289744122385129, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3265295085425913e-05, 'reg_lambda': 0.4317062396057998}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,138] Trial 771 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 287, 'max_depth': 115, 'learning_rate': 0.02993695303754866, 'n_estimators': 105, 'min_child_samples': 53, 'min_child_weight': 0.0005350006092184988, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.3859143526934204, 'reg_lambda': 0.22008398653216052}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,275] Trial 772 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 319, 'max_depth': 113, 'learning_rate': 0.01941184208214251, 'n_estimators': 155, 'min_child_samples': 59, 'min_child_weight': 0.00031886391364704876, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0053126753675413e-05, 'reg_lambda': 0.0017749157878808666}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,412] Trial 773 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 296, 'max_depth': 109, 'learning_rate': 0.0042130798522140925, 'n_estimators': 129, 'min_child_samples': 50, 'min_child_weight': 0.0018902197565348958, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2580150371912534e-05, 'reg_lambda': 0.0005526442684617795}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,576] Trial 774 finished with value: 0.7981467213347979 and parameters: {'num_leaves': 332, 'max_depth': 107, 'learning_rate': 0.03904217152987363, 'n_estimators': 205, 'min_child_samples': 40, 'min_child_weight': 0.0006850186132096621, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5797984269622584e-05, 'reg_lambda': 1.217692686923897}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,691] Trial 775 finished with value: 0.8219374163746324 and parameters: {'num_leaves': 271, 'max_depth': 117, 'learning_rate': 0.007748768301512382, 'n_estimators': 81, 'min_child_samples': 47, 'min_child_weight': 0.00045266542889059236, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8790000455937074e-05, 'reg_lambda': 0.0007965036279921613}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,829] Trial 776 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 354, 'max_depth': 125, 'learning_rate': 8.346290104425857e-05, 'n_estimators': 173, 'min_child_samples': 57, 'min_child_weight': 0.0004278665802635038, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 3.26830714062211e-05, 'reg_lambda': 0.5529609346920722}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:33,949] Trial 777 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 313, 'max_depth': 112, 'learning_rate': 0.0008298064451375636, 'n_estimators': 115, 'min_child_samples': 52, 'min_child_weight': 0.5831232982778662, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2571747949492252e-05, 'reg_lambda': 0.0012070909479494872}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,073] Trial 778 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 278, 'max_depth': 97, 'learning_rate': 0.012336289245096945, 'n_estimators': 141, 'min_child_samples': 55, 'min_child_weight': 0.0002166039361890268, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.9797822000927834, 'reg_lambda': 0.3404546953183543}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,205] Trial 779 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 234, 'max_depth': 103, 'learning_rate': 0.021792543316276114, 'n_estimators': 100, 'min_child_samples': 50, 'min_child_weight': 0.0008853670313034634, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5086508756631482e-05, 'reg_lambda': 0.0002543800052268534}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,324] Trial 780 finished with value: 0.814519979719652 and parameters: {'num_leaves': 304, 'max_depth': 115, 'learning_rate': 0.015742956754289255, 'n_estimators': 60, 'min_child_samples': 43, 'min_child_weight': 0.013831402872714468, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6017036138591098e-05, 'reg_lambda': 0.0004906786226882356}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,470] Trial 781 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 341, 'max_depth': 120, 'learning_rate': 0.010109990984107304, 'n_estimators': 158, 'min_child_samples': 48, 'min_child_weight': 0.00027496804655528643, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2300975956325793e-05, 'reg_lambda': 0.2528771940694599}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,611] Trial 782 finished with value: 0.780204207675669 and parameters: {'num_leaves': 254, 'max_depth': 112, 'learning_rate': 0.06851667995951133, 'n_estimators': 128, 'min_child_samples': 54, 'min_child_weight': 0.0005580686597087546, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.00038436122816615817, 'reg_lambda': 0.002589099696431717}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,771] Trial 783 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 288, 'max_depth': 109, 'learning_rate': 0.026020223788778288, 'n_estimators': 188, 'min_child_samples': 45, 'min_child_weight': 0.00014720601893730492, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0053890069160518e-05, 'reg_lambda': 0.8072124707122939}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:34,875] Trial 784 finished with value: 0.8019307272857932 and parameters: {'num_leaves': 327, 'max_depth': 51, 'learning_rate': 0.006083111900579524, 'n_estimators': 86, 'min_child_samples': 52, 'min_child_weight': 0.000364119040089186, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0715004621561696e-05, 'reg_lambda': 0.0009610726625072501}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,020] Trial 785 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 369, 'max_depth': 123, 'learning_rate': 0.015205183272350488, 'n_estimators': 145, 'min_child_samples': 64, 'min_child_weight': 0.0013130137366106232, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1749410467112215e-05, 'reg_lambda': 0.001545837926397826}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,153] Trial 786 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 350, 'max_depth': 107, 'learning_rate': 0.03580019438911229, 'n_estimators': 113, 'min_child_samples': 60, 'min_child_weight': 0.0007351428812394764, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.003040904568918e-05, 'reg_lambda': 0.0003689246914994063}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,320] Trial 787 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 321, 'max_depth': 71, 'learning_rate': 0.019457911084820905, 'n_estimators': 171, 'min_child_samples': 49, 'min_child_weight': 0.7998935078440059, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8458933501858165e-05, 'reg_lambda': 0.0007008180470529439}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,449] Trial 788 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 306, 'max_depth': 117, 'learning_rate': 0.011717586313541011, 'n_estimators': 127, 'min_child_samples': 57, 'min_child_weight': 0.0005131618360265243, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5296792028836383e-05, 'reg_lambda': 0.1522907805041208}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,593] Trial 789 finished with value: 0.828254477109439 and parameters: {'num_leaves': 411, 'max_depth': 105, 'learning_rate': 0.008270532359046408, 'n_estimators': 148, 'min_child_samples': 51, 'min_child_weight': 0.00039230445070291727, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4869776892459302e-05, 'reg_lambda': 0.6061678625552136}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,768] Trial 790 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 295, 'max_depth': 111, 'learning_rate': 0.025415455863266517, 'n_estimators': 239, 'min_child_samples': 54, 'min_child_weight': 0.0006385134635640554, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6389093762784553e-05, 'reg_lambda': 0.3477322644229064}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:35,905] Trial 791 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 336, 'max_depth': 114, 'learning_rate': 0.015042296984922212, 'n_estimators': 106, 'min_child_samples': 47, 'min_child_weight': 0.00024363105880526015, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3404358987973531e-05, 'reg_lambda': 0.002012958705950941}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,025] Trial 792 finished with value: 0.7484167964068502 and parameters: {'num_leaves': 359, 'max_depth': 101, 'learning_rate': 0.5895274920860027, 'n_estimators': 77, 'min_child_samples': 56, 'min_child_weight': 0.0003409333054758317, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0006764134262678e-05, 'reg_lambda': 0.43618207668829206}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,178] Trial 793 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 428, 'max_depth': 118, 'learning_rate': 0.03988067080672112, 'n_estimators': 205, 'min_child_samples': 53, 'min_child_weight': 0.001001588039142792, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.3859575941935612e-05, 'reg_lambda': 0.0006569576867917846}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,313] Trial 794 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 381, 'max_depth': 111, 'learning_rate': 0.01957675800671164, 'n_estimators': 124, 'min_child_samples': 50, 'min_child_weight': 0.4821033771226185, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.499040087920721e-05, 'reg_lambda': 1.043199519081162}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,492] Trial 795 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 264, 'max_depth': 26, 'learning_rate': 0.005115406383678415, 'n_estimators': 163, 'min_child_samples': 52, 'min_child_weight': 0.00048397381835985466, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.991343537451242e-05, 'reg_lambda': 0.0013579472145469928}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,615] Trial 796 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 281, 'max_depth': 115, 'learning_rate': 0.010839559455003114, 'n_estimators': 100, 'min_child_samples': 46, 'min_child_weight': 0.0007938486548381725, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5048472359683542e-05, 'reg_lambda': 0.0004611095563384186}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:36,926] Trial 797 finished with value: 0.77581499024798 and parameters: {'num_leaves': 315, 'max_depth': 108, 'learning_rate': 0.027920897522410285, 'n_estimators': 701, 'min_child_samples': 55, 'min_child_weight': 0.00031834398360375, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 2.6673580702181948e-05, 'reg_lambda': 0.0010758238266583738}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,065] Trial 798 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 299, 'max_depth': 46, 'learning_rate': 0.012627337017412584, 'n_estimators': 142, 'min_child_samples': 49, 'min_child_weight': 0.000611174097022903, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.294982800195301e-05, 'reg_lambda': 0.27190263063334863}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,272] Trial 799 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 342, 'max_depth': 106, 'learning_rate': 0.01929415497016614, 'n_estimators': 330, 'min_child_samples': 51, 'min_child_weight': 0.0004224751712909551, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.9905830589858156e-05, 'reg_lambda': 0.0008546431755402114}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,413] Trial 800 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 328, 'max_depth': 113, 'learning_rate': 0.00905549868621202, 'n_estimators': 182, 'min_child_samples': 58, 'min_child_weight': 0.00018814200739307023, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6135101750469646e-05, 'reg_lambda': 0.19885535001989182}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,542] Trial 801 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 286, 'max_depth': 121, 'learning_rate': 0.016186349932722333, 'n_estimators': 121, 'min_child_samples': 54, 'min_child_weight': 0.6269010987879179, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.0765567661511555e-05, 'reg_lambda': 0.5974933706214208}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,665] Trial 802 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 273, 'max_depth': 116, 'learning_rate': 0.04332453338665848, 'n_estimators': 87, 'min_child_samples': 47, 'min_child_weight': 0.00028130876787856246, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0029126189126717e-05, 'reg_lambda': 0.0006248936748825674}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,779] Trial 803 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 319, 'max_depth': 110, 'learning_rate': 0.026453363353735937, 'n_estimators': 58, 'min_child_samples': 49, 'min_child_weight': 0.0005051748935026809, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2987820540739472e-05, 'reg_lambda': 0.0031647529262120843}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:37,919] Trial 804 finished with value: 0.8101760010156956 and parameters: {'num_leaves': 348, 'max_depth': 102, 'learning_rate': 0.006537016744377705, 'n_estimators': 151, 'min_child_samples': 43, 'min_child_weight': 0.0007060358003148454, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0772168078875437e-05, 'reg_lambda': 0.0016394813241268234}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,048] Trial 805 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 335, 'max_depth': 119, 'learning_rate': 0.013104094881238208, 'n_estimators': 135, 'min_child_samples': 56, 'min_child_weight': 0.4264216707655464, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7161227550296972e-05, 'reg_lambda': 0.42038531064868273}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,199] Trial 806 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 305, 'max_depth': 114, 'learning_rate': 0.021220519860238516, 'n_estimators': 166, 'min_child_samples': 52, 'min_child_weight': 0.0010934250200935356, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.850497069994813e-05, 'reg_lambda': 0.0003204744889098214}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,322] Trial 807 finished with value: 0.8322757457573522 and parameters: {'num_leaves': 290, 'max_depth': 44, 'learning_rate': 0.009036035605597006, 'n_estimators': 106, 'min_child_samples': 53, 'min_child_weight': 0.00045776992420249027, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4696894501856926e-05, 'reg_lambda': 0.800816841384184}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,487] Trial 808 finished with value: 0.7845881595881596 and parameters: {'num_leaves': 362, 'max_depth': 105, 'learning_rate': 0.035348462369628006, 'n_estimators': 196, 'min_child_samples': 60, 'min_child_weight': 0.0003584037696893584, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.276758081148348e-05, 'reg_lambda': 0.00400674744876428}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,622] Trial 809 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 310, 'max_depth': 111, 'learning_rate': 0.015616555873438069, 'n_estimators': 120, 'min_child_samples': 45, 'min_child_weight': 0.00021214832616449383, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6178763470311094e-05, 'reg_lambda': 1.415078382853334}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:38,945] Trial 810 finished with value: 0.762456061251242 and parameters: {'num_leaves': 324, 'max_depth': 108, 'learning_rate': 0.05246291225576767, 'n_estimators': 640, 'min_child_samples': 50, 'min_child_weight': 0.0005885544011627725, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.122634864394559e-05, 'reg_lambda': 0.000491895613994837}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,096] Trial 811 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 261, 'max_depth': 98, 'learning_rate': 0.025138864507331746, 'n_estimators': 140, 'min_child_samples': 48, 'min_child_weight': 0.0008431404515857594, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2651301165719612e-05, 'reg_lambda': 0.0010390232187021016}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,205] Trial 812 finished with value: 0.8011367629688241 and parameters: {'num_leaves': 297, 'max_depth': 117, 'learning_rate': 0.011781932812926537, 'n_estimators': 93, 'min_child_samples': 92, 'min_child_weight': 0.00026686721166604695, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.954268969245063e-05, 'reg_lambda': 0.0007688519072726801}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,344] Trial 813 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 352, 'max_depth': 113, 'learning_rate': 0.007519164264448414, 'n_estimators': 172, 'min_child_samples': 55, 'min_child_weight': 0.0003859893473827954, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.677038846410307e-05, 'reg_lambda': 0.317046846129797}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,474] Trial 814 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 279, 'max_depth': 110, 'learning_rate': 3.6887785113948387e-07, 'n_estimators': 73, 'min_child_samples': 27, 'min_child_weight': 0.7419683153972177, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3737616234437044e-05, 'reg_lambda': 0.2091011819167908}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,621] Trial 815 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 335, 'max_depth': 104, 'learning_rate': 0.019614262658045337, 'n_estimators': 156, 'min_child_samples': 58, 'min_child_weight': 0.0005967852047095722, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2476220381137646e-05, 'reg_lambda': 0.0023787862263751586}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,760] Trial 816 finished with value: 0.8074315620902139 and parameters: {'num_leaves': 315, 'max_depth': 115, 'learning_rate': 0.004995847107351498, 'n_estimators': 112, 'min_child_samples': 51, 'min_child_weight': 0.00014972120901602835, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0095306134062162e-05, 'reg_lambda': 0.001264258626624661}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:39,907] Trial 817 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 269, 'max_depth': 119, 'learning_rate': 0.03168545587849762, 'n_estimators': 133, 'min_child_samples': 53, 'min_child_weight': 0.00045331404796983125, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.61611478996968e-05, 'reg_lambda': 0.0002313442473415809}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:40,083] Trial 818 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 367, 'max_depth': 50, 'learning_rate': 0.012597259227214148, 'n_estimators': 219, 'min_child_samples': 56, 'min_child_weight': 0.00030291168237209237, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6490869831210955e-05, 'reg_lambda': 0.0004150015898498058}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:40,306] Trial 819 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 304, 'max_depth': 58, 'learning_rate': 0.015609198121540623, 'n_estimators': 308, 'min_child_samples': 48, 'min_child_weight': 0.00011610011120949065, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0417221650897534e-05, 'reg_lambda': 0.576568899886733}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:40,485] Trial 820 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 343, 'max_depth': 107, 'learning_rate': 0.022432565022872702, 'n_estimators': 182, 'min_child_samples': 51, 'min_child_weight': 0.000797455673057879, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3204605068879922e-05, 'reg_lambda': 1.1149107928550095}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:40,615] Trial 821 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 288, 'max_depth': 112, 'learning_rate': 0.00821158607603566, 'n_estimators': 103, 'min_child_samples': 54, 'min_child_weight': 0.0005368672933749767, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6518902234443134e-05, 'reg_lambda': 0.4142777984335638}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:40,871] Trial 822 finished with value: 0.7756126662376662 and parameters: {'num_leaves': 326, 'max_depth': 109, 'learning_rate': 0.08986787453145932, 'n_estimators': 151, 'min_child_samples': 16, 'min_child_weight': 0.0014507385297258632, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.5537284625090676e-05, 'reg_lambda': 0.0005993263882503919}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,024] Trial 823 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 246, 'max_depth': 124, 'learning_rate': 0.011732444240227919, 'n_estimators': 125, 'min_child_samples': 46, 'min_child_weight': 0.0006665585725509912, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8590089953758787e-05, 'reg_lambda': 0.0008523071314856562}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,153] Trial 824 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 297, 'max_depth': 116, 'learning_rate': 0.03308134286444672, 'n_estimators': 87, 'min_child_samples': 49, 'min_child_weight': 0.8651036220574927, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.256506110684206e-05, 'reg_lambda': 0.0018676630692662486}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,267] Trial 825 finished with value: 0.828254477109439 and parameters: {'num_leaves': 354, 'max_depth': 101, 'learning_rate': 0.01772490692834199, 'n_estimators': 60, 'min_child_samples': 57, 'min_child_weight': 0.0003646245753521559, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0082844802997398e-05, 'reg_lambda': 0.7233715003526593}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,435] Trial 826 finished with value: 0.7891754645052336 and parameters: {'num_leaves': 399, 'max_depth': 113, 'learning_rate': 0.054204872805743244, 'n_estimators': 161, 'min_child_samples': 52, 'min_child_weight': 0.0004349763451344687, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9559453455347604e-05, 'reg_lambda': 0.13071836992152172}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,602] Trial 827 finished with value: 0.7976470259078955 and parameters: {'num_leaves': 374, 'max_depth': 118, 'learning_rate': 0.0034294300272571347, 'n_estimators': 135, 'min_child_samples': 54, 'min_child_weight': 0.00023284263135620972, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.601628140518985e-05, 'reg_lambda': 0.2682195098231693}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,774] Trial 828 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 317, 'max_depth': 105, 'learning_rate': 0.024018719018868498, 'n_estimators': 112, 'min_child_samples': 50, 'min_child_weight': 0.5371287532451219, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.277551438649299e-05, 'reg_lambda': 0.0012935108321642543}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:41,981] Trial 829 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 336, 'max_depth': 54, 'learning_rate': 0.01061353016153828, 'n_estimators': 185, 'min_child_samples': 44, 'min_child_weight': 0.00032701351543464453, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5635380759487164e-05, 'reg_lambda': 0.0003427041292311238}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:42,167] Trial 830 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 308, 'max_depth': 121, 'learning_rate': 0.016664064985914252, 'n_estimators': 148, 'min_child_samples': 55, 'min_child_weight': 0.00017286704677864833, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.289853174426325e-05, 'reg_lambda': 0.0005473866235024497}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:42,334] Trial 831 finished with value: 0.7960110421373203 and parameters: {'num_leaves': 280, 'max_depth': 111, 'learning_rate': 0.007052612823811953, 'n_estimators': 122, 'min_child_samples': 41, 'min_child_weight': 0.0009612137699017269, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.118301231897744e-05, 'reg_lambda': 0.17377751116433365}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:42,799] Trial 832 finished with value: 0.7803839056851105 and parameters: {'num_leaves': 254, 'max_depth': 108, 'learning_rate': 0.025482349663903097, 'n_estimators': 889, 'min_child_samples': 48, 'min_child_weight': 0.0005494694117742763, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.10801923867198e-05, 'reg_lambda': 0.49940995505787905}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:42,952] Trial 833 finished with value: 0.828254477109439 and parameters: {'num_leaves': 325, 'max_depth': 116, 'learning_rate': 0.012930780356030184, 'n_estimators': 98, 'min_child_samples': 52, 'min_child_weight': 0.0007126918480316368, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0089969702991039e-05, 'reg_lambda': 0.3273908127378031}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,129] Trial 834 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 291, 'max_depth': 113, 'learning_rate': 0.04167503283465659, 'n_estimators': 168, 'min_child_samples': 58, 'min_child_weight': 0.0004513089004450057, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7854257856605875e-05, 'reg_lambda': 0.0025833372127693132}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,286] Trial 835 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 346, 'max_depth': 110, 'learning_rate': 0.018297548858737106, 'n_estimators': 135, 'min_child_samples': 53, 'min_child_weight': 0.3718389164735412, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.817468125823339e-05, 'reg_lambda': 0.9256458087316431}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,424] Trial 836 finished with value: 0.8188643188643188 and parameters: {'num_leaves': 270, 'max_depth': 106, 'learning_rate': 0.01006342831834847, 'n_estimators': 76, 'min_child_samples': 46, 'min_child_weight': 0.000285591680644934, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3288940196686985e-05, 'reg_lambda': 0.0009782670993497542}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,597] Trial 837 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 359, 'max_depth': 48, 'learning_rate': 0.02970006683100767, 'n_estimators': 199, 'min_child_samples': 50, 'min_child_weight': 3.1032539044291785e-05, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.484222386382447e-05, 'reg_lambda': 0.0006763308752321072}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,734] Trial 838 finished with value: 0.8329250675208845 and parameters: {'num_leaves': 332, 'max_depth': 103, 'learning_rate': 0.015775444482700473, 'n_estimators': 112, 'min_child_samples': 56, 'min_child_weight': 0.000638558031013175, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.8769968266513175e-05, 'reg_lambda': 0.001626779245238565}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:43,904] Trial 839 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 313, 'max_depth': 116, 'learning_rate': 0.006104631027850605, 'n_estimators': 153, 'min_child_samples': 51, 'min_child_weight': 0.00020565862952794404, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5207239108762927e-05, 'reg_lambda': 0.36747598584908175}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:44,053] Trial 840 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 301, 'max_depth': 114, 'learning_rate': 0.022022982157033754, 'n_estimators': 92, 'min_child_samples': 47, 'min_child_weight': 0.0003957964137104034, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.2827308205735179e-05, 'reg_lambda': 0.0004742780425524734}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:44,406] Trial 841 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 281, 'max_depth': 119, 'learning_rate': 0.009333650429097139, 'n_estimators': 810, 'min_child_samples': 61, 'min_child_weight': 0.0008325065599681902, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5565024156180233e-05, 'reg_lambda': 0.00025929593644834464}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:44,561] Trial 842 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 342, 'max_depth': 108, 'learning_rate': 0.013636813206272315, 'n_estimators': 136, 'min_child_samples': 54, 'min_child_weight': 0.0011731250912548064, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.904140485529577e-05, 'reg_lambda': 0.0008109246234598117}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:44,763] Trial 843 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 324, 'max_depth': 99, 'learning_rate': 0.03487116758674571, 'n_estimators': 179, 'min_child_samples': 49, 'min_child_weight': 0.0005080902470650568, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2922665114489215e-05, 'reg_lambda': 0.2223374970201076}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:44,906] Trial 844 finished with value: 0.77581499024798 and parameters: {'num_leaves': 291, 'max_depth': 111, 'learning_rate': 0.1675395693546252, 'n_estimators': 120, 'min_child_samples': 52, 'min_child_weight': 0.0002640233284971033, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.1337855093404294e-05, 'reg_lambda': 0.6364533024330089}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,078] Trial 845 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 383, 'max_depth': 45, 'learning_rate': 0.01948322899381878, 'n_estimators': 153, 'min_child_samples': 55, 'min_child_weight': 0.6597327484842826, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.1391403564989814e-05, 'reg_lambda': 0.0003803376265146191}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,277] Trial 846 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 263, 'max_depth': 114, 'learning_rate': 0.008853428642485367, 'n_estimators': 228, 'min_child_samples': 58, 'min_child_weight': 0.000345555621360443, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0065369563868307e-05, 'reg_lambda': 0.0021043731497654918}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,435] Trial 847 finished with value: 0.8113125973051377 and parameters: {'num_leaves': 309, 'max_depth': 118, 'learning_rate': 0.060197931601643544, 'n_estimators': 102, 'min_child_samples': 45, 'min_child_weight': 0.0005381149891957862, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 2.2040405300566182e-05, 'reg_lambda': 0.0011413030303360754}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,574] Trial 848 finished with value: 0.8015928153859189 and parameters: {'num_leaves': 351, 'max_depth': 122, 'learning_rate': 0.004522532531353415, 'n_estimators': 66, 'min_child_samples': 48, 'min_child_weight': 0.0006493236395430915, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.610053016750709e-05, 'reg_lambda': 1.4201826339951193}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,733] Trial 849 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 334, 'max_depth': 103, 'learning_rate': 0.014068348045877027, 'n_estimators': 137, 'min_child_samples': 53, 'min_child_weight': 0.43530672625797684, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5011434104283308e-05, 'reg_lambda': 0.4879613903293286}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:45,916] Trial 850 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 318, 'max_depth': 109, 'learning_rate': 0.026165776326886003, 'n_estimators': 169, 'min_child_samples': 50, 'min_child_weight': 0.0003866443531859493, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.028749020879126e-05, 'reg_lambda': 0.03645856868569765}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,054] Trial 851 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 298, 'max_depth': 112, 'learning_rate': 0.018766069773594622, 'n_estimators': 119, 'min_child_samples': 56, 'min_child_weight': 0.9602764688696965, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0831344561136737e-05, 'reg_lambda': 0.2552970998205846}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,175] Trial 852 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 277, 'max_depth': 115, 'learning_rate': 0.01098088498220672, 'n_estimators': 87, 'min_child_samples': 52, 'min_child_weight': 0.0009013640544494842, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0032484888600317e-05, 'reg_lambda': 0.0005781322176061491}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,326] Trial 853 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 371, 'max_depth': 107, 'learning_rate': 0.007024204362288982, 'n_estimators': 193, 'min_child_samples': 59, 'min_child_weight': 0.0004646643509447091, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4407388837128e-05, 'reg_lambda': 0.0015684236351429374}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,475] Trial 854 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 344, 'max_depth': 112, 'learning_rate': 0.03273384492975889, 'n_estimators': 160, 'min_child_samples': 54, 'min_child_weight': 0.0002969990340996668, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3085050216688408e-05, 'reg_lambda': 0.003556574208764666}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,623] Trial 855 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 285, 'max_depth': 67, 'learning_rate': 0.013688415546739375, 'n_estimators': 142, 'min_child_samples': 47, 'min_child_weight': 0.00017442922111947072, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.150955090104787e-05, 'reg_lambda': 0.0008688826817256855}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,852] Trial 856 finished with value: 0.7979474829008179 and parameters: {'num_leaves': 360, 'max_depth': 105, 'learning_rate': 0.019935409244591043, 'n_estimators': 408, 'min_child_samples': 50, 'min_child_weight': 0.0007328597020961182, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7693298039417854e-05, 'reg_lambda': 0.9053281476906048}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:46,990] Trial 857 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 304, 'max_depth': 116, 'learning_rate': 2.403809348045044e-05, 'n_estimators': 104, 'min_child_samples': 42, 'min_child_weight': 0.0005465026873991528, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5971013418718885e-05, 'reg_lambda': 0.17423370925640694}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,127] Trial 858 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 334, 'max_depth': 120, 'learning_rate': 0.04210396079045339, 'n_estimators': 124, 'min_child_samples': 57, 'min_child_weight': 0.00040641687995413814, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3104279283970757e-05, 'reg_lambda': 0.0011083708318892656}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,291] Trial 859 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 317, 'max_depth': 110, 'learning_rate': 0.02663858619058723, 'n_estimators': 205, 'min_child_samples': 51, 'min_child_weight': 0.00198430524645931, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.70939237465298e-05, 'reg_lambda': 0.4217216353803774}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,417] Trial 860 finished with value: 0.8228188195813411 and parameters: {'num_leaves': 272, 'max_depth': 42, 'learning_rate': 0.009811836785081926, 'n_estimators': 80, 'min_child_samples': 53, 'min_child_weight': 8.376479507996676e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.00260958417736e-05, 'reg_lambda': 0.0006688555184891594}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,573] Trial 861 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 326, 'max_depth': 114, 'learning_rate': 0.016010169837430248, 'n_estimators': 171, 'min_child_samples': 49, 'min_child_weight': 0.0002411173850933011, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.0037093023609446e-05, 'reg_lambda': 0.0004436839385015869}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,726] Trial 862 finished with value: 0.8064473679030786 and parameters: {'num_leaves': 293, 'max_depth': 17, 'learning_rate': 0.023199732151192674, 'n_estimators': 148, 'min_child_samples': 44, 'min_child_weight': 0.0003144655160785384, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.328626203240973e-05, 'reg_lambda': 0.686021624052159}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,830] Trial 863 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 258, 'max_depth': 102, 'learning_rate': 0.012781390689075155, 'n_estimators': 56, 'min_child_samples': 55, 'min_child_weight': 0.000628717355287913, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0023769343592342407, 'reg_lambda': 0.0003033012114098168}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:47,972] Trial 864 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 310, 'max_depth': 97, 'learning_rate': 0.006345402882099866, 'n_estimators': 113, 'min_child_samples': 47, 'min_child_weight': 0.5898699234617543, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.603261011581784e-05, 'reg_lambda': 0.2897006292115699}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:48,118] Trial 865 finished with value: 0.828254477109439 and parameters: {'num_leaves': 350, 'max_depth': 118, 'learning_rate': 0.008860383745793997, 'n_estimators': 134, 'min_child_samples': 51, 'min_child_weight': 0.00013450798235592977, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.969771973371287e-05, 'reg_lambda': 0.0014458072747720696}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:48,244] Trial 866 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 285, 'max_depth': 107, 'learning_rate': 0.03357078379552843, 'n_estimators': 105, 'min_child_samples': 53, 'min_child_weight': 0.0009871526807692138, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4711471465116e-05, 'reg_lambda': 1.1191817704864475}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:48,415] Trial 867 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 326, 'max_depth': 111, 'learning_rate': 0.01695335745938103, 'n_estimators': 187, 'min_child_samples': 56, 'min_child_weight': 0.056548963621625516, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5624934663064597e-05, 'reg_lambda': 0.002181401251675165}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:48,729] Trial 868 finished with value: 0.77581499024798 and parameters: {'num_leaves': 296, 'max_depth': 114, 'learning_rate': 0.023372199571119637, 'n_estimators': 614, 'min_child_samples': 49, 'min_child_weight': 0.08488704917858023, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2562485246193671e-05, 'reg_lambda': 0.0007883246085349126}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:48,873] Trial 869 finished with value: 0.7933423684770556 and parameters: {'num_leaves': 339, 'max_depth': 109, 'learning_rate': 0.04972972780642343, 'n_estimators': 160, 'min_child_samples': 54, 'min_child_weight': 0.0004851895945210776, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 4.561300025328917e-05, 'reg_lambda': 0.33114021060580523}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,000] Trial 870 finished with value: 0.828254477109439 and parameters: {'num_leaves': 359, 'max_depth': 105, 'learning_rate': 0.012587662850298846, 'n_estimators': 89, 'min_child_samples': 51, 'min_child_weight': 0.7610804316054816, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8684542659226724e-05, 'reg_lambda': 0.0005038172392478344}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,144] Trial 871 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 269, 'max_depth': 100, 'learning_rate': 0.017854980165909896, 'n_estimators': 128, 'min_child_samples': 46, 'min_child_weight': 0.0007638901690594771, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6702427776202183e-05, 'reg_lambda': 0.5788954645156955}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,280] Trial 872 finished with value: 0.8171238954412691 and parameters: {'num_leaves': 303, 'max_depth': 62, 'learning_rate': 0.004929141272632966, 'n_estimators': 148, 'min_child_samples': 63, 'min_child_weight': 0.00038804266058487224, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008130884420469363, 'reg_lambda': 0.0011363982778661691}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,421] Trial 873 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 318, 'max_depth': 116, 'learning_rate': 0.0757446650286574, 'n_estimators': 115, 'min_child_samples': 59, 'min_child_weight': 0.0005761942352824639, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6115351481171005e-05, 'reg_lambda': 0.00040234753295550845}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,569] Trial 874 finished with value: 0.7990355797704357 and parameters: {'num_leaves': 333, 'max_depth': 75, 'learning_rate': 0.0019770050939341794, 'n_estimators': 215, 'min_child_samples': 88, 'min_child_weight': 0.00021548938485568944, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2750538778993443e-05, 'reg_lambda': 0.003230228346294561}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,728] Trial 875 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 368, 'max_depth': 112, 'learning_rate': 0.008421506097667945, 'n_estimators': 170, 'min_child_samples': 48, 'min_child_weight': 0.00031720552746164926, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.003556287121266e-05, 'reg_lambda': 0.122936130220604}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,843] Trial 876 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 311, 'max_depth': 49, 'learning_rate': 0.03448969560131388, 'n_estimators': 74, 'min_child_samples': 57, 'min_child_weight': 0.000499983103376799, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2149875385896692e-05, 'reg_lambda': 0.0005982398530226298}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:49,976] Trial 877 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 283, 'max_depth': 122, 'learning_rate': 1.8790976764016335e-08, 'n_estimators': 136, 'min_child_samples': 52, 'min_child_weight': 0.00038584187273527613, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.309940678068411e-05, 'reg_lambda': 0.41656122903270637}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:50,117] Trial 878 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 349, 'max_depth': 39, 'learning_rate': 0.012221547947126833, 'n_estimators': 98, 'min_child_samples': 55, 'min_child_weight': 0.0007461445631305807, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6051430318930025e-05, 'reg_lambda': 0.7642570536516455}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:50,421] Trial 879 finished with value: 0.7712329508461043 and parameters: {'num_leaves': 323, 'max_depth': 117, 'learning_rate': 0.02462994145138659, 'n_estimators': 520, 'min_child_samples': 50, 'min_child_weight': 0.4553555734016822, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 2.0998390181700224e-05, 'reg_lambda': 0.19056391029506287}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:50,591] Trial 880 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 292, 'max_depth': 109, 'learning_rate': 0.017661119565877237, 'n_estimators': 131, 'min_child_samples': 53, 'min_child_weight': 0.0010991779364069095, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2483933941188982e-05, 'reg_lambda': 0.0008791535401629475}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:51,024] Trial 881 finished with value: 0.8069275947718925 and parameters: {'num_leaves': 341, 'max_depth': 114, 'learning_rate': 0.011146554304824476, 'n_estimators': 743, 'min_child_samples': 49, 'min_child_weight': 0.00024715717324212113, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.008379992041557e-05, 'reg_lambda': 1.7147875265517531}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:51,227] Trial 882 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 240, 'max_depth': 106, 'learning_rate': 0.0068926708418360514, 'n_estimators': 185, 'min_child_samples': 44, 'min_child_weight': 0.0014030815885290055, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.00028613179389530655, 'reg_lambda': 0.0018859779336477577}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:51,580] Trial 883 finished with value: 0.780204207675669 and parameters: {'num_leaves': 273, 'max_depth': 119, 'learning_rate': 0.028830691862494148, 'n_estimators': 568, 'min_child_samples': 55, 'min_child_weight': 0.0006433588646033246, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5087724542764556e-05, 'reg_lambda': 0.2588829756405173}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:51,735] Trial 884 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 303, 'max_depth': 112, 'learning_rate': 0.015578775173268417, 'n_estimators': 157, 'min_child_samples': 46, 'min_child_weight': 0.0004447988724566506, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5705054221641475e-05, 'reg_lambda': 0.0028144220508726273}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:51,892] Trial 885 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 255, 'max_depth': 109, 'learning_rate': 0.04329330760696455, 'n_estimators': 108, 'min_child_samples': 52, 'min_child_weight': 0.0001782458065189538, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0008012811753824e-05, 'reg_lambda': 0.0006843048941505411}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,085] Trial 886 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 379, 'max_depth': 102, 'learning_rate': 0.023574934500285905, 'n_estimators': 145, 'min_child_samples': 48, 'min_child_weight': 0.9802451627027521, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.22265105379769e-05, 'reg_lambda': 0.00111495989572751}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,235] Trial 887 finished with value: 0.818480303400469 and parameters: {'num_leaves': 332, 'max_depth': 115, 'learning_rate': 0.009319221928952699, 'n_estimators': 88, 'min_child_samples': 60, 'min_child_weight': 1.8390822307464758e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9671802385303906e-05, 'reg_lambda': 0.00024901798117204366}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,421] Trial 888 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 392, 'max_depth': 124, 'learning_rate': 0.014453865453428742, 'n_estimators': 124, 'min_child_samples': 57, 'min_child_weight': 0.0003108491460270073, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.3834354293592057e-05, 'reg_lambda': 0.5492572407336901}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,629] Trial 889 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 355, 'max_depth': 111, 'learning_rate': 0.018198265015661755, 'n_estimators': 168, 'min_child_samples': 53, 'min_child_weight': 0.5394221708242496, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 1.5320127617550173e-05, 'reg_lambda': 0.0013803371331306432}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,851] Trial 890 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 316, 'max_depth': 46, 'learning_rate': 0.0035063203178895127, 'n_estimators': 242, 'min_child_samples': 51, 'min_child_weight': 0.0005535991164924913, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7795804829316403e-05, 'reg_lambda': 0.08771608275747259}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:52,981] Trial 891 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 281, 'max_depth': 118, 'learning_rate': 0.011173681823214987, 'n_estimators': 117, 'min_child_samples': 55, 'min_child_weight': 0.0008858591522494209, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2714209042220619e-05, 'reg_lambda': 0.35684121619033266}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,095] Trial 892 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 293, 'max_depth': 52, 'learning_rate': 0.031405786639230354, 'n_estimators': 43, 'min_child_samples': 50, 'min_child_weight': 0.00040675607286551606, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0178738012334088e-05, 'reg_lambda': 0.0003975286293700493}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,228] Trial 893 finished with value: 0.8094043185704923 and parameters: {'num_leaves': 345, 'max_depth': 104, 'learning_rate': 0.020481486218066326, 'n_estimators': 68, 'min_child_samples': 21, 'min_child_weight': 0.0001078967158068389, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.1937175395141446e-05, 'reg_lambda': 0.9860247461531213}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,384] Trial 894 finished with value: 0.8188643188643188 and parameters: {'num_leaves': 306, 'max_depth': 107, 'learning_rate': 0.005632070249919961, 'n_estimators': 146, 'min_child_samples': 48, 'min_child_weight': 0.35689791912243707, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6018336052587187e-05, 'reg_lambda': 0.0005714520793404751}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,559] Trial 895 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 324, 'max_depth': 113, 'learning_rate': 0.008131647423547718, 'n_estimators': 196, 'min_child_samples': 54, 'min_child_weight': 0.0006620105582328468, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.250622963209019e-05, 'reg_lambda': 0.004195598884234362}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,711] Trial 896 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 265, 'max_depth': 115, 'learning_rate': 0.013493341331701665, 'n_estimators': 95, 'min_child_samples': 45, 'min_child_weight': 0.00027006147589052484, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3832308107028705e-05, 'reg_lambda': 0.0016348995452633494}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:53,861] Trial 897 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 368, 'max_depth': 121, 'learning_rate': 0.04849044412307137, 'n_estimators': 128, 'min_child_samples': 52, 'min_child_weight': 0.0004922543320728096, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8195149282286325e-05, 'reg_lambda': 0.000880238306621288}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,003] Trial 898 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 337, 'max_depth': 110, 'learning_rate': 0.022190085277043484, 'n_estimators': 174, 'min_child_samples': 57, 'min_child_weight': 0.00035307080182558594, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3254952234763384, 'reg_lambda': 1.2335447337512653}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,148] Trial 899 finished with value: 0.8156946862829217 and parameters: {'num_leaves': 315, 'max_depth': 117, 'learning_rate': 0.029601943888867544, 'n_estimators': 153, 'min_child_samples': 50, 'min_child_weight': 0.0007612414567014068, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0055913369007519e-05, 'reg_lambda': 0.4567162417984235}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,287] Trial 900 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 296, 'max_depth': 107, 'learning_rate': 0.014228018961533133, 'n_estimators': 109, 'min_child_samples': 47, 'min_child_weight': 0.0005631080805710612, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.265824623943097e-05, 'reg_lambda': 0.2296218628310424}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,468] Trial 901 finished with value: 0.6406573239906573 and parameters: {'num_leaves': 278, 'max_depth': 113, 'learning_rate': 0.0006528435484615228, 'n_estimators': 271, 'min_child_samples': 54, 'min_child_weight': 0.690707007285305, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.5586894492942267e-05, 'reg_lambda': 0.002249012319283859}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,700] Trial 902 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 325, 'max_depth': 100, 'learning_rate': 0.010051983170376045, 'n_estimators': 138, 'min_child_samples': 11, 'min_child_weight': 0.00022176792052852864, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3921537282789487e-05, 'reg_lambda': 0.3160275174010606}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,845] Trial 903 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 360, 'max_depth': 44, 'learning_rate': 0.019278366297387252, 'n_estimators': 92, 'min_child_samples': 52, 'min_child_weight': 0.00042805591689635007, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2838200455449602e-05, 'reg_lambda': 0.7892323313685982}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:54,979] Trial 904 finished with value: 0.8025391462891464 and parameters: {'num_leaves': 306, 'max_depth': 8, 'learning_rate': 0.03887869160863732, 'n_estimators': 122, 'min_child_samples': 56, 'min_child_weight': 0.00015024837784136889, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.9431213441350637e-05, 'reg_lambda': 0.0007346251356782197}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:55,133] Trial 905 finished with value: 0.8244522639120946 and parameters: {'num_leaves': 347, 'max_depth': 104, 'learning_rate': 0.014164433384980019, 'n_estimators': 212, 'min_child_samples': 59, 'min_child_weight': 0.0003199286879480152, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.917808260251544e-05, 'reg_lambda': 0.00031955845800523807}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:55,289] Trial 906 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 286, 'max_depth': 110, 'learning_rate': 0.007701204877583605, 'n_estimators': 176, 'min_child_samples': 49, 'min_child_weight': 0.03036610632924477, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.2969622221336835e-05, 'reg_lambda': 0.16197282617020656}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:55,709] Trial 907 finished with value: 0.7803839056851105 and parameters: {'num_leaves': 332, 'max_depth': 120, 'learning_rate': 0.02430826232776749, 'n_estimators': 936, 'min_child_samples': 51, 'min_child_weight': 0.0008883193305832752, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 3.919641628399106e-05, 'reg_lambda': 0.0005064476850254804}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:55,863] Trial 908 finished with value: 0.7889673710297429 and parameters: {'num_leaves': 248, 'max_depth': 117, 'learning_rate': 0.061588426245870034, 'n_estimators': 157, 'min_child_samples': 43, 'min_child_weight': 0.000615949991450069, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.004858867682268572, 'reg_lambda': 0.0012690566138317612}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:55,980] Trial 909 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 297, 'max_depth': 108, 'learning_rate': 0.011732609891008427, 'n_estimators': 66, 'min_child_samples': 54, 'min_child_weight': 0.0004339432193862757, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7122860702839854e-05, 'reg_lambda': 0.5753675599578109}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,117] Trial 910 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 265, 'max_depth': 40, 'learning_rate': 0.01881352054109297, 'n_estimators': 106, 'min_child_samples': 47, 'min_child_weight': 0.7900313800328942, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2985386464987435e-05, 'reg_lambda': 0.00105729069082659}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,258] Trial 911 finished with value: 0.836977886977887 and parameters: {'num_leaves': 313, 'max_depth': 112, 'learning_rate': 0.0058915728324097135, 'n_estimators': 134, 'min_child_samples': 53, 'min_child_weight': 0.00020430430971138066, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.004773739684206e-05, 'reg_lambda': 0.0016537055884076125}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,416] Trial 912 finished with value: 0.7236622812070382 and parameters: {'num_leaves': 313, 'max_depth': 112, 'learning_rate': 0.0014509725084289788, 'n_estimators': 157, 'min_child_samples': 55, 'min_child_weight': 0.0001360301463630308, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0067355998823374e-05, 'reg_lambda': 0.0028247091946274794}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,562] Trial 913 finished with value: 0.8055537244561634 and parameters: {'num_leaves': 320, 'max_depth': 115, 'learning_rate': 0.002298093715471597, 'n_estimators': 185, 'min_child_samples': 57, 'min_child_weight': 0.00021508412368284577, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2609320296618742e-05, 'reg_lambda': 0.0020010551507465774}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,692] Trial 914 finished with value: 0.7784718975030395 and parameters: {'num_leaves': 309, 'max_depth': 112, 'learning_rate': 0.002775181224481694, 'n_estimators': 140, 'min_child_samples': 84, 'min_child_weight': 0.00016962795182200275, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1.2189700224474742e-05, 'reg_lambda': 0.002604229944031887}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,841] Trial 915 finished with value: 0.8122888649204439 and parameters: {'num_leaves': 323, 'max_depth': 110, 'learning_rate': 0.0034967607102416825, 'n_estimators': 167, 'min_child_samples': 53, 'min_child_weight': 0.00017106046178785826, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0034224221516151e-05, 'reg_lambda': 0.0018343945243727562}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:56,976] Trial 916 finished with value: 0.828254477109439 and parameters: {'num_leaves': 303, 'max_depth': 114, 'learning_rate': 0.006855956837091687, 'n_estimators': 132, 'min_child_samples': 56, 'min_child_weight': 0.00011205745701822933, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.006524069542969e-05, 'reg_lambda': 0.004089652623606709}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:57,152] Trial 917 finished with value: 0.8322757457573522 and parameters: {'num_leaves': 329, 'max_depth': 107, 'learning_rate': 0.004229545385061909, 'n_estimators': 187, 'min_child_samples': 53, 'min_child_weight': 0.0002227480498303034, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.4477736475932152e-05, 'reg_lambda': 0.002374234758303287}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:57,290] Trial 918 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 312, 'max_depth': 112, 'learning_rate': 0.006856091777331367, 'n_estimators': 155, 'min_child_samples': 61, 'min_child_weight': 0.00018073243758640113, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5352893343735712e-05, 'reg_lambda': 0.0017150338522480032}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:57,428] Trial 919 finished with value: 0.8132870204245668 and parameters: {'num_leaves': 341, 'max_depth': 116, 'learning_rate': 0.0058120393995977114, 'n_estimators': 139, 'min_child_samples': 58, 'min_child_weight': 0.0002001389076247743, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.3636280708418518e-05, 'reg_lambda': 0.2617913910363319}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:57,679] Trial 920 finished with value: 0.8288288288288288 and parameters: {'num_leaves': 316, 'max_depth': 110, 'learning_rate': 0.004232374068977014, 'n_estimators': 467, 'min_child_samples': 55, 'min_child_weight': 0.00024376200910962613, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2566293261449034e-05, 'reg_lambda': 0.43276227410584583}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:57,860] Trial 921 finished with value: 0.828254477109439 and parameters: {'num_leaves': 300, 'max_depth': 114, 'learning_rate': 0.005090189383359405, 'n_estimators': 205, 'min_child_samples': 52, 'min_child_weight': 0.00026817658434717185, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.627675963559665e-05, 'reg_lambda': 0.8449455630171111}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,039] Trial 922 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 332, 'max_depth': 106, 'learning_rate': 0.008911321151528576, 'n_estimators': 122, 'min_child_samples': 54, 'min_child_weight': 0.00013666026039653285, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0187695849785752e-05, 'reg_lambda': 0.001427378939233534}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,215] Trial 923 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 322, 'max_depth': 118, 'learning_rate': 0.005113210227302441, 'n_estimators': 168, 'min_child_samples': 51, 'min_child_weight': 9.098518341961199e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0438704293173892, 'reg_lambda': 0.058479786286671505}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,383] Trial 924 finished with value: 0.8141403815162681 and parameters: {'num_leaves': 352, 'max_depth': 95, 'learning_rate': 0.0028614057502131794, 'n_estimators': 146, 'min_child_samples': 56, 'min_child_weight': 0.008193114941332572, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8393966227233736e-05, 'reg_lambda': 0.3370358750567004}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,529] Trial 925 finished with value: 0.828254477109439 and parameters: {'num_leaves': 311, 'max_depth': 109, 'learning_rate': 0.010842608647698497, 'n_estimators': 123, 'min_child_samples': 53, 'min_child_weight': 0.0002624677342139251, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0014599713306533e-05, 'reg_lambda': 0.0031453132770040025}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,741] Trial 926 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 302, 'max_depth': 104, 'learning_rate': 0.007832020480184257, 'n_estimators': 369, 'min_child_samples': 58, 'min_child_weight': 0.0001996746733406941, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3229321325667708e-05, 'reg_lambda': 0.18672839913051142}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:58,890] Trial 927 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 339, 'max_depth': 112, 'learning_rate': 0.009914744456964247, 'n_estimators': 179, 'min_child_samples': 54, 'min_child_weight': 0.5329716157526146, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.000046843130962e-05, 'reg_lambda': 0.68826362433124}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,026] Trial 928 finished with value: 0.8322757457573522 and parameters: {'num_leaves': 323, 'max_depth': 116, 'learning_rate': 0.005457244940729146, 'n_estimators': 142, 'min_child_samples': 51, 'min_child_weight': 0.00015248614528437068, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.976641997960434e-05, 'reg_lambda': 0.1105951024024415}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,162] Trial 929 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 333, 'max_depth': 114, 'learning_rate': 0.015510650991954285, 'n_estimators': 116, 'min_child_samples': 56, 'min_child_weight': 0.0002968946329195535, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6108133332729388e-05, 'reg_lambda': 1.4040898868685514}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,339] Trial 930 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 289, 'max_depth': 120, 'learning_rate': 0.010985454149143896, 'n_estimators': 162, 'min_child_samples': 52, 'min_child_weight': 0.00033717052230251555, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4546492259985387e-05, 'reg_lambda': 0.0014939988034754464}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,471] Trial 931 finished with value: 0.8180626352268143 and parameters: {'num_leaves': 365, 'max_depth': 108, 'learning_rate': 0.00746689630283581, 'n_estimators': 100, 'min_child_samples': 50, 'min_child_weight': 0.4080625572710829, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.545344421601767e-05, 'reg_lambda': 0.00027234474530180085}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,615] Trial 932 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 308, 'max_depth': 112, 'learning_rate': 1.859625916185364e-06, 'n_estimators': 137, 'min_child_samples': 55, 'min_child_weight': 0.0012318817969781445, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2646737307743246e-05, 'reg_lambda': 0.001992279692721101}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,794] Trial 933 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 352, 'max_depth': 117, 'learning_rate': 0.014803147323429683, 'n_estimators': 196, 'min_child_samples': 59, 'min_child_weight': 0.00023900713285603594, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.069363720823873e-05, 'reg_lambda': 0.4588130694708549}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:14:59,957] Trial 934 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 297, 'max_depth': 106, 'learning_rate': 0.027773571115941913, 'n_estimators': 83, 'min_child_samples': 53, 'min_child_weight': 0.6380217843728594, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0023847186867648e-05, 'reg_lambda': 0.00037996323106808007}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:00,140] Trial 935 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 471, 'max_depth': 103, 'learning_rate': 0.011400331637939801, 'n_estimators': 157, 'min_child_samples': 50, 'min_child_weight': 0.00034719581510379805, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1.572417101837884e-05, 'reg_lambda': 0.24438332902399085}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:00,359] Trial 936 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 343, 'max_depth': 110, 'learning_rate': 0.016484449236954354, 'n_estimators': 227, 'min_child_samples': 57, 'min_child_weight': 0.9762132773687844, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.7110042626628084e-05, 'reg_lambda': 0.00020972199367037705}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:00,532] Trial 937 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 317, 'max_depth': 113, 'learning_rate': 0.009064956733859233, 'n_estimators': 126, 'min_child_samples': 53, 'min_child_weight': 0.023104380486168422, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.81153581554616e-05, 'reg_lambda': 0.5946728314117137}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:00,719] Trial 938 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 329, 'max_depth': 126, 'learning_rate': 0.022520997262297022, 'n_estimators': 110, 'min_child_samples': 51, 'min_child_weight': 0.3048502033798502, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3011937176920088e-05, 'reg_lambda': 0.3783509403488861}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:00,923] Trial 939 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 291, 'max_depth': 115, 'learning_rate': 0.005728158249576308, 'n_estimators': 174, 'min_child_samples': 55, 'min_child_weight': 0.00027904992193622335, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.0744862888053236e-05, 'reg_lambda': 0.002413721766252442}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,101] Trial 940 finished with value: 0.8020818358251869 and parameters: {'num_leaves': 375, 'max_depth': 119, 'learning_rate': 0.03298985523061364, 'n_estimators': 144, 'min_child_samples': 49, 'min_child_weight': 0.0007698470329315263, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.2897597455890163e-05, 'reg_lambda': 1.0609060895335232}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,246] Trial 941 finished with value: 0.8126744962188002 and parameters: {'num_leaves': 304, 'max_depth': 107, 'learning_rate': 0.0037381857362886635, 'n_estimators': 89, 'min_child_samples': 54, 'min_child_weight': 0.039295459398106435, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.462950614527563e-05, 'reg_lambda': 0.004769139208587102}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,415] Trial 942 finished with value: 0.8198198198198198 and parameters: {'num_leaves': 357, 'max_depth': 100, 'learning_rate': 0.013964135482173871, 'n_estimators': 120, 'min_child_samples': 52, 'min_child_weight': 0.00037916611971779157, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.54118262005434e-05, 'reg_lambda': 0.001379750977864735}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,611] Trial 943 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 318, 'max_depth': 111, 'learning_rate': 0.008190838413477279, 'n_estimators': 146, 'min_child_samples': 56, 'min_child_weight': 0.016449689110765085, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6147109504277834e-05, 'reg_lambda': 0.000580775371302656}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,785] Trial 944 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 338, 'max_depth': 117, 'learning_rate': 0.018121222124648197, 'n_estimators': 166, 'min_child_samples': 50, 'min_child_weight': 0.00018461404062911917, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.032842223965801e-05, 'reg_lambda': 0.0003768902478568185}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:01,938] Trial 945 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 312, 'max_depth': 109, 'learning_rate': 0.012326301381576232, 'n_estimators': 101, 'min_child_samples': 60, 'min_child_weight': 0.0010501489001721895, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 2.1236875452819638e-05, 'reg_lambda': 0.2043425829090313}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,108] Trial 946 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 327, 'max_depth': 122, 'learning_rate': 0.02443626243232317, 'n_estimators': 190, 'min_child_samples': 53, 'min_child_weight': 0.0005235615746670506, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3010058264203808e-05, 'reg_lambda': 2.154767471256396}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,270] Trial 947 finished with value: 0.7930855556354227 and parameters: {'num_leaves': 345, 'max_depth': 114, 'learning_rate': 0.04186946682682585, 'n_estimators': 132, 'min_child_samples': 57, 'min_child_weight': 0.001681059719065565, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.8402999832914324e-05, 'reg_lambda': 0.0018474470035275538}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,439] Trial 948 finished with value: 0.8154498159075866 and parameters: {'num_leaves': 296, 'max_depth': 105, 'learning_rate': 0.01822967161402439, 'n_estimators': 157, 'min_child_samples': 49, 'min_child_weight': 0.43821510480606185, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.7072561636301287e-05, 'reg_lambda': 0.2737822272225249}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,594] Trial 949 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 286, 'max_depth': 111, 'learning_rate': 0.011772076255771143, 'n_estimators': 76, 'min_child_samples': 52, 'min_child_weight': 0.00012091274960636774, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0104595122526405e-05, 'reg_lambda': 0.13748060064294151}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,729] Trial 950 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 358, 'max_depth': 115, 'learning_rate': 0.007670263676258995, 'n_estimators': 119, 'min_child_samples': 55, 'min_child_weight': 0.00020904294152041423, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3010103800413646e-05, 'reg_lambda': 0.0007555383249593148}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:02,923] Trial 951 finished with value: 0.7935636529386529 and parameters: {'num_leaves': 333, 'max_depth': 102, 'learning_rate': 0.030258607352366004, 'n_estimators': 205, 'min_child_samples': 51, 'min_child_weight': 0.00029800486108317274, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.004016062483173e-05, 'reg_lambda': 0.5061489131058581}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,065] Trial 952 finished with value: 0.8232095698523442 and parameters: {'num_leaves': 306, 'max_depth': 108, 'learning_rate': 0.014746033018118157, 'n_estimators': 53, 'min_child_samples': 46, 'min_child_weight': 0.00039792215321708793, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1613750032939264e-05, 'reg_lambda': 0.0010303275378764024}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,203] Trial 953 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 320, 'max_depth': 118, 'learning_rate': 0.02239668156418318, 'n_estimators': 101, 'min_child_samples': 62, 'min_child_weight': 0.011375718458510653, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.807561265559666e-05, 'reg_lambda': 0.35195341739936264}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,356] Trial 954 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 343, 'max_depth': 113, 'learning_rate': 0.000122683882143788, 'n_estimators': 141, 'min_child_samples': 58, 'min_child_weight': 0.0007293550092164645, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.60883820110988e-05, 'reg_lambda': 0.0005096367690437567}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,547] Trial 955 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 368, 'max_depth': 98, 'learning_rate': 0.010350684542479012, 'n_estimators': 180, 'min_child_samples': 54, 'min_child_weight': 0.8074828278181851, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.3882092940248867e-05, 'reg_lambda': 0.7747160909142385}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,742] Trial 956 finished with value: 0.8137326052008971 and parameters: {'num_leaves': 299, 'max_depth': 110, 'learning_rate': 0.006168022725718618, 'n_estimators': 126, 'min_child_samples': 48, 'min_child_weight': 0.0006060051275193028, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.621556133012609e-05, 'reg_lambda': 0.0028868632704907578}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:03,922] Trial 957 finished with value: 0.8200743962047155 and parameters: {'num_leaves': 325, 'max_depth': 116, 'learning_rate': 0.017338328656973854, 'n_estimators': 145, 'min_child_samples': 66, 'min_child_weight': 0.0004547235187147279, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2540545972984349e-05, 'reg_lambda': 1.5751352944423693}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,132] Trial 958 finished with value: 0.42711942711942713 and parameters: {'num_leaves': 311, 'max_depth': 106, 'learning_rate': 5.817290314594327e-05, 'n_estimators': 168, 'min_child_samples': 51, 'min_child_weight': 0.00014797299563652693, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0000986149069548e-05, 'reg_lambda': 0.0012721120365617583}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,291] Trial 959 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 287, 'max_depth': 112, 'learning_rate': 0.02698499747888802, 'n_estimators': 87, 'min_child_samples': 53, 'min_child_weight': 0.555846106975575, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9576455335880897e-05, 'reg_lambda': 1.0175872625649367}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,442] Trial 960 finished with value: 0.8023274828910966 and parameters: {'num_leaves': 349, 'max_depth': 121, 'learning_rate': 0.04056281994541077, 'n_estimators': 125, 'min_child_samples': 48, 'min_child_weight': 5.672281367090823e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.922953864818281e-05, 'reg_lambda': 0.0006756236214843119}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,594] Trial 961 finished with value: 0.828254477109439 and parameters: {'num_leaves': 379, 'max_depth': 103, 'learning_rate': 0.010086674633965714, 'n_estimators': 106, 'min_child_samples': 56, 'min_child_weight': 0.0002618273097459495, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.3224570357418349e-05, 'reg_lambda': 0.00030748005261222166}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,785] Trial 962 finished with value: 0.8067041831747713 and parameters: {'num_leaves': 301, 'max_depth': 109, 'learning_rate': 0.01662558252622098, 'n_estimators': 251, 'min_child_samples': 50, 'min_child_weight': 0.002400600393462356, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8715063020031393e-05, 'reg_lambda': 0.0035185550942161896}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:04,946] Trial 963 finished with value: 0.836977886977887 and parameters: {'num_leaves': 278, 'max_depth': 119, 'learning_rate': 0.004848371121402162, 'n_estimators': 155, 'min_child_samples': 54, 'min_child_weight': 0.0009375734272983664, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.6280648005841456e-05, 'reg_lambda': 0.0004768750104871562}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:05,120] Trial 964 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 291, 'max_depth': 122, 'learning_rate': 0.003988374557401941, 'n_estimators': 198, 'min_child_samples': 59, 'min_child_weight': 0.0011244323714674578, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.0005199520828471812, 'reg_lambda': 0.00024577318114570935}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:05,342] Trial 965 finished with value: 0.828254477109439 and parameters: {'num_leaves': 336, 'max_depth': 123, 'learning_rate': 0.004468935705568028, 'n_estimators': 219, 'min_child_samples': 57, 'min_child_weight': 0.0009943112527171318, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.720989559511575e-05, 'reg_lambda': 0.0003383243595096553}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:05,538] Trial 966 finished with value: 0.8062192382206252 and parameters: {'num_leaves': 280, 'max_depth': 120, 'learning_rate': 0.0026345680416803466, 'n_estimators': 184, 'min_child_samples': 55, 'min_child_weight': 0.0012672291797417659, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.3095735179956864e-05, 'reg_lambda': 0.00048758776099801107}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:05,721] Trial 967 finished with value: 0.8279211029211029 and parameters: {'num_leaves': 317, 'max_depth': 21, 'learning_rate': 0.00463929517254587, 'n_estimators': 163, 'min_child_samples': 55, 'min_child_weight': 0.0008258371986948637, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.1630891030209156e-05, 'reg_lambda': 0.00037958257133509555}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:05,931] Trial 968 finished with value: 0.8025512117819811 and parameters: {'num_leaves': 389, 'max_depth': 125, 'learning_rate': 0.002880112815634931, 'n_estimators': 175, 'min_child_samples': 58, 'min_child_weight': 0.0015831391858724775, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.957251450736955e-05, 'reg_lambda': 0.00016090700206239654}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,111] Trial 969 finished with value: 0.8326155914543202 and parameters: {'num_leaves': 308, 'max_depth': 118, 'learning_rate': 0.005614202127672968, 'n_estimators': 157, 'min_child_samples': 54, 'min_child_weight': 0.0010434955834200384, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.2508569780118494e-05, 'reg_lambda': 0.0004491720502808118}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,259] Trial 970 finished with value: 0.7367908903213446 and parameters: {'num_leaves': 327, 'max_depth': 120, 'learning_rate': 0.0016868791127186869, 'n_estimators': 149, 'min_child_samples': 57, 'min_child_weight': 0.0012953345503778728, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5220919536425047e-05, 'reg_lambda': 0.4640458898893828}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,423] Trial 971 finished with value: 0.8128060018297418 and parameters: {'num_leaves': 361, 'max_depth': 128, 'learning_rate': 0.003647795806762304, 'n_estimators': 179, 'min_child_samples': 53, 'min_child_weight': 0.0014533170219848453, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.326578376007385e-05, 'reg_lambda': 0.29329632233288344}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,584] Trial 972 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 295, 'max_depth': 119, 'learning_rate': 0.006894915576634367, 'n_estimators': 157, 'min_child_samples': 55, 'min_child_weight': 0.0008210004351501014, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 2.9084808505285594e-05, 'reg_lambda': 0.6453714165004882}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,724] Trial 973 finished with value: 0.805472173852318 and parameters: {'num_leaves': 349, 'max_depth': 123, 'learning_rate': 0.006511593308528025, 'n_estimators': 195, 'min_child_samples': 100, 'min_child_weight': 0.001834542499646504, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.653567461261809e-05, 'reg_lambda': 0.00027877741764402745}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:06,875] Trial 974 finished with value: 0.828254477109439 and parameters: {'num_leaves': 334, 'max_depth': 31, 'learning_rate': 0.008376910514318782, 'n_estimators': 139, 'min_child_samples': 53, 'min_child_weight': 0.0008571303965572717, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.7610036201118404e-05, 'reg_lambda': 0.17262972274323096}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:07,047] Trial 975 finished with value: 0.8235677855869861 and parameters: {'num_leaves': 317, 'max_depth': 116, 'learning_rate': 0.0053739493179767485, 'n_estimators': 164, 'min_child_samples': 61, 'min_child_weight': 0.000961609060737813, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.316620264636638e-05, 'reg_lambda': 0.0022368449094476595}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:07,236] Trial 976 finished with value: 0.8238939900895808 and parameters: {'num_leaves': 279, 'max_depth': 118, 'learning_rate': 0.00894354548784525, 'n_estimators': 140, 'min_child_samples': 56, 'min_child_weight': 0.00018074533050711344, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.126442267777363e-05, 'reg_lambda': 0.235633127151329}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:07,445] Trial 977 finished with value: 0.8062192382206252 and parameters: {'num_leaves': 304, 'max_depth': 114, 'learning_rate': 0.0022398555010364396, 'n_estimators': 207, 'min_child_samples': 59, 'min_child_weight': 0.6778403382625146, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 3.14146845698143e-05, 'reg_lambda': 0.0003923844413308356}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:07,701] Trial 978 finished with value: 0.8228188195813411 and parameters: {'num_leaves': 291, 'max_depth': 116, 'learning_rate': 0.004035762646298303, 'n_estimators': 178, 'min_child_samples': 52, 'min_child_weight': 0.35887556527733033, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8604784921097554e-05, 'reg_lambda': 0.3737589439077833}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:07,898] Trial 979 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 342, 'max_depth': 114, 'learning_rate': 0.011242634293503235, 'n_estimators': 131, 'min_child_samples': 54, 'min_child_weight': 0.00022920850753652112, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.0013870822341525498, 'reg_lambda': 0.9507135414116132}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,095] Trial 980 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 328, 'max_depth': 121, 'learning_rate': 0.006558104864522267, 'n_estimators': 164, 'min_child_samples': 45, 'min_child_weight': 0.0006310475490858843, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 5.561301467271259e-05, 'reg_lambda': 0.0015588525579595704}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,271] Trial 981 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 356, 'max_depth': 116, 'learning_rate': 0.012875671464711818, 'n_estimators': 143, 'min_child_samples': 57, 'min_child_weight': 0.000327317423553593, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.4883161504278083e-05, 'reg_lambda': 0.5968326173223939}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,434] Trial 982 finished with value: 0.828254477109439 and parameters: {'num_leaves': 314, 'max_depth': 118, 'learning_rate': 0.008849564244450027, 'n_estimators': 123, 'min_child_samples': 52, 'min_child_weight': 0.0012320647973514014, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.6606584918655103e-05, 'reg_lambda': 0.000478485827983819}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,580] Trial 983 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 302, 'max_depth': 112, 'learning_rate': 0.013346434464045672, 'n_estimators': 148, 'min_child_samples': 55, 'min_child_weight': 0.5132036304517479, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 3.445219615400896e-05, 'reg_lambda': 1.1936520577496545}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,751] Trial 984 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 284, 'max_depth': 24, 'learning_rate': 0.007890667094036248, 'n_estimators': 196, 'min_child_samples': 49, 'min_child_weight': 0.0006735598390159657, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2713951426534128e-05, 'reg_lambda': 0.3491182870553318}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:08,914] Trial 985 finished with value: 0.8285569013829883 and parameters: {'num_leaves': 324, 'max_depth': 124, 'learning_rate': 0.012237735875561468, 'n_estimators': 121, 'min_child_samples': 51, 'min_child_weight': 0.9993605396420435, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.2121903348602316e-05, 'reg_lambda': 0.0020232046353121456}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,094] Trial 986 finished with value: 0.828254477109439 and parameters: {'num_leaves': 372, 'max_depth': 108, 'learning_rate': 0.005346383628321873, 'n_estimators': 225, 'min_child_samples': 54, 'min_child_weight': 0.0009259551216130423, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.573917637502088e-05, 'reg_lambda': 0.0009243790917669696}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,259] Trial 987 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 339, 'max_depth': 113, 'learning_rate': 0.01996387323154409, 'n_estimators': 159, 'min_child_samples': 46, 'min_child_weight': 0.10354623147415846, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.5663877454266254e-05, 'reg_lambda': 0.0002179711549538495}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,470] Trial 988 finished with value: 0.7668475898578992 and parameters: {'num_leaves': 309, 'max_depth': 119, 'learning_rate': 0.24209514339553959, 'n_estimators': 183, 'min_child_samples': 49, 'min_child_weight': 0.0002740868462368287, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.8413820619373528e-05, 'reg_lambda': 0.0005876284378528072}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,631] Trial 989 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 351, 'max_depth': 111, 'learning_rate': 0.01026570539668458, 'n_estimators': 130, 'min_child_samples': 42, 'min_child_weight': 9.487367102355435e-05, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.2777336028249735e-05, 'reg_lambda': 0.5080407564858462}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,798] Trial 990 finished with value: 0.8332046332046333 and parameters: {'num_leaves': 295, 'max_depth': 105, 'learning_rate': 0.015075242144127107, 'n_estimators': 154, 'min_child_samples': 57, 'min_child_weight': 0.2875674552074707, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 4.2677550891906424e-05, 'reg_lambda': 0.0003233767329819365}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:09,951] Trial 991 finished with value: 0.8110781160149511 and parameters: {'num_leaves': 320, 'max_depth': 115, 'learning_rate': 0.027979340764688276, 'n_estimators': 136, 'min_child_samples': 53, 'min_child_weight': 0.000366344591449726, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.015613007626391348, 'reg_lambda': 0.22855606214096408}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,101] Trial 992 finished with value: 0.8134278644842026 and parameters: {'num_leaves': 333, 'max_depth': 109, 'learning_rate': 0.003227274355019732, 'n_estimators': 113, 'min_child_samples': 51, 'min_child_weight': 0.0007248829820318236, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.0021666922968277e-05, 'reg_lambda': 0.8295744238461225}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,277] Trial 993 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 286, 'max_depth': 117, 'learning_rate': 0.0072416913168691375, 'n_estimators': 173, 'min_child_samples': 59, 'min_child_weight': 0.0002066609178328539, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.813351746737816e-05, 'reg_lambda': 0.0012717685788876522}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,435] Trial 994 finished with value: 0.8241886674319105 and parameters: {'num_leaves': 360, 'max_depth': 100, 'learning_rate': 0.018792446170931943, 'n_estimators': 151, 'min_child_samples': 47, 'min_child_weight': 0.00046447328900061296, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.9805287607027485e-05, 'reg_lambda': 1.725443845294504}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,565] Trial 995 finished with value: 0.8192152390625673 and parameters: {'num_leaves': 211, 'max_depth': 113, 'learning_rate': 0.013167392045185721, 'n_estimators': 108, 'min_child_samples': 55, 'min_child_weight': 0.7379033149690776, 'subsample': 0.5, 'colsample_bytree': 0.7, 'reg_alpha': 1.302581171362414e-05, 'reg_lambda': 0.002648219884941863}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,703] Trial 996 finished with value: 0.7977136800666212 and parameters: {'num_leaves': 301, 'max_depth': 111, 'learning_rate': 0.03275649544123111, 'n_estimators': 133, 'min_child_samples': 52, 'min_child_weight': 0.00012810617364282498, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 0.09345939360798428, 'reg_lambda': 0.2995455401324442}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:10,884] Trial 997 finished with value: 0.7759794850808676 and parameters: {'num_leaves': 175, 'max_depth': 120, 'learning_rate': 0.06840208555218086, 'n_estimators': 186, 'min_child_samples': 49, 'min_child_weight': 0.0005162753342734446, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 2.1517614260259076e-05, 'reg_lambda': 0.0016542386866965687}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:11,038] Trial 998 finished with value: 0.8195335804031456 and parameters: {'num_leaves': 313, 'max_depth': 106, 'learning_rate': 0.00988336685753691, 'n_estimators': 164, 'min_child_samples': 56, 'min_child_weight': 0.0003141652077216601, 'subsample': 0.5, 'colsample_bytree': 0.8, 'reg_alpha': 1.5195892903285504e-05, 'reg_lambda': 0.6527771871440964}. Best is trial 303 with value: 0.8375802223628311.\n",
      "/tmp/ipykernel_182720/388030165.py:14: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
      "/tmp/ipykernel_182720/388030165.py:15: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
      "[I 2024-01-12 22:15:11,174] Trial 999 finished with value: 0.8151727016591882 and parameters: {'num_leaves': 346, 'max_depth': 116, 'learning_rate': 0.02214031806417683, 'n_estimators': 113, 'min_child_samples': 53, 'min_child_weight': 0.0006065565733247345, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.398288688469886e-05, 'reg_lambda': 0.0008955629248308578}. Best is trial 303 with value: 0.8375802223628311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 992, number of negative: 784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 1776, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558559 -> initscore=0.235314\n",
      "[LightGBM] [Info] Start training from score 0.235314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Accuracy: 0.815315\n",
      "Model F1 Score: 0.814813\n"
     ]
    }
   ],
   "source": [
    "from tabnanny import verbose\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 128),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0,log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 1,log=True),\n",
    "        'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1),\n",
    "        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10,log=True)\n",
    "    }\n",
    "    model = LGBMClassifier(**param,verbose=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = f1_score(y_val, preds, average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = LGBMClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"LGBM\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 22:15:46,467] A new study created in memory with name: no-name-451f4a35-8af8-4534-bad7-b6295b21a256\n",
      "[I 2024-01-12 22:15:47,718] Trial 0 finished with value: 0.8271595034654736 and parameters: {'n_estimators': 1455, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8271595034654736.\n",
      "[I 2024-01-12 22:15:48,119] Trial 1 finished with value: 0.8271595034654736 and parameters: {'n_estimators': 420, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8271595034654736.\n",
      "[I 2024-01-12 22:15:48,913] Trial 2 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 844, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.8271595034654736.\n",
      "[I 2024-01-12 22:15:50,091] Trial 3 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 1195, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8271595034654736.\n",
      "[I 2024-01-12 22:15:50,588] Trial 4 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 491, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 0 with value: 0.8271595034654736.\n",
      "[I 2024-01-12 22:15:51,073] Trial 5 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 484, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:51,469] Trial 6 finished with value: 0.804179070201375 and parameters: {'n_estimators': 612, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:52,371] Trial 7 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 947, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:52,721] Trial 8 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 395, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:53,133] Trial 9 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 473, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:53,257] Trial 10 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 102, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:54,385] Trial 11 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 1407, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:55,661] Trial 12 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 1415, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:56,658] Trial 13 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1079, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8292828261332198.\n",
      "[I 2024-01-12 22:15:56,804] Trial 14 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 155, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:56,953] Trial 15 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 141, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:57,185] Trial 16 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 262, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:57,530] Trial 17 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 268, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:58,108] Trial 18 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 636, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:58,677] Trial 19 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 595, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:58,961] Trial 20 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 256, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 14 with value: 0.8329250675208845.\n",
      "[I 2024-01-12 22:15:59,119] Trial 21 finished with value: 0.833675692499222 and parameters: {'n_estimators': 138, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 21 with value: 0.833675692499222.\n",
      "[I 2024-01-12 22:15:59,337] Trial 22 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 196, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 21 with value: 0.833675692499222.\n",
      "[I 2024-01-12 22:15:59,686] Trial 23 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 352, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 21 with value: 0.833675692499222.\n",
      "[I 2024-01-12 22:15:59,812] Trial 24 finished with value: 0.8426661956073721 and parameters: {'n_estimators': 101, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:00,004] Trial 25 finished with value: 0.7356363415355184 and parameters: {'n_estimators': 305, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:00,139] Trial 26 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 107, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:00,769] Trial 27 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 749, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:00,943] Trial 28 finished with value: 0.8326155914543202 and parameters: {'n_estimators': 199, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:01,201] Trial 29 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 207, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:01,440] Trial 30 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 361, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:01,591] Trial 31 finished with value: 0.8326155914543202 and parameters: {'n_estimators': 169, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:01,740] Trial 32 finished with value: 0.8132870204245668 and parameters: {'n_estimators': 202, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:02,012] Trial 33 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 317, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:02,124] Trial 34 finished with value: 0.8232095698523442 and parameters: {'n_estimators': 107, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:02,491] Trial 35 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 405, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:02,689] Trial 36 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 211, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:03,180] Trial 37 finished with value: 0.7084127396627398 and parameters: {'n_estimators': 558, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:04,011] Trial 38 finished with value: 0.833675692499222 and parameters: {'n_estimators': 721, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:04,939] Trial 39 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 808, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:06,380] Trial 40 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1304, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:07,482] Trial 41 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1057, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:08,179] Trial 42 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 746, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:09,111] Trial 43 finished with value: 0.833675692499222 and parameters: {'n_estimators': 944, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:09,988] Trial 44 finished with value: 0.833675692499222 and parameters: {'n_estimators': 904, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:10,882] Trial 45 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 887, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:11,885] Trial 46 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1010, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:12,794] Trial 47 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 925, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:14,074] Trial 48 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1165, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:15,370] Trial 49 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1154, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:16,704] Trial 50 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1210, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:18,007] Trial 51 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1192, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:19,320] Trial 52 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1199, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:20,610] Trial 53 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1189, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:21,899] Trial 54 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1193, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:23,357] Trial 55 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1298, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:24,739] Trial 56 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1260, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:26,330] Trial 57 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1470, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:27,532] Trial 58 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1109, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:29,080] Trial 59 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1380, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:30,382] Trial 60 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1231, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:31,578] Trial 61 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1124, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:32,948] Trial 62 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1273, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:34,404] Trial 63 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1361, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:35,645] Trial 64 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1145, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:36,738] Trial 65 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1022, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:38,089] Trial 66 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1258, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:39,341] Trial 67 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1156, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:40,783] Trial 68 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1340, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:42,394] Trial 69 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1424, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:43,570] Trial 70 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1056, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:44,890] Trial 71 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1225, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:46,057] Trial 72 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1105, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:47,328] Trial 73 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1170, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:48,418] Trial 74 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1002, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:49,544] Trial 75 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1017, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:50,608] Trial 76 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 983, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:51,799] Trial 77 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1098, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:52,830] Trial 78 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 977, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:53,965] Trial 79 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1064, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:54,907] Trial 80 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 880, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:55,984] Trial 81 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 999, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:57,036] Trial 82 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 963, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:58,156] Trial 83 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1041, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:16:59,436] Trial 84 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1174, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:00,351] Trial 85 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 833, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:01,548] Trial 86 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1084, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:02,091] Trial 87 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 453, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:03,348] Trial 88 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1117, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:04,425] Trial 89 finished with value: 0.833675692499222 and parameters: {'n_estimators': 986, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:05,637] Trial 90 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1142, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:06,662] Trial 91 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 969, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:07,779] Trial 92 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1031, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:08,766] Trial 93 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 918, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:09,718] Trial 94 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 870, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:10,480] Trial 95 finished with value: 0.833675692499222 and parameters: {'n_estimators': 700, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:11,753] Trial 96 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1175, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:12,933] Trial 97 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1086, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:14,385] Trial 98 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1322, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:15,365] Trial 99 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 997, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:16,691] Trial 100 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1239, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:17,704] Trial 101 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 940, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:18,909] Trial 102 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1124, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:19,967] Trial 103 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 982, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 24 with value: 0.8426661956073721.\n",
      "[I 2024-01-12 22:17:21,006] Trial 104 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 961, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:22,115] Trial 105 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1026, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:23,012] Trial 106 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 825, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:24,250] Trial 107 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1194, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:25,398] Trial 108 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1081, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:26,526] Trial 109 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1056, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:27,973] Trial 110 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1276, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:29,015] Trial 111 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 966, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:29,858] Trial 112 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 775, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:30,876] Trial 113 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 956, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:31,452] Trial 114 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 518, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:32,438] Trial 115 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 899, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:33,370] Trial 116 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 867, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:34,597] Trial 117 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1153, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:35,681] Trial 118 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1011, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:36,778] Trial 119 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1017, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:37,929] Trial 120 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1108, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:39,082] Trial 121 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1114, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:40,067] Trial 122 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 1054, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:41,300] Trial 123 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1201, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:42,469] Trial 124 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1087, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:43,622] Trial 125 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1138, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:44,891] Trial 126 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1171, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:46,189] Trial 127 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1226, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:47,166] Trial 128 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 937, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:48,271] Trial 129 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1010, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:49,464] Trial 130 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1101, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:50,512] Trial 131 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 978, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:51,506] Trial 132 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 918, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:52,637] Trial 133 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1046, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:53,700] Trial 134 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 998, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:54,858] Trial 135 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1073, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:55,968] Trial 136 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1032, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:56,970] Trial 137 finished with value: 0.833675692499222 and parameters: {'n_estimators': 957, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:58,145] Trial 138 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1127, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:17:59,392] Trial 139 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1174, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:00,291] Trial 140 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 850, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:01,199] Trial 141 finished with value: 0.833675692499222 and parameters: {'n_estimators': 874, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:02,167] Trial 142 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 929, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:03,015] Trial 143 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 800, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:03,957] Trial 144 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 901, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:04,988] Trial 145 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 983, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:05,905] Trial 146 finished with value: 0.833675692499222 and parameters: {'n_estimators': 958, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:07,009] Trial 147 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 1244, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:07,709] Trial 148 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 672, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:08,907] Trial 149 finished with value: 0.820490132990133 and parameters: {'n_estimators': 1020, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:10,280] Trial 150 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1290, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:11,500] Trial 151 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1147, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:12,781] Trial 152 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1206, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:13,955] Trial 153 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1096, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:15,220] Trial 154 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1180, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:16,351] Trial 155 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1057, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:17,664] Trial 156 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1225, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:18,843] Trial 157 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1119, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:20,076] Trial 158 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1169, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:20,892] Trial 159 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 925, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:22,005] Trial 160 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1035, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:23,159] Trial 161 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1076, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:24,253] Trial 162 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1003, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:25,472] Trial 163 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1149, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:26,638] Trial 164 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1093, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:27,934] Trial 165 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1206, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:28,974] Trial 166 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 976, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:30,154] Trial 167 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1114, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:31,251] Trial 168 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1070, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:32,369] Trial 169 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1040, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:33,397] Trial 170 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 946, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:34,783] Trial 171 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1269, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:36,071] Trial 172 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1204, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:37,363] Trial 173 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1225, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:38,593] Trial 174 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1162, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:39,947] Trial 175 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1250, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:41,048] Trial 176 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1000, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:42,274] Trial 177 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1185, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:43,663] Trial 178 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1310, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:44,882] Trial 179 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1136, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:45,854] Trial 180 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 895, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:46,998] Trial 181 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1080, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:47,789] Trial 182 finished with value: 0.7665056612425033 and parameters: {'n_estimators': 1104, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:48,876] Trial 183 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1018, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:49,999] Trial 184 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1063, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:51,200] Trial 185 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1136, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:52,219] Trial 186 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 985, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:52,606] Trial 187 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 357, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:53,695] Trial 188 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 1042, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:54,743] Trial 189 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 958, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:56,014] Trial 190 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1181, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:57,170] Trial 191 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1079, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:58,299] Trial 192 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1059, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:18:59,406] Trial 193 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1023, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:00,579] Trial 194 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1104, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:01,667] Trial 195 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1005, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:02,873] Trial 196 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1156, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:04,066] Trial 197 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1147, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:05,368] Trial 198 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1247, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:06,611] Trial 199 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1192, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:07,604] Trial 200 finished with value: 0.8275562882304457 and parameters: {'n_estimators': 1222, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:08,800] Trial 201 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1164, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:09,962] Trial 202 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1120, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:10,238] Trial 203 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 240, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:11,272] Trial 204 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 976, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:12,262] Trial 205 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 1050, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:13,435] Trial 206 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1094, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:14,430] Trial 207 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 926, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:14,774] Trial 208 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 313, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:15,992] Trial 209 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1125, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:17,269] Trial 210 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1155, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:18,291] Trial 211 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 953, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:19,345] Trial 212 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 987, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:20,444] Trial 213 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1048, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:21,365] Trial 214 finished with value: 0.833675692499222 and parameters: {'n_estimators': 857, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:22,371] Trial 215 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 949, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:23,432] Trial 216 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1010, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:24,399] Trial 217 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 901, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:25,625] Trial 218 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1194, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:26,767] Trial 219 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1075, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:27,819] Trial 220 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 969, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:28,668] Trial 221 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 818, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:29,604] Trial 222 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 878, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:30,441] Trial 223 finished with value: 0.833675692499222 and parameters: {'n_estimators': 779, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:31,076] Trial 224 finished with value: 0.833675692499222 and parameters: {'n_estimators': 589, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:31,853] Trial 225 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 866, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:32,846] Trial 226 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 932, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:33,734] Trial 227 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 1029, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:34,994] Trial 228 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1171, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:36,110] Trial 229 finished with value: 0.824887818514042 and parameters: {'n_estimators': 982, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:37,410] Trial 230 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1218, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:38,656] Trial 231 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1150, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:39,838] Trial 232 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1127, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:41,009] Trial 233 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1106, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:42,238] Trial 234 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1171, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:43,393] Trial 235 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1085, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:44,460] Trial 236 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1005, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:45,459] Trial 237 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 949, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:46,771] Trial 238 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1248, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:48,021] Trial 239 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1133, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:49,284] Trial 240 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1187, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:50,407] Trial 241 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1087, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:51,474] Trial 242 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1059, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:52,544] Trial 243 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1035, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:53,601] Trial 244 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1020, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:54,670] Trial 245 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1040, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:55,678] Trial 246 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 979, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:56,888] Trial 247 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1145, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:58,190] Trial 248 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1209, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:19:59,100] Trial 249 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 837, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:00,155] Trial 250 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 1109, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:01,207] Trial 251 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 999, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:02,285] Trial 252 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1029, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:03,506] Trial 253 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1163, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:04,450] Trial 254 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 919, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:05,573] Trial 255 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1068, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:06,607] Trial 256 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 971, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:07,862] Trial 257 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1194, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:08,642] Trial 258 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 736, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:09,718] Trial 259 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1007, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:10,722] Trial 260 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 947, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:11,829] Trial 261 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1047, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:13,152] Trial 262 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1237, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:14,284] Trial 263 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1106, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:15,447] Trial 264 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1076, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:16,648] Trial 265 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1145, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:17,999] Trial 266 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1273, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:18,968] Trial 267 finished with value: 0.833675692499222 and parameters: {'n_estimators': 899, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:20,170] Trial 268 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1162, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:21,224] Trial 269 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 985, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:21,376] Trial 270 finished with value: 0.8372937151563106 and parameters: {'n_estimators': 164, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:22,560] Trial 271 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1125, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:23,618] Trial 272 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1028, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:24,340] Trial 273 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 785, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:25,592] Trial 274 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1182, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:26,881] Trial 275 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1216, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:27,954] Trial 276 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 952, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:29,005] Trial 277 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1090, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:30,136] Trial 278 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1057, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:31,206] Trial 279 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1014, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:32,255] Trial 280 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 987, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:33,209] Trial 281 finished with value: 0.833675692499222 and parameters: {'n_estimators': 923, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:34,424] Trial 282 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1121, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:34,884] Trial 283 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 412, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:36,120] Trial 284 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1159, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:37,195] Trial 285 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1038, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:38,112] Trial 286 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 857, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:39,366] Trial 287 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1187, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:40,406] Trial 288 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 957, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:41,571] Trial 289 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1096, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:42,264] Trial 290 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 658, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:43,398] Trial 291 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1065, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:43,869] Trial 292 finished with value: 0.833675692499222 and parameters: {'n_estimators': 470, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:44,928] Trial 293 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 1233, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:45,993] Trial 294 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1131, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:46,947] Trial 295 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 883, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:48,035] Trial 296 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 995, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:48,601] Trial 297 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 528, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:49,857] Trial 298 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1202, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:50,958] Trial 299 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1023, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:51,936] Trial 300 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 914, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:52,969] Trial 301 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 962, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:54,185] Trial 302 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1148, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:55,289] Trial 303 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1073, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:55,459] Trial 304 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 133, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:56,334] Trial 305 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 819, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:57,330] Trial 306 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 936, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:57,477] Trial 307 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 117, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:57,665] Trial 308 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 159, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:57,824] Trial 309 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 123, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:58,018] Trial 310 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 149, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:58,183] Trial 311 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 126, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:20:59,224] Trial 312 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1007, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:00,323] Trial 313 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1037, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:00,564] Trial 314 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 207, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:01,628] Trial 315 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 984, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:02,475] Trial 316 finished with value: 0.8036745872848512 and parameters: {'n_estimators': 1100, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:02,809] Trial 317 finished with value: 0.833675692499222 and parameters: {'n_estimators': 277, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:03,832] Trial 318 finished with value: 0.833675692499222 and parameters: {'n_estimators': 970, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:05,178] Trial 319 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1265, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:05,326] Trial 320 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 111, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:06,429] Trial 321 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1061, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:06,573] Trial 322 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 104, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:07,867] Trial 323 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1213, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:09,005] Trial 324 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1004, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:10,183] Trial 325 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1172, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:10,990] Trial 326 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 758, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:12,092] Trial 327 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1032, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:12,918] Trial 328 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 906, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:13,122] Trial 329 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:14,292] Trial 330 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1112, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:15,300] Trial 331 finished with value: 0.833675692499222 and parameters: {'n_estimators': 956, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:16,431] Trial 332 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1072, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:17,500] Trial 333 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 1232, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:18,534] Trial 334 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1011, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:19,786] Trial 335 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1178, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:21,166] Trial 336 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1333, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:22,077] Trial 337 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 848, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:23,042] Trial 338 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 935, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:24,307] Trial 339 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1131, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:25,354] Trial 340 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 1090, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:26,449] Trial 341 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1046, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:27,319] Trial 342 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 986, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:28,571] Trial 343 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1198, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:29,950] Trial 344 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1297, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:31,515] Trial 345 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1500, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:32,432] Trial 346 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 876, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:33,625] Trial 347 finished with value: 0.824887818514042 and parameters: {'n_estimators': 1051, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:34,820] Trial 348 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1154, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:35,758] Trial 349 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 894, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:36,759] Trial 350 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 958, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:38,102] Trial 351 finished with value: 0.816089234993927 and parameters: {'n_estimators': 1123, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:39,157] Trial 352 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1010, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:39,896] Trial 353 finished with value: 0.820490132990133 and parameters: {'n_estimators': 706, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:41,226] Trial 354 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1256, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:42,361] Trial 355 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1087, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:43,372] Trial 356 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 982, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:44,475] Trial 357 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1037, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:45,459] Trial 358 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 925, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:46,649] Trial 359 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1147, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:47,879] Trial 360 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1213, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:49,105] Trial 361 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1201, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:50,377] Trial 362 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1229, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:51,610] Trial 363 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1189, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:52,873] Trial 364 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 1254, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:54,094] Trial 365 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1173, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:55,243] Trial 366 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1108, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:56,514] Trial 367 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1235, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:57,742] Trial 368 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1210, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:21:58,878] Trial 369 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 1285, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:00,050] Trial 370 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1139, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:01,163] Trial 371 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1066, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:02,417] Trial 372 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1183, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:03,598] Trial 373 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1102, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:04,701] Trial 374 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1034, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:05,671] Trial 375 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1163, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:06,932] Trial 376 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1215, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:07,065] Trial 377 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 101, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:08,186] Trial 378 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1081, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:09,356] Trial 379 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1131, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:10,455] Trial 380 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1014, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:11,557] Trial 381 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1047, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:12,345] Trial 382 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 810, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:13,549] Trial 383 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1159, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:14,714] Trial 384 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1107, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:14,896] Trial 385 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:15,970] Trial 386 finished with value: 0.833675692499222 and parameters: {'n_estimators': 985, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:16,454] Trial 387 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 445, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:17,398] Trial 388 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 870, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:18,527] Trial 389 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1067, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:19,613] Trial 390 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1012, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:20,683] Trial 391 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1003, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:21,655] Trial 392 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 934, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:22,695] Trial 393 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 968, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:23,786] Trial 394 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1022, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:25,065] Trial 395 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1245, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:26,284] Trial 396 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1169, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:27,560] Trial 397 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1211, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:27,991] Trial 398 finished with value: 0.824887818514042 and parameters: {'n_estimators': 378, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:29,016] Trial 399 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 997, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:30,041] Trial 400 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 962, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:31,306] Trial 401 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1192, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:32,511] Trial 402 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1130, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:33,468] Trial 403 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 911, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:34,565] Trial 404 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1024, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:36,060] Trial 405 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1381, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:36,755] Trial 406 finished with value: 0.824887818514042 and parameters: {'n_estimators': 601, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:37,652] Trial 407 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 841, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:38,713] Trial 408 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 983, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:39,950] Trial 409 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1147, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:41,267] Trial 410 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1274, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:42,428] Trial 411 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1088, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:43,693] Trial 412 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 1184, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:45,007] Trial 413 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1227, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:46,080] Trial 414 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1033, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:47,251] Trial 415 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1066, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:47,915] Trial 416 finished with value: 0.7397965341227752 and parameters: {'n_estimators': 955, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:49,102] Trial 417 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1114, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:50,007] Trial 418 finished with value: 0.833675692499222 and parameters: {'n_estimators': 887, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:51,076] Trial 419 finished with value: 0.833675692499222 and parameters: {'n_estimators': 991, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:52,399] Trial 420 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1154, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:53,749] Trial 421 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1050, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:55,197] Trial 422 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1213, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:55,374] Trial 423 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 140, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:55,648] Trial 424 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 233, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:56,753] Trial 425 finished with value: 0.824887818514042 and parameters: {'n_estimators': 934, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:57,925] Trial 426 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 1018, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:22:59,300] Trial 427 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 1176, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:00,661] Trial 428 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1193, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:01,910] Trial 429 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1171, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:03,216] Trial 430 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1244, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:04,518] Trial 431 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1197, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:05,791] Trial 432 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1133, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:07,181] Trial 433 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1236, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:08,492] Trial 434 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1171, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:09,489] Trial 435 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 970, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:10,896] Trial 436 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1270, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:12,213] Trial 437 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1158, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:13,617] Trial 438 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1206, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:14,905] Trial 439 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1134, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:15,999] Trial 440 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 994, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:16,839] Trial 441 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 795, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:17,068] Trial 442 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 185, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:17,881] Trial 443 finished with value: 0.8326155914543202 and parameters: {'n_estimators': 915, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:18,934] Trial 444 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 946, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:20,195] Trial 445 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1179, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:21,545] Trial 446 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 1227, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:22,549] Trial 447 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 1112, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:23,693] Trial 448 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1005, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:24,946] Trial 449 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1153, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:26,068] Trial 450 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 967, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:26,720] Trial 451 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 564, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:28,195] Trial 452 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1304, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:29,552] Trial 453 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 1205, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:29,950] Trial 454 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 331, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:30,968] Trial 455 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 884, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:31,110] Trial 456 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 103, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:31,965] Trial 457 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 763, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:33,132] Trial 458 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1043, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:34,091] Trial 459 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 828, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:35,280] Trial 460 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 1102, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:36,698] Trial 461 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1251, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:38,017] Trial 462 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1183, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:39,242] Trial 463 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1077, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:40,419] Trial 464 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1014, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:41,609] Trial 465 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 1137, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:42,724] Trial 466 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 984, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:43,766] Trial 467 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 948, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:44,961] Trial 468 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1050, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:46,360] Trial 469 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1209, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:47,692] Trial 470 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1165, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:48,799] Trial 471 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1023, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:49,736] Trial 472 finished with value: 0.833675692499222 and parameters: {'n_estimators': 863, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:50,918] Trial 473 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1085, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:51,973] Trial 474 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 928, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:53,158] Trial 475 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1126, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:54,269] Trial 476 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 993, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:54,885] Trial 477 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 508, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:55,653] Trial 478 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 630, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:57,084] Trial 479 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1227, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:58,290] Trial 480 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 1184, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:23:59,612] Trial 481 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1161, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:00,706] Trial 482 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 963, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:02,220] Trial 483 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1267, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:03,211] Trial 484 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 905, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:04,434] Trial 485 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1106, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:04,621] Trial 486 finished with value: 0.833675692499222 and parameters: {'n_estimators': 135, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:05,692] Trial 487 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1046, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:06,850] Trial 488 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1017, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:08,145] Trial 489 finished with value: 0.833675692499222 and parameters: {'n_estimators': 1131, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:09,282] Trial 490 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 1198, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:10,502] Trial 491 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 1063, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:11,626] Trial 492 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 1000, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:12,861] Trial 493 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 1149, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:13,954] Trial 494 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 975, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:15,456] Trial 495 finished with value: 0.820490132990133 and parameters: {'n_estimators': 1224, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:16,730] Trial 496 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1170, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:17,797] Trial 497 finished with value: 0.833675692499222 and parameters: {'n_estimators': 931, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'gini'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:19,007] Trial 498 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 1081, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:24:20,470] Trial 499 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 1251, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 104 with value: 0.8468468468468469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.833333\n",
      "Model F1 Score: 0.832169\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    }\n",
    "    model = ExtraTreesClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = f1_score(y_val, preds, average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = ExtraTreesClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"ET\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 22:25:09,256] A new study created in memory with name: no-name-ea6a3b47-9c55-40b9-830a-66cd2520c7e2\n",
      "[I 2024-01-12 22:25:09,554] Trial 0 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 235, 'max_depth': 23, 'learning_rate': 7.807825857601061e-05, 'gamma': 0.6777615538226325, 'min_child_weight': 4, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 0.0013526297198454577, 'reg_lambda': 0.001226222624650771}. Best is trial 0 with value: 0.42711942711942713.\n",
      "[I 2024-01-12 22:25:09,778] Trial 1 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 367, 'max_depth': 32, 'learning_rate': 1.2391929562549133e-08, 'gamma': 0.20539105747153732, 'min_child_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0008911891414624543, 'reg_lambda': 0.0002148066688669714}. Best is trial 0 with value: 0.42711942711942713.\n",
      "[I 2024-01-12 22:25:11,329] Trial 2 finished with value: 0.7714199834681762 and parameters: {'n_estimators': 988, 'max_depth': 3, 'learning_rate': 0.15779840177476628, 'gamma': 0.7911022136408292, 'min_child_weight': 7, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 1.8733243230711016e-05, 'reg_lambda': 0.6136567764016635}. Best is trial 2 with value: 0.7714199834681762.\n",
      "[I 2024-01-12 22:25:11,602] Trial 3 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 433, 'max_depth': 8, 'learning_rate': 7.835356474009162e-08, 'gamma': 0.17555745314934462, 'min_child_weight': 5, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 3.1295152708928686, 'reg_lambda': 0.5763693155107533}. Best is trial 2 with value: 0.7714199834681762.\n",
      "[I 2024-01-12 22:25:11,817] Trial 4 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 508, 'max_depth': 4, 'learning_rate': 0.00022558779748156925, 'gamma': 0.8197024241117334, 'min_child_weight': 9, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.08956147558404996, 'reg_lambda': 0.01934425980980685}. Best is trial 2 with value: 0.7714199834681762.\n",
      "[I 2024-01-12 22:25:11,884] Trial 5 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 1.0248916160403499e-08, 'gamma': 0.15646629965513184, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.933788334132343e-05, 'reg_lambda': 0.14063550021745508}. Best is trial 2 with value: 0.7714199834681762.\n",
      "[I 2024-01-12 22:25:12,253] Trial 6 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 110, 'max_depth': 24, 'learning_rate': 0.45340861799318954, 'gamma': 0.3232263003898337, 'min_child_weight': 8, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.00026980570866818763, 'reg_lambda': 2.2117236722606473}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:12,505] Trial 7 finished with value: 0.7573670227875413 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.0026393786892696352, 'gamma': 0.6052421971849399, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 2.613127235002271e-05, 'reg_lambda': 1.015181265278875e-05}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:12,640] Trial 8 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 157, 'max_depth': 8, 'learning_rate': 3.110339069166853e-08, 'gamma': 0.43307226731703063, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.008419187551502033, 'reg_lambda': 0.00043286326900120496}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:13,407] Trial 9 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 881, 'max_depth': 27, 'learning_rate': 1.773366570724072e-08, 'gamma': 0.7836922291797629, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0405654390463708, 'reg_lambda': 3.335195631873565e-05}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:13,871] Trial 10 finished with value: 0.7532904371869753 and parameters: {'n_estimators': 668, 'max_depth': 19, 'learning_rate': 0.8407705504000724, 'gamma': 0.4135574954505817, 'min_child_weight': 8, 'subsample': 0.5, 'colsample_bytree': 1.0, 'reg_alpha': 0.0004968494661858123, 'reg_lambda': 5.117984378811341}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:14,138] Trial 11 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 959, 'max_depth': 14, 'learning_rate': 0.7284706511746336, 'gamma': 0.9730528517024135, 'min_child_weight': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 1.0586286270024628e-05, 'reg_lambda': 8.768686673370999}. Best is trial 6 with value: 0.8023274828910966.\n",
      "[I 2024-01-12 22:25:14,558] Trial 12 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 771, 'max_depth': 15, 'learning_rate': 0.020356873982622096, 'gamma': 0.9950480864612264, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 0.00018998087250551483, 'reg_lambda': 9.039491146624647}. Best is trial 12 with value: 0.8069275947718925.\n",
      "[I 2024-01-12 22:25:14,872] Trial 13 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 726, 'max_depth': 16, 'learning_rate': 0.01255683490643733, 'gamma': 0.36476294281666555, 'min_child_weight': 10, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.00018425695244657988, 'reg_lambda': 1.0289826915437406}. Best is trial 12 with value: 0.8069275947718925.\n",
      "[I 2024-01-12 22:25:15,171] Trial 14 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 730, 'max_depth': 16, 'learning_rate': 0.012912489952964921, 'gamma': 0.9668016782666553, 'min_child_weight': 10, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.01689115762983875, 'reg_lambda': 0.05921011814435555}. Best is trial 12 with value: 0.8069275947718925.\n",
      "[I 2024-01-12 22:25:15,666] Trial 15 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 705, 'max_depth': 12, 'learning_rate': 0.011179657706269813, 'gamma': 0.5042494172591656, 'min_child_weight': 9, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.004750002628983136, 'reg_lambda': 0.5991455581142731}. Best is trial 12 with value: 0.8069275947718925.\n",
      "[I 2024-01-12 22:25:16,044] Trial 16 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 797, 'max_depth': 19, 'learning_rate': 1.1313736581930757e-05, 'gamma': 0.28020309233636637, 'min_child_weight': 10, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.0001134601093161546, 'reg_lambda': 0.012623210268215949}. Best is trial 12 with value: 0.8069275947718925.\n",
      "[I 2024-01-12 22:25:16,328] Trial 17 finished with value: 0.8180626352268143 and parameters: {'n_estimators': 581, 'max_depth': 11, 'learning_rate': 0.0013268753816285384, 'gamma': 0.5791274570754151, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.062428972850265115, 'reg_lambda': 1.756544779969554}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:16,918] Trial 18 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 570, 'max_depth': 11, 'learning_rate': 2.3288246130231328e-06, 'gamma': 0.6633073752226567, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.10406717769923671, 'reg_lambda': 0.11510102779193934}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:17,256] Trial 19 finished with value: 0.8122888649204439 and parameters: {'n_estimators': 596, 'max_depth': 9, 'learning_rate': 0.000955655232822514, 'gamma': 0.879571389381713, 'min_child_weight': 8, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.11655068338649743, 'reg_lambda': 0.0030991509143736906}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:17,756] Trial 20 finished with value: 0.7752787709789188 and parameters: {'n_estimators': 597, 'max_depth': 9, 'learning_rate': 0.0004429542821005793, 'gamma': 0.8752283833910091, 'min_child_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.2647895841390442, 'reg_lambda': 0.002615676477698804}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:17,910] Trial 21 finished with value: 0.760317750182615 and parameters: {'n_estimators': 340, 'max_depth': 12, 'learning_rate': 0.001161428567351471, 'gamma': 0.8966145584602193, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.030003988379021816, 'reg_lambda': 9.88615022837565}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:18,289] Trial 22 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 816, 'max_depth': 8, 'learning_rate': 3.8027515996613656e-05, 'gamma': 0.7261661585526756, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.7340505975422477, 'reg_lambda': 0.003679945729044029}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:19,379] Trial 23 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 617, 'max_depth': 14, 'learning_rate': 0.06427948352508112, 'gamma': 0.5310306716417226, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.0878519850256143, 'reg_lambda': 2.33941638853496}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:20,303] Trial 24 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 509, 'max_depth': 6, 'learning_rate': 0.0025608708286322533, 'gamma': 0.8990731320542485, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.0035510417617531987, 'reg_lambda': 0.057900473121359396}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:20,678] Trial 25 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 812, 'max_depth': 19, 'learning_rate': 0.027815889357785815, 'gamma': 0.9894549223480448, 'min_child_weight': 9, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.04780180955853448, 'reg_lambda': 0.24210495041679242}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:20,988] Trial 26 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 423, 'max_depth': 14, 'learning_rate': 2.159010558093477e-06, 'gamma': 0.7297582370604567, 'min_child_weight': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'reg_alpha': 0.4236921670827343, 'reg_lambda': 0.00018686056207362263}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:23,254] Trial 27 finished with value: 0.8048474005920815 and parameters: {'n_estimators': 648, 'max_depth': 10, 'learning_rate': 0.0007738021955428961, 'gamma': 0.861729464440601, 'min_child_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 5.4084105990951095, 'reg_lambda': 0.02878451336990403}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:23,618] Trial 28 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 557, 'max_depth': 6, 'learning_rate': 0.003644243196202074, 'gamma': 0.59567096362952, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.0017654535756605565, 'reg_lambda': 2.727387593533788}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:24,347] Trial 29 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 451, 'max_depth': 22, 'learning_rate': 7.815487488986768e-05, 'gamma': 0.6693849229334975, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.015109678164002082, 'reg_lambda': 0.0042614267392124825}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:24,888] Trial 30 finished with value: 0.7794400238895547 and parameters: {'n_estimators': 312, 'max_depth': 13, 'learning_rate': 0.06961672599593333, 'gamma': 0.9485525389569596, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.20805788451830481, 'reg_lambda': 0.0015857791838338625}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:25,180] Trial 31 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 511, 'max_depth': 6, 'learning_rate': 0.0030878790920636713, 'gamma': 0.9067465779597017, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.003338458855717883, 'reg_lambda': 0.04370407136428832}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:25,368] Trial 32 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.0003283154411657603, 'gamma': 0.827251388076233, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.00105953407470496, 'reg_lambda': 0.006122804997178766}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:25,968] Trial 33 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 536, 'max_depth': 10, 'learning_rate': 0.0015655137922155117, 'gamma': 0.9169559253266961, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.0031938092467469815, 'reg_lambda': 0.00038161337737841643}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:27,013] Trial 34 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 879, 'max_depth': 10, 'learning_rate': 2.7647337815601354e-05, 'gamma': 0.7532982467733236, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.037192540329979984, 'reg_lambda': 0.000504483905197247}. Best is trial 17 with value: 0.8180626352268143.\n",
      "[I 2024-01-12 22:25:27,131] Trial 35 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 435, 'max_depth': 17, 'learning_rate': 0.1936951520362922, 'gamma': 0.932770810213077, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 2.0712235604996394, 'reg_lambda': 9.112830464129872e-05}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:27,949] Trial 36 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 409, 'max_depth': 17, 'learning_rate': 0.00014858377617512584, 'gamma': 0.8332686602084327, 'min_child_weight': 7, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 1.6913506478298554, 'reg_lambda': 7.035921903516856e-05}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:28,067] Trial 37 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 455, 'max_depth': 25, 'learning_rate': 0.17313140874146468, 'gamma': 0.9301046460843835, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 5.491912305687361, 'reg_lambda': 0.0006209283599328727}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:28,243] Trial 38 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 544, 'max_depth': 2, 'learning_rate': 6.65950682877344e-06, 'gamma': 0.7807811533341754, 'min_child_weight': 6, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 1.8412300851478984, 'reg_lambda': 0.00014009887533737578}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:29,081] Trial 39 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 370, 'max_depth': 22, 'learning_rate': 1.7643274668896943e-07, 'gamma': 0.11876867140977387, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.2114467353147154, 'reg_lambda': 3.634266760022666e-05}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:29,134] Trial 40 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 25, 'max_depth': 11, 'learning_rate': 0.18278411229424618, 'gamma': 0.24068736925276718, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.5775056354950961, 'reg_lambda': 1.0711615555607264e-05}. Best is trial 35 with value: 0.8200743962047155.\n",
      "[I 2024-01-12 22:25:29,212] Trial 41 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 33, 'max_depth': 12, 'learning_rate': 0.25521077038885337, 'gamma': 0.21038830137214204, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.6052828680557183, 'reg_lambda': 1.0870472778441746e-05}. Best is trial 41 with value: 0.8241886674319105.\n",
      "[I 2024-01-12 22:25:29,282] Trial 42 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 63, 'max_depth': 30, 'learning_rate': 0.18898005918840757, 'gamma': 0.2378211003332379, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 9.365315370072878, 'reg_lambda': 1.0345768957752858e-05}. Best is trial 41 with value: 0.8241886674319105.\n",
      "[I 2024-01-12 22:25:29,351] Trial 43 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 73, 'max_depth': 31, 'learning_rate': 0.3237246551461422, 'gamma': 0.19523202037563214, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 9.014779024021234, 'reg_lambda': 2.487055272226822e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,409] Trial 44 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 22, 'max_depth': 32, 'learning_rate': 0.3601544849155615, 'gamma': 0.19434949145187452, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 8.914343308115573, 'reg_lambda': 2.146290596370131e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,521] Trial 45 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 82, 'max_depth': 31, 'learning_rate': 0.053190164785848065, 'gamma': 0.2460011845138877, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 2.5238922508954857, 'reg_lambda': 6.631807823483625e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,608] Trial 46 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 71, 'max_depth': 30, 'learning_rate': 0.05491449898378558, 'gamma': 0.24232891537741935, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 2.8155954127846217, 'reg_lambda': 7.438119179249073e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,692] Trial 47 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 190, 'max_depth': 30, 'learning_rate': 0.3232510624569337, 'gamma': 0.14147873978232067, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_alpha': 7.516538788134134, 'reg_lambda': 2.113280599461052e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,777] Trial 48 finished with value: 0.780204207675669 and parameters: {'n_estimators': 122, 'max_depth': 30, 'learning_rate': 0.9611025314469644, 'gamma': 0.32658485393821257, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.3155230976692365, 'reg_lambda': 6.907674038866187e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:29,874] Trial 49 finished with value: 0.7845881595881596 and parameters: {'n_estimators': 78, 'max_depth': 28, 'learning_rate': 0.1426924509940184, 'gamma': 0.43655196009229846, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 1.1992551684022505, 'reg_lambda': 1.0457654030345502e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:30,164] Trial 50 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 206, 'max_depth': 28, 'learning_rate': 0.03105660406704983, 'gamma': 0.10044018078341446, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 3.1361419920669413, 'reg_lambda': 4.053682045804823e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:30,250] Trial 51 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 70, 'max_depth': 30, 'learning_rate': 0.07643462784659466, 'gamma': 0.245671430086778, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 2.3610310811207946, 'reg_lambda': 9.923222844414454e-05}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:30,337] Trial 52 finished with value: 0.7945431727399606 and parameters: {'n_estimators': 143, 'max_depth': 31, 'learning_rate': 0.007173544344276289, 'gamma': 0.23549234954617979, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 9.727270942900075, 'reg_lambda': 0.00011561072141041272}. Best is trial 43 with value: 0.8290706763944796.\n",
      "[I 2024-01-12 22:25:30,421] Trial 53 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 61, 'max_depth': 27, 'learning_rate': 0.11074485059863076, 'gamma': 0.31016105631017926, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.0928766271001376, 'reg_lambda': 1.7493888381249573e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:30,849] Trial 54 finished with value: 0.7881248043410206 and parameters: {'n_estimators': 262, 'max_depth': 26, 'learning_rate': 0.09827726648279503, 'gamma': 0.3020845126195838, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1359220639673664, 'reg_lambda': 2.1421827965501912e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:30,950] Trial 55 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 168, 'max_depth': 28, 'learning_rate': 0.39466649441671686, 'gamma': 0.36194596431190174, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 2.1529174868056864, 'reg_lambda': 0.0002885036655341977}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,033] Trial 56 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 102, 'max_depth': 32, 'learning_rate': 0.03329064223134495, 'gamma': 0.16820743668486746, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.311745020426345, 'reg_lambda': 5.0997448982296776e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,110] Trial 57 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 98, 'max_depth': 32, 'learning_rate': 0.043092385282986145, 'gamma': 0.15992481908274755, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.734170670109653, 'reg_lambda': 4.6191989335703895e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,253] Trial 58 finished with value: 0.7699050401753104 and parameters: {'n_estimators': 45, 'max_depth': 29, 'learning_rate': 0.00774651402615021, 'gamma': 0.1943713818326328, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 3.7066339456916744, 'reg_lambda': 1.941926679300696e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,460] Trial 59 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 131, 'max_depth': 26, 'learning_rate': 0.016575407517684843, 'gamma': 0.27372707608316, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7053895959989489, 'reg_lambda': 0.0009795467929944598}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,594] Trial 60 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 234, 'max_depth': 32, 'learning_rate': 0.5876850544137548, 'gamma': 0.3498781772777325, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.37331996143719454, 'reg_lambda': 0.00020051027699681623}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:31,655] Trial 61 finished with value: 0.814519979719652 and parameters: {'n_estimators': 13, 'max_depth': 31, 'learning_rate': 0.10128190667782663, 'gamma': 0.39885890672491586, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.5651153153091433, 'reg_lambda': 9.739020226536219e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,016] Trial 62 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 110, 'max_depth': 20, 'learning_rate': 0.2332906359896049, 'gamma': 0.2780984542926597, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 3.938037443555057, 'reg_lambda': 1.8043400652586516e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,383] Trial 63 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 172, 'max_depth': 29, 'learning_rate': 0.029879591164106704, 'gamma': 0.2163897491396639, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.9989396276723082, 'reg_lambda': 5.0488883259255125e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,465] Trial 64 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 49, 'max_depth': 27, 'learning_rate': 0.1083466829730648, 'gamma': 0.1751888743341274, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4715415674009162, 'reg_lambda': 3.4167435419335624e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,668] Trial 65 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 91, 'max_depth': 24, 'learning_rate': 0.09896438069601915, 'gamma': 0.1614530745230835, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.061791257289924, 'reg_lambda': 2.429432916781756e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,777] Trial 66 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 90, 'max_depth': 27, 'learning_rate': 0.08369146483564185, 'gamma': 0.16506474940702484, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.745877111236243, 'reg_lambda': 3.311076162856892e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,861] Trial 67 finished with value: 0.7998688987494958 and parameters: {'n_estimators': 51, 'max_depth': 25, 'learning_rate': 0.020783739886407252, 'gamma': 0.12230185362744482, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4728681621497905, 'reg_lambda': 2.7747009832780895e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:32,966] Trial 68 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 136, 'max_depth': 23, 'learning_rate': 0.583727811234679, 'gamma': 0.18024846330637642, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 5.062457484010487, 'reg_lambda': 0.00015052958706511142}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:33,838] Trial 69 finished with value: 0.8223949706477587 and parameters: {'n_estimators': 223, 'max_depth': 27, 'learning_rate': 0.005559207194621155, 'gamma': 0.14051114747390875, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.4516636606166253, 'reg_lambda': 5.553224417261598e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:33,917] Trial 70 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 82, 'max_depth': 31, 'learning_rate': 0.049022809511576525, 'gamma': 0.26974421581973235, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.829025758005621, 'reg_lambda': 1.524240230639587e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:33,979] Trial 71 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 46, 'max_depth': 29, 'learning_rate': 0.12390139087525974, 'gamma': 0.20806234665207268, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8647219330166253, 'reg_lambda': 3.126532262921294e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,055] Trial 72 finished with value: 0.7845881595881596 and parameters: {'n_estimators': 107, 'max_depth': 26, 'learning_rate': 0.34073001437355815, 'gamma': 0.31367451830448156, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.48451776205217234, 'reg_lambda': 1.5275910994812503e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,383] Trial 73 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 11, 'max_depth': 31, 'learning_rate': 0.011928047977959523, 'gamma': 0.1844906619108325, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.671453631068767, 'reg_lambda': 2.7695504427926073e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,514] Trial 74 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 165, 'max_depth': 29, 'learning_rate': 0.04660898792325484, 'gamma': 0.2210107897273518, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 4.376340000590301, 'reg_lambda': 5.145428224158643e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,619] Trial 75 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 58, 'max_depth': 24, 'learning_rate': 0.9214150979692686, 'gamma': 0.2580590126133021, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.800854842463012, 'reg_lambda': 0.00029238866760844604}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,876] Trial 76 finished with value: 0.7704375758850468 and parameters: {'n_estimators': 151, 'max_depth': 28, 'learning_rate': 0.09875680249419094, 'gamma': 0.3006174776214819, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.3399063813346535, 'reg_lambda': 1.579426234537771e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:34,957] Trial 77 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 31, 'max_depth': 31, 'learning_rate': 0.2501225303377814, 'gamma': 0.14394218178559137, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 5.769689270305272e-05, 'reg_lambda': 8.843558869264479e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:35,116] Trial 78 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 97, 'max_depth': 25, 'learning_rate': 0.03229155236058879, 'gamma': 0.10773536889955587, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.8181277813516898, 'reg_lambda': 1.3040839787428412e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:35,333] Trial 79 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 195, 'max_depth': 25, 'learning_rate': 0.020998214496863232, 'gamma': 0.11053946945026825, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.988819546881492, 'reg_lambda': 0.0001383612780938158}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:36,109] Trial 80 finished with value: 0.779108838568298 and parameters: {'n_estimators': 189, 'max_depth': 27, 'learning_rate': 0.02371569726272188, 'gamma': 0.10046713169225083, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.1495579655863483, 'reg_lambda': 0.00016086123292688895}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:36,316] Trial 81 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 98, 'max_depth': 25, 'learning_rate': 0.03832343405077413, 'gamma': 0.1255505127322056, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.676684757407737, 'reg_lambda': 5.68736902294959e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:36,420] Trial 82 finished with value: 0.828254477109439 and parameters: {'n_estimators': 115, 'max_depth': 22, 'learning_rate': 0.03694310220744019, 'gamma': 0.12178699368740648, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.7788654297540236, 'reg_lambda': 0.00011636054221577615}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:36,699] Trial 83 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 125, 'max_depth': 21, 'learning_rate': 0.034353837813492986, 'gamma': 0.12270513950626775, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.3152055803717164, 'reg_lambda': 0.0002681136015934374}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:36,946] Trial 84 finished with value: 0.7930671055671057 and parameters: {'n_estimators': 101, 'max_depth': 25, 'learning_rate': 0.004783116421179001, 'gamma': 0.13520501513096847, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.7981574174811925, 'reg_lambda': 5.827931844012834e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,072] Trial 85 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 210, 'max_depth': 24, 'learning_rate': 0.015004340276985025, 'gamma': 0.1800359324148424, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.19134627034393, 'reg_lambda': 3.9337097149770866e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,198] Trial 86 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 147, 'max_depth': 26, 'learning_rate': 0.05675636855031254, 'gamma': 0.1014012054703276, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.7524506576912505, 'reg_lambda': 0.0008301955612385415}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,341] Trial 87 finished with value: 0.8031322241848557 and parameters: {'n_estimators': 66, 'max_depth': 23, 'learning_rate': 0.010564246067176389, 'gamma': 0.16276749244171182, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 1.1534680654926046, 'reg_lambda': 0.00012130514465174165}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,523] Trial 88 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 285, 'max_depth': 25, 'learning_rate': 0.02128006727481981, 'gamma': 0.11732784389380452, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.674715186638683, 'reg_lambda': 3.9158463354759286e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,721] Trial 89 finished with value: 0.7862614387437082 and parameters: {'n_estimators': 248, 'max_depth': 22, 'learning_rate': 0.002089700071083693, 'gamma': 0.1974012174487464, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.0006168584088966545, 'reg_lambda': 7.479282318655325e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,815] Trial 90 finished with value: 0.804179070201375 and parameters: {'n_estimators': 120, 'max_depth': 21, 'learning_rate': 0.007734598122742011, 'gamma': 0.48659955493387025, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 2.075142715125129, 'reg_lambda': 1.4027237424745367e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:37,988] Trial 91 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 82, 'max_depth': 27, 'learning_rate': 0.0656670002931797, 'gamma': 0.14823340107736557, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.4123770049671793, 'reg_lambda': 0.00010842770535357651}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,087] Trial 92 finished with value: 0.788723176958471 and parameters: {'n_estimators': 179, 'max_depth': 32, 'learning_rate': 0.14588213373445114, 'gamma': 0.2316447598445514, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.784303464856745, 'reg_lambda': 0.00021151556565013172}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,143] Trial 93 finished with value: 0.8011367629688241 and parameters: {'n_estimators': 44, 'max_depth': 30, 'learning_rate': 0.0403441834419057, 'gamma': 0.17666365780609888, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 7.121959383245327, 'reg_lambda': 0.0017123451474246895}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,228] Trial 94 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 73, 'max_depth': 28, 'learning_rate': 0.07640303697749139, 'gamma': 0.2611378320540554, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.794288591861275, 'reg_lambda': 6.128929921653016e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,274] Trial 95 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 10, 'max_depth': 29, 'learning_rate': 1.3700969041209182e-07, 'gamma': 0.12016361844899742, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 0.8330492373923359, 'reg_lambda': 0.0004347354205970538}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,336] Trial 96 finished with value: 0.824887818514042 and parameters: {'n_estimators': 106, 'max_depth': 30, 'learning_rate': 0.45737652058426137, 'gamma': 0.2024182893869887, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.09610589622649, 'reg_lambda': 2.9235400969208076e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,394] Trial 97 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 111, 'max_depth': 26, 'learning_rate': 0.5051090772680272, 'gamma': 0.1999838088175491, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.547278150339338, 'reg_lambda': 2.7934221512663556e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,462] Trial 98 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 139, 'max_depth': 23, 'learning_rate': 0.15934243986272206, 'gamma': 0.15279990501394555, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 9.279412685735146, 'reg_lambda': 1.3519913739973424e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,524] Trial 99 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 42, 'max_depth': 32, 'learning_rate': 0.29015465634016147, 'gamma': 0.21963157505463293, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.137030207763973, 'reg_lambda': 2.198792553795508e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,667] Trial 100 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 166, 'max_depth': 25, 'learning_rate': 0.02650977213702128, 'gamma': 0.13023496512761001, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.5468837529550571, 'reg_lambda': 8.014454151175113e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,738] Trial 101 finished with value: 0.7877696803643666 and parameters: {'n_estimators': 62, 'max_depth': 30, 'learning_rate': 0.6592371069943433, 'gamma': 0.29346240926385564, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.32514356452372, 'reg_lambda': 4.349139702009983e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,813] Trial 102 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 98, 'max_depth': 31, 'learning_rate': 0.12565610174642486, 'gamma': 0.1747431868135956, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 3.8597521392112495, 'reg_lambda': 0.00012943606302272771}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:38,891] Trial 103 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 79, 'max_depth': 29, 'learning_rate': 0.0738061573620199, 'gamma': 0.1590464875277811, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.3442766441894796, 'reg_lambda': 3.5292627128950116e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,030] Trial 104 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 126, 'max_depth': 28, 'learning_rate': 0.4461568345473149, 'gamma': 0.24586123468274382, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.421413098854485, 'reg_lambda': 6.185834645511219e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,090] Trial 105 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 31, 'max_depth': 24, 'learning_rate': 0.04171203174649214, 'gamma': 0.1964251047638668, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.346593379390889, 'reg_lambda': 0.009716067611009335}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,157] Trial 106 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 153, 'max_depth': 30, 'learning_rate': 0.2493096802328599, 'gamma': 0.6397695176937431, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 3.0409698065723245, 'reg_lambda': 2.2763544145047863e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,254] Trial 107 finished with value: 0.8232095698523442 and parameters: {'n_estimators': 96, 'max_depth': 32, 'learning_rate': 0.01677992691039521, 'gamma': 0.22182535017678395, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9985610322977296, 'reg_lambda': 0.00010028960986118454}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,321] Trial 108 finished with value: 0.7912918485806725 and parameters: {'n_estimators': 61, 'max_depth': 27, 'learning_rate': 0.010395877681053867, 'gamma': 0.3370228005953406, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.581051552730513, 'reg_lambda': 0.00017170900257534492}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,545] Trial 109 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 201, 'max_depth': 31, 'learning_rate': 0.0005832668878752973, 'gamma': 0.11278170529340237, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.00625101854366811, 'reg_lambda': 1.3300028567629388e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,670] Trial 110 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 129, 'max_depth': 28, 'learning_rate': 0.030718778846820574, 'gamma': 0.254130445603207, 'min_child_weight': 4, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 7.310282754964143, 'reg_lambda': 3.118461476958555e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,738] Trial 111 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 80, 'max_depth': 24, 'learning_rate': 0.10847087206193883, 'gamma': 0.16679063524768217, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.378176194774655, 'reg_lambda': 2.463542161001937e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,818] Trial 112 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 109, 'max_depth': 25, 'learning_rate': 0.1833675025514513, 'gamma': 0.14035712419894864, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.420567935739031, 'reg_lambda': 1.766907669057304e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,880] Trial 113 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 33, 'max_depth': 22, 'learning_rate': 0.06072637781778306, 'gamma': 0.17663329781864442, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.282599268431458, 'reg_lambda': 4.459065919670777e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:39,951] Trial 114 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 83, 'max_depth': 26, 'learning_rate': 0.12752596166811198, 'gamma': 0.20766379704534937, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.204906814350368, 'reg_lambda': 2.478536053057721e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:40,018] Trial 115 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 63, 'max_depth': 24, 'learning_rate': 0.08811272586685627, 'gamma': 0.13513430440200808, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.220872121624434, 'reg_lambda': 1.0510483189241247e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:40,187] Trial 116 finished with value: 0.805472173852318 and parameters: {'n_estimators': 50, 'max_depth': 27, 'learning_rate': 0.03612779567743822, 'gamma': 0.15487258677547805, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.177269076722249, 'reg_lambda': 5.405731273322107e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:40,878] Trial 117 finished with value: 0.7622616940165399 and parameters: {'n_estimators': 153, 'max_depth': 30, 'learning_rate': 0.4055546716056855, 'gamma': 0.28822173637788573, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.017408395688870305, 'reg_lambda': 1.9931785068516902e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:41,332] Trial 118 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 117, 'max_depth': 24, 'learning_rate': 0.206860804202528, 'gamma': 0.19126516517310946, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.866005058447266, 'reg_lambda': 7.884145868068057e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:41,603] Trial 119 finished with value: 0.8050772180423282 and parameters: {'n_estimators': 92, 'max_depth': 29, 'learning_rate': 0.0193502235844, 'gamma': 0.10302813824047444, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.099978777433732, 'reg_lambda': 3.269597223323664e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:41,854] Trial 120 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 180, 'max_depth': 18, 'learning_rate': 0.0565903859318323, 'gamma': 0.16920260843593787, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 9.899266999950475, 'reg_lambda': 4.348006114612523e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:41,946] Trial 121 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 87, 'max_depth': 24, 'learning_rate': 0.09470425209654235, 'gamma': 0.13049127150289858, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.186476258612436, 'reg_lambda': 2.5370067169319466e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:42,026] Trial 122 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 138, 'max_depth': 23, 'learning_rate': 0.11153457922864536, 'gamma': 0.23417586030317625, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.106949128859069, 'reg_lambda': 1.7231634636640598e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:42,098] Trial 123 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 28, 'max_depth': 26, 'learning_rate': 0.30499759434558255, 'gamma': 0.15338543086969203, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.729540348484454, 'reg_lambda': 1.3023527803573935e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:42,193] Trial 124 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 67, 'max_depth': 25, 'learning_rate': 7.371467719246157e-07, 'gamma': 0.18543830722614452, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4629744410985979, 'reg_lambda': 0.41769050383131795}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:43,331] Trial 125 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 110, 'max_depth': 21, 'learning_rate': 0.05078848140486982, 'gamma': 0.21137064423609828, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.7490274468362204, 'reg_lambda': 6.360584973768234e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,112] Trial 126 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 53, 'max_depth': 25, 'learning_rate': 0.08150779282521786, 'gamma': 0.16363601497579522, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 5.637105126531236, 'reg_lambda': 2.8918838218316466e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,203] Trial 127 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 98, 'max_depth': 32, 'learning_rate': 0.1653085565046016, 'gamma': 0.12131688028251551, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.086564600314082, 'reg_lambda': 9.902275206132858e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,253] Trial 128 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 11, 'max_depth': 31, 'learning_rate': 0.7796584211150713, 'gamma': 0.14115347186332805, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 2.1181832450196194, 'reg_lambda': 3.745576869826391e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,330] Trial 129 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 80, 'max_depth': 27, 'learning_rate': 0.0354933685256745, 'gamma': 0.22998476891932898, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.047538833159854, 'reg_lambda': 4.936234048172166e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,564] Trial 130 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 380, 'max_depth': 23, 'learning_rate': 0.014138688418313899, 'gamma': 0.1127875405861437, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 7.134139694867252, 'reg_lambda': 0.0001400901316035214}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,755] Trial 131 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 140, 'max_depth': 23, 'learning_rate': 0.14540934102529562, 'gamma': 0.15428696037802936, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 8.840026294711059, 'reg_lambda': 1.4024888707819637e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,866] Trial 132 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 138, 'max_depth': 24, 'learning_rate': 0.12005250094511853, 'gamma': 0.17177403553248194, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.838754788838432, 'reg_lambda': 1.8959624859498453e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:44,966] Trial 133 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 122, 'max_depth': 26, 'learning_rate': 0.0239861046802501, 'gamma': 0.19716830792708062, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.485577428588078, 'reg_lambda': 1.0395763848250232e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:45,240] Trial 134 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 951, 'max_depth': 22, 'learning_rate': 0.22488722000006137, 'gamma': 0.14651318588766538, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 9.97552053602887, 'reg_lambda': 2.6146675097098697e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:45,346] Trial 135 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 158, 'max_depth': 31, 'learning_rate': 0.06476967786670841, 'gamma': 0.38722732165472257, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.677775033486324, 'reg_lambda': 1.35868513678936e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:45,464] Trial 136 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 76, 'max_depth': 20, 'learning_rate': 0.04346867495582936, 'gamma': 0.1003839064106161, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.5807802121638246, 'reg_lambda': 2.1256989861309704e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:45,539] Trial 137 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 44, 'max_depth': 23, 'learning_rate': 0.5169156363381419, 'gamma': 0.25251684793175766, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.5521781289582437, 'reg_lambda': 7.472368170714932e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:45,609] Trial 138 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 100, 'max_depth': 29, 'learning_rate': 0.3303622394907873, 'gamma': 0.45266599194018, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 5.161534432955827, 'reg_lambda': 3.635187211205799e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:46,034] Trial 139 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 216, 'max_depth': 22, 'learning_rate': 0.17107587422820497, 'gamma': 0.5579129828260406, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.6943356462023745, 'reg_lambda': 0.0002372546050725996}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:47,016] Trial 140 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 189, 'max_depth': 25, 'learning_rate': 0.10063126213821626, 'gamma': 0.1286581461310605, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.1593953802799586, 'reg_lambda': 5.2952320788542076e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:47,358] Trial 141 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 88, 'max_depth': 25, 'learning_rate': 0.07816873284470321, 'gamma': 0.13840926924661714, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.314876549675698, 'reg_lambda': 2.6148094284269493e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:47,484] Trial 142 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 122, 'max_depth': 24, 'learning_rate': 0.02873473590053654, 'gamma': 0.17007476953154926, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.295270453432222, 'reg_lambda': 1.9339260217548876e-05}. Best is trial 53 with value: 0.8334547119166025.\n",
      "[I 2024-01-12 22:25:47,573] Trial 143 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 69, 'max_depth': 24, 'learning_rate': 0.10594123840211302, 'gamma': 0.1252300614979411, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.829560464277656, 'reg_lambda': 2.757360809038447e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:47,660] Trial 144 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 61, 'max_depth': 26, 'learning_rate': 0.04883388884120601, 'gamma': 0.21090778683026426, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.0048921467543974, 'reg_lambda': 1.5120223874386785e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:47,726] Trial 145 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 37, 'max_depth': 30, 'learning_rate': 0.22767325865117435, 'gamma': 0.18295767638723526, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 7.629819508581222, 'reg_lambda': 0.10129482879505469}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:48,123] Trial 146 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 106, 'max_depth': 23, 'learning_rate': 5.20458025838486e-05, 'gamma': 0.11772055809412747, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.5424268470153444, 'reg_lambda': 3.270799475031872e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:48,413] Trial 147 finished with value: 0.7663870252349325 and parameters: {'n_estimators': 58, 'max_depth': 24, 'learning_rate': 0.13490220899429403, 'gamma': 0.15889956568141356, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.0018504446567369928, 'reg_lambda': 4.5401591454550695e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:49,256] Trial 148 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 74, 'max_depth': 32, 'learning_rate': 0.0671393294574963, 'gamma': 0.15303850019007892, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.3692376092846357, 'reg_lambda': 9.435963456632238e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:49,572] Trial 149 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 163, 'max_depth': 28, 'learning_rate': 0.3748442897751884, 'gamma': 0.19015175169706047, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8447252414590587, 'reg_lambda': 7.079007235272531e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:49,956] Trial 150 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 131, 'max_depth': 27, 'learning_rate': 0.021415657337853458, 'gamma': 0.11625349674813008, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 2.5409919430258485, 'reg_lambda': 2.4100451075763875e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,142] Trial 151 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 92, 'max_depth': 24, 'learning_rate': 0.08330370695190588, 'gamma': 0.13559874362955465, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.9912184896037, 'reg_lambda': 2.5769019709909303e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,322] Trial 152 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 80, 'max_depth': 24, 'learning_rate': 0.10803032781125833, 'gamma': 0.12697090766597288, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.963417238574602, 'reg_lambda': 1.80556333321335e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,549] Trial 153 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 111, 'max_depth': 25, 'learning_rate': 0.18182691330417855, 'gamma': 0.10070865685250309, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.44045329325413, 'reg_lambda': 1.2645609769217234e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,614] Trial 154 finished with value: 0.8003283337405159 and parameters: {'n_estimators': 36, 'max_depth': 24, 'learning_rate': 0.03592884527553618, 'gamma': 0.16741123828878235, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.839856734691411, 'reg_lambda': 1.80650980905227e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,794] Trial 155 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 473, 'max_depth': 22, 'learning_rate': 0.054411425587833274, 'gamma': 0.1456686486810299, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.223799145820802, 'reg_lambda': 3.630218823328045e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,878] Trial 156 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 70, 'max_depth': 26, 'learning_rate': 0.00018156938450761623, 'gamma': 0.20785785223923423, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.396529512416759, 'reg_lambda': 1.684375049448998e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:50,941] Trial 157 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 20, 'max_depth': 21, 'learning_rate': 0.0937505891197755, 'gamma': 0.1293179519226889, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.0208262327818405, 'reg_lambda': 1.0056883011455647e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,034] Trial 158 finished with value: 0.824887818514042 and parameters: {'n_estimators': 52, 'max_depth': 30, 'learning_rate': 0.13285006961616816, 'gamma': 0.1772581415699053, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9420683977924882, 'reg_lambda': 5.1221844083553876e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,122] Trial 159 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 61, 'max_depth': 30, 'learning_rate': 0.12977555299417426, 'gamma': 0.269130374370215, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.8343238881303254, 'reg_lambda': 5.600142610927301e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,202] Trial 160 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 40, 'max_depth': 31, 'learning_rate': 0.28830710827896644, 'gamma': 0.2296420156623825, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0848289549909669, 'reg_lambda': 0.00011382483826138637}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,311] Trial 161 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 85, 'max_depth': 23, 'learning_rate': 0.17193692214066175, 'gamma': 0.1868373838106548, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.577900869708869, 'reg_lambda': 4.306267713793947e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,566] Trial 162 finished with value: 0.7834402964837748 and parameters: {'n_estimators': 103, 'max_depth': 29, 'learning_rate': 0.11065341733220954, 'gamma': 0.15761132062107241, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.06605409340576238, 'reg_lambda': 2.966718429289614e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,696] Trial 163 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 145, 'max_depth': 31, 'learning_rate': 0.059153749402975755, 'gamma': 0.12296281690574755, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.690138737152094, 'reg_lambda': 6.40566491464888e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,809] Trial 164 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 77, 'max_depth': 30, 'learning_rate': 0.2551324687397134, 'gamma': 0.1737756862177274, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.3366810922687784, 'reg_lambda': 2.3930633986231548e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:51,949] Trial 165 finished with value: 0.7964243679849838 and parameters: {'n_estimators': 48, 'max_depth': 25, 'learning_rate': 0.0401175517108351, 'gamma': 0.14751327713235882, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 7.389080309760936, 'reg_lambda': 3.584858986495542e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:52,030] Trial 166 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 112, 'max_depth': 32, 'learning_rate': 0.574685629312824, 'gamma': 0.19800320867068788, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3337425358974304, 'reg_lambda': 1.6268371977983525e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:53,372] Trial 167 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 325, 'max_depth': 24, 'learning_rate': 2.2253188823131714e-08, 'gamma': 0.11358790942214242, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9106254856478326, 'reg_lambda': 0.018309027003059135}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:53,633] Trial 168 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 699, 'max_depth': 26, 'learning_rate': 0.07559853903441886, 'gamma': 0.2129883222381102, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.3575607764578623, 'reg_lambda': 8.745037714300987e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:53,780] Trial 169 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 127, 'max_depth': 23, 'learning_rate': 0.028786301763320903, 'gamma': 0.17662242430713435, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.709306357334858, 'reg_lambda': 4.723367711783925e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:54,028] Trial 170 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 87, 'max_depth': 29, 'learning_rate': 0.994213568295888, 'gamma': 0.141183288286293, 'min_child_weight': 2, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_alpha': 4.139378161300839, 'reg_lambda': 0.0001896184357917537}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,001] Trial 171 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 90, 'max_depth': 24, 'learning_rate': 1.4114451013326165e-05, 'gamma': 0.12859121953273764, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 5.4833662113550865, 'reg_lambda': 2.2286334645981373e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,108] Trial 172 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 70, 'max_depth': 25, 'learning_rate': 0.10288794466860746, 'gamma': 0.10008252279195756, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.840867801435493, 'reg_lambda': 2.9582575871649854e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,198] Trial 173 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 54, 'max_depth': 24, 'learning_rate': 0.14922286742956758, 'gamma': 0.13034950432363185, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.831193660584893, 'reg_lambda': 1.2420180212851201e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,254] Trial 174 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 21, 'max_depth': 23, 'learning_rate': 0.09637623431997855, 'gamma': 0.1608918223620309, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.166387563794183, 'reg_lambda': 2.130130579059778e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,344] Trial 175 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 99, 'max_depth': 30, 'learning_rate': 0.051321835503333066, 'gamma': 0.14921710219267556, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.690975546589473, 'reg_lambda': 3.6754214503702216e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,423] Trial 176 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 121, 'max_depth': 31, 'learning_rate': 0.17660018678229455, 'gamma': 0.1824466665462595, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.2743557351977164, 'reg_lambda': 1.4605865015489854e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,488] Trial 177 finished with value: 0.7950711199781832 and parameters: {'n_estimators': 69, 'max_depth': 25, 'learning_rate': 0.018384007432629926, 'gamma': 0.12058626941503854, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.317663087212686, 'reg_lambda': 3.0012353517135453e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,565] Trial 178 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 139, 'max_depth': 22, 'learning_rate': 0.43054042997579756, 'gamma': 0.23866289843371777, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.195337116427908, 'reg_lambda': 6.684435961650388e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,636] Trial 179 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 90, 'max_depth': 24, 'learning_rate': 0.07131314665093699, 'gamma': 0.16243491968551851, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.658934416265028, 'reg_lambda': 0.00013528538680287282}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,698] Trial 180 finished with value: 0.824887818514042 and parameters: {'n_estimators': 49, 'max_depth': 27, 'learning_rate': 0.25517392174753145, 'gamma': 0.20064352511917075, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.9462344153718207, 'reg_lambda': 4.698502276670638e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,762] Trial 181 finished with value: 0.7979474829008179 and parameters: {'n_estimators': 50, 'max_depth': 27, 'learning_rate': 0.22659994115226878, 'gamma': 0.2007128371358668, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.148645446522759, 'reg_lambda': 5.21154142697422e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,825] Trial 182 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 26, 'max_depth': 28, 'learning_rate': 0.12330229618580915, 'gamma': 0.1376448275025704, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.5386705683006145, 'reg_lambda': 1.916236710653038e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:55,992] Trial 183 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 77, 'max_depth': 26, 'learning_rate': 0.35089133769483266, 'gamma': 0.22176452165185473, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.6976136788568166, 'reg_lambda': 4.1086098237964556e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,105] Trial 184 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 104, 'max_depth': 32, 'learning_rate': 0.03879702377930126, 'gamma': 0.18314431005951806, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.2135799813846024, 'reg_lambda': 2.4773390938699942e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,169] Trial 185 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 47, 'max_depth': 27, 'learning_rate': 0.0982542721386347, 'gamma': 0.11952892182146593, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.5684976796110357, 'reg_lambda': 7.901939126816131e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,225] Trial 186 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 11, 'max_depth': 25, 'learning_rate': 0.2297510340666609, 'gamma': 0.163762292411498, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.018034765494881, 'reg_lambda': 5.1049039610797036e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,390] Trial 187 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 66, 'max_depth': 25, 'learning_rate': 0.06471466663825343, 'gamma': 0.1955346904557446, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.310464718361457, 'reg_lambda': 2.8899810291878712e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,469] Trial 188 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 115, 'max_depth': 23, 'learning_rate': 0.14281168777497977, 'gamma': 0.13798830166853415, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.488985681171817, 'reg_lambda': 1.707841170201361e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,559] Trial 189 finished with value: 0.7254253358625067 and parameters: {'n_estimators': 87, 'max_depth': 26, 'learning_rate': 0.685357970693066, 'gamma': 0.2586052211876684, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.00020936913300581588, 'reg_lambda': 0.00011149672388535669}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,636] Trial 190 finished with value: 0.7945431727399606 and parameters: {'n_estimators': 34, 'max_depth': 31, 'learning_rate': 0.02676836987630164, 'gamma': 0.3127509667369639, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.758325999389745, 'reg_lambda': 1.4485757722914268}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,711] Trial 191 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 31, 'max_depth': 26, 'learning_rate': 0.4821402898529309, 'gamma': 0.15640648229141085, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.457213729179673, 'reg_lambda': 1.285819938505651e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,795] Trial 192 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 58, 'max_depth': 28, 'learning_rate': 0.34697392491000895, 'gamma': 0.1513896110426032, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.6334730384808096, 'reg_lambda': 1.2665782098985936e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:56,901] Trial 193 finished with value: 0.7889673710297429 and parameters: {'n_estimators': 78, 'max_depth': 25, 'learning_rate': 0.2342873263035111, 'gamma': 0.17217177033847547, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3930878598541507, 'reg_lambda': 2.161230246520574e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,040] Trial 194 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 51, 'max_depth': 27, 'learning_rate': 0.3118462753610861, 'gamma': 0.1005047111691636, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.732320660930368, 'reg_lambda': 1.5678767818420194e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,155] Trial 195 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 101, 'max_depth': 15, 'learning_rate': 0.15975623189779745, 'gamma': 0.13155936446849978, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8751088489794057, 'reg_lambda': 1.0081261791136043e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,219] Trial 196 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 31, 'max_depth': 24, 'learning_rate': 0.08858983832263127, 'gamma': 0.713078846098089, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.44686677584468, 'reg_lambda': 3.656266243688494e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,282] Trial 197 finished with value: 0.7554429429429429 and parameters: {'n_estimators': 10, 'max_depth': 26, 'learning_rate': 0.04710913635353302, 'gamma': 0.21810473443180584, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.008835014089779, 'reg_lambda': 2.5773200900428084e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,379] Trial 198 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 71, 'max_depth': 30, 'learning_rate': 0.0715326018977643, 'gamma': 0.14935734161365777, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.177467719812252, 'reg_lambda': 6.266417718276078e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,583] Trial 199 finished with value: 0.7477477477477478 and parameters: {'n_estimators': 124, 'max_depth': 24, 'learning_rate': 0.19218413111921215, 'gamma': 0.11612337277710397, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.6126509369711426e-05, 'reg_lambda': 1.6749258510290992e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,669] Trial 200 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 92, 'max_depth': 32, 'learning_rate': 0.11022819809201427, 'gamma': 0.1871109760910925, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.6225622794500043, 'reg_lambda': 4.275462562556323e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,732] Trial 201 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 30, 'max_depth': 28, 'learning_rate': 0.13016393598867604, 'gamma': 0.13242854160820539, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.9204779737299688, 'reg_lambda': 2.2640261130894957e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,813] Trial 202 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 52, 'max_depth': 28, 'learning_rate': 0.12570079277003143, 'gamma': 0.13787610497112515, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.527865363796478, 'reg_lambda': 1.932344458426021e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,906] Trial 203 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 64, 'max_depth': 29, 'learning_rate': 0.28503128530857486, 'gamma': 0.16459087307895962, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.3067652912046133, 'reg_lambda': 2.9967126645899933e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:57,969] Trial 204 finished with value: 0.8094043185704923 and parameters: {'n_estimators': 28, 'max_depth': 27, 'learning_rate': 0.04720438974624036, 'gamma': 0.11440779872975704, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.6635339513271108, 'reg_lambda': 1.3593778035524872e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,057] Trial 205 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 85, 'max_depth': 26, 'learning_rate': 0.07797610004183864, 'gamma': 0.13822749644208038, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.191367037523279, 'reg_lambda': 4.574474011267523}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,217] Trial 206 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 42, 'max_depth': 31, 'learning_rate': 0.17555139510309248, 'gamma': 0.17510695878241675, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.927808659605422, 'reg_lambda': 1.7976523579972498e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,309] Trial 207 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 112, 'max_depth': 25, 'learning_rate': 0.10835298198020592, 'gamma': 0.2012655444447267, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.596461306908494, 'reg_lambda': 3.215950492727347e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,397] Trial 208 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 146, 'max_depth': 28, 'learning_rate': 0.03182630227442257, 'gamma': 0.15420267762638712, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.9703732996168855, 'reg_lambda': 2.1301269948408673e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,546] Trial 209 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 71, 'max_depth': 29, 'learning_rate': 0.06397095972702384, 'gamma': 0.11649442216260902, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.11894576197188, 'reg_lambda': 8.425073507101567e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,624] Trial 210 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 98, 'max_depth': 27, 'learning_rate': 0.2655697210997492, 'gamma': 0.14773696227144575, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 3.555927755152227, 'reg_lambda': 5.3205261022449806e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,700] Trial 211 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 53, 'max_depth': 28, 'learning_rate': 0.08868847921946407, 'gamma': 0.28109297704854064, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.588056242473176, 'reg_lambda': 6.282110265253475e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,782] Trial 212 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 76, 'max_depth': 27, 'learning_rate': 0.055749989746614395, 'gamma': 0.22936010384025596, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.66006179479466, 'reg_lambda': 3.900672419256531e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:58,843] Trial 213 finished with value: 0.804179070201375 and parameters: {'n_estimators': 27, 'max_depth': 30, 'learning_rate': 0.04034471683908221, 'gamma': 0.18352183980164585, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.0741667798163674, 'reg_lambda': 9.044484297140533e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:59,102] Trial 214 finished with value: 0.7845881595881596 and parameters: {'n_estimators': 769, 'max_depth': 26, 'learning_rate': 0.13744617068488632, 'gamma': 0.2595487239908565, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.8551028877057891, 'reg_lambda': 2.857572104477683e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:59,180] Trial 215 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 84, 'max_depth': 23, 'learning_rate': 0.08265316470375658, 'gamma': 0.21193847114895392, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.258449586243717, 'reg_lambda': 1.307501993588224e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:25:59,746] Trial 216 finished with value: 0.816089234993927 and parameters: {'n_estimators': 110, 'max_depth': 23, 'learning_rate': 0.19292757575122657, 'gamma': 0.2120987667524614, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 9.666306628873008, 'reg_lambda': 1.1443432657716691e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:00,046] Trial 217 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 57, 'max_depth': 24, 'learning_rate': 0.0966939279992125, 'gamma': 0.17112843225748034, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.226451485558509, 'reg_lambda': 1.5732342508307406e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:00,460] Trial 218 finished with value: 0.805472173852318 and parameters: {'n_estimators': 87, 'max_depth': 22, 'learning_rate': 0.02055885820601684, 'gamma': 0.24329947922811757, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.303646425702158, 'reg_lambda': 1.9626621384596225e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:00,689] Trial 219 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 129, 'max_depth': 23, 'learning_rate': 0.06575006844816418, 'gamma': 0.1961381413164788, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 4.231956782299801, 'reg_lambda': 1.2021773534377266e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:00,763] Trial 220 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 39, 'max_depth': 25, 'learning_rate': 0.43298650327721894, 'gamma': 0.13055276911007704, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.351481204660379, 'reg_lambda': 1.0149812261404417e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:01,541] Trial 221 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 60, 'max_depth': 24, 'learning_rate': 0.1072595605658241, 'gamma': 0.16780386570648273, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.311255941219636, 'reg_lambda': 1.43635731775221e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:01,625] Trial 222 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 80, 'max_depth': 24, 'learning_rate': 0.1373275201555404, 'gamma': 0.16947745799524325, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.847464278765483, 'reg_lambda': 1.5889955241117885e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:01,696] Trial 223 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 54, 'max_depth': 24, 'learning_rate': 0.08808050086680416, 'gamma': 0.15002813999875186, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.927524145084078, 'reg_lambda': 2.2747028791967916e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:01,981] Trial 224 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 97, 'max_depth': 25, 'learning_rate': 0.05014151927381181, 'gamma': 0.10133364723750268, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.647289220629847, 'reg_lambda': 1.6811286518245855e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,065] Trial 225 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 63, 'max_depth': 23, 'learning_rate': 0.028723128863462722, 'gamma': 0.1839054095064079, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 3.719754589487031, 'reg_lambda': 2.6917318233517815e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,162] Trial 226 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 109, 'max_depth': 24, 'learning_rate': 0.2054211734904023, 'gamma': 0.20618700776985935, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.731475113800416, 'reg_lambda': 1.89166862130847e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,239] Trial 227 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 20, 'max_depth': 25, 'learning_rate': 0.08620801222625066, 'gamma': 0.1291276306433608, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.107136948611652, 'reg_lambda': 3.7907435036480074e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,342] Trial 228 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 78, 'max_depth': 23, 'learning_rate': 0.1368966358339791, 'gamma': 0.1500741618591236, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.3521318052665987, 'reg_lambda': 1.3720320992244198e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,406] Trial 229 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 44, 'max_depth': 26, 'learning_rate': 3.0076386139019707e-06, 'gamma': 0.16784184326927773, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4294791670227502, 'reg_lambda': 2.4614404681648528e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,663] Trial 230 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 93, 'max_depth': 30, 'learning_rate': 0.037851082875789435, 'gamma': 0.22280297105747626, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.979560237885239, 'reg_lambda': 4.25175437104335e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:02,913] Trial 231 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 58, 'max_depth': 24, 'learning_rate': 0.10989213685942245, 'gamma': 0.17600139363639244, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.02576546702317505, 'reg_lambda': 1.2965738848294571e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,003] Trial 232 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 69, 'max_depth': 24, 'learning_rate': 0.06739971973514694, 'gamma': 0.19918848065216596, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.424504308424082, 'reg_lambda': 1.4959157045066416e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,063] Trial 233 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 37, 'max_depth': 23, 'learning_rate': 0.10490173651980533, 'gamma': 0.15660901181389003, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.8175454633152235, 'reg_lambda': 1.929700994598688e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,345] Trial 234 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 61, 'max_depth': 25, 'learning_rate': 0.16578970777727828, 'gamma': 0.1287846262240519, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.7218466057162023, 'reg_lambda': 1.5436811990239e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,485] Trial 235 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 92, 'max_depth': 22, 'learning_rate': 0.28270969667699264, 'gamma': 0.16612036293259014, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.523427296758178, 'reg_lambda': 3.0263283977490504e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,594] Trial 236 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 122, 'max_depth': 31, 'learning_rate': 0.05742451900051159, 'gamma': 0.18904668626954413, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.999183760159017, 'reg_lambda': 1.0155192154554748e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,780] Trial 237 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 75, 'max_depth': 24, 'learning_rate': 0.09620231158691483, 'gamma': 0.14139665729835663, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.0992864425728275, 'reg_lambda': 2.277223886183515e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:03,886] Trial 238 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 106, 'max_depth': 24, 'learning_rate': 0.0753449279237365, 'gamma': 0.1182688104351767, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.1415427788638235, 'reg_lambda': 2.0881287729915447e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:04,032] Trial 239 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 78, 'max_depth': 25, 'learning_rate': 0.18836574591452865, 'gamma': 0.14185005050074048, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.2020064055906885, 'reg_lambda': 3.2782322268292576e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:04,448] Trial 240 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 138, 'max_depth': 26, 'learning_rate': 0.6093374754913696, 'gamma': 0.10118014452308814, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.1251544018998514, 'reg_lambda': 5.238199913869822e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:04,543] Trial 241 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 49, 'max_depth': 24, 'learning_rate': 0.11279309655272636, 'gamma': 0.14221170512283035, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.4556357645785944e-05, 'reg_lambda': 2.4330135213914764e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:04,620] Trial 242 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 75, 'max_depth': 23, 'learning_rate': 0.09067210898781372, 'gamma': 0.1651576922770847, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.129278296848472, 'reg_lambda': 1.4532193760099297e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,160] Trial 243 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 25, 'max_depth': 24, 'learning_rate': 0.1336820063901363, 'gamma': 0.12736971902206665, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.871726945045375, 'reg_lambda': 1.9515494987127186e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,244] Trial 244 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 52, 'max_depth': 23, 'learning_rate': 0.0476559619966366, 'gamma': 0.18113025021561788, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 4.207625087783581, 'reg_lambda': 1.3634089520954824e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,315] Trial 245 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 88, 'max_depth': 32, 'learning_rate': 0.24259772597900572, 'gamma': 0.15339022662797824, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.958969633785049, 'reg_lambda': 2.5675024543434156e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,397] Trial 246 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 67, 'max_depth': 25, 'learning_rate': 0.08344362207329606, 'gamma': 0.13958387342168502, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8316898402776953, 'reg_lambda': 0.006477432393137868}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,498] Trial 247 finished with value: 0.7799872591586683 and parameters: {'n_estimators': 110, 'max_depth': 31, 'learning_rate': 0.1323775278531391, 'gamma': 0.11957735350966572, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.00040046309980347884, 'reg_lambda': 1.6842531705907387e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,562] Trial 248 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 34, 'max_depth': 24, 'learning_rate': 0.05750151247824297, 'gamma': 0.20937930642026253, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 5.470323091839219, 'reg_lambda': 3.3230261368927984e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,641] Trial 249 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 98, 'max_depth': 24, 'learning_rate': 0.371049743759825, 'gamma': 0.16367306612549679, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5931200271834522, 'reg_lambda': 4.70234091497228e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,740] Trial 250 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 62, 'max_depth': 25, 'learning_rate': 0.032957984969186206, 'gamma': 0.19017909945703054, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.528059785416336, 'reg_lambda': 7.100473966534723e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,859] Trial 251 finished with value: 0.7794400238895547 and parameters: {'n_estimators': 80, 'max_depth': 22, 'learning_rate': 0.1749088696359245, 'gamma': 0.11303487600799482, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.100675410248488, 'reg_lambda': 2.2571638132935427e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:05,958] Trial 252 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 14, 'max_depth': 27, 'learning_rate': 0.09956322730293514, 'gamma': 0.23873982214232625, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.767433925692279, 'reg_lambda': 0.00014784799656560022}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:06,031] Trial 253 finished with value: 0.7820159307398136 and parameters: {'n_estimators': 51, 'max_depth': 26, 'learning_rate': 0.01185997427274411, 'gamma': 0.14293633628787292, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.637457033699746, 'reg_lambda': 1.3036371439862809e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:06,518] Trial 254 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 116, 'max_depth': 23, 'learning_rate': 0.07302828918360567, 'gamma': 0.4900079527534098, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.749276384523768, 'reg_lambda': 3.623866413428224e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:06,774] Trial 255 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 157, 'max_depth': 23, 'learning_rate': 0.0606642931918993, 'gamma': 0.4810758058383046, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.2604250916386395, 'reg_lambda': 4.051686983027597e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:06,898] Trial 256 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 125, 'max_depth': 18, 'learning_rate': 0.04973051323925805, 'gamma': 0.39395817397379324, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 2.706441894915427, 'reg_lambda': 5.6256759499322976e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:07,198] Trial 257 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 107, 'max_depth': 31, 'learning_rate': 0.06891438188904152, 'gamma': 0.3566581854301808, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.164096852783558, 'reg_lambda': 3.207925981110962e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:07,377] Trial 258 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 134, 'max_depth': 22, 'learning_rate': 6.010206366680372e-08, 'gamma': 0.13066053603655753, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.14286651417125992, 'reg_lambda': 0.0001006020433581077}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:07,867] Trial 259 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 91, 'max_depth': 30, 'learning_rate': 0.023366793157400693, 'gamma': 0.6372842032631021, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.43976546988767, 'reg_lambda': 2.6173727079385233e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:07,933] Trial 260 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 82, 'max_depth': 32, 'learning_rate': 0.2348364722688367, 'gamma': 0.41682944838224073, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 4.63948690982828, 'reg_lambda': 4.4428039093122066e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,030] Trial 261 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 112, 'max_depth': 29, 'learning_rate': 0.036818873315395864, 'gamma': 0.22303495254392083, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.3477520455884322, 'reg_lambda': 7.08806219694591e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,275] Trial 262 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 632, 'max_depth': 21, 'learning_rate': 0.14767193180014157, 'gamma': 0.5268410496129753, 'min_child_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 5.7357910184701035, 'reg_lambda': 3.072252491125633e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,374] Trial 263 finished with value: 0.8071179781643625 and parameters: {'n_estimators': 44, 'max_depth': 23, 'learning_rate': 0.07977744483035328, 'gamma': 0.33576126887575475, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.7188884222970937, 'reg_lambda': 0.03627914287562525}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,444] Trial 264 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.3292824934228272, 'gamma': 0.10019827308821283, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.802916314230947, 'reg_lambda': 2.023990150874136e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,674] Trial 265 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 92, 'max_depth': 27, 'learning_rate': 0.03771675625157731, 'gamma': 0.5800351874992121, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.656468959278331, 'reg_lambda': 4.050083655542272e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,777] Trial 266 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 71, 'max_depth': 26, 'learning_rate': 0.1850280353455664, 'gamma': 0.1852585199993876, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8742571368463605, 'reg_lambda': 1.7947625575099415e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,840] Trial 267 finished with value: 0.7178172489996356 and parameters: {'n_estimators': 12, 'max_depth': 25, 'learning_rate': 0.016851425043262935, 'gamma': 0.15292575013078108, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 3.6549644386950835, 'reg_lambda': 0.0015845828112789873}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:08,943] Trial 268 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 104, 'max_depth': 23, 'learning_rate': 0.1147419995266913, 'gamma': 0.12714131863075773, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.9230744140474725, 'reg_lambda': 5.991620922932798e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:09,120] Trial 269 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 154, 'max_depth': 23, 'learning_rate': 0.00029180433463046895, 'gamma': 0.11881289091519054, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.311941036521904, 'reg_lambda': 5.881417761255183e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:09,360] Trial 270 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 114, 'max_depth': 22, 'learning_rate': 0.13287136749243697, 'gamma': 0.8510336885556333, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.564807554551126, 'reg_lambda': 8.333991645196824e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:09,602] Trial 271 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 288, 'max_depth': 21, 'learning_rate': 4.896539767473602e-07, 'gamma': 0.7585444905562488, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 4.6818771031443775, 'reg_lambda': 9.938248619783512e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:10,037] Trial 272 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 394, 'max_depth': 22, 'learning_rate': 0.4857545947766167, 'gamma': 0.6919241899795916, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.5817884079001776, 'reg_lambda': 9.097093824674441e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:10,112] Trial 273 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 140, 'max_depth': 22, 'learning_rate': 0.26104897553383655, 'gamma': 0.4655472048825071, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.769012400816371, 'reg_lambda': 0.00011742613667848779}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:10,186] Trial 274 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 116, 'max_depth': 20, 'learning_rate': 0.14659197980986025, 'gamma': 0.8168319179777568, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.90012668024588, 'reg_lambda': 7.687116078750842e-05}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:10,315] Trial 275 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 169, 'max_depth': 23, 'learning_rate': 0.00012504806336101503, 'gamma': 0.9412738162538472, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.9774252389540963, 'reg_lambda': 0.0001567146317798529}. Best is trial 143 with value: 0.8378378378378378.\n",
      "[I 2024-01-12 22:26:10,474] Trial 276 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 107, 'max_depth': 22, 'learning_rate': 0.04963444215962691, 'gamma': 0.11951205436369702, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.581513052600669, 'reg_lambda': 6.052341340880203e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:10,581] Trial 277 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 108, 'max_depth': 22, 'learning_rate': 0.043657733546927764, 'gamma': 0.11202131755811169, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.860853826156009, 'reg_lambda': 5.5562720391803306e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:10,687] Trial 278 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 133, 'max_depth': 21, 'learning_rate': 0.027040691976877248, 'gamma': 0.5107271635461339, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.345471419405051, 'reg_lambda': 6.269100926034303e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:11,171] Trial 279 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 108, 'max_depth': 21, 'learning_rate': 0.052444129914148756, 'gamma': 0.11713297346954943, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.482343487454376, 'reg_lambda': 5.542457508441657e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:11,447] Trial 280 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 126, 'max_depth': 22, 'learning_rate': 0.03694038897510466, 'gamma': 0.11353269034928642, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 5.281258146423272, 'reg_lambda': 8.054337312770545e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:11,746] Trial 281 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 154, 'max_depth': 22, 'learning_rate': 0.02473642439461297, 'gamma': 0.2978121552365694, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 4.417650141795881, 'reg_lambda': 5.507763163649893e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:11,857] Trial 282 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 104, 'max_depth': 22, 'learning_rate': 0.04920182459347834, 'gamma': 0.10762786872697659, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.244005069204137, 'reg_lambda': 0.00012740475826914538}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:12,015] Trial 283 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 99, 'max_depth': 23, 'learning_rate': 0.06644785644461626, 'gamma': 0.13009758853441253, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.894903596148437, 'reg_lambda': 4.564943338553301e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:12,131] Trial 284 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 124, 'max_depth': 22, 'learning_rate': 0.07855195697113461, 'gamma': 0.2476969395290976, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.20858223182974, 'reg_lambda': 7.914420812750576e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:13,617] Trial 285 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 183, 'max_depth': 30, 'learning_rate': 0.03866739985904048, 'gamma': 0.10024983395671354, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.752511308917925, 'reg_lambda': 6.962170582648775e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:13,878] Trial 286 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 190, 'max_depth': 30, 'learning_rate': 0.019580126327408527, 'gamma': 0.6291691879557666, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.67340363798339, 'reg_lambda': 7.149202113152956e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:14,636] Trial 287 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 898, 'max_depth': 31, 'learning_rate': 0.03278315070688242, 'gamma': 0.10540857306603876, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.4446270488683437, 'reg_lambda': 5.29930281660421e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:14,774] Trial 288 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 245, 'max_depth': 30, 'learning_rate': 0.044163135344444854, 'gamma': 0.12311456848398826, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.191919838429005, 'reg_lambda': 0.00010812605395917965}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:14,944] Trial 289 finished with value: 0.7960110421373203 and parameters: {'n_estimators': 94, 'max_depth': 20, 'learning_rate': 0.01531402437010744, 'gamma': 0.10114631080763534, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 4.224661386678406, 'reg_lambda': 4.418303589411315e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:15,056] Trial 290 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 83, 'max_depth': 32, 'learning_rate': 0.029975882164627654, 'gamma': 0.5547147763066594, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.8016782043245128, 'reg_lambda': 6.531167236503675e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:16,044] Trial 291 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 588, 'max_depth': 31, 'learning_rate': 0.04523728068799383, 'gamma': 0.2100578447980202, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.928892692315008, 'reg_lambda': 3.681372170649426e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:16,162] Trial 292 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 114, 'max_depth': 29, 'learning_rate': 0.0629433520153077, 'gamma': 0.12616293969807807, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.442850928019009, 'reg_lambda': 8.069906121573317e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:16,451] Trial 293 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 223, 'max_depth': 7, 'learning_rate': 0.023631404939124846, 'gamma': 0.2741852024492685, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.4236419354472645, 'reg_lambda': 0.00011821945903887805}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:16,598] Trial 294 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 80, 'max_depth': 30, 'learning_rate': 0.08430874009107715, 'gamma': 0.13422478517423292, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 2.2838056108424944, 'reg_lambda': 0.0001738335823129174}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:17,190] Trial 295 finished with value: 0.779732673850321 and parameters: {'n_estimators': 172, 'max_depth': 21, 'learning_rate': 0.04245397521975322, 'gamma': 0.37163316901412957, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.2516480455773978, 'reg_lambda': 5.07486845729861e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:17,316] Trial 296 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 142, 'max_depth': 30, 'learning_rate': 0.10695943047305052, 'gamma': 0.10150156622421769, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.618255752495221, 'reg_lambda': 6.319250608782703e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:17,407] Trial 297 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 108, 'max_depth': 23, 'learning_rate': 0.06227342057836963, 'gamma': 0.8933172041563121, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.9663078736087356, 'reg_lambda': 3.716380889361077e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:17,918] Trial 298 finished with value: 0.7881248043410206 and parameters: {'n_estimators': 355, 'max_depth': 31, 'learning_rate': 0.031177784670368577, 'gamma': 0.22956343931430273, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8047835458623582, 'reg_lambda': 4.65045261584215e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:18,044] Trial 299 finished with value: 0.7905128094097212 and parameters: {'n_estimators': 71, 'max_depth': 23, 'learning_rate': 0.008609489451066507, 'gamma': 0.14564675068321226, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.074609087606622, 'reg_lambda': 9.541671868581326e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:18,434] Trial 300 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 527, 'max_depth': 22, 'learning_rate': 0.11565045692134766, 'gamma': 0.20112882852512087, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9914900600897463, 'reg_lambda': 3.746446026191774e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:18,947] Trial 301 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 94, 'max_depth': 29, 'learning_rate': 0.0661379166429991, 'gamma': 0.8633211188324403, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 7.789872572013734, 'reg_lambda': 0.0002994354777078687}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,039] Trial 302 finished with value: 0.828254477109439 and parameters: {'n_estimators': 72, 'max_depth': 31, 'learning_rate': 0.0430499718575094, 'gamma': 0.11873949936625287, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 4.039388858074064, 'reg_lambda': 6.898913839794065e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,118] Trial 303 finished with value: 0.7998688987494958 and parameters: {'n_estimators': 69, 'max_depth': 31, 'learning_rate': 0.016849401721526155, 'gamma': 0.4283539944277974, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 2.280490831224826, 'reg_lambda': 8.970694780981032e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,327] Trial 304 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 120, 'max_depth': 32, 'learning_rate': 0.04016508312529439, 'gamma': 0.11708702574884025, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 3.8516903599267316, 'reg_lambda': 6.811840729718418e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,411] Trial 305 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 75, 'max_depth': 31, 'learning_rate': 0.023447478080921864, 'gamma': 0.11434183746401744, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 3.2180742052963627, 'reg_lambda': 6.475310231198352e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,540] Trial 306 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 98, 'max_depth': 30, 'learning_rate': 0.0007861069839141504, 'gamma': 0.1341086809559631, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.4057843034656956, 'reg_lambda': 0.00014161324258076476}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,605] Trial 307 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 60, 'max_depth': 31, 'learning_rate': 0.04781267910928195, 'gamma': 0.6148493001151993, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 9.905273437211394, 'reg_lambda': 9.955605941861438e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:19,701] Trial 308 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 149, 'max_depth': 32, 'learning_rate': 0.07511259227831722, 'gamma': 0.10001622030931227, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 5.858794731777059, 'reg_lambda': 5.694969138991264e-05}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:20,015] Trial 309 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 83, 'max_depth': 30, 'learning_rate': 0.029977559671529534, 'gamma': 0.6557559131730436, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.0019742407169324803, 'reg_lambda': 0.0002224547559517225}. Best is trial 276 with value: 0.8380669565842438.\n",
      "[I 2024-01-12 22:26:20,097] Trial 310 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 48, 'max_depth': 29, 'learning_rate': 0.05220611854071714, 'gamma': 0.1393553266412396, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4658604415521124, 'reg_lambda': 4.7222474299987214e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,176] Trial 311 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 51, 'max_depth': 29, 'learning_rate': 0.05126103819271096, 'gamma': 0.14489096345569544, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.297984829749894, 'reg_lambda': 4.429635779239603e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,483] Trial 312 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 272, 'max_depth': 16, 'learning_rate': 0.0359121720976871, 'gamma': 0.1257673806286267, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.643190604230721, 'reg_lambda': 0.20648914034929672}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,565] Trial 313 finished with value: 0.789688397434177 and parameters: {'n_estimators': 42, 'max_depth': 29, 'learning_rate': 0.013463276516831187, 'gamma': 0.14789108581197002, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.7918713249129432, 'reg_lambda': 2.9346926655205544e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,645] Trial 314 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 120, 'max_depth': 21, 'learning_rate': 0.718992115683818, 'gamma': 0.1364788284390746, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.631000543203338, 'reg_lambda': 0.00246656827028982}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,725] Trial 315 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 104, 'max_depth': 30, 'learning_rate': 0.09314746968674517, 'gamma': 0.15957607523202696, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.5609383784847175, 'reg_lambda': 3.5815033034152665e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,805] Trial 316 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 62, 'max_depth': 13, 'learning_rate': 0.002091927056418605, 'gamma': 0.11927671284908337, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 4.415705295072879, 'reg_lambda': 4.9592550931369416e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,892] Trial 317 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 85, 'max_depth': 31, 'learning_rate': 0.17753173539497133, 'gamma': 0.1773715436631015, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.3279676974274044, 'reg_lambda': 7.318548656818137e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:20,990] Trial 318 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 131, 'max_depth': 24, 'learning_rate': 0.055486409684224185, 'gamma': 0.11672609177873079, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.655082333854171, 'reg_lambda': 3.252121376237246e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:21,071] Trial 319 finished with value: 0.8160427508253596 and parameters: {'n_estimators': 40, 'max_depth': 23, 'learning_rate': 0.021362289548407867, 'gamma': 0.12799779946982073, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.1038730383357747, 'reg_lambda': 5.441845037596252e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:21,153] Trial 320 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 69, 'max_depth': 25, 'learning_rate': 0.03873607124581109, 'gamma': 0.15546933463392215, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.275234588631951, 'reg_lambda': 3.615214370261556e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:21,641] Trial 321 finished with value: 0.8011367629688241 and parameters: {'n_estimators': 207, 'max_depth': 22, 'learning_rate': 0.005622552525649839, 'gamma': 0.10058953131260093, 'min_child_weight': 3, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.00013129111725292678, 'reg_lambda': 4.967817478822577e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:21,747] Trial 322 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 97, 'max_depth': 28, 'learning_rate': 0.10923294845847789, 'gamma': 0.19410970648357856, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1511953556641032, 'reg_lambda': 7.529846571156807e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:22,447] Trial 323 finished with value: 0.7707421707421708 and parameters: {'n_estimators': 179, 'max_depth': 23, 'learning_rate': 0.07012258516344104, 'gamma': 0.13802951404220198, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.01283718638174737, 'reg_lambda': 2.780344952747285e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:22,676] Trial 324 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 113, 'max_depth': 32, 'learning_rate': 1.861536122133913e-05, 'gamma': 0.17440528793283955, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 1.9879096303107304, 'reg_lambda': 4.3030248875876606e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:22,767] Trial 325 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 83, 'max_depth': 24, 'learning_rate': 0.026421358803524378, 'gamma': 0.1002505147009296, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.260342607807255, 'reg_lambda': 6.755306388748434e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:22,859] Trial 326 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 147, 'max_depth': 31, 'learning_rate': 0.14774005674244517, 'gamma': 0.1580445783961545, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.017043165616212, 'reg_lambda': 2.644758236897414e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:22,929] Trial 327 finished with value: 0.7712329508461043 and parameters: {'n_estimators': 49, 'max_depth': 25, 'learning_rate': 0.23059081006167034, 'gamma': 0.12094235461176858, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.007623359725326263, 'reg_lambda': 3.5178518869346985e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,004] Trial 328 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 65, 'max_depth': 24, 'learning_rate': 0.05565723354633167, 'gamma': 0.13625723231201134, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.947000583125792, 'reg_lambda': 8.915990945186818e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,112] Trial 329 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 100, 'max_depth': 30, 'learning_rate': 0.38164589800838705, 'gamma': 0.17543904915330466, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.800258785587768, 'reg_lambda': 5.325990720497921e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,191] Trial 330 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 124, 'max_depth': 28, 'learning_rate': 0.12315657849502219, 'gamma': 0.7921237390728566, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 3.495325486491404, 'reg_lambda': 0.8728491298287897}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,310] Trial 331 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 301, 'max_depth': 22, 'learning_rate': 0.07653584697518265, 'gamma': 0.21110258685305572, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.537851814809982, 'reg_lambda': 0.00012579638392850432}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,479] Trial 332 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 82, 'max_depth': 23, 'learning_rate': 0.0468842846653955, 'gamma': 0.1165611193404664, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.960624118806932, 'reg_lambda': 4.1270226155882944e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,551] Trial 333 finished with value: 0.7933675472137011 and parameters: {'n_estimators': 35, 'max_depth': 29, 'learning_rate': 0.030685909762492296, 'gamma': 0.1454524958466164, 'min_child_weight': 6, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 7.269271862466841, 'reg_lambda': 2.305979347044273e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,626] Trial 334 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 64, 'max_depth': 32, 'learning_rate': 0.1851053781068839, 'gamma': 0.18902395504489194, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.6928098354084478, 'reg_lambda': 6.226451291604445e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,807] Trial 335 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 164, 'max_depth': 25, 'learning_rate': 0.08428115192673832, 'gamma': 0.15348934800564698, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.9433271951835667, 'reg_lambda': 0.0006013508881610395}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:23,948] Trial 336 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 464, 'max_depth': 20, 'learning_rate': 0.11753950962127593, 'gamma': 0.12492856944581628, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.644550430880433, 'reg_lambda': 3.0449937491940028e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,098] Trial 337 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 101, 'max_depth': 22, 'learning_rate': 0.040616597638471086, 'gamma': 0.9558182974212324, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.04252954750132727, 'reg_lambda': 8.72418901468524e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,298] Trial 338 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 130, 'max_depth': 24, 'learning_rate': 0.01883536139991074, 'gamma': 0.10029787991438335, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.955370485553555, 'reg_lambda': 4.247563446536973e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,390] Trial 339 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 48, 'max_depth': 31, 'learning_rate': 0.05368028451296108, 'gamma': 0.16193671876676968, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 7.516356947197842, 'reg_lambda': 5.6093807352555706e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,482] Trial 340 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 80, 'max_depth': 27, 'learning_rate': 0.0012530246381138733, 'gamma': 0.13650754842407492, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.8310698582608601, 'reg_lambda': 2.5137444848904007e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,579] Trial 341 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 108, 'max_depth': 21, 'learning_rate': 0.07987206675321626, 'gamma': 0.11683459518829953, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.2757349451186277, 'reg_lambda': 3.2775939779033114e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,668] Trial 342 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 90, 'max_depth': 30, 'learning_rate': 6.063464293409753e-06, 'gamma': 0.19671372794824882, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.027433939794397, 'reg_lambda': 7.820622456201477e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,739] Trial 343 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 59, 'max_depth': 23, 'learning_rate': 0.2886567368125622, 'gamma': 0.31740478315707843, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3276210456568454, 'reg_lambda': 4.6218282307703395e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:24,939] Trial 344 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 139, 'max_depth': 26, 'learning_rate': 0.15366844145318526, 'gamma': 0.22058583898603148, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.5449590844073395, 'reg_lambda': 0.00012361685950085}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,010] Trial 345 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 77, 'max_depth': 29, 'learning_rate': 0.5087881540491789, 'gamma': 0.17226724840918545, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.13705254749108, 'reg_lambda': 2.2584982726151736e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,075] Trial 346 finished with value: 0.7988362849853958 and parameters: {'n_estimators': 29, 'max_depth': 24, 'learning_rate': 0.029825166251232153, 'gamma': 0.13684077629645083, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.0727054267797986, 'reg_lambda': 5.990443431526225e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,218] Trial 347 finished with value: 0.7843572540630146 and parameters: {'n_estimators': 116, 'max_depth': 22, 'learning_rate': 0.06225006009702539, 'gamma': 0.11828036245904468, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.082240494251462, 'reg_lambda': 3.694435914766902e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,304] Trial 348 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 96, 'max_depth': 25, 'learning_rate': 0.10072985448661143, 'gamma': 0.1487590649985492, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 6.049277420959878, 'reg_lambda': 9.820849926191303e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,378] Trial 349 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 50, 'max_depth': 32, 'learning_rate': 0.03977275565164391, 'gamma': 0.18063528911733207, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5653169230421335, 'reg_lambda': 2.79992819625802e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,471] Trial 350 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 68, 'max_depth': 32, 'learning_rate': 0.038632684407534354, 'gamma': 0.16632921068832546, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.0456069759600983, 'reg_lambda': 2.038092465151899e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:25,628] Trial 351 finished with value: 0.8079800902133323 and parameters: {'n_estimators': 75, 'max_depth': 32, 'learning_rate': 0.012335168036397035, 'gamma': 0.16062550682798896, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.156709073364309, 'reg_lambda': 1.8492719864791168e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:26,199] Trial 352 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 108, 'max_depth': 32, 'learning_rate': 0.025102437055140092, 'gamma': 0.5812351856113109, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.12496175046465, 'reg_lambda': 1.945008286532805e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:26,307] Trial 353 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 153, 'max_depth': 31, 'learning_rate': 0.041400233140963694, 'gamma': 0.9866050060675393, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.7549552503477486, 'reg_lambda': 1.012224033979086e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:26,444] Trial 354 finished with value: 0.8011367629688241 and parameters: {'n_estimators': 130, 'max_depth': 32, 'learning_rate': 0.01737043744838175, 'gamma': 0.13352619882340933, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.370643871814364, 'reg_lambda': 2.7254105566081857e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:26,760] Trial 355 finished with value: 0.8101760010156956 and parameters: {'n_estimators': 69, 'max_depth': 32, 'learning_rate': 0.03124741756362698, 'gamma': 0.11324971647912832, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.962625307775586, 'reg_lambda': 0.017988046031320884}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:26,888] Trial 356 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 87, 'max_depth': 32, 'learning_rate': 0.036367945867039925, 'gamma': 0.14741423271283616, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.454148713268932, 'reg_lambda': 2.2608697495057087e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,113] Trial 357 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 89, 'max_depth': 32, 'learning_rate': 0.02352206891951492, 'gamma': 0.1419283201502645, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.3981616309707614, 'reg_lambda': 2.147474032704936e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,203] Trial 358 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 40, 'max_depth': 32, 'learning_rate': 0.03986532616893462, 'gamma': 0.1576874547045045, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.223692266585972, 'reg_lambda': 1.547346566317396e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,276] Trial 359 finished with value: 0.7955601764400089 and parameters: {'n_estimators': 18, 'max_depth': 32, 'learning_rate': 0.04981375682752704, 'gamma': 0.1644478370702034, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.204632897877059, 'reg_lambda': 1.604957815931673e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,367] Trial 360 finished with value: 0.8141433939473363 and parameters: {'n_estimators': 38, 'max_depth': 32, 'learning_rate': 0.03146992189614856, 'gamma': 0.15151856476739553, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.465998962020098, 'reg_lambda': 1.3167846908799969e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,460] Trial 361 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 46, 'max_depth': 32, 'learning_rate': 0.0191017836698287, 'gamma': 0.17797394918766957, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.9488221965556485, 'reg_lambda': 1.6950395687900138e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,616] Trial 362 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 62, 'max_depth': 31, 'learning_rate': 0.036069562575091384, 'gamma': 0.15983599235992335, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.60840503077619, 'reg_lambda': 2.2060571850381364e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,691] Trial 363 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 37, 'max_depth': 32, 'learning_rate': 1.2689747108576593e-08, 'gamma': 0.6827873554716783, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 4.600280810050383, 'reg_lambda': 1.3624793723530947e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,823] Trial 364 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 94, 'max_depth': 32, 'learning_rate': 0.05417366641495271, 'gamma': 0.1347572332617834, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.332389251198383, 'reg_lambda': 2.682558489172072e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:27,954] Trial 365 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 118, 'max_depth': 31, 'learning_rate': 0.06261237376104763, 'gamma': 0.9215851635751333, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6273572357531605, 'reg_lambda': 1.921903781870327e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:28,076] Trial 366 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 57, 'max_depth': 32, 'learning_rate': 0.025024474693060957, 'gamma': 0.18155028945369822, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.4613636546679354, 'reg_lambda': 1.2441521114934963e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:28,273] Trial 367 finished with value: 0.8137326052008971 and parameters: {'n_estimators': 86, 'max_depth': 23, 'learning_rate': 0.01499495493371259, 'gamma': 0.14792825867435916, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.756948192930361, 'reg_lambda': 2.469719561770909e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:28,354] Trial 368 finished with value: 0.8094043185704923 and parameters: {'n_estimators': 33, 'max_depth': 21, 'learning_rate': 0.037176534345595334, 'gamma': 0.12885088087014848, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5292899322393505, 'reg_lambda': 1.6523517148978477e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:28,467] Trial 369 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 68, 'max_depth': 19, 'learning_rate': 0.06496739565498953, 'gamma': 0.16280018814155311, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.5352859659992513, 'reg_lambda': 3.161593101478792e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:29,142] Trial 370 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 687, 'max_depth': 24, 'learning_rate': 0.010087672890613547, 'gamma': 0.1128078785278479, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.682368942309997, 'reg_lambda': 2.0664601694123312e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:29,428] Trial 371 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 103, 'max_depth': 31, 'learning_rate': 0.037895870946710576, 'gamma': 0.14555507688313146, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1.9173541594223136, 'reg_lambda': 1.0617441701370334e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:29,556] Trial 372 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 192, 'max_depth': 32, 'learning_rate': 0.08122608457272026, 'gamma': 0.7352579823111822, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.140111306572342, 'reg_lambda': 2.658783692063223e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:29,696] Trial 373 finished with value: 0.828254477109439 and parameters: {'n_estimators': 130, 'max_depth': 23, 'learning_rate': 0.021764635624411166, 'gamma': 0.18360750034519752, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.970500345954146, 'reg_lambda': 3.743989128739234e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,012] Trial 374 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 484, 'max_depth': 24, 'learning_rate': 0.05681450020783934, 'gamma': 0.10197851060192707, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.30368840811569, 'reg_lambda': 1.6095683839826573e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,096] Trial 375 finished with value: 0.7933675472137011 and parameters: {'n_estimators': 12, 'max_depth': 22, 'learning_rate': 0.043134295658716376, 'gamma': 0.133790097620904, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.0010317607939155106, 'reg_lambda': 3.0994091610729157e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,183] Trial 376 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 53, 'max_depth': 32, 'learning_rate': 0.08139942120869795, 'gamma': 0.1712146317774155, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.666353018873443, 'reg_lambda': 2.1946224144209757e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,313] Trial 377 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 83, 'max_depth': 25, 'learning_rate': 0.02686479649361989, 'gamma': 0.12702804389494798, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.7684424572864486, 'reg_lambda': 1.7090058861729205e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,715] Trial 378 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 113, 'max_depth': 31, 'learning_rate': 0.0005012630582968503, 'gamma': 0.1514708857017379, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.251166537149342, 'reg_lambda': 1.0228234939234955e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:30,890] Trial 379 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 142, 'max_depth': 23, 'learning_rate': 0.04755349824187492, 'gamma': 0.19229020660715226, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.023607915470208, 'reg_lambda': 3.055149650892467e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:31,129] Trial 380 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 559, 'max_depth': 24, 'learning_rate': 0.09767350555336057, 'gamma': 0.443149115484398, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6686088908519585, 'reg_lambda': 2.3008149080562566e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:31,614] Trial 381 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 94, 'max_depth': 5, 'learning_rate': 7.53683362951393e-05, 'gamma': 0.5407163166300721, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.929372585195599, 'reg_lambda': 3.7945509875917146e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:31,699] Trial 382 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 66, 'max_depth': 22, 'learning_rate': 0.06782987562451727, 'gamma': 0.11806208990592082, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.9993289000179875, 'reg_lambda': 0.08969870173246026}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:32,385] Trial 383 finished with value: 0.7845881595881596 and parameters: {'n_estimators': 231, 'max_depth': 23, 'learning_rate': 0.0326554884183843, 'gamma': 0.10144023113899632, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0039101848412468184, 'reg_lambda': 0.005144059967754306}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,019] Trial 384 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 420, 'max_depth': 31, 'learning_rate': 0.05050108471179198, 'gamma': 0.16745865146682198, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.025530967454608387, 'reg_lambda': 0.00016999670460798462}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,116] Trial 385 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 35, 'max_depth': 32, 'learning_rate': 0.10182061595412795, 'gamma': 0.1419607265142399, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.7128030422902425, 'reg_lambda': 1.371193664380516e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,294] Trial 386 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 160, 'max_depth': 25, 'learning_rate': 0.017829731906824894, 'gamma': 0.1288995015134654, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.9752148886311076, 'reg_lambda': 0.001055220030150159}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,413] Trial 387 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 78, 'max_depth': 23, 'learning_rate': 0.037302580301155096, 'gamma': 0.15367812888349425, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.3161437656682256, 'reg_lambda': 4.5091571930759824e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,536] Trial 388 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 113, 'max_depth': 24, 'learning_rate': 0.06960317375999282, 'gamma': 0.20437130342700682, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.014912651201867, 'reg_lambda': 1.7184274564548208e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:33,638] Trial 389 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 51, 'max_depth': 26, 'learning_rate': 0.025265582061989023, 'gamma': 0.17720723342043498, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.2115056288612074, 'reg_lambda': 2.6686652701286978e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:34,682] Trial 390 finished with value: 0.7750929952558943 and parameters: {'n_estimators': 258, 'max_depth': 21, 'learning_rate': 0.12682304794646107, 'gamma': 0.1169741471617303, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.490681685270997, 'reg_lambda': 2.1357287655965707e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:34,787] Trial 391 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 100, 'max_depth': 32, 'learning_rate': 0.05902743767760545, 'gamma': 0.14157633109176798, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 7.539960615559404, 'reg_lambda': 3.726880331539765e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:34,871] Trial 392 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 77, 'max_depth': 31, 'learning_rate': 0.08782166408664926, 'gamma': 0.16435479064488634, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.903104650641609, 'reg_lambda': 5.889989539782874e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:35,001] Trial 393 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 28, 'max_depth': 25, 'learning_rate': 0.0037812283438483506, 'gamma': 0.37735838366369023, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 2.4018996122958214, 'reg_lambda': 8.264590217275346e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:35,144] Trial 394 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 128, 'max_depth': 22, 'learning_rate': 0.04110266648323905, 'gamma': 0.10080341815917404, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.672537906713555, 'reg_lambda': 0.00035667384057764726}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:35,491] Trial 395 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 174, 'max_depth': 24, 'learning_rate': 0.042836802202110835, 'gamma': 0.5036011209817413, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.045608821644743, 'reg_lambda': 3.012071325394128e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:35,801] Trial 396 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 144, 'max_depth': 18, 'learning_rate': 0.13076242079265074, 'gamma': 0.10379561014961877, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.909595376194094, 'reg_lambda': 0.009897408686104182}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:38,733] Trial 397 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 971, 'max_depth': 22, 'learning_rate': 0.03036024145681561, 'gamma': 0.10198529402526481, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 8.552208508211958, 'reg_lambda': 0.0004131600324690526}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:39,965] Trial 398 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 841, 'max_depth': 32, 'learning_rate': 0.06832686670644063, 'gamma': 0.12619039267245455, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.005287647491228, 'reg_lambda': 4.854742114302827e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,049] Trial 399 finished with value: 0.7877639275749704 and parameters: {'n_estimators': 59, 'max_depth': 31, 'learning_rate': 0.01243399560623752, 'gamma': 0.6031026562683061, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.046672733004242, 'reg_lambda': 1.3151196152871647e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,139] Trial 400 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 92, 'max_depth': 23, 'learning_rate': 0.09851430201813445, 'gamma': 0.19286812502343179, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.8610695364326775, 'reg_lambda': 1.933267806969609e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,237] Trial 401 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 92, 'max_depth': 23, 'learning_rate': 0.17205859711615545, 'gamma': 0.2186945854977665, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.0982399648151393, 'reg_lambda': 1.7860767767463146e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,321] Trial 402 finished with value: 0.820651992198384 and parameters: {'n_estimators': 90, 'max_depth': 23, 'learning_rate': 0.1724333006083502, 'gamma': 0.8376442847398993, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.713467867976049, 'reg_lambda': 1.9041787783180746e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,725] Trial 403 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 100, 'max_depth': 24, 'learning_rate': 0.2077148264535661, 'gamma': 0.23723700251246815, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.9119576824107, 'reg_lambda': 2.4964808851104256e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,828] Trial 404 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 79, 'max_depth': 23, 'learning_rate': 0.1390676735951289, 'gamma': 0.2199376615403184, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.677345405859448, 'reg_lambda': 2.0794545545128e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:40,923] Trial 405 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 114, 'max_depth': 23, 'learning_rate': 0.10052946070450462, 'gamma': 0.21194731853451262, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.101090974950958, 'reg_lambda': 3.157489707301205e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:41,022] Trial 406 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 122, 'max_depth': 24, 'learning_rate': 0.11290833239767654, 'gamma': 0.23582172496920675, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.982619550030974, 'reg_lambda': 3.279637450314922e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:41,638] Trial 407 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 755, 'max_depth': 24, 'learning_rate': 0.1849689327520316, 'gamma': 0.2618127502034471, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.285298190600138, 'reg_lambda': 2.1600360536659114e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:41,842] Trial 408 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 124, 'max_depth': 23, 'learning_rate': 0.11553756721968822, 'gamma': 0.23405321552424596, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.61563926435245, 'reg_lambda': 2.9488994423263233e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:41,944] Trial 409 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 137, 'max_depth': 23, 'learning_rate': 0.1684340406586912, 'gamma': 0.21819914559964873, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.486667422880979, 'reg_lambda': 2.5544295448359166e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,035] Trial 410 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 113, 'max_depth': 24, 'learning_rate': 0.1050009211131824, 'gamma': 0.20107061932758247, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.841612713754975, 'reg_lambda': 3.495419927748572e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,167] Trial 411 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 166, 'max_depth': 24, 'learning_rate': 0.23945110491059493, 'gamma': 0.24376425289406994, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.7759243328961904, 'reg_lambda': 0.4109671869949681}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,260] Trial 412 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 110, 'max_depth': 23, 'learning_rate': 0.12636350079127617, 'gamma': 0.21556971730998162, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.261441550087496, 'reg_lambda': 1.5893904871173042e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,369] Trial 413 finished with value: 0.824887818514042 and parameters: {'n_estimators': 95, 'max_depth': 25, 'learning_rate': 0.1468741310491518, 'gamma': 0.22188237171446767, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.222502061891753, 'reg_lambda': 1.4641442048282218e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,479] Trial 414 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 72, 'max_depth': 23, 'learning_rate': 0.212770112456937, 'gamma': 0.19014393398779775, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.34914761292053503, 'reg_lambda': 1.0476468427443924e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,584] Trial 415 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 104, 'max_depth': 24, 'learning_rate': 0.11001429561027978, 'gamma': 0.25094332614482007, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.353795163419705, 'reg_lambda': 1.854924996493649e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,711] Trial 416 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 153, 'max_depth': 25, 'learning_rate': 0.09356080477811389, 'gamma': 0.28652855617701795, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.602641594777263, 'reg_lambda': 1.2991192979188449e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:42,909] Trial 417 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 177, 'max_depth': 26, 'learning_rate': 0.10558404584737979, 'gamma': 0.28019105397339444, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.342078473371008, 'reg_lambda': 1.2431850967034089e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,020] Trial 418 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 197, 'max_depth': 25, 'learning_rate': 0.09978492943684784, 'gamma': 0.2791351176622953, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.889351512252714, 'reg_lambda': 1.3333473146926477e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,133] Trial 419 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 142, 'max_depth': 25, 'learning_rate': 0.09366606520329124, 'gamma': 0.2623203670228161, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.9357435779192755, 'reg_lambda': 1.682217885133202e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,258] Trial 420 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 141, 'max_depth': 25, 'learning_rate': 0.13452472345628794, 'gamma': 0.300912236897097, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.158871930233522, 'reg_lambda': 1.729516175918963e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,372] Trial 421 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 176, 'max_depth': 24, 'learning_rate': 0.12260024392160002, 'gamma': 0.2360825902979169, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.702067153174249, 'reg_lambda': 1.2404851931987053e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,519] Trial 422 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 166, 'max_depth': 24, 'learning_rate': 0.08912007781501567, 'gamma': 0.2057949308173055, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.925654243772411, 'reg_lambda': 2.0447093678151624e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,782] Trial 423 finished with value: 0.7657657657657657 and parameters: {'n_estimators': 147, 'max_depth': 26, 'learning_rate': 0.14572653336022792, 'gamma': 0.2609105246321469, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.1264525446973222e-05, 'reg_lambda': 1.0101288925927449e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:43,885] Trial 424 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 121, 'max_depth': 25, 'learning_rate': 0.2926254947907056, 'gamma': 0.2995211083561713, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.525319475489977, 'reg_lambda': 1.5052781418358005e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,066] Trial 425 finished with value: 0.824887818514042 and parameters: {'n_estimators': 121, 'max_depth': 24, 'learning_rate': 0.08053574636879669, 'gamma': 0.24923057417622105, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.734552928687143, 'reg_lambda': 2.375911176628156e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,171] Trial 426 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 157, 'max_depth': 24, 'learning_rate': 0.2069299620485579, 'gamma': 0.24203748054675486, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.600607353724236, 'reg_lambda': 1.721792268249752e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,422] Trial 427 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 215, 'max_depth': 25, 'learning_rate': 0.11343545050513064, 'gamma': 0.25113346392522035, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.338619224022828, 'reg_lambda': 2.4612341288689527e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,541] Trial 428 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 105, 'max_depth': 26, 'learning_rate': 0.07993073245211278, 'gamma': 0.2235287714970937, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.524688573132917, 'reg_lambda': 1.2944023098081736e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,634] Trial 429 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 64, 'max_depth': 24, 'learning_rate': 0.17125992171116572, 'gamma': 0.20963756653184226, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.2531152922268722, 'reg_lambda': 1.894637871229697e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,716] Trial 430 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 58, 'max_depth': 25, 'learning_rate': 0.16755965424157188, 'gamma': 0.21115486616109314, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.8759230957051027, 'reg_lambda': 1.0246465589445322e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:44,862] Trial 431 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 441, 'max_depth': 24, 'learning_rate': 0.2832221347527917, 'gamma': 0.2308005276993791, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.388561702988733, 'reg_lambda': 1.9889381104810716e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,147] Trial 432 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 82, 'max_depth': 24, 'learning_rate': 0.21196596369528276, 'gamma': 0.19779350424874018, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4848019400651165, 'reg_lambda': 1.4845315086833778e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,271] Trial 433 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 124, 'max_depth': 25, 'learning_rate': 7.736732129099452e-07, 'gamma': 0.2803288748103859, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.708678496355651, 'reg_lambda': 2.7349509493390072e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,355] Trial 434 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 56, 'max_depth': 23, 'learning_rate': 0.12221404231599224, 'gamma': 0.20953029406881213, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.773516136463149, 'reg_lambda': 1.800466097612603e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,456] Trial 435 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 102, 'max_depth': 26, 'learning_rate': 0.1542643534576325, 'gamma': 0.32545963182465915, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.474380468502624, 'reg_lambda': 2.7501822601613613e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,542] Trial 436 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 69, 'max_depth': 24, 'learning_rate': 0.3383226433440511, 'gamma': 0.19456767422871749, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.682145932395171, 'reg_lambda': 1.2921917816176273e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,620] Trial 437 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 46, 'max_depth': 26, 'learning_rate': 0.4405864538558787, 'gamma': 0.18805303900076525, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 2.02824232251697, 'reg_lambda': 3.259607068500255e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,704] Trial 438 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 72, 'max_depth': 25, 'learning_rate': 0.3018038339423045, 'gamma': 0.19336714757681314, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.3176130072217327, 'reg_lambda': 1.9408038712586957e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,797] Trial 439 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 13, 'max_depth': 9, 'learning_rate': 0.2924601819464187, 'gamma': 0.25521188282226914, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.5026604899949785, 'reg_lambda': 1.4493996720135829e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,876] Trial 440 finished with value: 0.816089234993927 and parameters: {'n_estimators': 62, 'max_depth': 25, 'learning_rate': 0.7145091114927336, 'gamma': 0.1859700036172625, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.701763860972972, 'reg_lambda': 2.3070408771949094e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:45,987] Trial 441 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 156, 'max_depth': 24, 'learning_rate': 0.3664661952489673, 'gamma': 0.228200755649533, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5719953911867535, 'reg_lambda': 7.307267789943398}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:46,082] Trial 442 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 91, 'max_depth': 24, 'learning_rate': 0.2186016177294662, 'gamma': 0.2075998608539067, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.765520545127251, 'reg_lambda': 3.329282765783032e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:46,295] Trial 443 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 132, 'max_depth': 27, 'learning_rate': 0.17404164165618474, 'gamma': 0.18326448046291946, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.79934374922814, 'reg_lambda': 1.2464178407276956e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:46,362] Trial 444 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 35, 'max_depth': 24, 'learning_rate': 0.22036707348671888, 'gamma': 0.2681267761399239, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.427216364263248, 'reg_lambda': 1.0104497132534315e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:46,460] Trial 445 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 106, 'max_depth': 24, 'learning_rate': 0.12783622393530467, 'gamma': 0.23763963225592533, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.976220555390848, 'reg_lambda': 1.7714983536443532e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:47,403] Trial 446 finished with value: 0.7660967150661299 and parameters: {'n_estimators': 69, 'max_depth': 25, 'learning_rate': 0.3562832213352379, 'gamma': 0.3439265938268281, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.833378138079454e-05, 'reg_lambda': 2.6996282385623857e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:47,490] Trial 447 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 48, 'max_depth': 23, 'learning_rate': 0.06460030375596276, 'gamma': 0.1966215245097841, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.0979218200030436, 'reg_lambda': 3.86618144847044e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:47,742] Trial 448 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 196, 'max_depth': 26, 'learning_rate': 0.08340657141819763, 'gamma': 0.17551697833310195, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.4858142689198965, 'reg_lambda': 2.1194451897044816e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:47,839] Trial 449 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 88, 'max_depth': 23, 'learning_rate': 0.1363190523427745, 'gamma': 0.22556767745131806, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.644683962380521, 'reg_lambda': 1.5592250683830565e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:47,955] Trial 450 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 90, 'max_depth': 23, 'learning_rate': 0.1581544486562502, 'gamma': 0.21615749012981544, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.936910944599561, 'reg_lambda': 1.4010332366128226e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,047] Trial 451 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 66, 'max_depth': 23, 'learning_rate': 0.2365067564004505, 'gamma': 0.22346665062614757, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.976656806953381, 'reg_lambda': 1.6757502759551793e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,137] Trial 452 finished with value: 0.824887818514042 and parameters: {'n_estimators': 113, 'max_depth': 22, 'learning_rate': 0.499512217647829, 'gamma': 0.23960995060023013, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.531569137928603, 'reg_lambda': 1.2752318097364934e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,238] Trial 453 finished with value: 0.7481041546866016 and parameters: {'n_estimators': 68, 'max_depth': 23, 'learning_rate': 0.28186640998463675, 'gamma': 0.2603572078364593, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0005400759986261019, 'reg_lambda': 1.6258856869537973e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,327] Trial 454 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 88, 'max_depth': 23, 'learning_rate': 0.3772325384789275, 'gamma': 0.22752910070102061, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.292180286279257, 'reg_lambda': 1.781295296447685e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,519] Trial 455 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 138, 'max_depth': 22, 'learning_rate': 0.9802938031974234, 'gamma': 0.24742103215662326, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.861591642788516, 'reg_lambda': 1.2646300437216293e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,602] Trial 456 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 114, 'max_depth': 23, 'learning_rate': 0.24598386495289762, 'gamma': 0.28848569887614534, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.769076956381707, 'reg_lambda': 1.608549405086849e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,689] Trial 457 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 78, 'max_depth': 15, 'learning_rate': 0.19146703761977735, 'gamma': 0.22302132228213642, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.8451088430443985, 'reg_lambda': 1.0150420475050404e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,817] Trial 458 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 338, 'max_depth': 23, 'learning_rate': 0.14441272737989533, 'gamma': 0.2067321215412295, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.155617757928238, 'reg_lambda': 2.066851541941251e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,898] Trial 459 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 98, 'max_depth': 22, 'learning_rate': 0.5558627699539127, 'gamma': 0.2439986747405188, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.10297880776153, 'reg_lambda': 2.2890205844533387e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:48,996] Trial 460 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 55, 'max_depth': 24, 'learning_rate': 3.3662971692920405e-05, 'gamma': 0.2245437034803925, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.6829267762930735, 'reg_lambda': 1.5931438217111636e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,090] Trial 461 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 130, 'max_depth': 23, 'learning_rate': 0.23599502429751368, 'gamma': 0.2724925604273943, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.897078664323447, 'reg_lambda': 1.3000409476900952e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,269] Trial 462 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 659, 'max_depth': 24, 'learning_rate': 0.1095846803092367, 'gamma': 0.20356449253576617, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.6855245603333495, 'reg_lambda': 2.0249334407753793e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,345] Trial 463 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 31, 'max_depth': 22, 'learning_rate': 0.14939191780649472, 'gamma': 0.21474464207490224, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.760141434402719, 'reg_lambda': 0.0027844269119083435}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,450] Trial 464 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 74, 'max_depth': 24, 'learning_rate': 0.10278384172090504, 'gamma': 0.2524399814348412, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.048806775852838, 'reg_lambda': 2.6375675009631395e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,661] Trial 465 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 159, 'max_depth': 24, 'learning_rate': 0.10333590397022856, 'gamma': 0.268826225503858, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.022167018430887, 'reg_lambda': 2.773942945654674e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,754] Trial 466 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 81, 'max_depth': 23, 'learning_rate': 0.06565681209600024, 'gamma': 0.28846837593769553, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.1233110249951075, 'reg_lambda': 1.0013055546444716e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,860] Trial 467 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 111, 'max_depth': 24, 'learning_rate': 0.09613606388884352, 'gamma': 0.26489138770557114, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.160074422549192, 'reg_lambda': 1.5762248398103555e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:49,952] Trial 468 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 66, 'max_depth': 23, 'learning_rate': 0.06811664542095727, 'gamma': 0.2528330616115515, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.94480671826199, 'reg_lambda': 2.5078762552567446e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,046] Trial 469 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 46, 'max_depth': 24, 'learning_rate': 0.140514131061728, 'gamma': 0.3075413740368359, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 3.0743967236875713, 'reg_lambda': 1.7673063989976947e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,167] Trial 470 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 180, 'max_depth': 25, 'learning_rate': 0.10995283740993884, 'gamma': 0.23349600891361108, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 4.357427020243759, 'reg_lambda': 2.9404821703661095e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,254] Trial 471 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 94, 'max_depth': 24, 'learning_rate': 0.19561517819882618, 'gamma': 0.25156033097932345, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.484363814925502, 'reg_lambda': 2.154918088375266e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,386] Trial 472 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 124, 'max_depth': 24, 'learning_rate': 0.06386945563070318, 'gamma': 0.2334665054541803, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.615009797419289, 'reg_lambda': 1.316389365882962e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,504] Trial 473 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 147, 'max_depth': 23, 'learning_rate': 0.0866185986765522, 'gamma': 0.2480432579280185, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.6763287791715578, 'reg_lambda': 1.9074262405183103e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,597] Trial 474 finished with value: 0.820490132990133 and parameters: {'n_estimators': 71, 'max_depth': 2, 'learning_rate': 0.15086111621694376, 'gamma': 0.2747362279117462, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.878930067156143, 'reg_lambda': 3.1021571476326676e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,766] Trial 475 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 95, 'max_depth': 22, 'learning_rate': 0.05785821410086516, 'gamma': 0.1951754252191515, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.216455546792529, 'reg_lambda': 1.5253293011426406e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,858] Trial 476 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 53, 'max_depth': 25, 'learning_rate': 0.1163476134502792, 'gamma': 0.22604905688215982, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.065704683030272, 'reg_lambda': 2.3335282886069603e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:50,957] Trial 477 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 106, 'max_depth': 23, 'learning_rate': 0.2144425990928988, 'gamma': 0.2145014432885721, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 4.196070989359147, 'reg_lambda': 1.2878863938961518e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,030] Trial 478 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 26, 'max_depth': 25, 'learning_rate': 0.09024245796200746, 'gamma': 0.2430790452895682, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.3545096293646255, 'reg_lambda': 3.5037069931919024e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,119] Trial 479 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 80, 'max_depth': 21, 'learning_rate': 0.0570985668071028, 'gamma': 0.18453166559687761, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.8539064109855055, 'reg_lambda': 0.055522101305927773}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,235] Trial 480 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 128, 'max_depth': 24, 'learning_rate': 0.13781477027494604, 'gamma': 0.2840989962846007, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.452163674940308, 'reg_lambda': 1.8941500975502338e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,329] Trial 481 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 61, 'max_depth': 22, 'learning_rate': 0.06946093477000657, 'gamma': 0.701861379450829, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5590272244768104, 'reg_lambda': 2.5893675556858898e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,409] Trial 482 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 41, 'max_depth': 21, 'learning_rate': 0.0551418429906655, 'gamma': 0.8132962832691844, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.279634560312425, 'reg_lambda': 2.4032800785819175e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,494] Trial 483 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 29, 'max_depth': 21, 'learning_rate': 0.0521347753744138, 'gamma': 0.7443027074307974, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.014937463816553, 'reg_lambda': 2.351383550261349e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,564] Trial 484 finished with value: 0.804179070201375 and parameters: {'n_estimators': 13, 'max_depth': 22, 'learning_rate': 0.05355882610242059, 'gamma': 0.17584905640994064, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.2637177965330273, 'reg_lambda': 1.6430445609701906e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,673] Trial 485 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 43, 'max_depth': 22, 'learning_rate': 0.06865725012509391, 'gamma': 0.7786276323917893, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.16228379659541042, 'reg_lambda': 2.5473861791997653e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,853] Trial 486 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 51, 'max_depth': 20, 'learning_rate': 0.07887290413369936, 'gamma': 0.8497846646543469, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4808191625587748, 'reg_lambda': 2.7660316041367663}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:51,941] Trial 487 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 39, 'max_depth': 21, 'learning_rate': 0.04832586487389195, 'gamma': 0.8121796607068474, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6021708330300333, 'reg_lambda': 1.0024824232514366e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,070] Trial 488 finished with value: 0.7830582868750806 and parameters: {'n_estimators': 61, 'max_depth': 22, 'learning_rate': 0.031831369712761494, 'gamma': 0.7289925987980221, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0023150820294827977, 'reg_lambda': 1.8785581902065115e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,159] Trial 489 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 28, 'max_depth': 23, 'learning_rate': 0.07533812659075301, 'gamma': 0.16135135880477944, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.1858362075708997, 'reg_lambda': 1.4362656384671236e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,251] Trial 490 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 63, 'max_depth': 23, 'learning_rate': 0.08089387313964783, 'gamma': 0.19083302514097136, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.6754131240951087, 'reg_lambda': 2.6867341704156607e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,327] Trial 491 finished with value: 0.7785362722521431 and parameters: {'n_estimators': 11, 'max_depth': 17, 'learning_rate': 0.044221707001753964, 'gamma': 0.7202876402458893, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2402714194838818, 'reg_lambda': 2.0654524522601482e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,410] Trial 492 finished with value: 0.8050772180423282 and parameters: {'n_estimators': 50, 'max_depth': 28, 'learning_rate': 0.022580759883533474, 'gamma': 0.16550119166258473, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.8923177930137833, 'reg_lambda': 1.2940076113182798e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,523] Trial 493 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 67, 'max_depth': 23, 'learning_rate': 0.05736023805254842, 'gamma': 0.9056858391023934, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 1.989139069398549, 'reg_lambda': 2.9232646483295056e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,662] Trial 494 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 78, 'max_depth': 22, 'learning_rate': 0.08688973131193839, 'gamma': 0.14281774104181538, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 3.2864440577370715, 'reg_lambda': 4.027033823839217e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,745] Trial 495 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 42, 'max_depth': 23, 'learning_rate': 0.04867679049291891, 'gamma': 0.7803376808522487, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.756333617633008, 'reg_lambda': 1.6716505985085357e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,826] Trial 496 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 50, 'max_depth': 22, 'learning_rate': 0.032564681923986344, 'gamma': 0.8072689146749721, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.325394790856453, 'reg_lambda': 2.2056984819346695e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:52,953] Trial 497 finished with value: 0.814519979719652 and parameters: {'n_estimators': 35, 'max_depth': 22, 'learning_rate': 0.0342773813749243, 'gamma': 0.8079834009922866, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6142018682487098, 'reg_lambda': 1.648799510687109e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,021] Trial 498 finished with value: 0.7799217852459588 and parameters: {'n_estimators': 12, 'max_depth': 22, 'learning_rate': 0.04646209414779319, 'gamma': 0.7708215064025591, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.497371712746843, 'reg_lambda': 2.177874357770762e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,109] Trial 499 finished with value: 0.8074315620902139 and parameters: {'n_estimators': 32, 'max_depth': 21, 'learning_rate': 0.02247056829404455, 'gamma': 0.7992248270884741, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.7267627196565445, 'reg_lambda': 1.3491743390059535e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,192] Trial 500 finished with value: 0.8326155914543202 and parameters: {'n_estimators': 49, 'max_depth': 20, 'learning_rate': 0.031727527759123436, 'gamma': 0.8392469987375305, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8145293826601825, 'reg_lambda': 2.2567917770809578e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,272] Trial 501 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 27, 'max_depth': 21, 'learning_rate': 2.3977122117670533e-07, 'gamma': 0.7874409744794759, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.5407054582834734, 'reg_lambda': 1.6824137742393595e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,365] Trial 502 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 47, 'max_depth': 22, 'learning_rate': 0.05550462460407878, 'gamma': 0.7929231809762373, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.339321666923343, 'reg_lambda': 2.8288187982386118e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,443] Trial 503 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 36, 'max_depth': 22, 'learning_rate': 0.058252826603750016, 'gamma': 0.8235465082198397, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4043520589163307, 'reg_lambda': 3.160562553556507e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,524] Trial 504 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 20, 'max_depth': 21, 'learning_rate': 0.05372736577568723, 'gamma': 0.8315333138513274, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.337862758464757, 'reg_lambda': 3.47813990131561e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,618] Trial 505 finished with value: 0.7971407701137431 and parameters: {'n_estimators': 43, 'max_depth': 22, 'learning_rate': 0.04522444624847631, 'gamma': 0.8150759197558386, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0003473521824458453, 'reg_lambda': 3.0073640432218103e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,683] Trial 506 finished with value: 0.78737656211765 and parameters: {'n_estimators': 12, 'max_depth': 21, 'learning_rate': 0.08115197757312553, 'gamma': 0.799557027557268, 'min_child_weight': 9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.0240623844947065, 'reg_lambda': 3.48700009263411e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,762] Trial 507 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 43, 'max_depth': 22, 'learning_rate': 0.05866087541750742, 'gamma': 0.8199534554028338, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.8254396504525787, 'reg_lambda': 0.0007397768400158343}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,859] Trial 508 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 33, 'max_depth': 19, 'learning_rate': 3.893185041457123e-08, 'gamma': 0.8806501258060181, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.00010302351541897193, 'reg_lambda': 2.6321215836361907e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:53,969] Trial 509 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 51, 'max_depth': 23, 'learning_rate': 0.10905524934659418, 'gamma': 0.7852814874162751, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2465713327306394, 'reg_lambda': 3.6085697555628186e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,134] Trial 510 finished with value: 0.820490132990133 and parameters: {'n_estimators': 28, 'max_depth': 23, 'learning_rate': 0.17127088497785192, 'gamma': 0.8576677005894295, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3282377520686839, 'reg_lambda': 4.2333636069934275e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,216] Trial 511 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 10, 'max_depth': 23, 'learning_rate': 0.11969521601136317, 'gamma': 0.771510075290943, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5768670049743125, 'reg_lambda': 4.3321832119252085e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,296] Trial 512 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 48, 'max_depth': 22, 'learning_rate': 6.144910851042866e-06, 'gamma': 0.7881529804715364, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.246372273179825, 'reg_lambda': 4.002568542725271e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,382] Trial 513 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 52, 'max_depth': 23, 'learning_rate': 0.29288064747738624, 'gamma': 0.8426342464930081, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.058654191043988, 'reg_lambda': 3.190842828707361e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,452] Trial 514 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 33, 'max_depth': 22, 'learning_rate': 0.1033333964947732, 'gamma': 0.825705955072197, 'min_child_weight': 1, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 2.796340950851059, 'reg_lambda': 2.4705913220744998e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,542] Trial 515 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 58, 'max_depth': 23, 'learning_rate': 0.15026979610821145, 'gamma': 0.7681720925862087, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.1709803164962824, 'reg_lambda': 4.3488589151043687e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,615] Trial 516 finished with value: 0.824887818514042 and parameters: {'n_estimators': 42, 'max_depth': 20, 'learning_rate': 0.23072640527661312, 'gamma': 0.7956000506818427, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.583733053964566, 'reg_lambda': 3.2444615432076506e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,716] Trial 517 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 70, 'max_depth': 23, 'learning_rate': 0.08744258150312574, 'gamma': 0.8117911943266098, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.9428139604723307, 'reg_lambda': 2.2819011528645303e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,802] Trial 518 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 58, 'max_depth': 22, 'learning_rate': 0.11152501436737146, 'gamma': 0.7927234807459016, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.593436261938946, 'reg_lambda': 2.9895975682526113e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,896] Trial 519 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 33, 'max_depth': 21, 'learning_rate': 0.2058459828774475, 'gamma': 0.7661303717186148, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0006958269796166118, 'reg_lambda': 1.8534912177607228e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:54,982] Trial 520 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 80, 'max_depth': 23, 'learning_rate': 0.0677316304988068, 'gamma': 0.8652719252428498, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.619173123783321, 'reg_lambda': 4.4112642543994235e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,070] Trial 521 finished with value: 0.820490132990133 and parameters: {'n_estimators': 56, 'max_depth': 21, 'learning_rate': 0.16796261930477177, 'gamma': 0.8140880396118712, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.043998601973102, 'reg_lambda': 2.599772140955166e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,222] Trial 522 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 25, 'max_depth': 23, 'learning_rate': 0.40415482998162194, 'gamma': 0.7585069199931297, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 6.454287018100786, 'reg_lambda': 1.9105751990033232e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,322] Trial 523 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 78, 'max_depth': 22, 'learning_rate': 0.11139200943775715, 'gamma': 0.8294981082396027, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.6185457256795464, 'reg_lambda': 3.175696038872635e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,400] Trial 524 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 46, 'max_depth': 23, 'learning_rate': 0.08000883822443818, 'gamma': 0.7492422481047983, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.087605428124332, 'reg_lambda': 1.3737080563981851e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,496] Trial 525 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 68, 'max_depth': 22, 'learning_rate': 0.0523660503308944, 'gamma': 0.8374566030983573, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.785010412692218, 'reg_lambda': 2.236446112330771e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,592] Trial 526 finished with value: 0.8071179781643625 and parameters: {'n_estimators': 86, 'max_depth': 22, 'learning_rate': 0.15143831124908488, 'gamma': 0.7867695083073105, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5518781220903966, 'reg_lambda': 3.8108325048597645e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,734] Trial 527 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 501, 'max_depth': 23, 'learning_rate': 0.2856939041439085, 'gamma': 0.793858325575987, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.304979667857499, 'reg_lambda': 1.607479951622973e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,806] Trial 528 finished with value: 0.7869448662323123 and parameters: {'n_estimators': 11, 'max_depth': 24, 'learning_rate': 0.08959504683678525, 'gamma': 0.8001218167052969, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.936222521897776, 'reg_lambda': 1.0102773312039137e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,882] Trial 529 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 62, 'max_depth': 23, 'learning_rate': 0.06262970876603885, 'gamma': 0.8229521259152883, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.488839674746513, 'reg_lambda': 2.7081467962117814e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:55,972] Trial 530 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 43, 'max_depth': 21, 'learning_rate': 0.12211922936912337, 'gamma': 0.7788091058351143, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0026983621160437, 'reg_lambda': 4.8445051441957886e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,065] Trial 531 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 86, 'max_depth': 23, 'learning_rate': 0.043373714850874226, 'gamma': 0.804490318533363, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.209746653019983, 'reg_lambda': 1.6954384705842924e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,150] Trial 532 finished with value: 0.820490132990133 and parameters: {'n_estimators': 29, 'max_depth': 22, 'learning_rate': 0.19335948137948972, 'gamma': 0.8149270112552854, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.1489447766681224, 'reg_lambda': 2.0438180278310726e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,343] Trial 533 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 66, 'max_depth': 24, 'learning_rate': 0.07571588815835671, 'gamma': 0.7716877495254056, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.969229347033212, 'reg_lambda': 1.3045835709861815e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,443] Trial 534 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 94, 'max_depth': 13, 'learning_rate': 0.13520441544203812, 'gamma': 0.8830469476744093, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.05783344805067691, 'reg_lambda': 3.2324556972284975e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,549] Trial 535 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 49, 'max_depth': 24, 'learning_rate': 0.09689230996277558, 'gamma': 0.8443011594500265, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.006009287204958015, 'reg_lambda': 2.1743074014288146e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,624] Trial 536 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 76, 'max_depth': 23, 'learning_rate': 0.36926501593758554, 'gamma': 0.8236794720364041, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.9175708479761477, 'reg_lambda': 3.898392138072458e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,833] Trial 537 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 720, 'max_depth': 22, 'learning_rate': 0.03372953732847042, 'gamma': 0.7879697204763702, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.482518567849112, 'reg_lambda': 2.6016087094615746e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:56,938] Trial 538 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 56, 'max_depth': 24, 'learning_rate': 0.05742181568354688, 'gamma': 0.7578090038192409, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.019415972386929277, 'reg_lambda': 1.5946995191950972e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:57,031] Trial 539 finished with value: 0.780204207675669 and parameters: {'n_estimators': 91, 'max_depth': 23, 'learning_rate': 0.20869494126791607, 'gamma': 0.8138091709366986, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.10270355565667329, 'reg_lambda': 4.9308617556053464e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:57,109] Trial 540 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 33, 'max_depth': 23, 'learning_rate': 0.10337447730197209, 'gamma': 0.7802061172629845, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.95774025376904, 'reg_lambda': 2.0179120029953727e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:57,204] Trial 541 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 76, 'max_depth': 22, 'learning_rate': 0.053304311477800896, 'gamma': 0.801938901100974, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.4681701120663817, 'reg_lambda': 1.1945320862615564e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:57,303] Trial 542 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 50, 'max_depth': 24, 'learning_rate': 0.0003027064572664052, 'gamma': 0.3134808664387875, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.171345818092255, 'reg_lambda': 3.57184610773465e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:57,950] Trial 543 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 909, 'max_depth': 28, 'learning_rate': 0.15604564836207344, 'gamma': 0.8574680410369979, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.387338354601253, 'reg_lambda': 2.7965443623677816e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,063] Trial 544 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 96, 'max_depth': 21, 'learning_rate': 0.029362097751608817, 'gamma': 0.20689550899637588, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.793887258715819, 'reg_lambda': 1.6256071847877177e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,142] Trial 545 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 12, 'max_depth': 23, 'learning_rate': 3.7248314967426177e-06, 'gamma': 0.8279584064073858, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.963915010682194, 'reg_lambda': 2.3049209236194118e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,235] Trial 546 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 68, 'max_depth': 22, 'learning_rate': 0.07465357947066864, 'gamma': 0.2599195456926757, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.397394737884944, 'reg_lambda': 0.15949626061020145}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,324] Trial 547 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 37, 'max_depth': 20, 'learning_rate': 0.2651836739329087, 'gamma': 0.22104350234031808, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.8235817693061063, 'reg_lambda': 1.0024582496028347e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,438] Trial 548 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 101, 'max_depth': 24, 'learning_rate': 0.042373262740116255, 'gamma': 0.20153573511213507, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.110636295799429, 'reg_lambda': 4.763162300788437e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,603] Trial 549 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 64, 'max_depth': 23, 'learning_rate': 0.11590663961135482, 'gamma': 0.288099230037171, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6092981928889567, 'reg_lambda': 3.047256265193012e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,705] Trial 550 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 83, 'max_depth': 21, 'learning_rate': 0.06787515925227586, 'gamma': 0.21393824841564546, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.534614317029117, 'reg_lambda': 1.6062169917301315e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,782] Trial 551 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 26, 'max_depth': 22, 'learning_rate': 0.006447315303318045, 'gamma': 0.23968905414800817, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.796342557049228, 'reg_lambda': 2.144073080103753e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,854] Trial 552 finished with value: 0.816089234993927 and parameters: {'n_estimators': 47, 'max_depth': 24, 'learning_rate': 0.1650387347973651, 'gamma': 0.7797431554534963, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.439683042239673, 'reg_lambda': 1.3581005883668923e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:58,947] Trial 553 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 71, 'max_depth': 23, 'learning_rate': 0.09155174415734164, 'gamma': 0.2623063280561533, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.598717751856586, 'reg_lambda': 3.265719681221775e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,040] Trial 554 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 62, 'max_depth': 23, 'learning_rate': 0.10454077774476896, 'gamma': 0.2699685334300081, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 3.5441240079875223, 'reg_lambda': 2.8039692945080196e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,151] Trial 555 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 80, 'max_depth': 23, 'learning_rate': 1.7399188867896824e-06, 'gamma': 0.25749417082324777, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.308837531428403, 'reg_lambda': 1.9731748186354635e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,238] Trial 556 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 44, 'max_depth': 24, 'learning_rate': 0.1897257573076204, 'gamma': 0.2954452448234056, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2790992811004371, 'reg_lambda': 0.007327412900923035}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,327] Trial 557 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 94, 'max_depth': 24, 'learning_rate': 0.1251684556585265, 'gamma': 0.27751481879625545, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.486491239196993, 'reg_lambda': 3.697310666058334e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,423] Trial 558 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 67, 'max_depth': 24, 'learning_rate': 0.2962562658643798, 'gamma': 0.319677905779025, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.015169464708117, 'reg_lambda': 3.8041656988138206e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,522] Trial 559 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 85, 'max_depth': 24, 'learning_rate': 0.08473130932618181, 'gamma': 0.3004121340299406, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.9503960777923797, 'reg_lambda': 2.906890884191691e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,690] Trial 560 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 33, 'max_depth': 25, 'learning_rate': 0.14751566503612223, 'gamma': 0.26699930739993144, 'min_child_weight': 9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.085349072697635, 'reg_lambda': 0.003894926279786292}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,778] Trial 561 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 58, 'max_depth': 23, 'learning_rate': 0.5037783257353339, 'gamma': 0.28741659807629477, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.91030825348963, 'reg_lambda': 2.4513957024420883e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:26:59,875] Trial 562 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 84, 'max_depth': 22, 'learning_rate': 0.21641230668002515, 'gamma': 0.25652940732033297, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.010552102174144295, 'reg_lambda': 3.522567354628443e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,085] Trial 563 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 626, 'max_depth': 25, 'learning_rate': 0.0925040146272812, 'gamma': 0.28935016072873593, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.095032674605598, 'reg_lambda': 1.8254489740798677e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,179] Trial 564 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 101, 'max_depth': 24, 'learning_rate': 0.13158310947835938, 'gamma': 0.9997532954473132, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.0821869642088275, 'reg_lambda': 2.367708199440121e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,245] Trial 565 finished with value: 0.7615819340164552 and parameters: {'n_estimators': 11, 'max_depth': 24, 'learning_rate': 0.06855676655672042, 'gamma': 0.27593882761274796, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.704733855248785, 'reg_lambda': 1.2624638891869918e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,417] Trial 566 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 49, 'max_depth': 11, 'learning_rate': 0.00017485138508905088, 'gamma': 0.2467110875776275, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0014007966390403859, 'reg_lambda': 3.287870769580786e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,528] Trial 567 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 70, 'max_depth': 23, 'learning_rate': 0.05508515887593016, 'gamma': 0.22984840344875176, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8428919886413808, 'reg_lambda': 1.6769707733972652e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,673] Trial 568 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 389, 'max_depth': 22, 'learning_rate': 0.12618401224999787, 'gamma': 0.6593154845980652, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.2341052834268895, 'reg_lambda': 2.272843827240296e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,814] Trial 569 finished with value: 0.824887818514042 and parameters: {'n_estimators': 33, 'max_depth': 24, 'learning_rate': 0.18496307007138282, 'gamma': 0.7427747854370186, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.572491745361451, 'reg_lambda': 2.88025587097985e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:00,917] Trial 570 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 102, 'max_depth': 23, 'learning_rate': 0.08584231388357084, 'gamma': 0.26497708337900966, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.34530573472781, 'reg_lambda': 4.009914516692924e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,001] Trial 571 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 59, 'max_depth': 21, 'learning_rate': 0.34940421219731765, 'gamma': 0.2470762849218231, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 9.874491236181052, 'reg_lambda': 1.5055112670262994e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,099] Trial 572 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 79, 'max_depth': 25, 'learning_rate': 0.06757147307511009, 'gamma': 0.22862650935045542, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 3.05492264640893, 'reg_lambda': 1.8678539706947854e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,187] Trial 573 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.22835569633230052, 'gamma': 0.2775748804664748, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7258966102244233, 'reg_lambda': 2.7389469022799496e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,262] Trial 574 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 26, 'max_depth': 22, 'learning_rate': 0.10639821986193365, 'gamma': 0.3259384589186813, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.190932292795722, 'reg_lambda': 2.0877535745467985e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,364] Trial 575 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 93, 'max_depth': 23, 'learning_rate': 0.14137351128938855, 'gamma': 0.2096876068798096, 'min_child_weight': 9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.781701251689854, 'reg_lambda': 1.4262704984488879e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,606] Trial 576 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 798, 'max_depth': 24, 'learning_rate': 0.04769106555371296, 'gamma': 0.8338030994541992, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.2381222929174434, 'reg_lambda': 4.113599586333586e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,705] Trial 577 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 75, 'max_depth': 23, 'learning_rate': 0.08358428297964747, 'gamma': 0.7982076593808595, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 6.334511853025967, 'reg_lambda': 0.023915091662546836}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,813] Trial 578 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 113, 'max_depth': 25, 'learning_rate': 0.17413458605501597, 'gamma': 0.2343758352593841, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.554796964387058, 'reg_lambda': 1.2001238910608496e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:01,918] Trial 579 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 48, 'max_depth': 24, 'learning_rate': 0.05414502084254047, 'gamma': 0.3065114269230565, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.782253120351101, 'reg_lambda': 0.0015026665473059093}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,008] Trial 580 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 71, 'max_depth': 22, 'learning_rate': 0.2600717196955991, 'gamma': 0.2565615185090263, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.237216860871158, 'reg_lambda': 3.124356001958168e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,096] Trial 581 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 27, 'max_depth': 23, 'learning_rate': 0.11275346827674969, 'gamma': 0.20051804019086206, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 6.453594204284597, 'reg_lambda': 2.189303192916361e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,202] Trial 582 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 95, 'max_depth': 22, 'learning_rate': 0.07106700723232073, 'gamma': 0.22702896721407084, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.445015635906154, 'reg_lambda': 1.570935218333196e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,303] Trial 583 finished with value: 0.8101760010156956 and parameters: {'n_estimators': 60, 'max_depth': 24, 'learning_rate': 0.03082784170237476, 'gamma': 0.8136131989487565, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 4.454272685070156, 'reg_lambda': 2.607570987198061e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,481] Trial 584 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 109, 'max_depth': 21, 'learning_rate': 0.6181140219450545, 'gamma': 0.19424448697123645, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 3.4850611123622937, 'reg_lambda': 3.710911330582112e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,583] Trial 585 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 42, 'max_depth': 25, 'learning_rate': 0.041928938510885416, 'gamma': 0.2159246973547014, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 8.06874274986174, 'reg_lambda': 1.0144589173964192e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,670] Trial 586 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 70, 'max_depth': 23, 'learning_rate': 0.10041566558489694, 'gamma': 0.7606329912244979, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.924151869126394, 'reg_lambda': 1.89581324797936e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,768] Trial 587 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 88, 'max_depth': 24, 'learning_rate': 0.14083740629098832, 'gamma': 0.27965403510676007, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 5.1289615852380415, 'reg_lambda': 4.383390521892433e-05}. Best is trial 310 with value: 0.8422205989773557.\n",
      "[I 2024-01-12 22:27:02,861] Trial 588 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 45, 'max_depth': 22, 'learning_rate': 0.062368739009833314, 'gamma': 0.2474622519346302, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1052463961468544, 'reg_lambda': 2.524105626633942e-05}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:02,941] Trial 589 finished with value: 0.7644917644917645 and parameters: {'n_estimators': 16, 'max_depth': 20, 'learning_rate': 0.022066759940697622, 'gamma': 0.23981731932804742, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.285368831252342, 'reg_lambda': 1.4233556732669635e-05}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,099] Trial 590 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 36, 'max_depth': 14, 'learning_rate': 0.04773876591869027, 'gamma': 0.18249973362484306, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9390636023262036, 'reg_lambda': 1.8351826969658182e-05}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,182] Trial 591 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 41, 'max_depth': 21, 'learning_rate': 0.06275439135984344, 'gamma': 0.8683361166911452, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3444161014918563, 'reg_lambda': 0.36019017445780216}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,281] Trial 592 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 25, 'max_depth': 21, 'learning_rate': 0.035432597761485524, 'gamma': 0.8722231793656726, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6498308865691726, 'reg_lambda': 1.2254056113395885e-05}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,384] Trial 593 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 49, 'max_depth': 19, 'learning_rate': 0.06823723681420132, 'gamma': 0.8465425867748999, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0680130194937365, 'reg_lambda': 0.299755938493541}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,480] Trial 594 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 63, 'max_depth': 19, 'learning_rate': 0.06933544302447685, 'gamma': 0.8724619145284852, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9192124463360639, 'reg_lambda': 0.47826114105976675}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,590] Trial 595 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 109, 'max_depth': 16, 'learning_rate': 0.17476004342622964, 'gamma': 0.9185383581797609, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4968176319594268, 'reg_lambda': 0.4483337862896624}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,682] Trial 596 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 87, 'max_depth': 20, 'learning_rate': 0.33107992104095685, 'gamma': 0.8957189028159825, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9229217775741342, 'reg_lambda': 0.3563764255083899}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,784] Trial 597 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 62, 'max_depth': 20, 'learning_rate': 0.08278464764725199, 'gamma': 0.8730987249601877, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7098989028022874, 'reg_lambda': 0.6065748146665797}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,873] Trial 598 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 57, 'max_depth': 17, 'learning_rate': 0.07272825431773991, 'gamma': 0.876563503758412, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.580435535253924, 'reg_lambda': 0.8675740869553311}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:03,969] Trial 599 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 59, 'max_depth': 19, 'learning_rate': 0.0741298723067943, 'gamma': 0.8848283031707862, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8778122420470121, 'reg_lambda': 0.6622418930074361}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,079] Trial 600 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.0696377207753029, 'gamma': 0.8792308912778156, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.605459137780965, 'reg_lambda': 0.7196583948755122}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,214] Trial 601 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 21, 'max_depth': 17, 'learning_rate': 0.0692991912811638, 'gamma': 0.8914467019540713, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.38850608796514935, 'reg_lambda': 0.6903402179464135}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,320] Trial 602 finished with value: 0.8279211029211029 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.029311270495939096, 'gamma': 0.8827933537008613, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4275062680631131, 'reg_lambda': 1.0291369050508068}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,419] Trial 603 finished with value: 0.833675692499222 and parameters: {'n_estimators': 52, 'max_depth': 19, 'learning_rate': 0.0647965534308654, 'gamma': 0.869833636721203, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6145729609596915, 'reg_lambda': 0.6531457861103551}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,527] Trial 604 finished with value: 0.8003283337405159 and parameters: {'n_estimators': 27, 'max_depth': 18, 'learning_rate': 0.04301229181611921, 'gamma': 0.869640333762532, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.587647902277949, 'reg_lambda': 0.5610421974404346}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,601] Trial 605 finished with value: 0.7859631697549913 and parameters: {'n_estimators': 11, 'max_depth': 18, 'learning_rate': 0.06442632816948221, 'gamma': 0.9133553012035999, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.7237498073869807, 'reg_lambda': 1.3591725082768242}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,701] Trial 606 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 48, 'max_depth': 21, 'learning_rate': 8.17944943711972e-05, 'gamma': 0.8984951474648497, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5168562125741935, 'reg_lambda': 0.7773131677974834}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,800] Trial 607 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 54, 'max_depth': 19, 'learning_rate': 0.03871595779598512, 'gamma': 0.8622604419434358, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3008403806603486, 'reg_lambda': 0.293686602377536}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,895] Trial 608 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 37, 'max_depth': 19, 'learning_rate': 0.06791551560743046, 'gamma': 0.8673709070303037, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6146108202116872, 'reg_lambda': 1.304916715705632}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:04,989] Trial 609 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 57, 'max_depth': 19, 'learning_rate': 0.016767377308985768, 'gamma': 0.8941033327019807, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5774497478862477, 'reg_lambda': 1.067860967327635}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,083] Trial 610 finished with value: 0.8137326052008971 and parameters: {'n_estimators': 34, 'max_depth': 18, 'learning_rate': 0.03458498642550515, 'gamma': 0.8750092111897044, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8896590881698099, 'reg_lambda': 0.569936128530115}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,183] Trial 611 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 50, 'max_depth': 18, 'learning_rate': 0.05854883958217634, 'gamma': 0.8551920917671643, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.061780777767863, 'reg_lambda': 0.4631647540213887}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,339] Trial 612 finished with value: 0.7178172489996356 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.028611322636571596, 'gamma': 0.9264474790945267, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7516288299055602, 'reg_lambda': 0.45814229200540035}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,429] Trial 613 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 33, 'max_depth': 18, 'learning_rate': 0.053476305886567745, 'gamma': 0.8792162631103707, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8242155936445008, 'reg_lambda': 0.6933984472280097}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,498] Trial 614 finished with value: 0.7460369022869022 and parameters: {'n_estimators': 10, 'max_depth': 17, 'learning_rate': 0.041700141103831224, 'gamma': 0.8571879916119922, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8509017763748222, 'reg_lambda': 0.624565758376882}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,574] Trial 615 finished with value: 0.8074315620902139 and parameters: {'n_estimators': 29, 'max_depth': 18, 'learning_rate': 0.027211873252591213, 'gamma': 0.875862316818372, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.711650958723599, 'reg_lambda': 0.9245876120744302}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,671] Trial 616 finished with value: 0.838267940547261 and parameters: {'n_estimators': 38, 'max_depth': 19, 'learning_rate': 0.05941906618107434, 'gamma': 0.9082959411959861, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.9347284819065436, 'reg_lambda': 0.2804746863479812}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,752] Trial 617 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 28, 'max_depth': 18, 'learning_rate': 0.0029255419882800453, 'gamma': 0.9487338810180895, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.0040901751575633, 'reg_lambda': 0.301336468214935}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,863] Trial 618 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 34, 'max_depth': 16, 'learning_rate': 0.048932749217235755, 'gamma': 0.8930082266842803, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.035710003238325, 'reg_lambda': 0.2471056792899708}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:05,968] Trial 619 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 48, 'max_depth': 18, 'learning_rate': 0.042434109926556184, 'gamma': 0.9036782066271476, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.8036477767561713, 'reg_lambda': 0.4384695823279082}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,066] Trial 620 finished with value: 0.7976470259078955 and parameters: {'n_estimators': 28, 'max_depth': 19, 'learning_rate': 0.02641134418139087, 'gamma': 0.9273559790469643, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.4738030886149171, 'reg_lambda': 0.21700898829512802}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,172] Trial 621 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 60, 'max_depth': 18, 'learning_rate': 0.001747445563587825, 'gamma': 0.9055051676996215, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0606743952515234, 'reg_lambda': 2.0219784133960927}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,272] Trial 622 finished with value: 0.8219374163746324 and parameters: {'n_estimators': 46, 'max_depth': 17, 'learning_rate': 0.019703739126654615, 'gamma': 0.8931750702613407, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.8167766959239088, 'reg_lambda': 0.33314873069397494}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,439] Trial 623 finished with value: 0.776113437381043 and parameters: {'n_estimators': 12, 'max_depth': 19, 'learning_rate': 0.03627827384361233, 'gamma': 0.845758482152386, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.1823879266538797, 'reg_lambda': 0.5230061469255511}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,535] Trial 624 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 38, 'max_depth': 19, 'learning_rate': 0.056619843317528985, 'gamma': 0.855330935715467, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.7991464252515337, 'reg_lambda': 0.378206024908874}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,684] Trial 625 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 59, 'max_depth': 17, 'learning_rate': 0.06694904006733207, 'gamma': 0.8814357220981194, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.45288593667100147, 'reg_lambda': 0.7116222857745919}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:06,774] Trial 626 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 30, 'max_depth': 20, 'learning_rate': 0.05139119117552953, 'gamma': 0.8579781299405083, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.1510875637755738, 'reg_lambda': 0.8604701033628462}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,070] Trial 627 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 999, 'max_depth': 17, 'learning_rate': 0.025036636376175845, 'gamma': 0.8806211527214953, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.7027632477535946, 'reg_lambda': 0.5614602275875168}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,187] Trial 628 finished with value: 0.8101760010156956 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.07254349255450472, 'gamma': 0.9705787073944498, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.9706229134001677, 'reg_lambda': 0.1781582666123343}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,275] Trial 629 finished with value: 0.7769684578195216 and parameters: {'n_estimators': 10, 'max_depth': 20, 'learning_rate': 0.04674409760793392, 'gamma': 0.9357402998715457, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5614554778076829, 'reg_lambda': 0.3006414946909969}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,359] Trial 630 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 45, 'max_depth': 18, 'learning_rate': 0.04034651158272413, 'gamma': 0.8482248312146735, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0009955512705409, 'reg_lambda': 1.145382459994352}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,562] Trial 631 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 61, 'max_depth': 19, 'learning_rate': 0.000924337410287778, 'gamma': 0.8811894989117871, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.21194168126077, 'reg_lambda': 1.6669682538093793}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,664] Trial 632 finished with value: 0.7812022676057091 and parameters: {'n_estimators': 40, 'max_depth': 19, 'learning_rate': 0.013573092735467519, 'gamma': 0.859413960614542, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3893442392144095, 'reg_lambda': 0.8137022931610316}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:07,794] Trial 633 finished with value: 0.8372937151563106 and parameters: {'n_estimators': 66, 'max_depth': 20, 'learning_rate': 0.06750063378844784, 'gamma': 0.9198268627158783, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7619530492280703, 'reg_lambda': 0.13029181244460047}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:08,318] Trial 634 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 26, 'max_depth': 20, 'learning_rate': 0.06181352870156643, 'gamma': 0.9341343805389358, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7504526695150725, 'reg_lambda': 0.4871922653745712}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:08,421] Trial 635 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 61, 'max_depth': 20, 'learning_rate': 0.07497878561822326, 'gamma': 0.9230391700037648, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.5713237645506526, 'reg_lambda': 0.12490592837978204}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:08,494] Trial 636 finished with value: 0.7315558802045288 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.03378858850009898, 'gamma': 0.9113518693008026, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7608933234790067, 'reg_lambda': 0.28514444661590826}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:08,666] Trial 637 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 39, 'max_depth': 20, 'learning_rate': 0.07274074009427324, 'gamma': 0.8825332152682435, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.22046517335401652, 'reg_lambda': 0.6820553760379561}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,195] Trial 638 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 605, 'max_depth': 20, 'learning_rate': 2.279053185120916e-05, 'gamma': 0.9102291866828245, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.24625168337208755, 'reg_lambda': 0.3922010712779648}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,300] Trial 639 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 38, 'max_depth': 19, 'learning_rate': 0.0627605015291698, 'gamma': 0.8891415342991468, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4289754276998284, 'reg_lambda': 0.5331596711665677}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,387] Trial 640 finished with value: 0.804646390820453 and parameters: {'n_estimators': 27, 'max_depth': 20, 'learning_rate': 0.04407289695630447, 'gamma': 0.9550174551651304, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.32006753523533116, 'reg_lambda': 0.0880053249357988}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,484] Trial 641 finished with value: 0.8084912498705603 and parameters: {'n_estimators': 46, 'max_depth': 18, 'learning_rate': 0.021382874043922473, 'gamma': 0.873165683661585, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9619530039644271, 'reg_lambda': 0.7881408392762063}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,594] Trial 642 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 46, 'max_depth': 19, 'learning_rate': 0.08246943647493157, 'gamma': 0.9047370963233029, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2154253135277684, 'reg_lambda': 0.6525933897810411}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,756] Trial 643 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 31, 'max_depth': 19, 'learning_rate': 0.09064099040593537, 'gamma': 0.9010158684014111, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3796740739361566, 'reg_lambda': 0.6366205367866614}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:09,833] Trial 644 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 26, 'max_depth': 18, 'learning_rate': 0.05134993816987032, 'gamma': 0.8434654730728555, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.104574608531037, 'reg_lambda': 1.0660675043639467}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,130] Trial 645 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 829, 'max_depth': 17, 'learning_rate': 0.03130391513274755, 'gamma': 0.8747590921518151, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.6008146089722309, 'reg_lambda': 0.7882051891081275}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,218] Trial 646 finished with value: 0.7950711199781832 and parameters: {'n_estimators': 10, 'max_depth': 18, 'learning_rate': 0.07901019746222468, 'gamma': 0.8556780173979076, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2431247822198204, 'reg_lambda': 0.46693132171966967}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,309] Trial 647 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 45, 'max_depth': 19, 'learning_rate': 0.05218707539427702, 'gamma': 0.8751094289934351, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 1.0718079767292437, 'reg_lambda': 0.5739850361100864}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,405] Trial 648 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 53, 'max_depth': 17, 'learning_rate': 0.0895588005285562, 'gamma': 0.9045453521519484, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3451957661572258, 'reg_lambda': 1.0225825038452012}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,498] Trial 649 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 44, 'max_depth': 20, 'learning_rate': 0.0310689613719942, 'gamma': 0.8417693782627282, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9812636795676494, 'reg_lambda': 0.7749253072324696}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,618] Trial 650 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 71, 'max_depth': 19, 'learning_rate': 0.07696635795770532, 'gamma': 0.9000128229577103, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.1805934928044915, 'reg_lambda': 0.4005944475280676}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,702] Trial 651 finished with value: 0.8094043185704923 and parameters: {'n_estimators': 24, 'max_depth': 18, 'learning_rate': 0.04259664716684617, 'gamma': 0.8610657723885304, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8235709243349925, 'reg_lambda': 0.6186380307955867}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,904] Trial 652 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 52, 'max_depth': 20, 'learning_rate': 0.059540347096589286, 'gamma': 0.889524498672814, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5195136793733367, 'reg_lambda': 0.31727517232005786}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:10,991] Trial 653 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 1.2043236971042052e-05, 'gamma': 0.887854783723255, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2403331611353765, 'reg_lambda': 0.22051889200194896}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,137] Trial 654 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 362, 'max_depth': 19, 'learning_rate': 0.07856595319528918, 'gamma': 0.8683742558055431, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.8319185798700376, 'reg_lambda': 1.3612304593906412}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,268] Trial 655 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 72, 'max_depth': 18, 'learning_rate': 0.037671671084222126, 'gamma': 0.8452141088315287, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.643297919064422, 'reg_lambda': 0.4201875979765318}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,372] Trial 656 finished with value: 0.8031322241848557 and parameters: {'n_estimators': 40, 'max_depth': 20, 'learning_rate': 0.021245109201723813, 'gamma': 0.9149205654497042, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.36873493079769465, 'reg_lambda': 0.7458039626753257}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,469] Trial 657 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 53, 'max_depth': 16, 'learning_rate': 0.05566882302425212, 'gamma': 0.8833838374237666, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3836914089105743, 'reg_lambda': 2.7226716827023334}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,583] Trial 658 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 75, 'max_depth': 17, 'learning_rate': 0.1008564615222536, 'gamma': 0.8634278510221635, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9056362675520019, 'reg_lambda': 0.5758060772035093}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,670] Trial 659 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 28, 'max_depth': 18, 'learning_rate': 0.0744902861458212, 'gamma': 0.835842705129753, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.48716515350040007, 'reg_lambda': 0.8839274645473189}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,771] Trial 660 finished with value: 0.7888174243619327 and parameters: {'n_estimators': 55, 'max_depth': 20, 'learning_rate': 0.008929142457203686, 'gamma': 0.9107090314163773, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2313377700979389, 'reg_lambda': 0.3592266031426649}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:11,875] Trial 661 finished with value: 0.8137326052008971 and parameters: {'n_estimators': 35, 'max_depth': 18, 'learning_rate': 0.036447675819370584, 'gamma': 0.8506331737325497, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6634803580703876, 'reg_lambda': 0.4337522906179002}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,089] Trial 662 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 306, 'max_depth': 19, 'learning_rate': 0.05372351008566811, 'gamma': 0.891344862474925, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0119873651001476, 'reg_lambda': 0.6451723068223778}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,194] Trial 663 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 72, 'max_depth': 20, 'learning_rate': 0.09364609186235436, 'gamma': 0.94137203158208, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.423958903739774, 'reg_lambda': 0.24156479693629979}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,296] Trial 664 finished with value: 0.8128060018297418 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.015496109703433224, 'gamma': 0.881187374464453, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8546129162706991, 'reg_lambda': 0.01360104941020836}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,378] Trial 665 finished with value: 0.6999570586474776 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.027528270457020713, 'gamma': 0.8586513116609603, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6360989306065726, 'reg_lambda': 0.9562287324566506}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,484] Trial 666 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 77, 'max_depth': 16, 'learning_rate': 0.052531377850159426, 'gamma': 0.9020149605559902, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.22624797023434842, 'reg_lambda': 0.5309177382202727}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,578] Trial 667 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 40, 'max_depth': 20, 'learning_rate': 0.07973885328727494, 'gamma': 0.8723691595238048, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1768325700836089, 'reg_lambda': 1.630315229017206}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,675] Trial 668 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 61, 'max_depth': 17, 'learning_rate': 0.04453712094100502, 'gamma': 0.8443418927792365, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4080748754089583, 'reg_lambda': 1.2753332618675346}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,779] Trial 669 finished with value: 0.8036745872848512 and parameters: {'n_estimators': 31, 'max_depth': 17, 'learning_rate': 0.028727652314419795, 'gamma': 0.847294769840329, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4222867584333543, 'reg_lambda': 1.1707600429992104}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:12,884] Trial 670 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 82, 'max_depth': 16, 'learning_rate': 0.04031419140149951, 'gamma': 0.8331024670215584, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.40956124470261, 'reg_lambda': 1.8307611917315059}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,249] Trial 671 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 545, 'max_depth': 17, 'learning_rate': 0.021795654264823563, 'gamma': 0.8412103344814699, 'min_child_weight': 1, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.5432780958502113, 'reg_lambda': 1.3211481593917804}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,357] Trial 672 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 46, 'max_depth': 18, 'learning_rate': 0.04051286746595519, 'gamma': 0.8612519850250056, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0994959175025383, 'reg_lambda': 0.7711812011006569}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,455] Trial 673 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 25, 'max_depth': 18, 'learning_rate': 0.04528981238560166, 'gamma': 0.8602459610179629, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.048350338723682, 'reg_lambda': 1.0975085869809096}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,553] Trial 674 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 58, 'max_depth': 16, 'learning_rate': 0.052317237030536014, 'gamma': 0.9260259443598832, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7013110083522653, 'reg_lambda': 0.9276390735446578}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,675] Trial 675 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 80, 'max_depth': 17, 'learning_rate': 0.09243325916912766, 'gamma': 0.8875869253870828, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4515497737231331, 'reg_lambda': 0.7018950319408412}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,769] Trial 676 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 40, 'max_depth': 17, 'learning_rate': 0.10196621005679343, 'gamma': 0.8639677152255958, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0508421982448504, 'reg_lambda': 0.7857824119618463}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,860] Trial 677 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 29, 'max_depth': 17, 'learning_rate': 1.2920242348777135e-07, 'gamma': 0.8680581533985235, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9045557224152123, 'reg_lambda': 0.7609240506905516}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:13,933] Trial 678 finished with value: 0.8098075348075349 and parameters: {'n_estimators': 11, 'max_depth': 16, 'learning_rate': 0.11696750402749244, 'gamma': 0.8491190609978004, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1156204570894475, 'reg_lambda': 1.2081494959909083}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,028] Trial 679 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 40, 'max_depth': 15, 'learning_rate': 0.11351286912527296, 'gamma': 0.8950487135575989, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6102497459806205, 'reg_lambda': 0.9197516785885391}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,202] Trial 680 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 29, 'max_depth': 18, 'learning_rate': 0.08494627600135797, 'gamma': 0.8725220077262051, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8133267190892041, 'reg_lambda': 1.4686754415263574}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,301] Trial 681 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 44, 'max_depth': 15, 'learning_rate': 0.12498345209103197, 'gamma': 0.830658868671805, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.218423261537728, 'reg_lambda': 0.5996978811806166}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,390] Trial 682 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 39, 'max_depth': 17, 'learning_rate': 5.0005456679843484e-05, 'gamma': 0.9100980493664454, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.6056738066492846, 'reg_lambda': 2.1932552953617033}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,500] Trial 683 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 59, 'max_depth': 18, 'learning_rate': 0.06782282964566824, 'gamma': 0.8596416112274042, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0351431862879548, 'reg_lambda': 0.7737098982364221}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,733] Trial 684 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 935, 'max_depth': 18, 'learning_rate': 0.09676740008153067, 'gamma': 0.8828172146560844, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7121477501554, 'reg_lambda': 0.5014777171810278}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,823] Trial 685 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 28, 'max_depth': 16, 'learning_rate': 0.066370412965488, 'gamma': 0.8497029215443528, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 0.46500216383115683, 'reg_lambda': 0.38130409181262476}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:14,920] Trial 686 finished with value: 0.8116845918083032 and parameters: {'n_estimators': 51, 'max_depth': 18, 'learning_rate': 0.12800786506130463, 'gamma': 0.8886788116241293, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.429417791285588, 'reg_lambda': 0.6695585187842858}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,040] Trial 687 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.05565119073305176, 'gamma': 0.933168518455218, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8468339381776733, 'reg_lambda': 0.9148150509617584}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,147] Trial 688 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.08706086451764315, 'gamma': 0.9723173793664222, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3332616583705836, 'reg_lambda': 1.0787394881585775}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,344] Trial 689 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 80, 'max_depth': 20, 'learning_rate': 0.05825285942207943, 'gamma': 0.9557652987481328, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5127434283527799, 'reg_lambda': 1.537986096263081}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,457] Trial 690 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 66, 'max_depth': 19, 'learning_rate': 0.09620943844072617, 'gamma': 0.920628984479881, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.796836502602641, 'reg_lambda': 0.3229962994775105}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,550] Trial 691 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 11, 'max_depth': 17, 'learning_rate': 0.12764072580539407, 'gamma': 0.9314153220981968, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6054644679202642, 'reg_lambda': 1.034470505363366}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,655] Trial 692 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 59, 'max_depth': 19, 'learning_rate': 0.06607762056968468, 'gamma': 0.40590326902199453, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8888710195304709, 'reg_lambda': 0.6044575903882335}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,759] Trial 693 finished with value: 0.833675692499222 and parameters: {'n_estimators': 73, 'max_depth': 17, 'learning_rate': 0.07727329700920758, 'gamma': 0.9079168834160014, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.4581085343210962, 'reg_lambda': 0.24161602721740458}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,882] Trial 694 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 87, 'max_depth': 20, 'learning_rate': 0.053870673864981546, 'gamma': 0.9365253112577815, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6956853323617449, 'reg_lambda': 3.143102376104313}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:15,986] Trial 695 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 43, 'max_depth': 20, 'learning_rate': 0.13066485578344672, 'gamma': 0.9142355724711936, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9965889507763335, 'reg_lambda': 0.9267816881143193}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,074] Trial 696 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 23, 'max_depth': 19, 'learning_rate': 0.09205085782250269, 'gamma': 0.9029177591803423, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.615105554648162, 'reg_lambda': 0.4487456716484066}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,183] Trial 697 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 58, 'max_depth': 18, 'learning_rate': 0.052075743474713734, 'gamma': 0.9424421254877852, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.195820187936606, 'reg_lambda': 1.4181873640449847}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,298] Trial 698 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 81, 'max_depth': 20, 'learning_rate': 0.12620311902463222, 'gamma': 0.8845075769670944, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3850770595313567, 'reg_lambda': 0.695192766704181}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,453] Trial 699 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 41, 'max_depth': 19, 'learning_rate': 0.0789928758743403, 'gamma': 0.8364343774712684, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6005364419025953, 'reg_lambda': 0.35120015433641344}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,549] Trial 700 finished with value: 0.8050772180423282 and parameters: {'n_estimators': 26, 'max_depth': 17, 'learning_rate': 0.04690312719295912, 'gamma': 0.8983148390478898, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8496155618619157, 'reg_lambda': 0.1707379270697642}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,641] Trial 701 finished with value: 0.816089234993927 and parameters: {'n_estimators': 60, 'max_depth': 18, 'learning_rate': 0.14493623789295637, 'gamma': 0.9567163896319898, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1823414807506705, 'reg_lambda': 0.8028250980524082}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,764] Trial 702 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 88, 'max_depth': 18, 'learning_rate': 0.06882564354205811, 'gamma': 0.8723517284224396, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6037152079821912, 'reg_lambda': 0.5380197723337837}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,862] Trial 703 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 47, 'max_depth': 19, 'learning_rate': 0.10269156357980266, 'gamma': 0.9209851205708564, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7391276700659263, 'reg_lambda': 0.524409280262936}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:16,959] Trial 704 finished with value: 0.727465743527625 and parameters: {'n_estimators': 10, 'max_depth': 20, 'learning_rate': 0.037517574984637474, 'gamma': 0.8830331228270265, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5374384210781691, 'reg_lambda': 1.1963139741696223}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,078] Trial 705 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 69, 'max_depth': 21, 'learning_rate': 0.05338457285748311, 'gamma': 0.8385561102819129, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.3007393715361371, 'reg_lambda': 1.6846517161686347}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,177] Trial 706 finished with value: 0.824887818514042 and parameters: {'n_estimators': 32, 'max_depth': 17, 'learning_rate': 0.16710636190735476, 'gamma': 0.8603332609884773, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9462244573752427, 'reg_lambda': 0.28724571602231525}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,280] Trial 707 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 87, 'max_depth': 18, 'learning_rate': 0.08520663554222728, 'gamma': 0.4602713209139896, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2633983539656264, 'reg_lambda': 0.9409649422000615}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,422] Trial 708 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 58, 'max_depth': 19, 'learning_rate': 0.06568658033500088, 'gamma': 0.9002696559294742, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.03615695421503226, 'reg_lambda': 0.44668578307877377}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,579] Trial 709 finished with value: 0.828254477109439 and parameters: {'n_estimators': 43, 'max_depth': 17, 'learning_rate': 0.033514493377477944, 'gamma': 0.8740264311589295, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5254818832265407, 'reg_lambda': 0.7112897537876042}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,699] Trial 710 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 67, 'max_depth': 20, 'learning_rate': 0.09968923295056512, 'gamma': 0.8269506403924674, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8729916300881339, 'reg_lambda': 0.045443374755867995}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,790] Trial 711 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 26, 'max_depth': 19, 'learning_rate': 0.059358159600175917, 'gamma': 0.8528852589059801, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.6277956992755452, 'reg_lambda': 0.6245059483336673}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,883] Trial 712 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 86, 'max_depth': 16, 'learning_rate': 0.15270151027329185, 'gamma': 0.8928108845735386, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0607054276231096, 'reg_lambda': 0.4062751010485634}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:17,979] Trial 713 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 45, 'max_depth': 20, 'learning_rate': 0.10686939989254808, 'gamma': 0.8696680415552541, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.4398966950947651, 'reg_lambda': 1.1681270478819419}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:18,060] Trial 714 finished with value: 0.7596184419713831 and parameters: {'n_estimators': 10, 'max_depth': 21, 'learning_rate': 0.04623012121052495, 'gamma': 0.9319482829725769, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.512493913761296, 'reg_lambda': 2.0440434916932366}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:18,163] Trial 715 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.07423632371992922, 'gamma': 0.9058376292770495, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7763436392235504, 'reg_lambda': 0.8434651795400288}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:18,282] Trial 716 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 82, 'max_depth': 17, 'learning_rate': 0.026915936633931655, 'gamma': 0.84866721855367, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7082726123360339, 'reg_lambda': 1.038426459561666}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:18,826] Trial 717 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 97, 'max_depth': 18, 'learning_rate': 0.04981290237149832, 'gamma': 0.8816667465098434, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4176693575024802, 'reg_lambda': 1.4302307749847338}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:18,941] Trial 718 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 72, 'max_depth': 18, 'learning_rate': 0.036688765747608536, 'gamma': 0.9203118716377321, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6279139891159465, 'reg_lambda': 0.8485785769811052}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,076] Trial 719 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 63, 'max_depth': 17, 'learning_rate': 0.0004152574107760481, 'gamma': 0.8708869635650753, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5021827828355037, 'reg_lambda': 0.5195065076482992}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,213] Trial 720 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 99, 'max_depth': 18, 'learning_rate': 0.06952075457524037, 'gamma': 0.8530473428242642, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8568476289388552, 'reg_lambda': 0.8434172431832984}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,311] Trial 721 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 54, 'max_depth': 16, 'learning_rate': 0.14599964233397972, 'gamma': 0.8292393876446003, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.8466809339829982, 'reg_lambda': 0.2100882855306389}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,419] Trial 722 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 76, 'max_depth': 18, 'learning_rate': 0.1064686739406253, 'gamma': 0.9451038006434772, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.27235993200385017, 'reg_lambda': 1.1807873285604102}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,529] Trial 723 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 31, 'max_depth': 21, 'learning_rate': 0.06219356823129894, 'gamma': 0.9009085112090346, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6725389216935561, 'reg_lambda': 4.089348322330816}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,644] Trial 724 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 94, 'max_depth': 19, 'learning_rate': 0.040719248080987085, 'gamma': 0.9779714119125815, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.11508099647664254, 'reg_lambda': 7.097076706249989}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,800] Trial 725 finished with value: 0.818480303400469 and parameters: {'n_estimators': 59, 'max_depth': 17, 'learning_rate': 0.023087145375420802, 'gamma': 0.8846859373405102, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6836900396703132, 'reg_lambda': 0.002079947337250185}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:19,914] Trial 726 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 69, 'max_depth': 20, 'learning_rate': 0.0836852584988953, 'gamma': 0.5269470449340405, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0546794325857018, 'reg_lambda': 0.3717855267189967}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,023] Trial 727 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 99, 'max_depth': 18, 'learning_rate': 0.16583805293561635, 'gamma': 0.8313775802486513, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0752872520811334, 'reg_lambda': 0.2725653241219697}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,153] Trial 728 finished with value: 0.820490132990133 and parameters: {'n_estimators': 80, 'max_depth': 19, 'learning_rate': 0.09208281671937586, 'gamma': 0.6314256830062774, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1413148654203524, 'reg_lambda': 0.19776763973594647}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,274] Trial 729 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 95, 'max_depth': 21, 'learning_rate': 0.1293292874170968, 'gamma': 0.5651781193994396, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8431297664975727, 'reg_lambda': 0.32583902936741715}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,378] Trial 730 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 71, 'max_depth': 17, 'learning_rate': 0.053210422580544404, 'gamma': 0.47925600191050566, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.6570281036906884, 'reg_lambda': 0.375991149322439}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,482] Trial 731 finished with value: 0.8424571599211106 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.08837955600270107, 'gamma': 0.8477680261296572, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0493268214284972, 'reg_lambda': 0.2465724187448773}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,591] Trial 732 finished with value: 0.8071179781643625 and parameters: {'n_estimators': 106, 'max_depth': 20, 'learning_rate': 0.16737925489302752, 'gamma': 0.43256546814357766, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4012240672710554, 'reg_lambda': 0.4719737603567155}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,692] Trial 733 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 88, 'max_depth': 20, 'learning_rate': 0.10657100143214379, 'gamma': 0.8433537545542059, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1500393878464927, 'reg_lambda': 0.25702011006865716}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,787] Trial 734 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 78, 'max_depth': 21, 'learning_rate': 0.1865100580576418, 'gamma': 0.8295347768762609, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.023709165947016, 'reg_lambda': 0.18728887009848813}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:20,937] Trial 735 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 105, 'max_depth': 15, 'learning_rate': 0.0940105588549829, 'gamma': 0.8191795137879534, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4767850222156493, 'reg_lambda': 0.2900789627942706}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,089] Trial 736 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 66, 'max_depth': 19, 'learning_rate': 0.1253615874432302, 'gamma': 0.3871298881591083, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.726108970942413, 'reg_lambda': 0.2439897450655374}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,189] Trial 737 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 87, 'max_depth': 4, 'learning_rate': 0.07958501734488078, 'gamma': 0.5227629459659078, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5582032078071003, 'reg_lambda': 0.34336046806027193}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,303] Trial 738 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 59, 'max_depth': 19, 'learning_rate': 0.07693376909547132, 'gamma': 0.8503254191446196, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9469194989614313, 'reg_lambda': 0.43445956158435084}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,409] Trial 739 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 115, 'max_depth': 20, 'learning_rate': 0.17547032534643198, 'gamma': 0.6139554845624582, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7078697384589947, 'reg_lambda': 0.4943778100353423}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,514] Trial 740 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 66, 'max_depth': 19, 'learning_rate': 0.11497755708750859, 'gamma': 0.8541044130369242, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8653379467322088, 'reg_lambda': 0.033258120045816755}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,630] Trial 741 finished with value: 0.7911738342524212 and parameters: {'n_estimators': 93, 'max_depth': 21, 'learning_rate': 0.004271446139475551, 'gamma': 0.9588158114525516, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.322703393241244, 'reg_lambda': 0.43449384999984736}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,734] Trial 742 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 69, 'max_depth': 7, 'learning_rate': 0.08360484658473702, 'gamma': 0.6845943848914089, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.852102581067609, 'reg_lambda': 0.5652625782778146}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:21,832] Trial 743 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 80, 'max_depth': 21, 'learning_rate': 0.13928944293197837, 'gamma': 0.589010464986435, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.616027068855553, 'reg_lambda': 1.8920403814071018}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,029] Trial 744 finished with value: 0.780204207675669 and parameters: {'n_estimators': 60, 'max_depth': 16, 'learning_rate': 0.1932864489431497, 'gamma': 0.35430518061161964, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.9636613114991467, 'reg_lambda': 0.38656198389073965}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,146] Trial 745 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 113, 'max_depth': 20, 'learning_rate': 1.3578549595079709e-06, 'gamma': 0.8579246695281959, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.7338356120910101, 'reg_lambda': 0.8577091272003361}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,253] Trial 746 finished with value: 0.8422205989773557 and parameters: {'n_estimators': 56, 'max_depth': 18, 'learning_rate': 0.0671993993909035, 'gamma': 0.8352079438823032, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7546615759379027, 'reg_lambda': 0.4211081309009215}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,359] Trial 747 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 96, 'max_depth': 18, 'learning_rate': 0.1148796383088539, 'gamma': 0.8188106252981785, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7156587349334497, 'reg_lambda': 0.562253237758507}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,481] Trial 748 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 79, 'max_depth': 18, 'learning_rate': 0.0380469945628794, 'gamma': 0.8258699554314666, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5299733619264126, 'reg_lambda': 0.07450384181805557}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,584] Trial 749 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 61, 'max_depth': 17, 'learning_rate': 0.08145573144407507, 'gamma': 0.9300551396428063, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5398288499298, 'reg_lambda': 1.237026686828153}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,708] Trial 750 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 119, 'max_depth': 18, 'learning_rate': 0.05525154825543621, 'gamma': 0.8336037301820088, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.5106571113456243e-05, 'reg_lambda': 0.4523765870030146}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,819] Trial 751 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 95, 'max_depth': 17, 'learning_rate': 0.09951019467987375, 'gamma': 0.6666877887636471, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7437871286557972, 'reg_lambda': 0.8270949203602691}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:22,910] Trial 752 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 58, 'max_depth': 19, 'learning_rate': 0.2178943191215265, 'gamma': 0.8385575520793705, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3768859086015102, 'reg_lambda': 0.6294682658066356}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:23,017] Trial 753 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 75, 'max_depth': 18, 'learning_rate': 0.07572555373282218, 'gamma': 0.8226772805316753, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9580557675560076, 'reg_lambda': 0.9432239230106876}. Best is trial 588 with value: 0.8424571599211106.\n",
      "[I 2024-01-12 22:27:23,177] Trial 754 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 53, 'max_depth': 19, 'learning_rate': 0.04251320129860889, 'gamma': 0.8565236103885162, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5197041385134271, 'reg_lambda': 0.35400439618998114}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:23,450] Trial 755 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 581, 'max_depth': 19, 'learning_rate': 0.01994333056736286, 'gamma': 0.8616313558425958, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.45794900809832717, 'reg_lambda': 0.2483026468843442}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:23,678] Trial 756 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 403, 'max_depth': 19, 'learning_rate': 0.02869700765562293, 'gamma': 0.8617278087483188, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.41483813565497873, 'reg_lambda': 0.31076054176070933}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:23,834] Trial 757 finished with value: 0.8098075348075349 and parameters: {'n_estimators': 101, 'max_depth': 19, 'learning_rate': 0.014592576010737083, 'gamma': 0.8461013561827744, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.48077628449341203, 'reg_lambda': 0.1291219725662631}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:23,964] Trial 758 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 79, 'max_depth': 18, 'learning_rate': 0.03804919722946965, 'gamma': 0.9149080442323554, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.7270994717455256, 'reg_lambda': 0.3822589757736311}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:24,261] Trial 759 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 335, 'max_depth': 18, 'learning_rate': 0.029047982109303143, 'gamma': 0.8643512304327481, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5905198479207892, 'reg_lambda': 0.171886823249153}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:24,367] Trial 760 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 57, 'max_depth': 17, 'learning_rate': 0.04532335909325605, 'gamma': 0.8952027784989536, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6934183918686785, 'reg_lambda': 0.48759022410595404}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:24,504] Trial 761 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 85, 'max_depth': 19, 'learning_rate': 0.04671973089359841, 'gamma': 0.8462282946396318, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.31895768885554904, 'reg_lambda': 0.3869962690737047}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:24,767] Trial 762 finished with value: 0.7884424718940626 and parameters: {'n_estimators': 865, 'max_depth': 18, 'learning_rate': 0.026946636956525622, 'gamma': 0.9357802415893942, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8419006621980866, 'reg_lambda': 0.6140652259411588}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:24,872] Trial 763 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 49, 'max_depth': 19, 'learning_rate': 0.05837509120405369, 'gamma': 0.5372562372554819, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5403409362378833, 'reg_lambda': 1.6468744930450854}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,011] Trial 764 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 115, 'max_depth': 18, 'learning_rate': 0.03657279380534847, 'gamma': 0.8739942025852189, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.860261949152967, 'reg_lambda': 0.2987362580918443}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,136] Trial 765 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 69, 'max_depth': 17, 'learning_rate': 0.06254783017238146, 'gamma': 0.9137980583042477, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3704323598058321, 'reg_lambda': 0.47436310569159795}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,336] Trial 766 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 45, 'max_depth': 16, 'learning_rate': 0.03588721815675433, 'gamma': 0.8918317906828122, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5830833282797397, 'reg_lambda': 0.724436813385391}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,480] Trial 767 finished with value: 0.8098075348075349 and parameters: {'n_estimators': 98, 'max_depth': 19, 'learning_rate': 0.019803132725640358, 'gamma': 0.8452792848250736, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1129426648981808, 'reg_lambda': 0.2112287165484652}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,599] Trial 768 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 72, 'max_depth': 17, 'learning_rate': 0.06625071731344893, 'gamma': 0.868179583634622, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.7184701998185326, 'reg_lambda': 2.343372342346796}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,715] Trial 769 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 53, 'max_depth': 18, 'learning_rate': 0.00011733612234141558, 'gamma': 0.9020812943067108, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0319782843745546, 'reg_lambda': 0.3579298326907433}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,818] Trial 770 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 28, 'max_depth': 20, 'learning_rate': 0.05099184594389004, 'gamma': 0.6461409145095994, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0025569688457869047, 'reg_lambda': 0.4934062118793212}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:25,925] Trial 771 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 87, 'max_depth': 19, 'learning_rate': 0.08579094678216681, 'gamma': 0.8547306213499432, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5522821997965603, 'reg_lambda': 1.0179810087996708}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,203] Trial 772 finished with value: 0.780204207675669 and parameters: {'n_estimators': 432, 'max_depth': 16, 'learning_rate': 0.03980448547621616, 'gamma': 0.42048808389643866, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.43356023782271497, 'reg_lambda': 0.6486288962059352}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,317] Trial 773 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.13003442364284867, 'gamma': 0.7097268490941927, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.864067820111384, 'reg_lambda': 1.3105517323877864}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,523] Trial 774 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 125, 'max_depth': 18, 'learning_rate': 0.06897360479083664, 'gamma': 0.82982778726828, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.695650663422307, 'reg_lambda': 0.9075068551908565}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,626] Trial 775 finished with value: 0.8141433939473363 and parameters: {'n_estimators': 42, 'max_depth': 20, 'learning_rate': 0.027600687665938175, 'gamma': 0.8782237662351751, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1977664470325882, 'reg_lambda': 0.2958374422718483}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,745] Trial 776 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 102, 'max_depth': 17, 'learning_rate': 0.05045790719652645, 'gamma': 0.8875629709245294, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9465040182604153, 'reg_lambda': 0.506328719448712}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:26,943] Trial 777 finished with value: 0.8020818358251869 and parameters: {'n_estimators': 680, 'max_depth': 19, 'learning_rate': 0.08965044878451058, 'gamma': 0.9392153019638668, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6205423144553193, 'reg_lambda': 0.014253457861185611}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,054] Trial 778 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 60, 'max_depth': 18, 'learning_rate': 0.14480116164686527, 'gamma': 0.5106818775758506, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.49141240305373873, 'reg_lambda': 0.8073009423733178}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,138] Trial 779 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 28, 'max_depth': 20, 'learning_rate': 0.08088926932676932, 'gamma': 0.9201167255246361, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.747826353439609, 'reg_lambda': 0.24042818420731252}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,310] Trial 780 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 281, 'max_depth': 19, 'learning_rate': 0.04917062614545133, 'gamma': 0.8415122676391893, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.2091350728962702, 'reg_lambda': 0.3911854681309744}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,428] Trial 781 finished with value: 0.820490132990133 and parameters: {'n_estimators': 82, 'max_depth': 18, 'learning_rate': 0.10882408667432365, 'gamma': 0.8604282758562966, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9523729526268526, 'reg_lambda': 1.2285230386391612}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,604] Trial 782 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 45, 'max_depth': 17, 'learning_rate': 0.034165058000521074, 'gamma': 0.811882247181154, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.9316980935933403, 'reg_lambda': 0.15101350883005288}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,729] Trial 783 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 72, 'max_depth': 16, 'learning_rate': 0.061482920049495106, 'gamma': 0.9037985330315688, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0.312287958058667, 'reg_lambda': 0.5976089426106005}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,834] Trial 784 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 108, 'max_depth': 20, 'learning_rate': 0.15840165090949912, 'gamma': 0.8736045676731408, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5953499938899034, 'reg_lambda': 0.008404542402803913}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:27,931] Trial 785 finished with value: 0.7969915828977976 and parameters: {'n_estimators': 55, 'max_depth': 19, 'learning_rate': 0.01137476456306742, 'gamma': 0.8397557824716276, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.7494462818490735, 'reg_lambda': 0.7032125281083543}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,029] Trial 786 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 28, 'max_depth': 18, 'learning_rate': 0.08697861352672076, 'gamma': 0.8869659120620614, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2809141534853383, 'reg_lambda': 0.3837610247081183}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,148] Trial 787 finished with value: 0.8232095698523442 and parameters: {'n_estimators': 88, 'max_depth': 20, 'learning_rate': 0.018155512824463375, 'gamma': 0.8185197110248958, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7939882912916822, 'reg_lambda': 1.0243943171788867}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,262] Trial 788 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 66, 'max_depth': 15, 'learning_rate': 0.039649281215188174, 'gamma': 0.9876335393231128, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0170915179272206, 'reg_lambda': 1.6960470001124208}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,367] Trial 789 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 40, 'max_depth': 17, 'learning_rate': 0.06652157874640423, 'gamma': 0.8604992601815631, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6388953480317784, 'reg_lambda': 0.5158759579133494}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,569] Trial 790 finished with value: 0.7840892754456584 and parameters: {'n_estimators': 512, 'max_depth': 19, 'learning_rate': 0.21389831081324479, 'gamma': 0.567686916786951, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.00015913939347167647, 'reg_lambda': 0.0005408561657276815}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:28,733] Trial 791 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 88, 'max_depth': 18, 'learning_rate': 0.11388252850537146, 'gamma': 0.9134987225649036, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.422286434032212, 'reg_lambda': 0.0009606739383404519}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:29,490] Trial 792 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 736, 'max_depth': 19, 'learning_rate': 0.02502026051141408, 'gamma': 0.8513908228471154, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.3617022481784953, 'reg_lambda': 0.2368990556758859}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:29,596] Trial 793 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 53, 'max_depth': 20, 'learning_rate': 0.04874227108392557, 'gamma': 0.9535202817951949, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8446733559326864, 'reg_lambda': 0.02614213401408373}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:29,682] Trial 794 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 27, 'max_depth': 18, 'learning_rate': 0.07781747190790908, 'gamma': 0.8945469918261756, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8207875955656437, 'reg_lambda': 0.7561779495020419}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:29,854] Trial 795 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 114, 'max_depth': 19, 'learning_rate': 0.12319938595590642, 'gamma': 0.8779095673126728, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 7.890646764885931e-05, 'reg_lambda': 0.4375885990441747}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:29,970] Trial 796 finished with value: 0.8061567358864657 and parameters: {'n_estimators': 71, 'max_depth': 17, 'learning_rate': 0.05713109835479123, 'gamma': 0.8641961709704025, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1.0587012669573674, 'reg_lambda': 0.32180386356826496}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,082] Trial 797 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 47, 'max_depth': 16, 'learning_rate': 0.037621793144129584, 'gamma': 0.8326118197778156, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.552432233645077, 'reg_lambda': 0.9031739740523517}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,182] Trial 798 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 87, 'max_depth': 20, 'learning_rate': 0.09670227179342186, 'gamma': 0.919955376879129, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.3512730128208836, 'reg_lambda': 0.6343088821657363}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,292] Trial 799 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 65, 'max_depth': 18, 'learning_rate': 0.1768538814488388, 'gamma': 0.4493633878957072, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.7383812010738592, 'reg_lambda': 0.004411665133460611}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,375] Trial 800 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 27, 'max_depth': 17, 'learning_rate': 2.1329403233067668e-08, 'gamma': 0.8920592629044752, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.7866735711871453, 'reg_lambda': 3.6574474319136536}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,505] Trial 801 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 124, 'max_depth': 18, 'learning_rate': 0.0684218172552205, 'gamma': 0.8776856117379224, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0222802522237877, 'reg_lambda': 0.5310623548933595}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,628] Trial 802 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 99, 'max_depth': 19, 'learning_rate': 0.030757017967302857, 'gamma': 0.845236968391577, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3663303013483688, 'reg_lambda': 1.300676802929783}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,722] Trial 803 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 47, 'max_depth': 19, 'learning_rate': 0.1337468583966062, 'gamma': 0.4955064451061692, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6727763013104165, 'reg_lambda': 0.3650107174168377}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:30,927] Trial 804 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 75, 'max_depth': 20, 'learning_rate': 4.631951573709828e-07, 'gamma': 0.9676715426518797, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.49300184737844843, 'reg_lambda': 0.17975060020196526}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,013] Trial 805 finished with value: 0.7950711199781832 and parameters: {'n_estimators': 23, 'max_depth': 18, 'learning_rate': 0.04706917855167915, 'gamma': 0.818021153224832, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1990799239472325, 'reg_lambda': 0.28388898691461417}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,115] Trial 806 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 59, 'max_depth': 17, 'learning_rate': 0.08782458553925206, 'gamma': 0.8504658188701542, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9184192249036089, 'reg_lambda': 0.94538027821992}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,240] Trial 807 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 99, 'max_depth': 19, 'learning_rate': 0.05794098518138937, 'gamma': 0.9389315849164139, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.7220758185551313, 'reg_lambda': 0.6056622752320909}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,338] Trial 808 finished with value: 0.8069275947718925 and parameters: {'n_estimators': 44, 'max_depth': 21, 'learning_rate': 0.2132557524191547, 'gamma': 0.9096553240861526, 'min_child_weight': 2, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.3581728249929272, 'reg_lambda': 1.4685763164177643}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,590] Trial 809 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 645, 'max_depth': 20, 'learning_rate': 0.10362132306062798, 'gamma': 0.8659815689173064, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.810555777568311, 'reg_lambda': 0.45010263822137214}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,720] Trial 810 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 73, 'max_depth': 19, 'learning_rate': 0.024712480977324622, 'gamma': 0.8265884770151536, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5591660145445266, 'reg_lambda': 0.7814796171245846}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:31,821] Trial 811 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 26, 'max_depth': 18, 'learning_rate': 0.07217181319966498, 'gamma': 0.9005229227506764, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0390568052084066, 'reg_lambda': 0.6000974228139175}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,021] Trial 812 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 83, 'max_depth': 18, 'learning_rate': 0.04443507401241365, 'gamma': 0.4712119615359116, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.0320261181708155, 'reg_lambda': 1.1789176628669649}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,132] Trial 813 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 61, 'max_depth': 16, 'learning_rate': 0.15113474657205572, 'gamma': 0.8743757668352183, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.018623594434005953, 'reg_lambda': 0.35885738752666374}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,236] Trial 814 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 44, 'max_depth': 20, 'learning_rate': 0.07460537510118793, 'gamma': 0.8416642102811457, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7117081771635732, 'reg_lambda': 0.9715795855666145}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,348] Trial 815 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 108, 'max_depth': 20, 'learning_rate': 0.10184137517615284, 'gamma': 0.8560791326616726, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.4650313801749164, 'reg_lambda': 1.8734187251129069}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,563] Trial 816 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 457, 'max_depth': 20, 'learning_rate': 0.13627001912888204, 'gamma': 0.8847715526721731, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.647857723622387, 'reg_lambda': 1.0569569612442018}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,653] Trial 817 finished with value: 0.779732673850321 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.19317468629992957, 'gamma': 0.9270235469468286, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.6853056820290804, 'reg_lambda': 2.1429453577354893}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,769] Trial 818 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 84, 'max_depth': 20, 'learning_rate': 0.08204780315718396, 'gamma': 0.8373765707911217, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.28916015900076636, 'reg_lambda': 0.927826709012673}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:32,891] Trial 819 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 132, 'max_depth': 19, 'learning_rate': 0.10761588545372469, 'gamma': 0.8691333679114976, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4924575198782535, 'reg_lambda': 1.470270156616852}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,015] Trial 820 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 53, 'max_depth': 20, 'learning_rate': 0.06680491766202032, 'gamma': 0.8946502118561305, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.00024366139220668046, 'reg_lambda': 0.898790636733247}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,160] Trial 821 finished with value: 0.7935636529386529 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.2476742766978851, 'gamma': 0.856088860505116, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.35547054230853165, 'reg_lambda': 0.7423667644696784}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,314] Trial 822 finished with value: 0.7930855556354227 and parameters: {'n_estimators': 95, 'max_depth': 19, 'learning_rate': 0.041765776601723155, 'gamma': 0.17751001273969969, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.848043376001376, 'reg_lambda': 0.4694118499380606}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,424] Trial 823 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 39, 'max_depth': 14, 'learning_rate': 0.14902075780425, 'gamma': 0.9090430791121459, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.6738184056227132, 'reg_lambda': 1.1620197074497998}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,545] Trial 824 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 77, 'max_depth': 17, 'learning_rate': 0.08783315738385503, 'gamma': 0.9469720973879595, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0558889430084301, 'reg_lambda': 0.6696662632996198}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,684] Trial 825 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 53, 'max_depth': 18, 'learning_rate': 0.05789986165902794, 'gamma': 0.8792658929576413, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.874544197575703, 'reg_lambda': 0.5657142432773954}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,830] Trial 826 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 107, 'max_depth': 17, 'learning_rate': 0.03457016381049184, 'gamma': 0.8404436997337622, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5379346722486184, 'reg_lambda': 0.26193300066238506}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:33,930] Trial 827 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.11516636799273618, 'gamma': 0.854219549321647, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9923036473560484, 'reg_lambda': 0.7617505328037818}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,036] Trial 828 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 40, 'max_depth': 20, 'learning_rate': 0.0710043878015727, 'gamma': 0.8938458448956944, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.764785825227902, 'reg_lambda': 1.3649298131319387}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,146] Trial 829 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 89, 'max_depth': 19, 'learning_rate': 0.04910537833870338, 'gamma': 0.8114153142883643, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.2622552149830124, 'reg_lambda': 0.445217766634301}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,360] Trial 830 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 127, 'max_depth': 21, 'learning_rate': 0.018321905102373862, 'gamma': 0.8695165397485769, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5841547667628966, 'reg_lambda': 0.3359256593152498}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,470] Trial 831 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 55, 'max_depth': 20, 'learning_rate': 0.17656386685716108, 'gamma': 0.9169506761993799, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.38224562525106776, 'reg_lambda': 0.8739903892677192}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,574] Trial 832 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 30, 'max_depth': 18, 'learning_rate': 0.08525629265282653, 'gamma': 0.18115048293869043, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1136694793237605, 'reg_lambda': 1.100120330644511}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,682] Trial 833 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 73, 'max_depth': 19, 'learning_rate': 0.03027500905024676, 'gamma': 0.8415319715854387, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7876472407116409, 'reg_lambda': 0.21044684283288084}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,783] Trial 834 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 44, 'max_depth': 17, 'learning_rate': 0.13322609730852328, 'gamma': 0.36219915875394665, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.44371063861530485, 'reg_lambda': 0.06482811047523276}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:34,903] Trial 835 finished with value: 0.7927927927927928 and parameters: {'n_estimators': 95, 'max_depth': 15, 'learning_rate': 0.05606887105912461, 'gamma': 0.547168862559139, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9539266150741079, 'reg_lambda': 0.5924506034922159}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,031] Trial 836 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.08723028709365484, 'gamma': 0.8820949644732953, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6162961984674428, 'reg_lambda': 2.3111347259772024}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,140] Trial 837 finished with value: 0.816089234993927 and parameters: {'n_estimators': 25, 'max_depth': 12, 'learning_rate': 0.24108342280606165, 'gamma': 0.8640897197954063, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.452023454976426, 'reg_lambda': 0.4707968829145625}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,232] Trial 838 finished with value: 0.7709940327616593 and parameters: {'n_estimators': 11, 'max_depth': 21, 'learning_rate': 0.045284442803777525, 'gamma': 0.8321524660931947, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7094542411469883, 'reg_lambda': 1.7281365245278557}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,420] Trial 839 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 78, 'max_depth': 20, 'learning_rate': 0.10291551475238499, 'gamma': 0.5984665531598786, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.004499067880074059, 'reg_lambda': 0.7214649278823004}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,566] Trial 840 finished with value: 0.7977136800666212 and parameters: {'n_estimators': 114, 'max_depth': 19, 'learning_rate': 0.06482744229903825, 'gamma': 0.9283208138893494, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.1317233730576128, 'reg_lambda': 0.34253438886727644}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,689] Trial 841 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 51, 'max_depth': 17, 'learning_rate': 0.0012991749396152662, 'gamma': 0.1929687576266598, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8939984090918665, 'reg_lambda': 0.9626236529258393}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,817] Trial 842 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 89, 'max_depth': 19, 'learning_rate': 0.029128376400792293, 'gamma': 0.8938398048828812, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.350896094924279, 'reg_lambda': 0.5972684353073144}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:35,924] Trial 843 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 59, 'max_depth': 18, 'learning_rate': 0.12303899765551932, 'gamma': 0.8502325298550447, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5847737399698185, 'reg_lambda': 0.4295846387210089}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,023] Trial 844 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 43, 'max_depth': 20, 'learning_rate': 0.06625731881004573, 'gamma': 0.908341270144585, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4731152622413101, 'reg_lambda': 0.2645037423435246}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,130] Trial 845 finished with value: 0.7998688987494958 and parameters: {'n_estimators': 28, 'max_depth': 20, 'learning_rate': 0.0393379258360458, 'gamma': 0.940234453790268, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.25798958110962306, 'reg_lambda': 0.18525483003890178}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,232] Trial 846 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 39, 'max_depth': 20, 'learning_rate': 0.0006383940772923075, 'gamma': 0.9115687219440787, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.08398891254461446, 'reg_lambda': 0.1530947801793108}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,338] Trial 847 finished with value: 0.8012698915924722 and parameters: {'n_estimators': 29, 'max_depth': 21, 'learning_rate': 0.020916507745569836, 'gamma': 0.906210307752415, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4417065973339127, 'reg_lambda': 0.09612927579517211}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,529] Trial 848 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 48, 'max_depth': 20, 'learning_rate': 0.0441899652339676, 'gamma': 0.9262876302544876, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.45816068883670447, 'reg_lambda': 0.3439002602020378}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,622] Trial 849 finished with value: 0.7784718975030395 and parameters: {'n_estimators': 25, 'max_depth': 20, 'learning_rate': 0.016075830853031325, 'gamma': 0.9648571137410241, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.37415052736041815, 'reg_lambda': 0.2518561052186022}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,735] Trial 850 finished with value: 0.8223949706477587 and parameters: {'n_estimators': 47, 'max_depth': 20, 'learning_rate': 0.0260236572021408, 'gamma': 0.9528666017730171, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.22667608331505043, 'reg_lambda': 0.11870816386154157}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,821] Trial 851 finished with value: 0.804179070201375 and parameters: {'n_estimators': 24, 'max_depth': 20, 'learning_rate': 0.03620283213510999, 'gamma': 0.9334918573199855, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.28809906075468283, 'reg_lambda': 0.23621638594571095}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:36,931] Trial 852 finished with value: 0.8329250675208845 and parameters: {'n_estimators': 47, 'max_depth': 19, 'learning_rate': 0.04238891765206809, 'gamma': 0.932736342815832, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3378304922064685, 'reg_lambda': 0.2967531345352439}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,038] Trial 853 finished with value: 0.8074315620902139 and parameters: {'n_estimators': 41, 'max_depth': 20, 'learning_rate': 0.024419980298507435, 'gamma': 0.9145770298671342, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4700296100731547, 'reg_lambda': 0.18980242588718987}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,156] Trial 854 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 57, 'max_depth': 21, 'learning_rate': 0.049340526356085525, 'gamma': 0.9566947940451971, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.42780730969439845, 'reg_lambda': 0.26087679483102527}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,251] Trial 855 finished with value: 0.7709940327616593 and parameters: {'n_estimators': 12, 'max_depth': 19, 'learning_rate': 0.03726363367942726, 'gamma': 0.9246246471845758, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.29522737343372785, 'reg_lambda': 0.34044136081604376}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,345] Trial 856 finished with value: 0.7896924797574592 and parameters: {'n_estimators': 11, 'max_depth': 20, 'learning_rate': 0.05836499034362075, 'gamma': 0.9071693954399123, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5096160331749047, 'reg_lambda': 0.3704677786861471}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,444] Trial 857 finished with value: 0.8188643188643188 and parameters: {'n_estimators': 43, 'max_depth': 19, 'learning_rate': 0.02970265739094764, 'gamma': 0.9487350396767543, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6165885408409788, 'reg_lambda': 0.24052655229445882}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,637] Trial 858 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 62, 'max_depth': 21, 'learning_rate': 0.061007680444066216, 'gamma': 0.9283217969213446, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4092695176254374, 'reg_lambda': 0.4201532587898891}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,755] Trial 859 finished with value: 0.7854420441568328 and parameters: {'n_estimators': 37, 'max_depth': 19, 'learning_rate': 0.012418174513341781, 'gamma': 0.8982810743871789, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.594309406324814, 'reg_lambda': 0.27297065955859734}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,882] Trial 860 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 60, 'max_depth': 20, 'learning_rate': 0.04647840549488733, 'gamma': 0.8900432076335507, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7588298847303785, 'reg_lambda': 0.1608852171875463}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:37,973] Trial 861 finished with value: 0.7950711199781832 and parameters: {'n_estimators': 34, 'max_depth': 19, 'learning_rate': 0.03161589786539098, 'gamma': 0.9806739227531067, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.35415522582528824, 'reg_lambda': 0.49081343030327823}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,097] Trial 862 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 67, 'max_depth': 20, 'learning_rate': 0.06438082420840097, 'gamma': 0.9168187046765587, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5239720428403438, 'reg_lambda': 0.2967450871674808}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,240] Trial 863 finished with value: 0.7837837837837838 and parameters: {'n_estimators': 251, 'max_depth': 18, 'learning_rate': 0.06935051042356759, 'gamma': 0.8755888042984772, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7309832089220789, 'reg_lambda': 0.3871756462288978}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,367] Trial 864 finished with value: 0.8094043185704923 and parameters: {'n_estimators': 46, 'max_depth': 21, 'learning_rate': 0.022571699178484093, 'gamma': 0.9004094788946061, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9170842855878564, 'reg_lambda': 0.5349407630564557}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,473] Trial 865 finished with value: 0.804646390820453 and parameters: {'n_estimators': 25, 'max_depth': 16, 'learning_rate': 0.0427825170290435, 'gamma': 0.8875297890467593, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.19272568833000933, 'reg_lambda': 0.558815281731452}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,590] Trial 866 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 67, 'max_depth': 19, 'learning_rate': 0.0782883502441817, 'gamma': 0.8703093821713566, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.45736491865001444, 'reg_lambda': 0.0012980342491063558}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,721] Trial 867 finished with value: 0.7927182029735046 and parameters: {'n_estimators': 11, 'max_depth': 20, 'learning_rate': 0.05128585076545136, 'gamma': 0.9340631864372508, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6520532883827179, 'reg_lambda': 0.21496572469161093}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,838] Trial 868 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 50, 'max_depth': 18, 'learning_rate': 0.03630903952330874, 'gamma': 0.9650594233284775, 'min_child_weight': 2, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.1587306647311929, 'reg_lambda': 0.7179245774934113}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:38,962] Trial 869 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 74, 'max_depth': 19, 'learning_rate': 3.827526820833674e-06, 'gamma': 0.9194084981514286, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9433097135029095, 'reg_lambda': 0.36614236947074413}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:39,080] Trial 870 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 42, 'max_depth': 18, 'learning_rate': 0.0726749266327065, 'gamma': 0.8825417910676923, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6767834603727653, 'reg_lambda': 1.1201225992216155}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:39,182] Trial 871 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 58, 'max_depth': 20, 'learning_rate': 0.04892900645718089, 'gamma': 0.9060475817665822, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.150338278643541, 'reg_lambda': 0.7721205140611304}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:39,808] Trial 872 finished with value: 0.6534142167245615 and parameters: {'n_estimators': 28, 'max_depth': 19, 'learning_rate': 0.008085892453407727, 'gamma': 0.8658346438429658, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5159224836713628, 'reg_lambda': 0.14121218001200503}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:39,946] Trial 873 finished with value: 0.818480303400469 and parameters: {'n_estimators': 74, 'max_depth': 21, 'learning_rate': 0.020799189853115276, 'gamma': 0.8572909833680578, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.3510437767475427, 'reg_lambda': 0.4395263004046509}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,053] Trial 874 finished with value: 0.833675692499222 and parameters: {'n_estimators': 39, 'max_depth': 17, 'learning_rate': 0.07989893051730142, 'gamma': 0.40206255173810634, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.85061399931372, 'reg_lambda': 0.302164674474416}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,174] Trial 875 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 57, 'max_depth': 18, 'learning_rate': 0.031844450045155404, 'gamma': 0.9472329417207382, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7030305350435391, 'reg_lambda': 1.3679463144546367}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,265] Trial 876 finished with value: 0.7693086169293156 and parameters: {'n_estimators': 10, 'max_depth': 20, 'learning_rate': 0.052628862156992355, 'gamma': 0.8910740727676527, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 1.4103530298905826, 'reg_lambda': 0.5631313058870209}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,381] Trial 877 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 79, 'max_depth': 19, 'learning_rate': 0.09873461153717891, 'gamma': 0.8323842683419279, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9944915501311499, 'reg_lambda': 0.2160179757488207}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,485] Trial 878 finished with value: 0.833675692499222 and parameters: {'n_estimators': 39, 'max_depth': 17, 'learning_rate': 0.0680818774662139, 'gamma': 0.9255410231893809, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5812433622895987, 'reg_lambda': 0.8936997383300822}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,588] Trial 879 finished with value: 0.8238939900895808 and parameters: {'n_estimators': 60, 'max_depth': 19, 'learning_rate': 0.03766580153877464, 'gamma': 0.9020119549771144, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8615090655118427, 'reg_lambda': 0.686396844977823}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,710] Trial 880 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 80, 'max_depth': 16, 'learning_rate': 0.1537085160667585, 'gamma': 0.8049200579277849, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.46574222958854544, 'reg_lambda': 0.32485262782230473}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,810] Trial 881 finished with value: 0.8036745872848512 and parameters: {'n_estimators': 27, 'max_depth': 28, 'learning_rate': 0.01618141474400564, 'gamma': 0.8750841711067094, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 1.1972406145383432, 'reg_lambda': 0.4822175955434974}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:40,951] Trial 882 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 53, 'max_depth': 27, 'learning_rate': 5.431601740551052e-08, 'gamma': 0.8442054401040942, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7356672152269915, 'reg_lambda': 0.9728383861133953}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,160] Trial 883 finished with value: 0.788723176958471 and parameters: {'n_estimators': 775, 'max_depth': 21, 'learning_rate': 0.09116300046505735, 'gamma': 0.8799634947794082, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1.4455192827497716, 'reg_lambda': 0.4238393414354793}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,272] Trial 884 finished with value: 0.8419561449521878 and parameters: {'n_estimators': 72, 'max_depth': 20, 'learning_rate': 0.055693410497606524, 'gamma': 0.8640523500318303, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0134479082473844, 'reg_lambda': 1.437571295699241}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,381] Trial 885 finished with value: 0.8105102594233028 and parameters: {'n_estimators': 78, 'max_depth': 20, 'learning_rate': 0.023899172920777666, 'gamma': 0.8525436938449236, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.995598604923898, 'reg_lambda': 2.5988004292702964}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,489] Trial 886 finished with value: 0.818480303400469 and parameters: {'n_estimators': 42, 'max_depth': 20, 'learning_rate': 0.03048839561288975, 'gamma': 0.8619100731387143, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1581393622373275, 'reg_lambda': 1.7795245592553126}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,607] Trial 887 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 66, 'max_depth': 21, 'learning_rate': 0.04383559073422276, 'gamma': 0.8914974083286039, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5810716386422272, 'reg_lambda': 5.489959210178483}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,694] Trial 888 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 29, 'max_depth': 20, 'learning_rate': 1.1138501131454646e-08, 'gamma': 0.8286164406898966, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8037533398868474, 'reg_lambda': 1.3288852337442412}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:41,817] Trial 889 finished with value: 0.8285569013829883 and parameters: {'n_estimators': 90, 'max_depth': 21, 'learning_rate': 0.053945295146390126, 'gamma': 0.8678549269121096, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5301825767596072, 'reg_lambda': 2.978581121445872}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,056] Trial 890 finished with value: 0.7342118961309366 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.03503890012258532, 'gamma': 0.852083350311689, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0625121567341247, 'reg_lambda': 1.6431898143662276}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,174] Trial 891 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 54, 'max_depth': 20, 'learning_rate': 0.057894449392428216, 'gamma': 0.8180124105617192, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6433580441071447, 'reg_lambda': 1.0212282657269085}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,282] Trial 892 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 75, 'max_depth': 19, 'learning_rate': 0.026347432080452742, 'gamma': 0.9115184187463936, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.24859508177013798, 'reg_lambda': 1.9721412191602348}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,390] Trial 893 finished with value: 0.8332046332046333 and parameters: {'n_estimators': 42, 'max_depth': 18, 'learning_rate': 0.04406912848631408, 'gamma': 0.8822210243362917, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.363161825496264, 'reg_lambda': 1.6198503781225644}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,521] Trial 894 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 61, 'max_depth': 20, 'learning_rate': 0.06955132110383969, 'gamma': 0.8355846443685206, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.37061569349845314, 'reg_lambda': 1.4086348924223113}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,795] Trial 895 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 89, 'max_depth': 19, 'learning_rate': 0.05781097700537384, 'gamma': 0.8696842410239349, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.821559396264643, 'reg_lambda': 1.1773639433098428}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,895] Trial 896 finished with value: 0.804646390820453 and parameters: {'n_estimators': 29, 'max_depth': 21, 'learning_rate': 0.03575161281322686, 'gamma': 0.897063056122799, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0217997469071296, 'reg_lambda': 0.7968273341768934}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:42,992] Trial 897 finished with value: 0.8338679303851168 and parameters: {'n_estimators': 57, 'max_depth': 18, 'learning_rate': 0.0840643359666829, 'gamma': 0.9395099101374325, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6022103961096149, 'reg_lambda': 0.6366789830848136}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,196] Trial 898 finished with value: 0.8050772180423282 and parameters: {'n_estimators': 75, 'max_depth': 19, 'learning_rate': 0.017584448391366313, 'gamma': 0.8528010816120708, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.7481606769505784, 'reg_lambda': 2.32873208448595}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,301] Trial 899 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 44, 'max_depth': 20, 'learning_rate': 0.04708417991332513, 'gamma': 0.8065520200771973, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.7684172586734592, 'reg_lambda': 1.084440591288879}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,463] Trial 900 finished with value: 0.7993717855786823 and parameters: {'n_estimators': 10, 'max_depth': 18, 'learning_rate': 0.06958906848753842, 'gamma': 0.9219690690740897, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3411081564502054, 'reg_lambda': 0.7323369206629853}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,608] Trial 901 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 94, 'max_depth': 20, 'learning_rate': 8.870397735206495e-06, 'gamma': 0.8864239379968213, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4387820294724621, 'reg_lambda': 0.0032078213445982415}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,708] Trial 902 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 29, 'max_depth': 19, 'learning_rate': 0.10937081473475628, 'gamma': 0.8409553018775298, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.990964283883433, 'reg_lambda': 0.28896329684123234}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,841] Trial 903 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.030953282961978308, 'gamma': 0.8687668088275758, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5886680780558348, 'reg_lambda': 0.5359403011811789}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:43,943] Trial 904 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 48, 'max_depth': 9, 'learning_rate': 0.04875798125711105, 'gamma': 0.9087954690031438, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8654029097050618, 'reg_lambda': 0.37102892895672807}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,089] Trial 905 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 82, 'max_depth': 17, 'learning_rate': 0.07516027425979585, 'gamma': 0.8548768122847351, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.720841752465929, 'reg_lambda': 0.8537191433779633}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,292] Trial 906 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 60, 'max_depth': 21, 'learning_rate': 0.1190029075800217, 'gamma': 0.8258121638765993, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1921001459107714, 'reg_lambda': 0.21056618292184504}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,416] Trial 907 finished with value: 0.8019307272857932 and parameters: {'n_estimators': 28, 'max_depth': 20, 'learning_rate': 0.02388725535641259, 'gamma': 0.8805570779043469, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.31411910539016275, 'reg_lambda': 1.4549313287272052}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,565] Trial 908 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 100, 'max_depth': 29, 'learning_rate': 0.060642781163103586, 'gamma': 0.9002943612627001, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.707098048256096, 'reg_lambda': 0.5571648710390558}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,671] Trial 909 finished with value: 0.8058318352269737 and parameters: {'n_estimators': 41, 'max_depth': 19, 'learning_rate': 0.042809832962985885, 'gamma': 0.3764134093604733, 'min_child_weight': 9, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5260440601729871, 'reg_lambda': 1.1105959347026648}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,786] Trial 910 finished with value: 0.8292828261332198 and parameters: {'n_estimators': 72, 'max_depth': 17, 'learning_rate': 0.09479130871419633, 'gamma': 0.8674131653566263, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1417310250041246, 'reg_lambda': 0.4105739458991333}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,880] Trial 911 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 55, 'max_depth': 18, 'learning_rate': 0.15265155244760303, 'gamma': 0.8400141332305253, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8101517240379924, 'reg_lambda': 0.7246628634304385}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:44,987] Trial 912 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 82, 'max_depth': 21, 'learning_rate': 0.08159170164771141, 'gamma': 0.9772314230941869, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.9015325729483767, 'reg_lambda': 0.271690281463011}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,088] Trial 913 finished with value: 0.8228188195813411 and parameters: {'n_estimators': 39, 'max_depth': 19, 'learning_rate': 0.03313469990229442, 'gamma': 0.9347151315055773, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0271237548943663, 'reg_lambda': 0.1517049284089139}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,236] Trial 914 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 104, 'max_depth': 20, 'learning_rate': 0.05155162709085483, 'gamma': 0.8872923550331214, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4455908628799321, 'reg_lambda': 0.019984090137961305}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,410] Trial 915 finished with value: 0.7710755653612796 and parameters: {'n_estimators': 26, 'max_depth': 16, 'learning_rate': 0.014340220718905, 'gamma': 0.9134221967217767, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3265673439658061, 'reg_lambda': 0.4999628300486625}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,541] Trial 916 finished with value: 0.8468468468468469 and parameters: {'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.07605555615306392, 'gamma': 0.8587756824760522, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6357865667246703, 'reg_lambda': 0.9903644745190329}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,673] Trial 917 finished with value: 0.8101760010156956 and parameters: {'n_estimators': 97, 'max_depth': 18, 'learning_rate': 0.11916554913908538, 'gamma': 0.8223871945343252, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 0.9536101439518467, 'reg_lambda': 1.4310208744098003}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,785] Trial 918 finished with value: 0.8071179781643625 and parameters: {'n_estimators': 77, 'max_depth': 17, 'learning_rate': 0.1568627617686095, 'gamma': 0.8473635593285127, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.6698074143525163, 'reg_lambda': 0.8072250349177048}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:45,909] Trial 919 finished with value: 0.8241886674319105 and parameters: {'n_estimators': 67, 'max_depth': 18, 'learning_rate': 0.08581256021605158, 'gamma': 0.8578246105308357, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5064452390731546, 'reg_lambda': 1.0344967503490006}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,051] Trial 920 finished with value: 0.8023274828910966 and parameters: {'n_estimators': 99, 'max_depth': 17, 'learning_rate': 0.10180075034048196, 'gamma': 0.8403800488166011, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0062108293393577756, 'reg_lambda': 1.2669101962085931}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,240] Trial 921 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 83, 'max_depth': 18, 'learning_rate': 0.045943954688608866, 'gamma': 0.34147253778052383, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.8785513426690548, 'reg_lambda': 0.8600209320328838}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,352] Trial 922 finished with value: 0.8110781160149511 and parameters: {'n_estimators': 58, 'max_depth': 16, 'learning_rate': 0.23313815378449043, 'gamma': 0.8172110683516421, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6930697515182912, 'reg_lambda': 1.8509058517597723}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,552] Trial 923 finished with value: 0.8235677855869861 and parameters: {'n_estimators': 69, 'max_depth': 17, 'learning_rate': 0.026922040466176782, 'gamma': 0.8634279524835533, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.069364039655354, 'reg_lambda': 0.8971232916044175}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,678] Trial 924 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 90, 'max_depth': 18, 'learning_rate': 0.07216931909317062, 'gamma': 0.8054366363625363, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8628837759927692, 'reg_lambda': 1.1983547353202095}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,823] Trial 925 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 109, 'max_depth': 19, 'learning_rate': 0.11494618297909442, 'gamma': 0.8365378896732334, 'min_child_weight': 1, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0.8718421384975789, 'reg_lambda': 0.6475638805214544}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:46,940] Trial 926 finished with value: 0.8375802223628311 and parameters: {'n_estimators': 53, 'max_depth': 18, 'learning_rate': 0.040080784456422464, 'gamma': 0.6936829211149285, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.27777320616805, 'reg_lambda': 2.3351487593659073}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,059] Trial 927 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 74, 'max_depth': 17, 'learning_rate': 0.07078751651009246, 'gamma': 0.6242964246526992, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5893707009178, 'reg_lambda': 1.7026596889346144}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,169] Trial 928 finished with value: 0.8067041831747713 and parameters: {'n_estimators': 53, 'max_depth': 19, 'learning_rate': 0.14423638553472548, 'gamma': 0.8589702862203273, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7573029857145662, 'reg_lambda': 0.6675208096114574}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,275] Trial 929 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 86, 'max_depth': 18, 'learning_rate': 0.05739969066765359, 'gamma': 0.8762003684684763, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.464148563327806, 'reg_lambda': 0.0002689337487771397}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,367] Trial 930 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 26, 'max_depth': 19, 'learning_rate': 0.09408872404069243, 'gamma': 0.8483642044884301, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.065988332367209, 'reg_lambda': 1.0143772764629049}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,639] Trial 931 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 113, 'max_depth': 16, 'learning_rate': 0.03604031273804545, 'gamma': 0.8312870817641695, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.5776967682943047, 'reg_lambda': 0.6387585484054155}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,752] Trial 932 finished with value: 0.8202977117191788 and parameters: {'n_estimators': 65, 'max_depth': 18, 'learning_rate': 0.19619584119539485, 'gamma': 0.8739771643743482, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0534338831004957, 'reg_lambda': 1.2373094442001524}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,832] Trial 933 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.002246503916626561, 'gamma': 0.8570225746003537, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.9634085008507873, 'reg_lambda': 0.8313534557308846}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:47,947] Trial 934 finished with value: 0.8031322241848557 and parameters: {'n_estimators': 43, 'max_depth': 17, 'learning_rate': 0.02245377126467142, 'gamma': 0.8214428989233079, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7516486973342208, 'reg_lambda': 0.006159019882023706}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,070] Trial 935 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 80, 'max_depth': 18, 'learning_rate': 0.05414705415522201, 'gamma': 0.8811814931183017, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3533694015392415, 'reg_lambda': 0.5201630042971283}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,322] Trial 936 finished with value: 0.8064473679030786 and parameters: {'n_estimators': 480, 'max_depth': 17, 'learning_rate': 0.07806133643321087, 'gamma': 0.8463541180389037, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.9010510828877146, 'reg_lambda': 1.128169501238496}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,478] Trial 937 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 313, 'max_depth': 19, 'learning_rate': 0.13217048684726468, 'gamma': 0.8748091519220184, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6177467310874858, 'reg_lambda': 1.9065250435796504}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,596] Trial 938 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 51, 'max_depth': 18, 'learning_rate': 0.04417323108750695, 'gamma': 0.8618835636699068, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0008400624902520243, 'reg_lambda': 9.743429682617547}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,779] Trial 939 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 94, 'max_depth': 11, 'learning_rate': 0.062462576826302046, 'gamma': 0.8968465810980315, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.417954624914397, 'reg_lambda': 0.6807587486026492}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,887] Trial 940 finished with value: 0.8380669565842438 and parameters: {'n_estimators': 65, 'max_depth': 27, 'learning_rate': 0.10345537850645913, 'gamma': 0.8421744728143497, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6728098401715952, 'reg_lambda': 0.4679538639447745}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:48,980] Trial 941 finished with value: 0.790252321286804 and parameters: {'n_estimators': 27, 'max_depth': 19, 'learning_rate': 0.030496181027685032, 'gamma': 0.8024160666387428, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.014284648960016235, 'reg_lambda': 1.4357810402064917}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,084] Trial 942 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 42, 'max_depth': 17, 'learning_rate': 0.16909175552674974, 'gamma': 0.8285858107038108, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.101129222589297, 'reg_lambda': 0.9393654876856458}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,195] Trial 943 finished with value: 0.8378378378378378 and parameters: {'n_estimators': 69, 'max_depth': 18, 'learning_rate': 0.056901260471214736, 'gamma': 0.886683430567668, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7585439749453985, 'reg_lambda': 0.3859562711053974}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,325] Trial 944 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 117, 'max_depth': 19, 'learning_rate': 0.08512050269806655, 'gamma': 0.8598235698174437, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5300217321943054, 'reg_lambda': 0.5873075148065363}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,484] Trial 945 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 96, 'max_depth': 20, 'learning_rate': 0.00022643529042734616, 'gamma': 0.8905020096074994, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.869540364323897, 'reg_lambda': 0.8831627839295477}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,612] Trial 946 finished with value: 0.8018018018018018 and parameters: {'n_estimators': 54, 'max_depth': 19, 'learning_rate': 0.036775161958474835, 'gamma': 0.8689717234509943, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1.1959372847779628, 'reg_lambda': 0.6402222961714835}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:49,700] Trial 947 finished with value: 0.7854420441568328 and parameters: {'n_estimators': 27, 'max_depth': 18, 'learning_rate': 0.018775075280318607, 'gamma': 0.838716267836841, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.8612134444036492, 'reg_lambda': 0.39530275259508824}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,241] Trial 948 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 77, 'max_depth': 20, 'learning_rate': 0.11524498584875292, 'gamma': 0.8573422651543389, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.009822354157257619, 'reg_lambda': 0.04321809882325657}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,365] Trial 949 finished with value: 0.7933423684770556 and parameters: {'n_estimators': 55, 'max_depth': 15, 'learning_rate': 0.2962444610298794, 'gamma': 0.8742231477393185, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.6395963425323595, 'reg_lambda': 1.4161866793792999}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,495] Trial 950 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 47, 'max_depth': 17, 'learning_rate': 2.2861981185424604e-07, 'gamma': 0.8189272029875526, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4523718106004688, 'reg_lambda': 3.301281860852715}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,621] Trial 951 finished with value: 0.8246851893910718 and parameters: {'n_estimators': 82, 'max_depth': 21, 'learning_rate': 0.06280525784691918, 'gamma': 0.8967723729322674, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9275888296763867, 'reg_lambda': 0.8194619556447699}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,733] Trial 952 finished with value: 0.8188643188643188 and parameters: {'n_estimators': 29, 'max_depth': 16, 'learning_rate': 0.04546098989516439, 'gamma': 0.6731656498117758, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.36441090388042086, 'reg_lambda': 0.4969409172303797}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:50,861] Trial 953 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 103, 'max_depth': 19, 'learning_rate': 0.07870752794540833, 'gamma': 0.8400489912798886, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5004691549124163, 'reg_lambda': 1.1745198439263234}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,034] Trial 954 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 72, 'max_depth': 18, 'learning_rate': 0.02625211060117591, 'gamma': 0.945454324181124, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7186760704306048, 'reg_lambda': 0.7650421428580161}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,137] Trial 955 finished with value: 0.8027171914182223 and parameters: {'n_estimators': 42, 'max_depth': 20, 'learning_rate': 0.19070298816799242, 'gamma': 0.9243303575680416, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1487466301820786, 'reg_lambda': 0.34942447957114975}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,243] Trial 956 finished with value: 0.8288288288288288 and parameters: {'n_estimators': 62, 'max_depth': 29, 'learning_rate': 0.117663076433374, 'gamma': 0.8843172600608438, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.7362432261591532, 'reg_lambda': 0.5553383312610102}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,344] Trial 957 finished with value: 0.7367908903213446 and parameters: {'n_estimators': 24, 'max_depth': 19, 'learning_rate': 0.010531933206645035, 'gamma': 0.8570450659490702, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 2.0445874164418503, 'reg_lambda': 0.9660134798693921}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,465] Trial 958 finished with value: 0.8198198198198198 and parameters: {'n_estimators': 83, 'max_depth': 17, 'learning_rate': 0.05066584887465903, 'gamma': 0.905209612900622, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.383049476767545, 'reg_lambda': 1.6008181436257132}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,571] Trial 959 finished with value: 0.838267940547261 and parameters: {'n_estimators': 40, 'max_depth': 18, 'learning_rate': 0.08010220795842557, 'gamma': 0.9933139717306991, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.929755285196507, 'reg_lambda': 0.6266388658635437}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,680] Trial 960 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 60, 'max_depth': 18, 'learning_rate': 0.15058439136570115, 'gamma': 0.996354246374413, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.5983151405755789, 'reg_lambda': 0.46564261952173436}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,795] Trial 961 finished with value: 0.8250604918234916 and parameters: {'n_estimators': 130, 'max_depth': 17, 'learning_rate': 0.09598329201983576, 'gamma': 0.9920901799206312, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.142745703563997, 'reg_lambda': 0.3311652640403764}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:51,889] Trial 962 finished with value: 0.753205440480134 and parameters: {'n_estimators': 11, 'max_depth': 18, 'learning_rate': 0.035904723070510854, 'gamma': 0.955311716425642, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9240488006125052, 'reg_lambda': 0.45480874572870295}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,111] Trial 963 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.051960869481528026, 'gamma': 0.953427411442068, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0013442723281680891, 'reg_lambda': 0.6257019028310218}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,204] Trial 964 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 35, 'max_depth': 17, 'learning_rate': 0.25069638820406226, 'gamma': 0.8922765637189857, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.6313524539724653, 'reg_lambda': 0.3835526853624371}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,317] Trial 965 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 64, 'max_depth': 16, 'learning_rate': 0.07238705561154155, 'gamma': 0.9301996946551878, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.0528017729224712, 'reg_lambda': 0.614667484304774}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,529] Trial 966 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 374, 'max_depth': 18, 'learning_rate': 0.12133004722590582, 'gamma': 0.8750295616942831, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.3061996233131712, 'reg_lambda': 0.0003831238821691098}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,679] Trial 967 finished with value: 0.8192152390625673 and parameters: {'n_estimators': 86, 'max_depth': 18, 'learning_rate': 0.0299385980780422, 'gamma': 0.9147903375754826, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.9278281412919095, 'reg_lambda': 0.4809131964892988}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,785] Trial 968 finished with value: 0.8290706763944796 and parameters: {'n_estimators': 39, 'max_depth': 17, 'learning_rate': 0.08951189126929232, 'gamma': 0.984623427827395, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.006072708043208, 'reg_lambda': 0.3190114171164952}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,875] Trial 969 finished with value: 0.7988362849853958 and parameters: {'n_estimators': 10, 'max_depth': 19, 'learning_rate': 0.05937838749866021, 'gamma': 0.9744131337220557, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.5735860251023085, 'reg_lambda': 0.6944803981422979}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:52,986] Trial 970 finished with value: 0.824887818514042 and parameters: {'n_estimators': 59, 'max_depth': 17, 'learning_rate': 0.15646947521379553, 'gamma': 0.9918288981605562, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.8662720260636019, 'reg_lambda': 0.001953006032592495}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,208] Trial 971 finished with value: 0.8148629126582771 and parameters: {'n_estimators': 116, 'max_depth': 28, 'learning_rate': 0.035435654603854186, 'gamma': 0.999953648040305, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.4310537555039733, 'reg_lambda': 0.5283306754048139}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,336] Trial 972 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 76, 'max_depth': 18, 'learning_rate': 9.822106573250089e-08, 'gamma': 0.9752501287045638, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 0.48531852654907504, 'reg_lambda': 0.7422278725470134}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,440] Trial 973 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 28, 'max_depth': 16, 'learning_rate': 0.04545217615263716, 'gamma': 0.9447597572513794, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.1338554135806795, 'reg_lambda': 0.3444965859795915}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,534] Trial 974 finished with value: 0.8334547119166025 and parameters: {'n_estimators': 49, 'max_depth': 18, 'learning_rate': 0.09841327112896814, 'gamma': 0.9608697213921855, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 2.0164838632002144, 'reg_lambda': 0.4506279723331802}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,661] Trial 975 finished with value: 0.8151727016591882 and parameters: {'n_estimators': 96, 'max_depth': 19, 'learning_rate': 0.020138989835792535, 'gamma': 0.8969907895165247, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.688158427531928, 'reg_lambda': 0.20794189434180071}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,791] Trial 976 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 72, 'max_depth': 19, 'learning_rate': 0.06828943922676049, 'gamma': 0.514076049637746, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 1.0174054364605878, 'reg_lambda': 0.771517099395349}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:53,907] Trial 977 finished with value: 0.8384411196911198 and parameters: {'n_estimators': 41, 'max_depth': 18, 'learning_rate': 0.10748315148408645, 'gamma': 0.9708045789996124, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.7971815855287708, 'reg_lambda': 0.5423654923281398}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,013] Trial 978 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 26, 'max_depth': 17, 'learning_rate': 0.005490935301422243, 'gamma': 0.9744232310757538, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.36844851342822466, 'reg_lambda': 0.9792925828115485}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,104] Trial 979 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 10, 'max_depth': 18, 'learning_rate': 1.76400856606759e-05, 'gamma': 0.9799677652114785, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.5944514124681566, 'reg_lambda': 0.6191077213827749}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,300] Trial 980 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 31, 'max_depth': 17, 'learning_rate': 0.21410510071290662, 'gamma': 0.989876614757454, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.4788159261332426, 'reg_lambda': 0.8056046518637153}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,392] Trial 981 finished with value: 0.8113125973051377 and parameters: {'n_estimators': 43, 'max_depth': 18, 'learning_rate': 0.32979447914353555, 'gamma': 0.9765887198845957, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.7531780312561465, 'reg_lambda': 0.5718365326664206}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,490] Trial 982 finished with value: 0.8296193925884646 and parameters: {'n_estimators': 43, 'max_depth': 16, 'learning_rate': 0.15267640013372494, 'gamma': 0.9724580631137253, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.2887078831479619, 'reg_lambda': 0.000713884685547625}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,668] Trial 983 finished with value: 0.8250604918234916 and parameters: {'n_estimators': 25, 'max_depth': 17, 'learning_rate': 0.12273664589297661, 'gamma': 0.9647294932363398, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.6015834864190742, 'reg_lambda': 1.182494492323043}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,783] Trial 984 finished with value: 0.8115146396396395 and parameters: {'n_estimators': 50, 'max_depth': 18, 'learning_rate': 0.20091675229358857, 'gamma': 0.9589301745785501, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.8160894981821015, 'reg_lambda': 0.7922407474396027}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:54,898] Trial 985 finished with value: 0.824887818514042 and parameters: {'n_estimators': 51, 'max_depth': 18, 'learning_rate': 0.09667754821223112, 'gamma': 0.9835991859371809, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.44592588588950777, 'reg_lambda': 0.5572967456156429}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,002] Trial 986 finished with value: 0.7625811839976843 and parameters: {'n_estimators': 10, 'max_depth': 17, 'learning_rate': 0.048099189497321365, 'gamma': 0.9587334499426619, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.80448530549371, 'reg_lambda': 1.0588970036755216}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,101] Trial 987 finished with value: 0.8200743962047155 and parameters: {'n_estimators': 35, 'max_depth': 14, 'learning_rate': 0.06959912709977802, 'gamma': 0.9851449069671906, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.5905871262684066, 'reg_lambda': 2.4075779991201918}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,223] Trial 988 finished with value: 0.8154498159075866 and parameters: {'n_estimators': 63, 'max_depth': 18, 'learning_rate': 0.13636915678632205, 'gamma': 0.9968040093127922, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 1.3344628053967528e-05, 'reg_lambda': 0.4455615014313456}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,429] Trial 989 finished with value: 0.814519979719652 and parameters: {'n_estimators': 57, 'max_depth': 16, 'learning_rate': 0.028144938152240003, 'gamma': 0.9486264342107987, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.2549038861176263, 'reg_lambda': 0.7018608973743751}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,543] Trial 990 finished with value: 0.8014869384434602 and parameters: {'n_estimators': 29, 'max_depth': 19, 'learning_rate': 0.05846578871906092, 'gamma': 0.9695596344834736, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.4041099405379316, 'reg_lambda': 0.01129369194582528}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,673] Trial 991 finished with value: 0.7974449198985706 and parameters: {'n_estimators': 83, 'max_depth': 17, 'learning_rate': 0.1019485513067596, 'gamma': 0.9970955306546593, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.8329618096870024, 'reg_lambda': 1.4466314124526833}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,790] Trial 992 finished with value: 0.8195335804031456 and parameters: {'n_estimators': 43, 'max_depth': 18, 'learning_rate': 0.03735195519996806, 'gamma': 0.9405861585208682, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.572102097891045, 'reg_lambda': 1.008746416256005}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:55,892] Trial 993 finished with value: 0.8025391462891464 and parameters: {'n_estimators': 68, 'max_depth': 19, 'learning_rate': 0.16876529039185284, 'gamma': 0.9996092909729279, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.6155852524851236, 'reg_lambda': 0.574854014212896}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,046] Trial 994 finished with value: 0.8159077066429673 and parameters: {'n_estimators': 94, 'max_depth': 17, 'learning_rate': 0.0750181005353353, 'gamma': 0.93190114767544, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.0581999557959128, 'reg_lambda': 0.8157809985553893}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,147] Trial 995 finished with value: 0.7676754768953352 and parameters: {'n_estimators': 10, 'max_depth': 18, 'learning_rate': 0.047079837132069355, 'gamma': 0.9468218905075716, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.039601891378828566, 'reg_lambda': 1.7887297672978262}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,259] Trial 996 finished with value: 0.8156946862829217 and parameters: {'n_estimators': 55, 'max_depth': 15, 'learning_rate': 0.12372242030988852, 'gamma': 0.922041426348905, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 2.0506992188047115, 'reg_lambda': 0.4879848405674758}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,371] Trial 997 finished with value: 0.789688397434177 and parameters: {'n_estimators': 37, 'max_depth': 19, 'learning_rate': 0.014248047454294553, 'gamma': 0.9778042785535133, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.8965825283248627, 'reg_lambda': 0.2940926189962935}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,571] Trial 998 finished with value: 0.42711942711942713 and parameters: {'n_estimators': 78, 'max_depth': 18, 'learning_rate': 1.0376921765825552e-06, 'gamma': 0.959841826192971, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.6587166501330391, 'reg_lambda': 1.2102788891521055}. Best is trial 754 with value: 0.8468468468468469.\n",
      "[I 2024-01-12 22:27:56,706] Trial 999 finished with value: 0.8244522639120946 and parameters: {'n_estimators': 61, 'max_depth': 19, 'learning_rate': 0.06014288313658233, 'gamma': 0.9172517476364829, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 1.4563564395047082, 'reg_lambda': 0.6719747001197084}. Best is trial 754 with value: 0.8468468468468469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.819820\n",
      "Model F1 Score: 0.819150\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0,log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10,log=True)\n",
    "    }\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = f1_score(y_val, preds,average=\"weighted\")\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Fit the model with best hyperparameters\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions \n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# Check the accuracy and F1 score of the model\n",
    "print(\"Model Accuracy: %f\" % accuracy_score(y_test, preds))\n",
    "print(\"Model F1 Score: %f\" % f1_score(y_test, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open(\"XGB\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr=pickle.load(open('LR', 'rb'))\n",
    "gb=pickle.load(open(\"GB\", 'rb'))\n",
    "rf=pickle.load(open(\"RF\", 'rb'))\n",
    "lgbm=pickle.load(open(\"LGBM\", 'rb'))\n",
    "et=pickle.load(open(\"ET\", 'rb'))\n",
    "xgb=pickle.load(open(\"XGB\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f9c7523f4f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb=CatBoostClassifier()\n",
    "cb.load_model(\"CB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8234451318788668\n",
      "\n",
      "\n",
      "0.860480630621168\n",
      "\n",
      "\n",
      "0.7646839416736325\n",
      "\n",
      "\n",
      "0.7963257375022079\n",
      "\n",
      "\n",
      "0.8149359443477092\n",
      "\n",
      "\n",
      "0.8558558558558559\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8198198198198198\n",
      "\n",
      "\n",
      "0.8029615436331855\n",
      "\n",
      "\n",
      "0.8380954533128446\n",
      "\n",
      "\n",
      "0.8158175673301635\n",
      "\n",
      "\n",
      "0.8422275247635742\n",
      "\n",
      "\n",
      "0.8344981412639405\n",
      "\n",
      "\n",
      "0.8468468468468469\n",
      "\n",
      "\n",
      "0.8204895780294953\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1=cb.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=cb.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=lr.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=lr.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=gb.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=gb.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=rf.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=rf.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=lgbm.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=lgbm.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=et.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=et.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "p1=xgb.predict(X_val)\n",
    "print(f1_score(p1,y_val,average=\"weighted\"))\n",
    "print(\"\\n\")\n",
    "p2=xgb.predict(X_test)\n",
    "print(f1_score(p2,y_test,average=\"weighted\"))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Weights: [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51        91\n",
      "           1       0.66      0.66      0.66       131\n",
      "\n",
      "    accuracy                           0.60       222\n",
      "   macro avg       0.59      0.58      0.58       222\n",
      "weighted avg       0.60      0.60      0.60       222\n",
      "\n",
      "Precision: 0.659091\n",
      "Recall: 0.664122\n",
      "F1 Score: 0.661597\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "preds_cb = cb.predict(X_val)\n",
    "preds_lr = lr.predict(X_val)\n",
    "preds_gb = gb.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_lgbm = lgbm.predict(X_val)\n",
    "preds_et = et.predict(X_val)\n",
    "preds_xgb = xgb.predict(X_val)\n",
    "\n",
    "# Stack predictions\n",
    "preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n",
    "\n",
    "def loss_func(weights):\n",
    "    \n",
    "    final_prediction = np.average(preds, axis=0, weights=weights)\n",
    "    final_prediction = [1 if prob > 0.5 else 0 for prob in final_prediction]\n",
    "    return 1 - f1_score(y_val, final_prediction, average='weighted')\n",
    "\n",
    "# The algorithm needs a starting value, let's start with equal weights\n",
    "starting_values = [1/7,1/7,1/7,1/7,1/7,1/7,1/7]\n",
    "\n",
    "# Our weights are bound between 0 and 1\n",
    "bounds = [(0, 1)]*7\n",
    "\n",
    "# We want our weights to sum to 1\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "\n",
    "# We use 'SLSQP' as our solver, SLSQP stands for Sequential Least Squares Programming\n",
    "res = minimize(loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensemble Weights: {weights}'.format(weights=res['x']))\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get the predictions from each model on the test set\n",
    "preds_cb = cb.predict(X_test)\n",
    "preds_lr = lr.predict(X_test)\n",
    "preds_gb = gb.predict(X_test)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_lgbm = lgbm.predict(X_val)\n",
    "preds_et = et.predict(X_val)\n",
    "preds_xgb = xgb.predict(X_val)\n",
    "\n",
    "# Stack the predictions together\n",
    "preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n",
    "\n",
    "# Calculate the weighted average of predictions\n",
    "final_preds = np.average(preds, axis=0, weights=res['x'])\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, final_preds))\n",
    "\n",
    "# Print Precision, Recall and F1 Score\n",
    "print(\"Precision: %f\" % precision_score(y_test, final_preds))\n",
    "print(\"Recall: %f\" % recall_score(y_test, final_preds))\n",
    "print(\"F1 Score: %f\" % f1_score(y_test, final_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        93\n",
      "           1       0.86      0.84      0.85       129\n",
      "\n",
      "    accuracy                           0.83       222\n",
      "   macro avg       0.82      0.83      0.82       222\n",
      "weighted avg       0.83      0.83      0.83       222\n",
      "\n",
      "Precision: 0.858268\n",
      "Recall: 0.844961\n",
      "F1 Score: 0.851562\n"
     ]
    }
   ],
   "source": [
    "preds_cb = cb.predict(X_val)\n",
    "preds_lr = lr.predict(X_val)\n",
    "preds_gb = gb.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_lgbm = lgbm.predict(X_val)\n",
    "preds_et = et.predict(X_val)\n",
    "preds_xgb = xgb.predict(X_val)\n",
    "# Stack the predictions together\n",
    "preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n",
    "\n",
    "# Calculate the weighted average of predictions\n",
    "final_preds = np.average(preds, axis=0, weights=res['x'])\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_val, final_preds))\n",
    "\n",
    "# Print Precision, Recall and F1 Score\n",
    "print(\"Precision: %f\" % precision_score(y_val, final_preds))\n",
    "print(\"Recall: %f\" % recall_score(y_val, final_preds))\n",
    "print(\"F1 Score: %f\" % f1_score(y_val, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ensemble Weights: [0.19354089 0.02799009 0.212809   0.02781544 0.00409978 0.2239887\n",
      " 0.3097561 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.44      0.43        91\n",
      "           1       0.60      0.58      0.59       131\n",
      "\n",
      "    accuracy                           0.52       222\n",
      "   macro avg       0.51      0.51      0.51       222\n",
      "weighted avg       0.53      0.52      0.52       222\n",
      "\n",
      "Precision: 0.598425\n",
      "Recall: 0.580153\n",
      "F1 Score: 0.589147\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "preds_cb = cb.predict(X_val)\n",
    "preds_lr = lr.predict(X_val)\n",
    "preds_gb = gb.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_lgbm = lgbm.predict(X_val)\n",
    "preds_et = et.predict(X_val)\n",
    "preds_xgb = xgb.predict(X_val)\n",
    "# Stack predictions\n",
    "preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n",
    "\n",
    "def loss_func(weights):\n",
    "    \n",
    "    final_prediction = np.average(preds, axis=0, weights=weights)\n",
    "    # Convert probabilities to class labels\n",
    "    final_prediction = [1 if prob > 0.5 else 0 for prob in final_prediction]\n",
    "    return 1 - f1_score(y_val, final_prediction, average='weighted')\n",
    "\n",
    "# Our weights are bound between 0 and 1\n",
    "bounds = [(0, 1)]*7\n",
    "\n",
    "# We want our weights to sum to 1\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "\n",
    "# Number of random starting points\n",
    "num_starts = 10\n",
    "\n",
    "best_score = np.inf\n",
    "best_weights = None\n",
    "\n",
    "# Perform optimization with several randomly chosen starting points\n",
    "for _ in range(num_starts):\n",
    "    # Randomly choose starting weights\n",
    "    values = np.random.rand(7)\n",
    "    starting_values = values / np.sum(values)\n",
    "\n",
    "    res = minimize(loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "    if res.fun < best_score:\n",
    "        best_score = res.fun\n",
    "        best_weights = res.x\n",
    "\n",
    "# Calculate the weighted average of predictions\n",
    "final_preds = np.average(preds, axis=0, weights=best_weights)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n",
    "\n",
    "print('Best Ensemble Weights: {weights}'.format(weights=best_weights))\n",
    "\n",
    "print(classification_report(y_test, final_preds))\n",
    "\n",
    "# Print Precision, Recall and F1 Score\n",
    "print(\"Precision: %f\" % precision_score(y_test, final_preds))\n",
    "print(\"Recall: %f\" % recall_score(y_test, final_preds))\n",
    "print(\"F1 Score: %f\" % f1_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        93\n",
      "           1       0.88      0.87      0.88       129\n",
      "\n",
      "    accuracy                           0.86       222\n",
      "   macro avg       0.85      0.85      0.85       222\n",
      "weighted avg       0.86      0.86      0.86       222\n",
      "\n",
      "Precision: 0.881890\n",
      "Recall: 0.868217\n",
      "F1 Score: 0.875000\n"
     ]
    }
   ],
   "source": [
    "preds_cb = cb.predict(X_val)\n",
    "preds_lr = lr.predict(X_val)\n",
    "preds_gb = gb.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_lgbm = lgbm.predict(X_val)\n",
    "preds_et = et.predict(X_val)\n",
    "preds_xgb = xgb.predict(X_val)\n",
    "# Stack the predictions together\n",
    "preds = np.vstack([preds_cb, preds_lr, preds_gb, preds_rf, preds_lgbm,preds_et,preds_xgb])\n",
    "\n",
    "# Calculate the weighted average of predictions\n",
    "final_preds = np.average(preds, axis=0, weights=best_weights)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "final_preds = [1 if prob > 0.5 else 0 for prob in final_preds]\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_val, final_preds))\n",
    "\n",
    "# Print Precision, Recall and F1 Score\n",
    "print(\"Precision: %f\" % precision_score(y_val, final_preds))\n",
    "print(\"Recall: %f\" % recall_score(y_val, final_preds))\n",
    "print(\"F1 Score: %f\" % f1_score(y_val, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement Measure between cb and lr: 0.14864864864864866\n",
      "Correlation of Errors between cb and lr: 0.5552065852268625\n",
      "Disagreement Measure between cb and gb: 0.05405405405405406\n",
      "Correlation of Errors between cb and gb: 0.8174381543181655\n",
      "Disagreement Measure between cb and rf: 0.07657657657657657\n",
      "Correlation of Errors between cb and rf: 0.7383313890293738\n",
      "Disagreement Measure between cb and lgbm: 0.06756756756756757\n",
      "Correlation of Errors between cb and lgbm: 0.7603083947786671\n",
      "Disagreement Measure between cb and et: 0.06306306306306306\n",
      "Correlation of Errors between cb and et: 0.7747352037273628\n",
      "Disagreement Measure between cb and xgb: 0.05855855855855856\n",
      "Correlation of Errors between cb and xgb: 0.7897266244040544\n",
      "Disagreement Measure between lr and gb: 0.11261261261261261\n",
      "Correlation of Errors between lr and gb: 0.6686845784267827\n",
      "Disagreement Measure between lr and rf: 0.16216216216216217\n",
      "Correlation of Errors between lr and rf: 0.5155712693484107\n",
      "Disagreement Measure between lr and lgbm: 0.15315315315315314\n",
      "Correlation of Errors between lr and lgbm: 0.5357647452099613\n",
      "Disagreement Measure between lr and et: 0.16666666666666666\n",
      "Correlation of Errors between lr and et: 0.4903744949642425\n",
      "Disagreement Measure between lr and xgb: 0.15315315315315314\n",
      "Correlation of Errors between lr and xgb: 0.5326593479942578\n",
      "Disagreement Measure between gb and rf: 0.07657657657657657\n",
      "Correlation of Errors between gb and rf: 0.7433849855451019\n",
      "Disagreement Measure between gb and lgbm: 0.04954954954954955\n",
      "Correlation of Errors between gb and lgbm: 0.8298831138096903\n",
      "Disagreement Measure between gb and et: 0.07207207207207207\n",
      "Correlation of Errors between gb and et: 0.7497219973821706\n",
      "Disagreement Measure between gb and xgb: 0.06756756756756757\n",
      "Correlation of Errors between gb and xgb: 0.7645946516936646\n",
      "Disagreement Measure between rf and lgbm: 0.06306306306306306\n",
      "Correlation of Errors between rf and lgbm: 0.7794443715234973\n",
      "Disagreement Measure between rf and et: 0.07657657657657657\n",
      "Correlation of Errors between rf and et: 0.7298567821996715\n",
      "Disagreement Measure between rf and xgb: 0.07207207207207207\n",
      "Correlation of Errors between rf and xgb: 0.744403872498153\n",
      "Disagreement Measure between lgbm and et: 0.06756756756756757\n",
      "Correlation of Errors between lgbm and et: 0.7486326254506521\n",
      "Disagreement Measure between lgbm and xgb: 0.036036036036036036\n",
      "Correlation of Errors between lgbm and xgb: 0.8648421295081764\n",
      "Disagreement Measure between et and xgb: 0.05855855855855856\n",
      "Correlation of Errors between et and xgb: 0.7770505562351231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "models = [cb, lr, gb,rf,lgbm,et,xgb]\n",
    "model_names = ['cb', 'lr', 'gb', 'rf', 'lgbm','et','xgb']\n",
    "\n",
    "# Get the predictions from each model on the validation set\n",
    "preds = [model.predict(X_val) for model in models]\n",
    "\n",
    "# Calculate Disagreement Measure and Correlation of Errors\n",
    "for i in range(len(models)):\n",
    "    for j in range(i+1, len(models)):\n",
    "        # Disagreement Measure\n",
    "        disagree = np.mean(preds[i] != preds[j])\n",
    "        print(f'Disagreement Measure between {model_names[i]} and {model_names[j]}: {disagree}')\n",
    "        \n",
    "        # Correlation of Errors\n",
    "        errors_i = preds[i] != y_val\n",
    "        errors_j = preds[j] != y_val\n",
    "        correlation = np.corrcoef(errors_i, errors_j)[0, 1]\n",
    "        print(f'Correlation of Errors between {model_names[i]} and {model_names[j]}: {correlation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for Reading :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
